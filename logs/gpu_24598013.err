Loaded module: cuda/12.4
[2025-04-08 13:50:52,297 INFO train.py line 134 3298914] => Loading config ...
[2025-04-08 13:50:52,298 INFO train.py line 136 3298914] Save path: /work3/s204157/data/ego3d/exp/sonata/debug
[2025-04-08 13:50:53,093 INFO train.py line 137 3298914] Config:
weight = '/work3/s204157/data/ego3d/exp/scannet/debug/model/sonata.pth'
resume = False
evaluate = True
test_only = False
seed = 54609880
save_path = '/work3/s204157/data/ego3d/exp/sonata/debug'
num_worker = 8
batch_size = 4
batch_size_val = None
batch_size_test = None
epoch = 800
eval_epoch = 100
clip_grad = 3.0
sync_bn = False
enable_amp = True
amp_dtype = 'float16'
empty_cache = False
empty_cache_per_epoch = False
find_unused_parameters = False
mix_prob = 0.8
param_dicts = [dict(keyword='block', lr=0.0002)]
hooks = [
    dict(
        type='CheckpointLoader',
        keywords='module.student.backbone',
        replacement='module.backbone'),
    dict(type='IterationTimer', warmup_iter=2),
    dict(type='InformationWriter'),
    dict(type='SemSegEvaluator'),
    dict(type='CheckpointSaver', save_freq=None),
    dict(type='PreciseEvaluator', test_last=False)
]
train = dict(type='DefaultTrainer')
test = dict(type='SemSegTester', verbose=True)
model = dict(
    type='DefaultSegmentorV2',
    num_classes=20,
    backbone_out_channels=64,
    backbone=dict(
        type='PT-v3m2',
        in_channels=9,
        order=('z', 'z-trans', 'hilbert', 'hilbert-trans'),
        stride=(2, 2, 2, 2),
        enc_depths=(3, 3, 3, 12, 3),
        enc_channels=(48, 96, 192, 384, 512),
        enc_num_head=(3, 6, 12, 24, 32),
        enc_patch_size=(1024, 1024, 1024, 1024, 1024),
        dec_depths=(2, 2, 2, 2),
        dec_channels=(64, 96, 192, 384),
        dec_num_head=(4, 6, 12, 24),
        dec_patch_size=(1024, 1024, 1024, 1024),
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.3,
        shuffle_orders=True,
        pre_norm=True,
        enable_rpe=False,
        enable_flash=True,
        upcast_attention=False,
        upcast_softmax=False,
        traceable=False,
        mask_token=False,
        enc_mode=False,
        freeze_encoder=False),
    criteria=[
        dict(type='CrossEntropyLoss', loss_weight=1.0, ignore_index=-1),
        dict(
            type='LovaszLoss',
            mode='multiclass',
            loss_weight=1.0,
            ignore_index=-1)
    ],
    freeze_backbone=False)
optimizer = dict(type='AdamW', lr=0.002, weight_decay=0.02)
scheduler = dict(
    type='OneCycleLR',
    max_lr=[0.002, 0.0002],
    pct_start=0.05,
    anneal_strategy='cos',
    div_factor=10.0,
    final_div_factor=1000.0)
dataset_type = 'ScanNetDataset'
data_root = '/work3/s204157/data/ego3d/preprocessed_data'
data = dict(
    num_classes=20,
    ignore_index=-1,
    names=[
        'wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door',
        'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain',
        'refridgerator', 'shower curtain', 'toilet', 'sink', 'bathtub',
        'otherfurniture'
    ],
    train=dict(
        type='ScanNetDataset',
        split='train',
        data_root='/work3/s204157/data/ego3d/preprocessed_data',
        transform=[
            dict(type='CenterShift', apply_z=True),
            dict(
                type='RandomDropout',
                dropout_ratio=0.2,
                dropout_application_ratio=1.0),
            dict(
                type='RandomRotate',
                angle=[-1, 1],
                axis='z',
                center=[0, 0, 0],
                p=0.5),
            dict(
                type='RandomRotate',
                angle=[-0.015625, 0.015625],
                axis='x',
                p=0.5),
            dict(
                type='RandomRotate',
                angle=[-0.015625, 0.015625],
                axis='y',
                p=0.5),
            dict(type='RandomScale', scale=[0.9, 1.1]),
            dict(type='RandomFlip', p=0.5),
            dict(type='RandomJitter', sigma=0.005, clip=0.02),
            dict(
                type='ElasticDistortion',
                distortion_params=[[0.2, 0.4], [0.8, 1.6]]),
            dict(type='ChromaticAutoContrast', p=0.2, blend_factor=None),
            dict(type='ChromaticTranslation', p=0.95, ratio=0.05),
            dict(type='ChromaticJitter', p=0.95, std=0.05),
            dict(
                type='GridSample',
                grid_size=0.02,
                hash_type='fnv',
                mode='train',
                return_grid_coord=True),
            dict(type='SphereCrop', point_max=102400, mode='random'),
            dict(type='CenterShift', apply_z=False),
            dict(type='NormalizeColor'),
            dict(type='ToTensor'),
            dict(
                type='Collect',
                keys=('coord', 'grid_coord', 'segment'),
                feat_keys=('coord', 'color', 'normal'))
        ],
        test_mode=False,
        loop=8),
    val=dict(
        type='ScanNetDataset',
        split='val',
        data_root='/work3/s204157/data/ego3d/preprocessed_data',
        transform=[
            dict(type='CenterShift', apply_z=True),
            dict(
                type='GridSample',
                grid_size=0.02,
                hash_type='fnv',
                mode='train',
                return_grid_coord=True),
            dict(type='CenterShift', apply_z=False),
            dict(type='NormalizeColor'),
            dict(type='ToTensor'),
            dict(
                type='Collect',
                keys=('coord', 'grid_coord', 'segment'),
                feat_keys=('coord', 'color', 'normal'))
        ],
        test_mode=False),
    test=dict(
        type='ScanNetDataset',
        split='val',
        data_root='/work3/s204157/data/ego3d/preprocessed_data',
        transform=[
            dict(type='CenterShift', apply_z=True),
            dict(type='NormalizeColor')
        ],
        test_mode=True,
        test_cfg=dict(
            voxelize=dict(
                type='GridSample',
                grid_size=0.02,
                hash_type='fnv',
                mode='test',
                return_grid_coord=True),
            crop=None,
            post_transform=[
                dict(type='CenterShift', apply_z=False),
                dict(type='ToTensor'),
                dict(
                    type='Collect',
                    keys=('coord', 'grid_coord', 'index'),
                    feat_keys=('coord', 'color', 'normal'))
            ],
            aug_transform=[[{
                'type': 'RandomRotateTargetAngle',
                'angle': [0],
                'axis': 'z',
                'center': [0, 0, 0],
                'p': 1
            }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [0.5],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [1],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [1.5],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [0],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [0.95, 0.95]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [0.5],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [0.95, 0.95]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [1],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [0.95, 0.95]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [1.5],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [0.95, 0.95]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [0],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [1.05, 1.05]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [0.5],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [1.05, 1.05]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [1],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [1.05, 1.05]
                           }],
                           [{
                               'type': 'RandomRotateTargetAngle',
                               'angle': [1.5],
                               'axis': 'z',
                               'center': [0, 0, 0],
                               'p': 1
                           }, {
                               'type': 'RandomScale',
                               'scale': [1.05, 1.05]
                           }], [{
                               'type': 'RandomFlip',
                               'p': 1
                           }]])))
num_worker_per_gpu = 8
batch_size_per_gpu = 4
batch_size_val_per_gpu = 1
batch_size_test_per_gpu = 1

[2025-04-08 13:50:53,093 INFO train.py line 138 3298914] => Building model ...
[2025-04-08 13:50:54,825 INFO train.py line 239 3298914] Num params: 124794148
[2025-04-08 13:50:55,215 INFO train.py line 140 3298914] => Building writer ...
[2025-04-08 13:50:55,222 INFO train.py line 249 3298914] Tensorboard writer logging dir: /work3/s204157/data/ego3d/exp/sonata/debug
[2025-04-08 13:50:55,222 INFO train.py line 142 3298914] => Building train dataset & dataloader ...
[2025-04-08 13:50:55,257 INFO defaults.py line 70 3298914] Totally 1201 x 8 samples in preprocessed_data train set.
/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-04-08 13:50:55,261 INFO train.py line 144 3298914] => Building val dataset & dataloader ...
[2025-04-08 13:50:55,268 INFO defaults.py line 70 3298914] Totally 312 x 1 samples in preprocessed_data val set.
[2025-04-08 13:50:55,269 INFO train.py line 146 3298914] => Building optimize, scheduler, scaler(amp) ...
[2025-04-08 13:50:55,272 INFO optimizer.py line 54 3298914] Params Group 1 - lr: 0.002; Params: ['seg_head.weight', 'seg_head.bias', 'backbone.embedding.stem.linear.weight', 'backbone.embedding.stem.linear.bias', 'backbone.embedding.stem.norm.weight', 'backbone.embedding.stem.norm.bias', 'backbone.enc.enc1.down.proj.weight', 'backbone.enc.enc1.down.proj.bias', 'backbone.enc.enc1.down.norm.0.weight', 'backbone.enc.enc1.down.norm.0.bias', 'backbone.enc.enc2.down.proj.weight', 'backbone.enc.enc2.down.proj.bias', 'backbone.enc.enc2.down.norm.0.weight', 'backbone.enc.enc2.down.norm.0.bias', 'backbone.enc.enc3.down.proj.weight', 'backbone.enc.enc3.down.proj.bias', 'backbone.enc.enc3.down.norm.0.weight', 'backbone.enc.enc3.down.norm.0.bias', 'backbone.enc.enc4.down.proj.weight', 'backbone.enc.enc4.down.proj.bias', 'backbone.enc.enc4.down.norm.0.weight', 'backbone.enc.enc4.down.norm.0.bias', 'backbone.dec.dec3.up.proj.0.weight', 'backbone.dec.dec3.up.proj.0.bias', 'backbone.dec.dec3.up.proj.1.weight', 'backbone.dec.dec3.up.proj.1.bias', 'backbone.dec.dec3.up.proj_skip.0.weight', 'backbone.dec.dec3.up.proj_skip.0.bias', 'backbone.dec.dec3.up.proj_skip.1.weight', 'backbone.dec.dec3.up.proj_skip.1.bias', 'backbone.dec.dec2.up.proj.0.weight', 'backbone.dec.dec2.up.proj.0.bias', 'backbone.dec.dec2.up.proj.1.weight', 'backbone.dec.dec2.up.proj.1.bias', 'backbone.dec.dec2.up.proj_skip.0.weight', 'backbone.dec.dec2.up.proj_skip.0.bias', 'backbone.dec.dec2.up.proj_skip.1.weight', 'backbone.dec.dec2.up.proj_skip.1.bias', 'backbone.dec.dec1.up.proj.0.weight', 'backbone.dec.dec1.up.proj.0.bias', 'backbone.dec.dec1.up.proj.1.weight', 'backbone.dec.dec1.up.proj.1.bias', 'backbone.dec.dec1.up.proj_skip.0.weight', 'backbone.dec.dec1.up.proj_skip.0.bias', 'backbone.dec.dec1.up.proj_skip.1.weight', 'backbone.dec.dec1.up.proj_skip.1.bias', 'backbone.dec.dec0.up.proj.0.weight', 'backbone.dec.dec0.up.proj.0.bias', 'backbone.dec.dec0.up.proj.1.weight', 'backbone.dec.dec0.up.proj.1.bias', 'backbone.dec.dec0.up.proj_skip.0.weight', 'backbone.dec.dec0.up.proj_skip.0.bias', 'backbone.dec.dec0.up.proj_skip.1.weight', 'backbone.dec.dec0.up.proj_skip.1.bias'].
[2025-04-08 13:50:55,272 INFO optimizer.py line 54 3298914] Params Group 2 - lr: 0.0002; Params: ['backbone.enc.enc0.block0.cpe.0.weight', 'backbone.enc.enc0.block0.cpe.0.bias', 'backbone.enc.enc0.block0.cpe.1.weight', 'backbone.enc.enc0.block0.cpe.1.bias', 'backbone.enc.enc0.block0.cpe.2.weight', 'backbone.enc.enc0.block0.cpe.2.bias', 'backbone.enc.enc0.block0.norm1.0.weight', 'backbone.enc.enc0.block0.norm1.0.bias', 'backbone.enc.enc0.block0.attn.qkv.weight', 'backbone.enc.enc0.block0.attn.qkv.bias', 'backbone.enc.enc0.block0.attn.proj.weight', 'backbone.enc.enc0.block0.attn.proj.bias', 'backbone.enc.enc0.block0.norm2.0.weight', 'backbone.enc.enc0.block0.norm2.0.bias', 'backbone.enc.enc0.block0.mlp.0.fc1.weight', 'backbone.enc.enc0.block0.mlp.0.fc1.bias', 'backbone.enc.enc0.block0.mlp.0.fc2.weight', 'backbone.enc.enc0.block0.mlp.0.fc2.bias', 'backbone.enc.enc0.block1.cpe.0.weight', 'backbone.enc.enc0.block1.cpe.0.bias', 'backbone.enc.enc0.block1.cpe.1.weight', 'backbone.enc.enc0.block1.cpe.1.bias', 'backbone.enc.enc0.block1.cpe.2.weight', 'backbone.enc.enc0.block1.cpe.2.bias', 'backbone.enc.enc0.block1.norm1.0.weight', 'backbone.enc.enc0.block1.norm1.0.bias', 'backbone.enc.enc0.block1.attn.qkv.weight', 'backbone.enc.enc0.block1.attn.qkv.bias', 'backbone.enc.enc0.block1.attn.proj.weight', 'backbone.enc.enc0.block1.attn.proj.bias', 'backbone.enc.enc0.block1.norm2.0.weight', 'backbone.enc.enc0.block1.norm2.0.bias', 'backbone.enc.enc0.block1.mlp.0.fc1.weight', 'backbone.enc.enc0.block1.mlp.0.fc1.bias', 'backbone.enc.enc0.block1.mlp.0.fc2.weight', 'backbone.enc.enc0.block1.mlp.0.fc2.bias', 'backbone.enc.enc0.block2.cpe.0.weight', 'backbone.enc.enc0.block2.cpe.0.bias', 'backbone.enc.enc0.block2.cpe.1.weight', 'backbone.enc.enc0.block2.cpe.1.bias', 'backbone.enc.enc0.block2.cpe.2.weight', 'backbone.enc.enc0.block2.cpe.2.bias', 'backbone.enc.enc0.block2.norm1.0.weight', 'backbone.enc.enc0.block2.norm1.0.bias', 'backbone.enc.enc0.block2.attn.qkv.weight', 'backbone.enc.enc0.block2.attn.qkv.bias', 'backbone.enc.enc0.block2.attn.proj.weight', 'backbone.enc.enc0.block2.attn.proj.bias', 'backbone.enc.enc0.block2.norm2.0.weight', 'backbone.enc.enc0.block2.norm2.0.bias', 'backbone.enc.enc0.block2.mlp.0.fc1.weight', 'backbone.enc.enc0.block2.mlp.0.fc1.bias', 'backbone.enc.enc0.block2.mlp.0.fc2.weight', 'backbone.enc.enc0.block2.mlp.0.fc2.bias', 'backbone.enc.enc1.block0.cpe.0.weight', 'backbone.enc.enc1.block0.cpe.0.bias', 'backbone.enc.enc1.block0.cpe.1.weight', 'backbone.enc.enc1.block0.cpe.1.bias', 'backbone.enc.enc1.block0.cpe.2.weight', 'backbone.enc.enc1.block0.cpe.2.bias', 'backbone.enc.enc1.block0.norm1.0.weight', 'backbone.enc.enc1.block0.norm1.0.bias', 'backbone.enc.enc1.block0.attn.qkv.weight', 'backbone.enc.enc1.block0.attn.qkv.bias', 'backbone.enc.enc1.block0.attn.proj.weight', 'backbone.enc.enc1.block0.attn.proj.bias', 'backbone.enc.enc1.block0.norm2.0.weight', 'backbone.enc.enc1.block0.norm2.0.bias', 'backbone.enc.enc1.block0.mlp.0.fc1.weight', 'backbone.enc.enc1.block0.mlp.0.fc1.bias', 'backbone.enc.enc1.block0.mlp.0.fc2.weight', 'backbone.enc.enc1.block0.mlp.0.fc2.bias', 'backbone.enc.enc1.block1.cpe.0.weight', 'backbone.enc.enc1.block1.cpe.0.bias', 'backbone.enc.enc1.block1.cpe.1.weight', 'backbone.enc.enc1.block1.cpe.1.bias', 'backbone.enc.enc1.block1.cpe.2.weight', 'backbone.enc.enc1.block1.cpe.2.bias', 'backbone.enc.enc1.block1.norm1.0.weight', 'backbone.enc.enc1.block1.norm1.0.bias', 'backbone.enc.enc1.block1.attn.qkv.weight', 'backbone.enc.enc1.block1.attn.qkv.bias', 'backbone.enc.enc1.block1.attn.proj.weight', 'backbone.enc.enc1.block1.attn.proj.bias', 'backbone.enc.enc1.block1.norm2.0.weight', 'backbone.enc.enc1.block1.norm2.0.bias', 'backbone.enc.enc1.block1.mlp.0.fc1.weight', 'backbone.enc.enc1.block1.mlp.0.fc1.bias', 'backbone.enc.enc1.block1.mlp.0.fc2.weight', 'backbone.enc.enc1.block1.mlp.0.fc2.bias', 'backbone.enc.enc1.block2.cpe.0.weight', 'backbone.enc.enc1.block2.cpe.0.bias', 'backbone.enc.enc1.block2.cpe.1.weight', 'backbone.enc.enc1.block2.cpe.1.bias', 'backbone.enc.enc1.block2.cpe.2.weight', 'backbone.enc.enc1.block2.cpe.2.bias', 'backbone.enc.enc1.block2.norm1.0.weight', 'backbone.enc.enc1.block2.norm1.0.bias', 'backbone.enc.enc1.block2.attn.qkv.weight', 'backbone.enc.enc1.block2.attn.qkv.bias', 'backbone.enc.enc1.block2.attn.proj.weight', 'backbone.enc.enc1.block2.attn.proj.bias', 'backbone.enc.enc1.block2.norm2.0.weight', 'backbone.enc.enc1.block2.norm2.0.bias', 'backbone.enc.enc1.block2.mlp.0.fc1.weight', 'backbone.enc.enc1.block2.mlp.0.fc1.bias', 'backbone.enc.enc1.block2.mlp.0.fc2.weight', 'backbone.enc.enc1.block2.mlp.0.fc2.bias', 'backbone.enc.enc2.block0.cpe.0.weight', 'backbone.enc.enc2.block0.cpe.0.bias', 'backbone.enc.enc2.block0.cpe.1.weight', 'backbone.enc.enc2.block0.cpe.1.bias', 'backbone.enc.enc2.block0.cpe.2.weight', 'backbone.enc.enc2.block0.cpe.2.bias', 'backbone.enc.enc2.block0.norm1.0.weight', 'backbone.enc.enc2.block0.norm1.0.bias', 'backbone.enc.enc2.block0.attn.qkv.weight', 'backbone.enc.enc2.block0.attn.qkv.bias', 'backbone.enc.enc2.block0.attn.proj.weight', 'backbone.enc.enc2.block0.attn.proj.bias', 'backbone.enc.enc2.block0.norm2.0.weight', 'backbone.enc.enc2.block0.norm2.0.bias', 'backbone.enc.enc2.block0.mlp.0.fc1.weight', 'backbone.enc.enc2.block0.mlp.0.fc1.bias', 'backbone.enc.enc2.block0.mlp.0.fc2.weight', 'backbone.enc.enc2.block0.mlp.0.fc2.bias', 'backbone.enc.enc2.block1.cpe.0.weight', 'backbone.enc.enc2.block1.cpe.0.bias', 'backbone.enc.enc2.block1.cpe.1.weight', 'backbone.enc.enc2.block1.cpe.1.bias', 'backbone.enc.enc2.block1.cpe.2.weight', 'backbone.enc.enc2.block1.cpe.2.bias', 'backbone.enc.enc2.block1.norm1.0.weight', 'backbone.enc.enc2.block1.norm1.0.bias', 'backbone.enc.enc2.block1.attn.qkv.weight', 'backbone.enc.enc2.block1.attn.qkv.bias', 'backbone.enc.enc2.block1.attn.proj.weight', 'backbone.enc.enc2.block1.attn.proj.bias', 'backbone.enc.enc2.block1.norm2.0.weight', 'backbone.enc.enc2.block1.norm2.0.bias', 'backbone.enc.enc2.block1.mlp.0.fc1.weight', 'backbone.enc.enc2.block1.mlp.0.fc1.bias', 'backbone.enc.enc2.block1.mlp.0.fc2.weight', 'backbone.enc.enc2.block1.mlp.0.fc2.bias', 'backbone.enc.enc2.block2.cpe.0.weight', 'backbone.enc.enc2.block2.cpe.0.bias', 'backbone.enc.enc2.block2.cpe.1.weight', 'backbone.enc.enc2.block2.cpe.1.bias', 'backbone.enc.enc2.block2.cpe.2.weight', 'backbone.enc.enc2.block2.cpe.2.bias', 'backbone.enc.enc2.block2.norm1.0.weight', 'backbone.enc.enc2.block2.norm1.0.bias', 'backbone.enc.enc2.block2.attn.qkv.weight', 'backbone.enc.enc2.block2.attn.qkv.bias', 'backbone.enc.enc2.block2.attn.proj.weight', 'backbone.enc.enc2.block2.attn.proj.bias', 'backbone.enc.enc2.block2.norm2.0.weight', 'backbone.enc.enc2.block2.norm2.0.bias', 'backbone.enc.enc2.block2.mlp.0.fc1.weight', 'backbone.enc.enc2.block2.mlp.0.fc1.bias', 'backbone.enc.enc2.block2.mlp.0.fc2.weight', 'backbone.enc.enc2.block2.mlp.0.fc2.bias', 'backbone.enc.enc3.block0.cpe.0.weight', 'backbone.enc.enc3.block0.cpe.0.bias', 'backbone.enc.enc3.block0.cpe.1.weight', 'backbone.enc.enc3.block0.cpe.1.bias', 'backbone.enc.enc3.block0.cpe.2.weight', 'backbone.enc.enc3.block0.cpe.2.bias', 'backbone.enc.enc3.block0.norm1.0.weight', 'backbone.enc.enc3.block0.norm1.0.bias', 'backbone.enc.enc3.block0.attn.qkv.weight', 'backbone.enc.enc3.block0.attn.qkv.bias', 'backbone.enc.enc3.block0.attn.proj.weight', 'backbone.enc.enc3.block0.attn.proj.bias', 'backbone.enc.enc3.block0.norm2.0.weight', 'backbone.enc.enc3.block0.norm2.0.bias', 'backbone.enc.enc3.block0.mlp.0.fc1.weight', 'backbone.enc.enc3.block0.mlp.0.fc1.bias', 'backbone.enc.enc3.block0.mlp.0.fc2.weight', 'backbone.enc.enc3.block0.mlp.0.fc2.bias', 'backbone.enc.enc3.block1.cpe.0.weight', 'backbone.enc.enc3.block1.cpe.0.bias', 'backbone.enc.enc3.block1.cpe.1.weight', 'backbone.enc.enc3.block1.cpe.1.bias', 'backbone.enc.enc3.block1.cpe.2.weight', 'backbone.enc.enc3.block1.cpe.2.bias', 'backbone.enc.enc3.block1.norm1.0.weight', 'backbone.enc.enc3.block1.norm1.0.bias', 'backbone.enc.enc3.block1.attn.qkv.weight', 'backbone.enc.enc3.block1.attn.qkv.bias', 'backbone.enc.enc3.block1.attn.proj.weight', 'backbone.enc.enc3.block1.attn.proj.bias', 'backbone.enc.enc3.block1.norm2.0.weight', 'backbone.enc.enc3.block1.norm2.0.bias', 'backbone.enc.enc3.block1.mlp.0.fc1.weight', 'backbone.enc.enc3.block1.mlp.0.fc1.bias', 'backbone.enc.enc3.block1.mlp.0.fc2.weight', 'backbone.enc.enc3.block1.mlp.0.fc2.bias', 'backbone.enc.enc3.block2.cpe.0.weight', 'backbone.enc.enc3.block2.cpe.0.bias', 'backbone.enc.enc3.block2.cpe.1.weight', 'backbone.enc.enc3.block2.cpe.1.bias', 'backbone.enc.enc3.block2.cpe.2.weight', 'backbone.enc.enc3.block2.cpe.2.bias', 'backbone.enc.enc3.block2.norm1.0.weight', 'backbone.enc.enc3.block2.norm1.0.bias', 'backbone.enc.enc3.block2.attn.qkv.weight', 'backbone.enc.enc3.block2.attn.qkv.bias', 'backbone.enc.enc3.block2.attn.proj.weight', 'backbone.enc.enc3.block2.attn.proj.bias', 'backbone.enc.enc3.block2.norm2.0.weight', 'backbone.enc.enc3.block2.norm2.0.bias', 'backbone.enc.enc3.block2.mlp.0.fc1.weight', 'backbone.enc.enc3.block2.mlp.0.fc1.bias', 'backbone.enc.enc3.block2.mlp.0.fc2.weight', 'backbone.enc.enc3.block2.mlp.0.fc2.bias', 'backbone.enc.enc3.block3.cpe.0.weight', 'backbone.enc.enc3.block3.cpe.0.bias', 'backbone.enc.enc3.block3.cpe.1.weight', 'backbone.enc.enc3.block3.cpe.1.bias', 'backbone.enc.enc3.block3.cpe.2.weight', 'backbone.enc.enc3.block3.cpe.2.bias', 'backbone.enc.enc3.block3.norm1.0.weight', 'backbone.enc.enc3.block3.norm1.0.bias', 'backbone.enc.enc3.block3.attn.qkv.weight', 'backbone.enc.enc3.block3.attn.qkv.bias', 'backbone.enc.enc3.block3.attn.proj.weight', 'backbone.enc.enc3.block3.attn.proj.bias', 'backbone.enc.enc3.block3.norm2.0.weight', 'backbone.enc.enc3.block3.norm2.0.bias', 'backbone.enc.enc3.block3.mlp.0.fc1.weight', 'backbone.enc.enc3.block3.mlp.0.fc1.bias', 'backbone.enc.enc3.block3.mlp.0.fc2.weight', 'backbone.enc.enc3.block3.mlp.0.fc2.bias', 'backbone.enc.enc3.block4.cpe.0.weight', 'backbone.enc.enc3.block4.cpe.0.bias', 'backbone.enc.enc3.block4.cpe.1.weight', 'backbone.enc.enc3.block4.cpe.1.bias', 'backbone.enc.enc3.block4.cpe.2.weight', 'backbone.enc.enc3.block4.cpe.2.bias', 'backbone.enc.enc3.block4.norm1.0.weight', 'backbone.enc.enc3.block4.norm1.0.bias', 'backbone.enc.enc3.block4.attn.qkv.weight', 'backbone.enc.enc3.block4.attn.qkv.bias', 'backbone.enc.enc3.block4.attn.proj.weight', 'backbone.enc.enc3.block4.attn.proj.bias', 'backbone.enc.enc3.block4.norm2.0.weight', 'backbone.enc.enc3.block4.norm2.0.bias', 'backbone.enc.enc3.block4.mlp.0.fc1.weight', 'backbone.enc.enc3.block4.mlp.0.fc1.bias', 'backbone.enc.enc3.block4.mlp.0.fc2.weight', 'backbone.enc.enc3.block4.mlp.0.fc2.bias', 'backbone.enc.enc3.block5.cpe.0.weight', 'backbone.enc.enc3.block5.cpe.0.bias', 'backbone.enc.enc3.block5.cpe.1.weight', 'backbone.enc.enc3.block5.cpe.1.bias', 'backbone.enc.enc3.block5.cpe.2.weight', 'backbone.enc.enc3.block5.cpe.2.bias', 'backbone.enc.enc3.block5.norm1.0.weight', 'backbone.enc.enc3.block5.norm1.0.bias', 'backbone.enc.enc3.block5.attn.qkv.weight', 'backbone.enc.enc3.block5.attn.qkv.bias', 'backbone.enc.enc3.block5.attn.proj.weight', 'backbone.enc.enc3.block5.attn.proj.bias', 'backbone.enc.enc3.block5.norm2.0.weight', 'backbone.enc.enc3.block5.norm2.0.bias', 'backbone.enc.enc3.block5.mlp.0.fc1.weight', 'backbone.enc.enc3.block5.mlp.0.fc1.bias', 'backbone.enc.enc3.block5.mlp.0.fc2.weight', 'backbone.enc.enc3.block5.mlp.0.fc2.bias', 'backbone.enc.enc3.block6.cpe.0.weight', 'backbone.enc.enc3.block6.cpe.0.bias', 'backbone.enc.enc3.block6.cpe.1.weight', 'backbone.enc.enc3.block6.cpe.1.bias', 'backbone.enc.enc3.block6.cpe.2.weight', 'backbone.enc.enc3.block6.cpe.2.bias', 'backbone.enc.enc3.block6.norm1.0.weight', 'backbone.enc.enc3.block6.norm1.0.bias', 'backbone.enc.enc3.block6.attn.qkv.weight', 'backbone.enc.enc3.block6.attn.qkv.bias', 'backbone.enc.enc3.block6.attn.proj.weight', 'backbone.enc.enc3.block6.attn.proj.bias', 'backbone.enc.enc3.block6.norm2.0.weight', 'backbone.enc.enc3.block6.norm2.0.bias', 'backbone.enc.enc3.block6.mlp.0.fc1.weight', 'backbone.enc.enc3.block6.mlp.0.fc1.bias', 'backbone.enc.enc3.block6.mlp.0.fc2.weight', 'backbone.enc.enc3.block6.mlp.0.fc2.bias', 'backbone.enc.enc3.block7.cpe.0.weight', 'backbone.enc.enc3.block7.cpe.0.bias', 'backbone.enc.enc3.block7.cpe.1.weight', 'backbone.enc.enc3.block7.cpe.1.bias', 'backbone.enc.enc3.block7.cpe.2.weight', 'backbone.enc.enc3.block7.cpe.2.bias', 'backbone.enc.enc3.block7.norm1.0.weight', 'backbone.enc.enc3.block7.norm1.0.bias', 'backbone.enc.enc3.block7.attn.qkv.weight', 'backbone.enc.enc3.block7.attn.qkv.bias', 'backbone.enc.enc3.block7.attn.proj.weight', 'backbone.enc.enc3.block7.attn.proj.bias', 'backbone.enc.enc3.block7.norm2.0.weight', 'backbone.enc.enc3.block7.norm2.0.bias', 'backbone.enc.enc3.block7.mlp.0.fc1.weight', 'backbone.enc.enc3.block7.mlp.0.fc1.bias', 'backbone.enc.enc3.block7.mlp.0.fc2.weight', 'backbone.enc.enc3.block7.mlp.0.fc2.bias', 'backbone.enc.enc3.block8.cpe.0.weight', 'backbone.enc.enc3.block8.cpe.0.bias', 'backbone.enc.enc3.block8.cpe.1.weight', 'backbone.enc.enc3.block8.cpe.1.bias', 'backbone.enc.enc3.block8.cpe.2.weight', 'backbone.enc.enc3.block8.cpe.2.bias', 'backbone.enc.enc3.block8.norm1.0.weight', 'backbone.enc.enc3.block8.norm1.0.bias', 'backbone.enc.enc3.block8.attn.qkv.weight', 'backbone.enc.enc3.block8.attn.qkv.bias', 'backbone.enc.enc3.block8.attn.proj.weight', 'backbone.enc.enc3.block8.attn.proj.bias', 'backbone.enc.enc3.block8.norm2.0.weight', 'backbone.enc.enc3.block8.norm2.0.bias', 'backbone.enc.enc3.block8.mlp.0.fc1.weight', 'backbone.enc.enc3.block8.mlp.0.fc1.bias', 'backbone.enc.enc3.block8.mlp.0.fc2.weight', 'backbone.enc.enc3.block8.mlp.0.fc2.bias', 'backbone.enc.enc3.block9.cpe.0.weight', 'backbone.enc.enc3.block9.cpe.0.bias', 'backbone.enc.enc3.block9.cpe.1.weight', 'backbone.enc.enc3.block9.cpe.1.bias', 'backbone.enc.enc3.block9.cpe.2.weight', 'backbone.enc.enc3.block9.cpe.2.bias', 'backbone.enc.enc3.block9.norm1.0.weight', 'backbone.enc.enc3.block9.norm1.0.bias', 'backbone.enc.enc3.block9.attn.qkv.weight', 'backbone.enc.enc3.block9.attn.qkv.bias', 'backbone.enc.enc3.block9.attn.proj.weight', 'backbone.enc.enc3.block9.attn.proj.bias', 'backbone.enc.enc3.block9.norm2.0.weight', 'backbone.enc.enc3.block9.norm2.0.bias', 'backbone.enc.enc3.block9.mlp.0.fc1.weight', 'backbone.enc.enc3.block9.mlp.0.fc1.bias', 'backbone.enc.enc3.block9.mlp.0.fc2.weight', 'backbone.enc.enc3.block9.mlp.0.fc2.bias', 'backbone.enc.enc3.block10.cpe.0.weight', 'backbone.enc.enc3.block10.cpe.0.bias', 'backbone.enc.enc3.block10.cpe.1.weight', 'backbone.enc.enc3.block10.cpe.1.bias', 'backbone.enc.enc3.block10.cpe.2.weight', 'backbone.enc.enc3.block10.cpe.2.bias', 'backbone.enc.enc3.block10.norm1.0.weight', 'backbone.enc.enc3.block10.norm1.0.bias', 'backbone.enc.enc3.block10.attn.qkv.weight', 'backbone.enc.enc3.block10.attn.qkv.bias', 'backbone.enc.enc3.block10.attn.proj.weight', 'backbone.enc.enc3.block10.attn.proj.bias', 'backbone.enc.enc3.block10.norm2.0.weight', 'backbone.enc.enc3.block10.norm2.0.bias', 'backbone.enc.enc3.block10.mlp.0.fc1.weight', 'backbone.enc.enc3.block10.mlp.0.fc1.bias', 'backbone.enc.enc3.block10.mlp.0.fc2.weight', 'backbone.enc.enc3.block10.mlp.0.fc2.bias', 'backbone.enc.enc3.block11.cpe.0.weight', 'backbone.enc.enc3.block11.cpe.0.bias', 'backbone.enc.enc3.block11.cpe.1.weight', 'backbone.enc.enc3.block11.cpe.1.bias', 'backbone.enc.enc3.block11.cpe.2.weight', 'backbone.enc.enc3.block11.cpe.2.bias', 'backbone.enc.enc3.block11.norm1.0.weight', 'backbone.enc.enc3.block11.norm1.0.bias', 'backbone.enc.enc3.block11.attn.qkv.weight', 'backbone.enc.enc3.block11.attn.qkv.bias', 'backbone.enc.enc3.block11.attn.proj.weight', 'backbone.enc.enc3.block11.attn.proj.bias', 'backbone.enc.enc3.block11.norm2.0.weight', 'backbone.enc.enc3.block11.norm2.0.bias', 'backbone.enc.enc3.block11.mlp.0.fc1.weight', 'backbone.enc.enc3.block11.mlp.0.fc1.bias', 'backbone.enc.enc3.block11.mlp.0.fc2.weight', 'backbone.enc.enc3.block11.mlp.0.fc2.bias', 'backbone.enc.enc4.block0.cpe.0.weight', 'backbone.enc.enc4.block0.cpe.0.bias', 'backbone.enc.enc4.block0.cpe.1.weight', 'backbone.enc.enc4.block0.cpe.1.bias', 'backbone.enc.enc4.block0.cpe.2.weight', 'backbone.enc.enc4.block0.cpe.2.bias', 'backbone.enc.enc4.block0.norm1.0.weight', 'backbone.enc.enc4.block0.norm1.0.bias', 'backbone.enc.enc4.block0.attn.qkv.weight', 'backbone.enc.enc4.block0.attn.qkv.bias', 'backbone.enc.enc4.block0.attn.proj.weight', 'backbone.enc.enc4.block0.attn.proj.bias', 'backbone.enc.enc4.block0.norm2.0.weight', 'backbone.enc.enc4.block0.norm2.0.bias', 'backbone.enc.enc4.block0.mlp.0.fc1.weight', 'backbone.enc.enc4.block0.mlp.0.fc1.bias', 'backbone.enc.enc4.block0.mlp.0.fc2.weight', 'backbone.enc.enc4.block0.mlp.0.fc2.bias', 'backbone.enc.enc4.block1.cpe.0.weight', 'backbone.enc.enc4.block1.cpe.0.bias', 'backbone.enc.enc4.block1.cpe.1.weight', 'backbone.enc.enc4.block1.cpe.1.bias', 'backbone.enc.enc4.block1.cpe.2.weight', 'backbone.enc.enc4.block1.cpe.2.bias', 'backbone.enc.enc4.block1.norm1.0.weight', 'backbone.enc.enc4.block1.norm1.0.bias', 'backbone.enc.enc4.block1.attn.qkv.weight', 'backbone.enc.enc4.block1.attn.qkv.bias', 'backbone.enc.enc4.block1.attn.proj.weight', 'backbone.enc.enc4.block1.attn.proj.bias', 'backbone.enc.enc4.block1.norm2.0.weight', 'backbone.enc.enc4.block1.norm2.0.bias', 'backbone.enc.enc4.block1.mlp.0.fc1.weight', 'backbone.enc.enc4.block1.mlp.0.fc1.bias', 'backbone.enc.enc4.block1.mlp.0.fc2.weight', 'backbone.enc.enc4.block1.mlp.0.fc2.bias', 'backbone.enc.enc4.block2.cpe.0.weight', 'backbone.enc.enc4.block2.cpe.0.bias', 'backbone.enc.enc4.block2.cpe.1.weight', 'backbone.enc.enc4.block2.cpe.1.bias', 'backbone.enc.enc4.block2.cpe.2.weight', 'backbone.enc.enc4.block2.cpe.2.bias', 'backbone.enc.enc4.block2.norm1.0.weight', 'backbone.enc.enc4.block2.norm1.0.bias', 'backbone.enc.enc4.block2.attn.qkv.weight', 'backbone.enc.enc4.block2.attn.qkv.bias', 'backbone.enc.enc4.block2.attn.proj.weight', 'backbone.enc.enc4.block2.attn.proj.bias', 'backbone.enc.enc4.block2.norm2.0.weight', 'backbone.enc.enc4.block2.norm2.0.bias', 'backbone.enc.enc4.block2.mlp.0.fc1.weight', 'backbone.enc.enc4.block2.mlp.0.fc1.bias', 'backbone.enc.enc4.block2.mlp.0.fc2.weight', 'backbone.enc.enc4.block2.mlp.0.fc2.bias', 'backbone.dec.dec3.block0.cpe.0.weight', 'backbone.dec.dec3.block0.cpe.0.bias', 'backbone.dec.dec3.block0.cpe.1.weight', 'backbone.dec.dec3.block0.cpe.1.bias', 'backbone.dec.dec3.block0.cpe.2.weight', 'backbone.dec.dec3.block0.cpe.2.bias', 'backbone.dec.dec3.block0.norm1.0.weight', 'backbone.dec.dec3.block0.norm1.0.bias', 'backbone.dec.dec3.block0.attn.qkv.weight', 'backbone.dec.dec3.block0.attn.qkv.bias', 'backbone.dec.dec3.block0.attn.proj.weight', 'backbone.dec.dec3.block0.attn.proj.bias', 'backbone.dec.dec3.block0.norm2.0.weight', 'backbone.dec.dec3.block0.norm2.0.bias', 'backbone.dec.dec3.block0.mlp.0.fc1.weight', 'backbone.dec.dec3.block0.mlp.0.fc1.bias', 'backbone.dec.dec3.block0.mlp.0.fc2.weight', 'backbone.dec.dec3.block0.mlp.0.fc2.bias', 'backbone.dec.dec3.block1.cpe.0.weight', 'backbone.dec.dec3.block1.cpe.0.bias', 'backbone.dec.dec3.block1.cpe.1.weight', 'backbone.dec.dec3.block1.cpe.1.bias', 'backbone.dec.dec3.block1.cpe.2.weight', 'backbone.dec.dec3.block1.cpe.2.bias', 'backbone.dec.dec3.block1.norm1.0.weight', 'backbone.dec.dec3.block1.norm1.0.bias', 'backbone.dec.dec3.block1.attn.qkv.weight', 'backbone.dec.dec3.block1.attn.qkv.bias', 'backbone.dec.dec3.block1.attn.proj.weight', 'backbone.dec.dec3.block1.attn.proj.bias', 'backbone.dec.dec3.block1.norm2.0.weight', 'backbone.dec.dec3.block1.norm2.0.bias', 'backbone.dec.dec3.block1.mlp.0.fc1.weight', 'backbone.dec.dec3.block1.mlp.0.fc1.bias', 'backbone.dec.dec3.block1.mlp.0.fc2.weight', 'backbone.dec.dec3.block1.mlp.0.fc2.bias', 'backbone.dec.dec2.block0.cpe.0.weight', 'backbone.dec.dec2.block0.cpe.0.bias', 'backbone.dec.dec2.block0.cpe.1.weight', 'backbone.dec.dec2.block0.cpe.1.bias', 'backbone.dec.dec2.block0.cpe.2.weight', 'backbone.dec.dec2.block0.cpe.2.bias', 'backbone.dec.dec2.block0.norm1.0.weight', 'backbone.dec.dec2.block0.norm1.0.bias', 'backbone.dec.dec2.block0.attn.qkv.weight', 'backbone.dec.dec2.block0.attn.qkv.bias', 'backbone.dec.dec2.block0.attn.proj.weight', 'backbone.dec.dec2.block0.attn.proj.bias', 'backbone.dec.dec2.block0.norm2.0.weight', 'backbone.dec.dec2.block0.norm2.0.bias', 'backbone.dec.dec2.block0.mlp.0.fc1.weight', 'backbone.dec.dec2.block0.mlp.0.fc1.bias', 'backbone.dec.dec2.block0.mlp.0.fc2.weight', 'backbone.dec.dec2.block0.mlp.0.fc2.bias', 'backbone.dec.dec2.block1.cpe.0.weight', 'backbone.dec.dec2.block1.cpe.0.bias', 'backbone.dec.dec2.block1.cpe.1.weight', 'backbone.dec.dec2.block1.cpe.1.bias', 'backbone.dec.dec2.block1.cpe.2.weight', 'backbone.dec.dec2.block1.cpe.2.bias', 'backbone.dec.dec2.block1.norm1.0.weight', 'backbone.dec.dec2.block1.norm1.0.bias', 'backbone.dec.dec2.block1.attn.qkv.weight', 'backbone.dec.dec2.block1.attn.qkv.bias', 'backbone.dec.dec2.block1.attn.proj.weight', 'backbone.dec.dec2.block1.attn.proj.bias', 'backbone.dec.dec2.block1.norm2.0.weight', 'backbone.dec.dec2.block1.norm2.0.bias', 'backbone.dec.dec2.block1.mlp.0.fc1.weight', 'backbone.dec.dec2.block1.mlp.0.fc1.bias', 'backbone.dec.dec2.block1.mlp.0.fc2.weight', 'backbone.dec.dec2.block1.mlp.0.fc2.bias', 'backbone.dec.dec1.block0.cpe.0.weight', 'backbone.dec.dec1.block0.cpe.0.bias', 'backbone.dec.dec1.block0.cpe.1.weight', 'backbone.dec.dec1.block0.cpe.1.bias', 'backbone.dec.dec1.block0.cpe.2.weight', 'backbone.dec.dec1.block0.cpe.2.bias', 'backbone.dec.dec1.block0.norm1.0.weight', 'backbone.dec.dec1.block0.norm1.0.bias', 'backbone.dec.dec1.block0.attn.qkv.weight', 'backbone.dec.dec1.block0.attn.qkv.bias', 'backbone.dec.dec1.block0.attn.proj.weight', 'backbone.dec.dec1.block0.attn.proj.bias', 'backbone.dec.dec1.block0.norm2.0.weight', 'backbone.dec.dec1.block0.norm2.0.bias', 'backbone.dec.dec1.block0.mlp.0.fc1.weight', 'backbone.dec.dec1.block0.mlp.0.fc1.bias', 'backbone.dec.dec1.block0.mlp.0.fc2.weight', 'backbone.dec.dec1.block0.mlp.0.fc2.bias', 'backbone.dec.dec1.block1.cpe.0.weight', 'backbone.dec.dec1.block1.cpe.0.bias', 'backbone.dec.dec1.block1.cpe.1.weight', 'backbone.dec.dec1.block1.cpe.1.bias', 'backbone.dec.dec1.block1.cpe.2.weight', 'backbone.dec.dec1.block1.cpe.2.bias', 'backbone.dec.dec1.block1.norm1.0.weight', 'backbone.dec.dec1.block1.norm1.0.bias', 'backbone.dec.dec1.block1.attn.qkv.weight', 'backbone.dec.dec1.block1.attn.qkv.bias', 'backbone.dec.dec1.block1.attn.proj.weight', 'backbone.dec.dec1.block1.attn.proj.bias', 'backbone.dec.dec1.block1.norm2.0.weight', 'backbone.dec.dec1.block1.norm2.0.bias', 'backbone.dec.dec1.block1.mlp.0.fc1.weight', 'backbone.dec.dec1.block1.mlp.0.fc1.bias', 'backbone.dec.dec1.block1.mlp.0.fc2.weight', 'backbone.dec.dec1.block1.mlp.0.fc2.bias', 'backbone.dec.dec0.block0.cpe.0.weight', 'backbone.dec.dec0.block0.cpe.0.bias', 'backbone.dec.dec0.block0.cpe.1.weight', 'backbone.dec.dec0.block0.cpe.1.bias', 'backbone.dec.dec0.block0.cpe.2.weight', 'backbone.dec.dec0.block0.cpe.2.bias', 'backbone.dec.dec0.block0.norm1.0.weight', 'backbone.dec.dec0.block0.norm1.0.bias', 'backbone.dec.dec0.block0.attn.qkv.weight', 'backbone.dec.dec0.block0.attn.qkv.bias', 'backbone.dec.dec0.block0.attn.proj.weight', 'backbone.dec.dec0.block0.attn.proj.bias', 'backbone.dec.dec0.block0.norm2.0.weight', 'backbone.dec.dec0.block0.norm2.0.bias', 'backbone.dec.dec0.block0.mlp.0.fc1.weight', 'backbone.dec.dec0.block0.mlp.0.fc1.bias', 'backbone.dec.dec0.block0.mlp.0.fc2.weight', 'backbone.dec.dec0.block0.mlp.0.fc2.bias', 'backbone.dec.dec0.block1.cpe.0.weight', 'backbone.dec.dec0.block1.cpe.0.bias', 'backbone.dec.dec0.block1.cpe.1.weight', 'backbone.dec.dec0.block1.cpe.1.bias', 'backbone.dec.dec0.block1.cpe.2.weight', 'backbone.dec.dec0.block1.cpe.2.bias', 'backbone.dec.dec0.block1.norm1.0.weight', 'backbone.dec.dec0.block1.norm1.0.bias', 'backbone.dec.dec0.block1.attn.qkv.weight', 'backbone.dec.dec0.block1.attn.qkv.bias', 'backbone.dec.dec0.block1.attn.proj.weight', 'backbone.dec.dec0.block1.attn.proj.bias', 'backbone.dec.dec0.block1.norm2.0.weight', 'backbone.dec.dec0.block1.norm2.0.bias', 'backbone.dec.dec0.block1.mlp.0.fc1.weight', 'backbone.dec.dec0.block1.mlp.0.fc1.bias', 'backbone.dec.dec0.block1.mlp.0.fc2.weight', 'backbone.dec.dec0.block1.mlp.0.fc2.bias'].
[2025-04-08 13:50:55,273 INFO train.py line 150 3298914] => Building hooks ...
[2025-04-08 13:50:55,274 INFO misc.py line 209 3298914] => Loading checkpoint & weight ...
[2025-04-08 13:50:55,275 INFO misc.py line 211 3298914] Loading weight at: /work3/s204157/data/ego3d/exp/scannet/debug/model/sonata.pth
/zhome/c9/c/156514/Pointcept/pointcept/engines/hooks/misc.py:212: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(
[2025-04-08 13:50:56,242 INFO misc.py line 216 3298914] Loading layer weights with keyword: module.student.backbone, replace keyword with: module.backbone
[2025-04-08 13:50:56,246 INFO misc.py line 233 3298914] Missing keys: ['seg_head.weight', 'seg_head.bias', 'backbone.embedding.stem.linear.weight', 'backbone.embedding.stem.linear.bias', 'backbone.embedding.stem.norm.weight', 'backbone.embedding.stem.norm.bias', 'backbone.enc.enc0.block0.cpe.0.weight', 'backbone.enc.enc0.block0.cpe.0.bias', 'backbone.enc.enc0.block0.cpe.1.weight', 'backbone.enc.enc0.block0.cpe.1.bias', 'backbone.enc.enc0.block0.cpe.2.weight', 'backbone.enc.enc0.block0.cpe.2.bias', 'backbone.enc.enc0.block0.norm1.0.weight', 'backbone.enc.enc0.block0.norm1.0.bias', 'backbone.enc.enc0.block0.attn.qkv.weight', 'backbone.enc.enc0.block0.attn.qkv.bias', 'backbone.enc.enc0.block0.attn.proj.weight', 'backbone.enc.enc0.block0.attn.proj.bias', 'backbone.enc.enc0.block0.norm2.0.weight', 'backbone.enc.enc0.block0.norm2.0.bias', 'backbone.enc.enc0.block0.mlp.0.fc1.weight', 'backbone.enc.enc0.block0.mlp.0.fc1.bias', 'backbone.enc.enc0.block0.mlp.0.fc2.weight', 'backbone.enc.enc0.block0.mlp.0.fc2.bias', 'backbone.enc.enc0.block1.cpe.0.weight', 'backbone.enc.enc0.block1.cpe.0.bias', 'backbone.enc.enc0.block1.cpe.1.weight', 'backbone.enc.enc0.block1.cpe.1.bias', 'backbone.enc.enc0.block1.cpe.2.weight', 'backbone.enc.enc0.block1.cpe.2.bias', 'backbone.enc.enc0.block1.norm1.0.weight', 'backbone.enc.enc0.block1.norm1.0.bias', 'backbone.enc.enc0.block1.attn.qkv.weight', 'backbone.enc.enc0.block1.attn.qkv.bias', 'backbone.enc.enc0.block1.attn.proj.weight', 'backbone.enc.enc0.block1.attn.proj.bias', 'backbone.enc.enc0.block1.norm2.0.weight', 'backbone.enc.enc0.block1.norm2.0.bias', 'backbone.enc.enc0.block1.mlp.0.fc1.weight', 'backbone.enc.enc0.block1.mlp.0.fc1.bias', 'backbone.enc.enc0.block1.mlp.0.fc2.weight', 'backbone.enc.enc0.block1.mlp.0.fc2.bias', 'backbone.enc.enc0.block2.cpe.0.weight', 'backbone.enc.enc0.block2.cpe.0.bias', 'backbone.enc.enc0.block2.cpe.1.weight', 'backbone.enc.enc0.block2.cpe.1.bias', 'backbone.enc.enc0.block2.cpe.2.weight', 'backbone.enc.enc0.block2.cpe.2.bias', 'backbone.enc.enc0.block2.norm1.0.weight', 'backbone.enc.enc0.block2.norm1.0.bias', 'backbone.enc.enc0.block2.attn.qkv.weight', 'backbone.enc.enc0.block2.attn.qkv.bias', 'backbone.enc.enc0.block2.attn.proj.weight', 'backbone.enc.enc0.block2.attn.proj.bias', 'backbone.enc.enc0.block2.norm2.0.weight', 'backbone.enc.enc0.block2.norm2.0.bias', 'backbone.enc.enc0.block2.mlp.0.fc1.weight', 'backbone.enc.enc0.block2.mlp.0.fc1.bias', 'backbone.enc.enc0.block2.mlp.0.fc2.weight', 'backbone.enc.enc0.block2.mlp.0.fc2.bias', 'backbone.enc.enc1.down.proj.weight', 'backbone.enc.enc1.down.proj.bias', 'backbone.enc.enc1.down.norm.0.weight', 'backbone.enc.enc1.down.norm.0.bias', 'backbone.enc.enc1.block0.cpe.0.weight', 'backbone.enc.enc1.block0.cpe.0.bias', 'backbone.enc.enc1.block0.cpe.1.weight', 'backbone.enc.enc1.block0.cpe.1.bias', 'backbone.enc.enc1.block0.cpe.2.weight', 'backbone.enc.enc1.block0.cpe.2.bias', 'backbone.enc.enc1.block0.norm1.0.weight', 'backbone.enc.enc1.block0.norm1.0.bias', 'backbone.enc.enc1.block0.attn.qkv.weight', 'backbone.enc.enc1.block0.attn.qkv.bias', 'backbone.enc.enc1.block0.attn.proj.weight', 'backbone.enc.enc1.block0.attn.proj.bias', 'backbone.enc.enc1.block0.norm2.0.weight', 'backbone.enc.enc1.block0.norm2.0.bias', 'backbone.enc.enc1.block0.mlp.0.fc1.weight', 'backbone.enc.enc1.block0.mlp.0.fc1.bias', 'backbone.enc.enc1.block0.mlp.0.fc2.weight', 'backbone.enc.enc1.block0.mlp.0.fc2.bias', 'backbone.enc.enc1.block1.cpe.0.weight', 'backbone.enc.enc1.block1.cpe.0.bias', 'backbone.enc.enc1.block1.cpe.1.weight', 'backbone.enc.enc1.block1.cpe.1.bias', 'backbone.enc.enc1.block1.cpe.2.weight', 'backbone.enc.enc1.block1.cpe.2.bias', 'backbone.enc.enc1.block1.norm1.0.weight', 'backbone.enc.enc1.block1.norm1.0.bias', 'backbone.enc.enc1.block1.attn.qkv.weight', 'backbone.enc.enc1.block1.attn.qkv.bias', 'backbone.enc.enc1.block1.attn.proj.weight', 'backbone.enc.enc1.block1.attn.proj.bias', 'backbone.enc.enc1.block1.norm2.0.weight', 'backbone.enc.enc1.block1.norm2.0.bias', 'backbone.enc.enc1.block1.mlp.0.fc1.weight', 'backbone.enc.enc1.block1.mlp.0.fc1.bias', 'backbone.enc.enc1.block1.mlp.0.fc2.weight', 'backbone.enc.enc1.block1.mlp.0.fc2.bias', 'backbone.enc.enc1.block2.cpe.0.weight', 'backbone.enc.enc1.block2.cpe.0.bias', 'backbone.enc.enc1.block2.cpe.1.weight', 'backbone.enc.enc1.block2.cpe.1.bias', 'backbone.enc.enc1.block2.cpe.2.weight', 'backbone.enc.enc1.block2.cpe.2.bias', 'backbone.enc.enc1.block2.norm1.0.weight', 'backbone.enc.enc1.block2.norm1.0.bias', 'backbone.enc.enc1.block2.attn.qkv.weight', 'backbone.enc.enc1.block2.attn.qkv.bias', 'backbone.enc.enc1.block2.attn.proj.weight', 'backbone.enc.enc1.block2.attn.proj.bias', 'backbone.enc.enc1.block2.norm2.0.weight', 'backbone.enc.enc1.block2.norm2.0.bias', 'backbone.enc.enc1.block2.mlp.0.fc1.weight', 'backbone.enc.enc1.block2.mlp.0.fc1.bias', 'backbone.enc.enc1.block2.mlp.0.fc2.weight', 'backbone.enc.enc1.block2.mlp.0.fc2.bias', 'backbone.enc.enc2.down.proj.weight', 'backbone.enc.enc2.down.proj.bias', 'backbone.enc.enc2.down.norm.0.weight', 'backbone.enc.enc2.down.norm.0.bias', 'backbone.enc.enc2.block0.cpe.0.weight', 'backbone.enc.enc2.block0.cpe.0.bias', 'backbone.enc.enc2.block0.cpe.1.weight', 'backbone.enc.enc2.block0.cpe.1.bias', 'backbone.enc.enc2.block0.cpe.2.weight', 'backbone.enc.enc2.block0.cpe.2.bias', 'backbone.enc.enc2.block0.norm1.0.weight', 'backbone.enc.enc2.block0.norm1.0.bias', 'backbone.enc.enc2.block0.attn.qkv.weight', 'backbone.enc.enc2.block0.attn.qkv.bias', 'backbone.enc.enc2.block0.attn.proj.weight', 'backbone.enc.enc2.block0.attn.proj.bias', 'backbone.enc.enc2.block0.norm2.0.weight', 'backbone.enc.enc2.block0.norm2.0.bias', 'backbone.enc.enc2.block0.mlp.0.fc1.weight', 'backbone.enc.enc2.block0.mlp.0.fc1.bias', 'backbone.enc.enc2.block0.mlp.0.fc2.weight', 'backbone.enc.enc2.block0.mlp.0.fc2.bias', 'backbone.enc.enc2.block1.cpe.0.weight', 'backbone.enc.enc2.block1.cpe.0.bias', 'backbone.enc.enc2.block1.cpe.1.weight', 'backbone.enc.enc2.block1.cpe.1.bias', 'backbone.enc.enc2.block1.cpe.2.weight', 'backbone.enc.enc2.block1.cpe.2.bias', 'backbone.enc.enc2.block1.norm1.0.weight', 'backbone.enc.enc2.block1.norm1.0.bias', 'backbone.enc.enc2.block1.attn.qkv.weight', 'backbone.enc.enc2.block1.attn.qkv.bias', 'backbone.enc.enc2.block1.attn.proj.weight', 'backbone.enc.enc2.block1.attn.proj.bias', 'backbone.enc.enc2.block1.norm2.0.weight', 'backbone.enc.enc2.block1.norm2.0.bias', 'backbone.enc.enc2.block1.mlp.0.fc1.weight', 'backbone.enc.enc2.block1.mlp.0.fc1.bias', 'backbone.enc.enc2.block1.mlp.0.fc2.weight', 'backbone.enc.enc2.block1.mlp.0.fc2.bias', 'backbone.enc.enc2.block2.cpe.0.weight', 'backbone.enc.enc2.block2.cpe.0.bias', 'backbone.enc.enc2.block2.cpe.1.weight', 'backbone.enc.enc2.block2.cpe.1.bias', 'backbone.enc.enc2.block2.cpe.2.weight', 'backbone.enc.enc2.block2.cpe.2.bias', 'backbone.enc.enc2.block2.norm1.0.weight', 'backbone.enc.enc2.block2.norm1.0.bias', 'backbone.enc.enc2.block2.attn.qkv.weight', 'backbone.enc.enc2.block2.attn.qkv.bias', 'backbone.enc.enc2.block2.attn.proj.weight', 'backbone.enc.enc2.block2.attn.proj.bias', 'backbone.enc.enc2.block2.norm2.0.weight', 'backbone.enc.enc2.block2.norm2.0.bias', 'backbone.enc.enc2.block2.mlp.0.fc1.weight', 'backbone.enc.enc2.block2.mlp.0.fc1.bias', 'backbone.enc.enc2.block2.mlp.0.fc2.weight', 'backbone.enc.enc2.block2.mlp.0.fc2.bias', 'backbone.enc.enc3.down.proj.weight', 'backbone.enc.enc3.down.proj.bias', 'backbone.enc.enc3.down.norm.0.weight', 'backbone.enc.enc3.down.norm.0.bias', 'backbone.enc.enc3.block0.cpe.0.weight', 'backbone.enc.enc3.block0.cpe.0.bias', 'backbone.enc.enc3.block0.cpe.1.weight', 'backbone.enc.enc3.block0.cpe.1.bias', 'backbone.enc.enc3.block0.cpe.2.weight', 'backbone.enc.enc3.block0.cpe.2.bias', 'backbone.enc.enc3.block0.norm1.0.weight', 'backbone.enc.enc3.block0.norm1.0.bias', 'backbone.enc.enc3.block0.attn.qkv.weight', 'backbone.enc.enc3.block0.attn.qkv.bias', 'backbone.enc.enc3.block0.attn.proj.weight', 'backbone.enc.enc3.block0.attn.proj.bias', 'backbone.enc.enc3.block0.norm2.0.weight', 'backbone.enc.enc3.block0.norm2.0.bias', 'backbone.enc.enc3.block0.mlp.0.fc1.weight', 'backbone.enc.enc3.block0.mlp.0.fc1.bias', 'backbone.enc.enc3.block0.mlp.0.fc2.weight', 'backbone.enc.enc3.block0.mlp.0.fc2.bias', 'backbone.enc.enc3.block1.cpe.0.weight', 'backbone.enc.enc3.block1.cpe.0.bias', 'backbone.enc.enc3.block1.cpe.1.weight', 'backbone.enc.enc3.block1.cpe.1.bias', 'backbone.enc.enc3.block1.cpe.2.weight', 'backbone.enc.enc3.block1.cpe.2.bias', 'backbone.enc.enc3.block1.norm1.0.weight', 'backbone.enc.enc3.block1.norm1.0.bias', 'backbone.enc.enc3.block1.attn.qkv.weight', 'backbone.enc.enc3.block1.attn.qkv.bias', 'backbone.enc.enc3.block1.attn.proj.weight', 'backbone.enc.enc3.block1.attn.proj.bias', 'backbone.enc.enc3.block1.norm2.0.weight', 'backbone.enc.enc3.block1.norm2.0.bias', 'backbone.enc.enc3.block1.mlp.0.fc1.weight', 'backbone.enc.enc3.block1.mlp.0.fc1.bias', 'backbone.enc.enc3.block1.mlp.0.fc2.weight', 'backbone.enc.enc3.block1.mlp.0.fc2.bias', 'backbone.enc.enc3.block2.cpe.0.weight', 'backbone.enc.enc3.block2.cpe.0.bias', 'backbone.enc.enc3.block2.cpe.1.weight', 'backbone.enc.enc3.block2.cpe.1.bias', 'backbone.enc.enc3.block2.cpe.2.weight', 'backbone.enc.enc3.block2.cpe.2.bias', 'backbone.enc.enc3.block2.norm1.0.weight', 'backbone.enc.enc3.block2.norm1.0.bias', 'backbone.enc.enc3.block2.attn.qkv.weight', 'backbone.enc.enc3.block2.attn.qkv.bias', 'backbone.enc.enc3.block2.attn.proj.weight', 'backbone.enc.enc3.block2.attn.proj.bias', 'backbone.enc.enc3.block2.norm2.0.weight', 'backbone.enc.enc3.block2.norm2.0.bias', 'backbone.enc.enc3.block2.mlp.0.fc1.weight', 'backbone.enc.enc3.block2.mlp.0.fc1.bias', 'backbone.enc.enc3.block2.mlp.0.fc2.weight', 'backbone.enc.enc3.block2.mlp.0.fc2.bias', 'backbone.enc.enc3.block3.cpe.0.weight', 'backbone.enc.enc3.block3.cpe.0.bias', 'backbone.enc.enc3.block3.cpe.1.weight', 'backbone.enc.enc3.block3.cpe.1.bias', 'backbone.enc.enc3.block3.cpe.2.weight', 'backbone.enc.enc3.block3.cpe.2.bias', 'backbone.enc.enc3.block3.norm1.0.weight', 'backbone.enc.enc3.block3.norm1.0.bias', 'backbone.enc.enc3.block3.attn.qkv.weight', 'backbone.enc.enc3.block3.attn.qkv.bias', 'backbone.enc.enc3.block3.attn.proj.weight', 'backbone.enc.enc3.block3.attn.proj.bias', 'backbone.enc.enc3.block3.norm2.0.weight', 'backbone.enc.enc3.block3.norm2.0.bias', 'backbone.enc.enc3.block3.mlp.0.fc1.weight', 'backbone.enc.enc3.block3.mlp.0.fc1.bias', 'backbone.enc.enc3.block3.mlp.0.fc2.weight', 'backbone.enc.enc3.block3.mlp.0.fc2.bias', 'backbone.enc.enc3.block4.cpe.0.weight', 'backbone.enc.enc3.block4.cpe.0.bias', 'backbone.enc.enc3.block4.cpe.1.weight', 'backbone.enc.enc3.block4.cpe.1.bias', 'backbone.enc.enc3.block4.cpe.2.weight', 'backbone.enc.enc3.block4.cpe.2.bias', 'backbone.enc.enc3.block4.norm1.0.weight', 'backbone.enc.enc3.block4.norm1.0.bias', 'backbone.enc.enc3.block4.attn.qkv.weight', 'backbone.enc.enc3.block4.attn.qkv.bias', 'backbone.enc.enc3.block4.attn.proj.weight', 'backbone.enc.enc3.block4.attn.proj.bias', 'backbone.enc.enc3.block4.norm2.0.weight', 'backbone.enc.enc3.block4.norm2.0.bias', 'backbone.enc.enc3.block4.mlp.0.fc1.weight', 'backbone.enc.enc3.block4.mlp.0.fc1.bias', 'backbone.enc.enc3.block4.mlp.0.fc2.weight', 'backbone.enc.enc3.block4.mlp.0.fc2.bias', 'backbone.enc.enc3.block5.cpe.0.weight', 'backbone.enc.enc3.block5.cpe.0.bias', 'backbone.enc.enc3.block5.cpe.1.weight', 'backbone.enc.enc3.block5.cpe.1.bias', 'backbone.enc.enc3.block5.cpe.2.weight', 'backbone.enc.enc3.block5.cpe.2.bias', 'backbone.enc.enc3.block5.norm1.0.weight', 'backbone.enc.enc3.block5.norm1.0.bias', 'backbone.enc.enc3.block5.attn.qkv.weight', 'backbone.enc.enc3.block5.attn.qkv.bias', 'backbone.enc.enc3.block5.attn.proj.weight', 'backbone.enc.enc3.block5.attn.proj.bias', 'backbone.enc.enc3.block5.norm2.0.weight', 'backbone.enc.enc3.block5.norm2.0.bias', 'backbone.enc.enc3.block5.mlp.0.fc1.weight', 'backbone.enc.enc3.block5.mlp.0.fc1.bias', 'backbone.enc.enc3.block5.mlp.0.fc2.weight', 'backbone.enc.enc3.block5.mlp.0.fc2.bias', 'backbone.enc.enc3.block6.cpe.0.weight', 'backbone.enc.enc3.block6.cpe.0.bias', 'backbone.enc.enc3.block6.cpe.1.weight', 'backbone.enc.enc3.block6.cpe.1.bias', 'backbone.enc.enc3.block6.cpe.2.weight', 'backbone.enc.enc3.block6.cpe.2.bias', 'backbone.enc.enc3.block6.norm1.0.weight', 'backbone.enc.enc3.block6.norm1.0.bias', 'backbone.enc.enc3.block6.attn.qkv.weight', 'backbone.enc.enc3.block6.attn.qkv.bias', 'backbone.enc.enc3.block6.attn.proj.weight', 'backbone.enc.enc3.block6.attn.proj.bias', 'backbone.enc.enc3.block6.norm2.0.weight', 'backbone.enc.enc3.block6.norm2.0.bias', 'backbone.enc.enc3.block6.mlp.0.fc1.weight', 'backbone.enc.enc3.block6.mlp.0.fc1.bias', 'backbone.enc.enc3.block6.mlp.0.fc2.weight', 'backbone.enc.enc3.block6.mlp.0.fc2.bias', 'backbone.enc.enc3.block7.cpe.0.weight', 'backbone.enc.enc3.block7.cpe.0.bias', 'backbone.enc.enc3.block7.cpe.1.weight', 'backbone.enc.enc3.block7.cpe.1.bias', 'backbone.enc.enc3.block7.cpe.2.weight', 'backbone.enc.enc3.block7.cpe.2.bias', 'backbone.enc.enc3.block7.norm1.0.weight', 'backbone.enc.enc3.block7.norm1.0.bias', 'backbone.enc.enc3.block7.attn.qkv.weight', 'backbone.enc.enc3.block7.attn.qkv.bias', 'backbone.enc.enc3.block7.attn.proj.weight', 'backbone.enc.enc3.block7.attn.proj.bias', 'backbone.enc.enc3.block7.norm2.0.weight', 'backbone.enc.enc3.block7.norm2.0.bias', 'backbone.enc.enc3.block7.mlp.0.fc1.weight', 'backbone.enc.enc3.block7.mlp.0.fc1.bias', 'backbone.enc.enc3.block7.mlp.0.fc2.weight', 'backbone.enc.enc3.block7.mlp.0.fc2.bias', 'backbone.enc.enc3.block8.cpe.0.weight', 'backbone.enc.enc3.block8.cpe.0.bias', 'backbone.enc.enc3.block8.cpe.1.weight', 'backbone.enc.enc3.block8.cpe.1.bias', 'backbone.enc.enc3.block8.cpe.2.weight', 'backbone.enc.enc3.block8.cpe.2.bias', 'backbone.enc.enc3.block8.norm1.0.weight', 'backbone.enc.enc3.block8.norm1.0.bias', 'backbone.enc.enc3.block8.attn.qkv.weight', 'backbone.enc.enc3.block8.attn.qkv.bias', 'backbone.enc.enc3.block8.attn.proj.weight', 'backbone.enc.enc3.block8.attn.proj.bias', 'backbone.enc.enc3.block8.norm2.0.weight', 'backbone.enc.enc3.block8.norm2.0.bias', 'backbone.enc.enc3.block8.mlp.0.fc1.weight', 'backbone.enc.enc3.block8.mlp.0.fc1.bias', 'backbone.enc.enc3.block8.mlp.0.fc2.weight', 'backbone.enc.enc3.block8.mlp.0.fc2.bias', 'backbone.enc.enc3.block9.cpe.0.weight', 'backbone.enc.enc3.block9.cpe.0.bias', 'backbone.enc.enc3.block9.cpe.1.weight', 'backbone.enc.enc3.block9.cpe.1.bias', 'backbone.enc.enc3.block9.cpe.2.weight', 'backbone.enc.enc3.block9.cpe.2.bias', 'backbone.enc.enc3.block9.norm1.0.weight', 'backbone.enc.enc3.block9.norm1.0.bias', 'backbone.enc.enc3.block9.attn.qkv.weight', 'backbone.enc.enc3.block9.attn.qkv.bias', 'backbone.enc.enc3.block9.attn.proj.weight', 'backbone.enc.enc3.block9.attn.proj.bias', 'backbone.enc.enc3.block9.norm2.0.weight', 'backbone.enc.enc3.block9.norm2.0.bias', 'backbone.enc.enc3.block9.mlp.0.fc1.weight', 'backbone.enc.enc3.block9.mlp.0.fc1.bias', 'backbone.enc.enc3.block9.mlp.0.fc2.weight', 'backbone.enc.enc3.block9.mlp.0.fc2.bias', 'backbone.enc.enc3.block10.cpe.0.weight', 'backbone.enc.enc3.block10.cpe.0.bias', 'backbone.enc.enc3.block10.cpe.1.weight', 'backbone.enc.enc3.block10.cpe.1.bias', 'backbone.enc.enc3.block10.cpe.2.weight', 'backbone.enc.enc3.block10.cpe.2.bias', 'backbone.enc.enc3.block10.norm1.0.weight', 'backbone.enc.enc3.block10.norm1.0.bias', 'backbone.enc.enc3.block10.attn.qkv.weight', 'backbone.enc.enc3.block10.attn.qkv.bias', 'backbone.enc.enc3.block10.attn.proj.weight', 'backbone.enc.enc3.block10.attn.proj.bias', 'backbone.enc.enc3.block10.norm2.0.weight', 'backbone.enc.enc3.block10.norm2.0.bias', 'backbone.enc.enc3.block10.mlp.0.fc1.weight', 'backbone.enc.enc3.block10.mlp.0.fc1.bias', 'backbone.enc.enc3.block10.mlp.0.fc2.weight', 'backbone.enc.enc3.block10.mlp.0.fc2.bias', 'backbone.enc.enc3.block11.cpe.0.weight', 'backbone.enc.enc3.block11.cpe.0.bias', 'backbone.enc.enc3.block11.cpe.1.weight', 'backbone.enc.enc3.block11.cpe.1.bias', 'backbone.enc.enc3.block11.cpe.2.weight', 'backbone.enc.enc3.block11.cpe.2.bias', 'backbone.enc.enc3.block11.norm1.0.weight', 'backbone.enc.enc3.block11.norm1.0.bias', 'backbone.enc.enc3.block11.attn.qkv.weight', 'backbone.enc.enc3.block11.attn.qkv.bias', 'backbone.enc.enc3.block11.attn.proj.weight', 'backbone.enc.enc3.block11.attn.proj.bias', 'backbone.enc.enc3.block11.norm2.0.weight', 'backbone.enc.enc3.block11.norm2.0.bias', 'backbone.enc.enc3.block11.mlp.0.fc1.weight', 'backbone.enc.enc3.block11.mlp.0.fc1.bias', 'backbone.enc.enc3.block11.mlp.0.fc2.weight', 'backbone.enc.enc3.block11.mlp.0.fc2.bias', 'backbone.enc.enc4.down.proj.weight', 'backbone.enc.enc4.down.proj.bias', 'backbone.enc.enc4.down.norm.0.weight', 'backbone.enc.enc4.down.norm.0.bias', 'backbone.enc.enc4.block0.cpe.0.weight', 'backbone.enc.enc4.block0.cpe.0.bias', 'backbone.enc.enc4.block0.cpe.1.weight', 'backbone.enc.enc4.block0.cpe.1.bias', 'backbone.enc.enc4.block0.cpe.2.weight', 'backbone.enc.enc4.block0.cpe.2.bias', 'backbone.enc.enc4.block0.norm1.0.weight', 'backbone.enc.enc4.block0.norm1.0.bias', 'backbone.enc.enc4.block0.attn.qkv.weight', 'backbone.enc.enc4.block0.attn.qkv.bias', 'backbone.enc.enc4.block0.attn.proj.weight', 'backbone.enc.enc4.block0.attn.proj.bias', 'backbone.enc.enc4.block0.norm2.0.weight', 'backbone.enc.enc4.block0.norm2.0.bias', 'backbone.enc.enc4.block0.mlp.0.fc1.weight', 'backbone.enc.enc4.block0.mlp.0.fc1.bias', 'backbone.enc.enc4.block0.mlp.0.fc2.weight', 'backbone.enc.enc4.block0.mlp.0.fc2.bias', 'backbone.enc.enc4.block1.cpe.0.weight', 'backbone.enc.enc4.block1.cpe.0.bias', 'backbone.enc.enc4.block1.cpe.1.weight', 'backbone.enc.enc4.block1.cpe.1.bias', 'backbone.enc.enc4.block1.cpe.2.weight', 'backbone.enc.enc4.block1.cpe.2.bias', 'backbone.enc.enc4.block1.norm1.0.weight', 'backbone.enc.enc4.block1.norm1.0.bias', 'backbone.enc.enc4.block1.attn.qkv.weight', 'backbone.enc.enc4.block1.attn.qkv.bias', 'backbone.enc.enc4.block1.attn.proj.weight', 'backbone.enc.enc4.block1.attn.proj.bias', 'backbone.enc.enc4.block1.norm2.0.weight', 'backbone.enc.enc4.block1.norm2.0.bias', 'backbone.enc.enc4.block1.mlp.0.fc1.weight', 'backbone.enc.enc4.block1.mlp.0.fc1.bias', 'backbone.enc.enc4.block1.mlp.0.fc2.weight', 'backbone.enc.enc4.block1.mlp.0.fc2.bias', 'backbone.enc.enc4.block2.cpe.0.weight', 'backbone.enc.enc4.block2.cpe.0.bias', 'backbone.enc.enc4.block2.cpe.1.weight', 'backbone.enc.enc4.block2.cpe.1.bias', 'backbone.enc.enc4.block2.cpe.2.weight', 'backbone.enc.enc4.block2.cpe.2.bias', 'backbone.enc.enc4.block2.norm1.0.weight', 'backbone.enc.enc4.block2.norm1.0.bias', 'backbone.enc.enc4.block2.attn.qkv.weight', 'backbone.enc.enc4.block2.attn.qkv.bias', 'backbone.enc.enc4.block2.attn.proj.weight', 'backbone.enc.enc4.block2.attn.proj.bias', 'backbone.enc.enc4.block2.norm2.0.weight', 'backbone.enc.enc4.block2.norm2.0.bias', 'backbone.enc.enc4.block2.mlp.0.fc1.weight', 'backbone.enc.enc4.block2.mlp.0.fc1.bias', 'backbone.enc.enc4.block2.mlp.0.fc2.weight', 'backbone.enc.enc4.block2.mlp.0.fc2.bias', 'backbone.dec.dec3.up.proj.0.weight', 'backbone.dec.dec3.up.proj.0.bias', 'backbone.dec.dec3.up.proj.1.weight', 'backbone.dec.dec3.up.proj.1.bias', 'backbone.dec.dec3.up.proj_skip.0.weight', 'backbone.dec.dec3.up.proj_skip.0.bias', 'backbone.dec.dec3.up.proj_skip.1.weight', 'backbone.dec.dec3.up.proj_skip.1.bias', 'backbone.dec.dec3.block0.cpe.0.weight', 'backbone.dec.dec3.block0.cpe.0.bias', 'backbone.dec.dec3.block0.cpe.1.weight', 'backbone.dec.dec3.block0.cpe.1.bias', 'backbone.dec.dec3.block0.cpe.2.weight', 'backbone.dec.dec3.block0.cpe.2.bias', 'backbone.dec.dec3.block0.norm1.0.weight', 'backbone.dec.dec3.block0.norm1.0.bias', 'backbone.dec.dec3.block0.attn.qkv.weight', 'backbone.dec.dec3.block0.attn.qkv.bias', 'backbone.dec.dec3.block0.attn.proj.weight', 'backbone.dec.dec3.block0.attn.proj.bias', 'backbone.dec.dec3.block0.norm2.0.weight', 'backbone.dec.dec3.block0.norm2.0.bias', 'backbone.dec.dec3.block0.mlp.0.fc1.weight', 'backbone.dec.dec3.block0.mlp.0.fc1.bias', 'backbone.dec.dec3.block0.mlp.0.fc2.weight', 'backbone.dec.dec3.block0.mlp.0.fc2.bias', 'backbone.dec.dec3.block1.cpe.0.weight', 'backbone.dec.dec3.block1.cpe.0.bias', 'backbone.dec.dec3.block1.cpe.1.weight', 'backbone.dec.dec3.block1.cpe.1.bias', 'backbone.dec.dec3.block1.cpe.2.weight', 'backbone.dec.dec3.block1.cpe.2.bias', 'backbone.dec.dec3.block1.norm1.0.weight', 'backbone.dec.dec3.block1.norm1.0.bias', 'backbone.dec.dec3.block1.attn.qkv.weight', 'backbone.dec.dec3.block1.attn.qkv.bias', 'backbone.dec.dec3.block1.attn.proj.weight', 'backbone.dec.dec3.block1.attn.proj.bias', 'backbone.dec.dec3.block1.norm2.0.weight', 'backbone.dec.dec3.block1.norm2.0.bias', 'backbone.dec.dec3.block1.mlp.0.fc1.weight', 'backbone.dec.dec3.block1.mlp.0.fc1.bias', 'backbone.dec.dec3.block1.mlp.0.fc2.weight', 'backbone.dec.dec3.block1.mlp.0.fc2.bias', 'backbone.dec.dec2.up.proj.0.weight', 'backbone.dec.dec2.up.proj.0.bias', 'backbone.dec.dec2.up.proj.1.weight', 'backbone.dec.dec2.up.proj.1.bias', 'backbone.dec.dec2.up.proj_skip.0.weight', 'backbone.dec.dec2.up.proj_skip.0.bias', 'backbone.dec.dec2.up.proj_skip.1.weight', 'backbone.dec.dec2.up.proj_skip.1.bias', 'backbone.dec.dec2.block0.cpe.0.weight', 'backbone.dec.dec2.block0.cpe.0.bias', 'backbone.dec.dec2.block0.cpe.1.weight', 'backbone.dec.dec2.block0.cpe.1.bias', 'backbone.dec.dec2.block0.cpe.2.weight', 'backbone.dec.dec2.block0.cpe.2.bias', 'backbone.dec.dec2.block0.norm1.0.weight', 'backbone.dec.dec2.block0.norm1.0.bias', 'backbone.dec.dec2.block0.attn.qkv.weight', 'backbone.dec.dec2.block0.attn.qkv.bias', 'backbone.dec.dec2.block0.attn.proj.weight', 'backbone.dec.dec2.block0.attn.proj.bias', 'backbone.dec.dec2.block0.norm2.0.weight', 'backbone.dec.dec2.block0.norm2.0.bias', 'backbone.dec.dec2.block0.mlp.0.fc1.weight', 'backbone.dec.dec2.block0.mlp.0.fc1.bias', 'backbone.dec.dec2.block0.mlp.0.fc2.weight', 'backbone.dec.dec2.block0.mlp.0.fc2.bias', 'backbone.dec.dec2.block1.cpe.0.weight', 'backbone.dec.dec2.block1.cpe.0.bias', 'backbone.dec.dec2.block1.cpe.1.weight', 'backbone.dec.dec2.block1.cpe.1.bias', 'backbone.dec.dec2.block1.cpe.2.weight', 'backbone.dec.dec2.block1.cpe.2.bias', 'backbone.dec.dec2.block1.norm1.0.weight', 'backbone.dec.dec2.block1.norm1.0.bias', 'backbone.dec.dec2.block1.attn.qkv.weight', 'backbone.dec.dec2.block1.attn.qkv.bias', 'backbone.dec.dec2.block1.attn.proj.weight', 'backbone.dec.dec2.block1.attn.proj.bias', 'backbone.dec.dec2.block1.norm2.0.weight', 'backbone.dec.dec2.block1.norm2.0.bias', 'backbone.dec.dec2.block1.mlp.0.fc1.weight', 'backbone.dec.dec2.block1.mlp.0.fc1.bias', 'backbone.dec.dec2.block1.mlp.0.fc2.weight', 'backbone.dec.dec2.block1.mlp.0.fc2.bias', 'backbone.dec.dec1.up.proj.0.weight', 'backbone.dec.dec1.up.proj.0.bias', 'backbone.dec.dec1.up.proj.1.weight', 'backbone.dec.dec1.up.proj.1.bias', 'backbone.dec.dec1.up.proj_skip.0.weight', 'backbone.dec.dec1.up.proj_skip.0.bias', 'backbone.dec.dec1.up.proj_skip.1.weight', 'backbone.dec.dec1.up.proj_skip.1.bias', 'backbone.dec.dec1.block0.cpe.0.weight', 'backbone.dec.dec1.block0.cpe.0.bias', 'backbone.dec.dec1.block0.cpe.1.weight', 'backbone.dec.dec1.block0.cpe.1.bias', 'backbone.dec.dec1.block0.cpe.2.weight', 'backbone.dec.dec1.block0.cpe.2.bias', 'backbone.dec.dec1.block0.norm1.0.weight', 'backbone.dec.dec1.block0.norm1.0.bias', 'backbone.dec.dec1.block0.attn.qkv.weight', 'backbone.dec.dec1.block0.attn.qkv.bias', 'backbone.dec.dec1.block0.attn.proj.weight', 'backbone.dec.dec1.block0.attn.proj.bias', 'backbone.dec.dec1.block0.norm2.0.weight', 'backbone.dec.dec1.block0.norm2.0.bias', 'backbone.dec.dec1.block0.mlp.0.fc1.weight', 'backbone.dec.dec1.block0.mlp.0.fc1.bias', 'backbone.dec.dec1.block0.mlp.0.fc2.weight', 'backbone.dec.dec1.block0.mlp.0.fc2.bias', 'backbone.dec.dec1.block1.cpe.0.weight', 'backbone.dec.dec1.block1.cpe.0.bias', 'backbone.dec.dec1.block1.cpe.1.weight', 'backbone.dec.dec1.block1.cpe.1.bias', 'backbone.dec.dec1.block1.cpe.2.weight', 'backbone.dec.dec1.block1.cpe.2.bias', 'backbone.dec.dec1.block1.norm1.0.weight', 'backbone.dec.dec1.block1.norm1.0.bias', 'backbone.dec.dec1.block1.attn.qkv.weight', 'backbone.dec.dec1.block1.attn.qkv.bias', 'backbone.dec.dec1.block1.attn.proj.weight', 'backbone.dec.dec1.block1.attn.proj.bias', 'backbone.dec.dec1.block1.norm2.0.weight', 'backbone.dec.dec1.block1.norm2.0.bias', 'backbone.dec.dec1.block1.mlp.0.fc1.weight', 'backbone.dec.dec1.block1.mlp.0.fc1.bias', 'backbone.dec.dec1.block1.mlp.0.fc2.weight', 'backbone.dec.dec1.block1.mlp.0.fc2.bias', 'backbone.dec.dec0.up.proj.0.weight', 'backbone.dec.dec0.up.proj.0.bias', 'backbone.dec.dec0.up.proj.1.weight', 'backbone.dec.dec0.up.proj.1.bias', 'backbone.dec.dec0.up.proj_skip.0.weight', 'backbone.dec.dec0.up.proj_skip.0.bias', 'backbone.dec.dec0.up.proj_skip.1.weight', 'backbone.dec.dec0.up.proj_skip.1.bias', 'backbone.dec.dec0.block0.cpe.0.weight', 'backbone.dec.dec0.block0.cpe.0.bias', 'backbone.dec.dec0.block0.cpe.1.weight', 'backbone.dec.dec0.block0.cpe.1.bias', 'backbone.dec.dec0.block0.cpe.2.weight', 'backbone.dec.dec0.block0.cpe.2.bias', 'backbone.dec.dec0.block0.norm1.0.weight', 'backbone.dec.dec0.block0.norm1.0.bias', 'backbone.dec.dec0.block0.attn.qkv.weight', 'backbone.dec.dec0.block0.attn.qkv.bias', 'backbone.dec.dec0.block0.attn.proj.weight', 'backbone.dec.dec0.block0.attn.proj.bias', 'backbone.dec.dec0.block0.norm2.0.weight', 'backbone.dec.dec0.block0.norm2.0.bias', 'backbone.dec.dec0.block0.mlp.0.fc1.weight', 'backbone.dec.dec0.block0.mlp.0.fc1.bias', 'backbone.dec.dec0.block0.mlp.0.fc2.weight', 'backbone.dec.dec0.block0.mlp.0.fc2.bias', 'backbone.dec.dec0.block1.cpe.0.weight', 'backbone.dec.dec0.block1.cpe.0.bias', 'backbone.dec.dec0.block1.cpe.1.weight', 'backbone.dec.dec0.block1.cpe.1.bias', 'backbone.dec.dec0.block1.cpe.2.weight', 'backbone.dec.dec0.block1.cpe.2.bias', 'backbone.dec.dec0.block1.norm1.0.weight', 'backbone.dec.dec0.block1.norm1.0.bias', 'backbone.dec.dec0.block1.attn.qkv.weight', 'backbone.dec.dec0.block1.attn.qkv.bias', 'backbone.dec.dec0.block1.attn.proj.weight', 'backbone.dec.dec0.block1.attn.proj.bias', 'backbone.dec.dec0.block1.norm2.0.weight', 'backbone.dec.dec0.block1.norm2.0.bias', 'backbone.dec.dec0.block1.mlp.0.fc1.weight', 'backbone.dec.dec0.block1.mlp.0.fc1.bias', 'backbone.dec.dec0.block1.mlp.0.fc2.weight', 'backbone.dec.dec0.block1.mlp.0.fc2.bias']
[2025-04-08 13:50:56,247 INFO train.py line 157 3298914] >>>>>>>>>>>>>>>> Start Training >>>>>>>>>>>>>>>>
[2025-04-08 13:51:17,309 INFO misc.py line 113 3298914] Train: [1/100][1/2402] Data 2.924 (2.924) Batch 20.336 (20.336) Remain 1356:51:59 loss: 4.6427 Lr: 0.00020
[2025-04-08 13:51:18,933 INFO misc.py line 113 3298914] Train: [1/100][2/2402] Data 0.003 (0.003) Batch 1.623 (1.623) Remain 108:15:22 loss: 4.6247 Lr: 0.00020
[2025-04-08 13:51:19,317 INFO misc.py line 113 3298914] Train: [1/100][3/2402] Data 0.003 (0.003) Batch 0.384 (0.384) Remain 25:38:10 loss: 4.1538 Lr: 0.00020
[2025-04-08 13:51:19,833 INFO misc.py line 113 3298914] Train: [1/100][4/2402] Data 0.003 (0.003) Batch 0.516 (0.516) Remain 34:25:08 loss: 4.0579 Lr: 0.00020
[2025-04-08 13:51:20,264 INFO misc.py line 113 3298914] Train: [1/100][5/2402] Data 0.003 (0.003) Batch 0.431 (0.474) Remain 31:36:03 loss: 3.8539 Lr: 0.00020
[2025-04-08 13:51:20,710 INFO misc.py line 113 3298914] Train: [1/100][6/2402] Data 0.003 (0.003) Batch 0.445 (0.464) Remain 30:58:01 loss: 3.5989 Lr: 0.00020
[2025-04-08 13:51:21,131 INFO misc.py line 113 3298914] Train: [1/100][7/2402] Data 0.003 (0.003) Batch 0.421 (0.453) Remain 30:14:40 loss: 3.2657 Lr: 0.00020
[2025-04-08 13:51:21,600 INFO misc.py line 113 3298914] Train: [1/100][8/2402] Data 0.004 (0.003) Batch 0.469 (0.456) Remain 30:27:21 loss: 3.4599 Lr: 0.00020
[2025-04-08 13:51:22,065 INFO misc.py line 113 3298914] Train: [1/100][9/2402] Data 0.004 (0.003) Batch 0.466 (0.458) Remain 30:33:31 loss: 3.1927 Lr: 0.00020
[2025-04-08 13:51:22,492 INFO misc.py line 113 3298914] Train: [1/100][10/2402] Data 0.003 (0.003) Batch 0.426 (0.453) Remain 30:15:17 loss: 2.9078 Lr: 0.00020
[2025-04-08 13:51:22,991 INFO misc.py line 113 3298914] Train: [1/100][11/2402] Data 0.003 (0.003) Batch 0.499 (0.459) Remain 30:38:14 loss: 3.0643 Lr: 0.00020
[2025-04-08 13:51:23,572 INFO misc.py line 113 3298914] Train: [1/100][12/2402] Data 0.003 (0.003) Batch 0.580 (0.473) Remain 31:32:06 loss: 3.2662 Lr: 0.00020
[2025-04-08 13:51:24,136 INFO misc.py line 113 3298914] Train: [1/100][13/2402] Data 0.004 (0.003) Batch 0.565 (0.482) Remain 32:09:06 loss: 3.3094 Lr: 0.00020
[2025-04-08 13:51:24,629 INFO misc.py line 113 3298914] Train: [1/100][14/2402] Data 0.003 (0.003) Batch 0.493 (0.483) Remain 32:13:04 loss: 3.3072 Lr: 0.00020
[2025-04-08 13:51:25,022 INFO misc.py line 113 3298914] Train: [1/100][15/2402] Data 0.004 (0.003) Batch 0.392 (0.475) Remain 31:42:53 loss: 3.1786 Lr: 0.00020
[2025-04-08 13:51:25,594 INFO misc.py line 113 3298914] Train: [1/100][16/2402] Data 0.004 (0.003) Batch 0.572 (0.483) Remain 32:12:29 loss: 3.1543 Lr: 0.00020
[2025-04-08 13:51:26,162 INFO misc.py line 113 3298914] Train: [1/100][17/2402] Data 0.004 (0.004) Batch 0.569 (0.489) Remain 32:37:10 loss: 2.8392 Lr: 0.00020
[2025-04-08 13:51:26,689 INFO misc.py line 113 3298914] Train: [1/100][18/2402] Data 0.004 (0.004) Batch 0.527 (0.491) Remain 32:47:18 loss: 2.6872 Lr: 0.00020
[2025-04-08 13:51:27,247 INFO misc.py line 113 3298914] Train: [1/100][19/2402] Data 0.003 (0.004) Batch 0.558 (0.496) Remain 33:04:00 loss: 2.9358 Lr: 0.00020
[2025-04-08 13:51:27,655 INFO misc.py line 113 3298914] Train: [1/100][20/2402] Data 0.003 (0.004) Batch 0.407 (0.490) Remain 32:43:10 loss: 2.4313 Lr: 0.00020
[2025-04-08 13:51:28,086 INFO misc.py line 113 3298914] Train: [1/100][21/2402] Data 0.003 (0.004) Batch 0.432 (0.487) Remain 32:30:09 loss: 2.3608 Lr: 0.00020
[2025-04-08 13:51:28,642 INFO misc.py line 113 3298914] Train: [1/100][22/2402] Data 0.003 (0.004) Batch 0.556 (0.491) Remain 32:44:34 loss: 3.0353 Lr: 0.00020
[2025-04-08 13:51:29,147 INFO misc.py line 113 3298914] Train: [1/100][23/2402] Data 0.003 (0.004) Batch 0.505 (0.491) Remain 32:47:19 loss: 2.5818 Lr: 0.00020
[2025-04-08 13:51:29,595 INFO misc.py line 113 3298914] Train: [1/100][24/2402] Data 0.003 (0.003) Batch 0.449 (0.489) Remain 32:39:08 loss: 2.5521 Lr: 0.00020
[2025-04-08 13:51:30,134 INFO misc.py line 113 3298914] Train: [1/100][25/2402] Data 0.004 (0.003) Batch 0.539 (0.492) Remain 32:48:05 loss: 2.9486 Lr: 0.00020
[2025-04-08 13:51:30,639 INFO misc.py line 113 3298914] Train: [1/100][26/2402] Data 0.004 (0.004) Batch 0.505 (0.492) Remain 32:50:25 loss: 2.7989 Lr: 0.00020
[2025-04-08 13:51:31,216 INFO misc.py line 113 3298914] Train: [1/100][27/2402] Data 0.003 (0.003) Batch 0.577 (0.496) Remain 33:04:30 loss: 2.8830 Lr: 0.00020
[2025-04-08 13:51:31,675 INFO misc.py line 113 3298914] Train: [1/100][28/2402] Data 0.004 (0.003) Batch 0.459 (0.494) Remain 32:58:35 loss: 2.7212 Lr: 0.00020
[2025-04-08 13:51:32,207 INFO misc.py line 113 3298914] Train: [1/100][29/2402] Data 0.003 (0.003) Batch 0.532 (0.496) Remain 33:04:26 loss: 2.7299 Lr: 0.00020
[2025-04-08 13:51:32,678 INFO misc.py line 113 3298914] Train: [1/100][30/2402] Data 0.003 (0.003) Batch 0.471 (0.495) Remain 33:00:45 loss: 2.8262 Lr: 0.00020
[2025-04-08 13:51:33,132 INFO misc.py line 113 3298914] Train: [1/100][31/2402] Data 0.004 (0.003) Batch 0.454 (0.493) Remain 32:54:54 loss: 3.0678 Lr: 0.00020
[2025-04-08 13:51:33,651 INFO misc.py line 113 3298914] Train: [1/100][32/2402] Data 0.003 (0.003) Batch 0.519 (0.494) Remain 32:58:23 loss: 2.4305 Lr: 0.00020
[2025-04-08 13:51:34,208 INFO misc.py line 113 3298914] Train: [1/100][33/2402] Data 0.003 (0.003) Batch 0.558 (0.496) Remain 33:06:50 loss: 2.9769 Lr: 0.00020
[2025-04-08 13:51:34,615 INFO misc.py line 113 3298914] Train: [1/100][34/2402] Data 0.003 (0.003) Batch 0.406 (0.493) Remain 32:55:12 loss: 2.7781 Lr: 0.00020
[2025-04-08 13:51:35,026 INFO misc.py line 113 3298914] Train: [1/100][35/2402] Data 0.003 (0.003) Batch 0.411 (0.491) Remain 32:44:54 loss: 2.7044 Lr: 0.00020
[2025-04-08 13:51:35,460 INFO misc.py line 113 3298914] Train: [1/100][36/2402] Data 0.003 (0.003) Batch 0.434 (0.489) Remain 32:38:01 loss: 2.4099 Lr: 0.00020
[2025-04-08 13:51:35,975 INFO misc.py line 113 3298914] Train: [1/100][37/2402] Data 0.003 (0.003) Batch 0.515 (0.490) Remain 32:40:59 loss: 2.7829 Lr: 0.00020
[2025-04-08 13:51:36,479 INFO misc.py line 113 3298914] Train: [1/100][38/2402] Data 0.004 (0.003) Batch 0.505 (0.490) Remain 32:42:40 loss: 2.9688 Lr: 0.00020
[2025-04-08 13:51:36,899 INFO misc.py line 113 3298914] Train: [1/100][39/2402] Data 0.004 (0.003) Batch 0.419 (0.488) Remain 32:34:45 loss: 2.6901 Lr: 0.00020
[2025-04-08 13:51:37,280 INFO misc.py line 113 3298914] Train: [1/100][40/2402] Data 0.004 (0.003) Batch 0.382 (0.485) Remain 32:23:12 loss: 3.1470 Lr: 0.00020
[2025-04-08 13:51:37,718 INFO misc.py line 113 3298914] Train: [1/100][41/2402] Data 0.003 (0.003) Batch 0.438 (0.484) Remain 32:18:08 loss: 2.4712 Lr: 0.00020
[2025-04-08 13:51:38,089 INFO misc.py line 113 3298914] Train: [1/100][42/2402] Data 0.004 (0.003) Batch 0.372 (0.481) Remain 32:06:35 loss: 2.7104 Lr: 0.00020
[2025-04-08 13:51:38,596 INFO misc.py line 113 3298914] Train: [1/100][43/2402] Data 0.003 (0.003) Batch 0.506 (0.482) Remain 32:09:03 loss: 2.6679 Lr: 0.00020
[2025-04-08 13:51:39,103 INFO misc.py line 113 3298914] Train: [1/100][44/2402] Data 0.004 (0.003) Batch 0.508 (0.483) Remain 32:11:32 loss: 2.6734 Lr: 0.00020
[2025-04-08 13:51:39,568 INFO misc.py line 113 3298914] Train: [1/100][45/2402] Data 0.003 (0.003) Batch 0.465 (0.482) Remain 32:09:50 loss: 2.5689 Lr: 0.00020
[2025-04-08 13:51:40,052 INFO misc.py line 113 3298914] Train: [1/100][46/2402] Data 0.003 (0.003) Batch 0.484 (0.482) Remain 32:10:02 loss: 2.3621 Lr: 0.00020
[2025-04-08 13:51:40,558 INFO misc.py line 113 3298914] Train: [1/100][47/2402] Data 0.004 (0.003) Batch 0.506 (0.483) Remain 32:12:12 loss: 2.6773 Lr: 0.00020
[2025-04-08 13:51:41,119 INFO misc.py line 113 3298914] Train: [1/100][48/2402] Data 0.003 (0.003) Batch 0.560 (0.484) Remain 32:19:05 loss: 2.5170 Lr: 0.00020
[2025-04-08 13:51:41,541 INFO misc.py line 113 3298914] Train: [1/100][49/2402] Data 0.004 (0.003) Batch 0.422 (0.483) Remain 32:13:38 loss: 2.7144 Lr: 0.00020
[2025-04-08 13:51:41,893 INFO misc.py line 113 3298914] Train: [1/100][50/2402] Data 0.003 (0.003) Batch 0.352 (0.480) Remain 32:02:27 loss: 2.4412 Lr: 0.00020
[2025-04-08 13:51:42,422 INFO misc.py line 113 3298914] Train: [1/100][51/2402] Data 0.004 (0.003) Batch 0.529 (0.481) Remain 32:06:31 loss: 2.6224 Lr: 0.00020
[2025-04-08 13:51:42,843 INFO misc.py line 113 3298914] Train: [1/100][52/2402] Data 0.004 (0.004) Batch 0.422 (0.480) Remain 32:01:38 loss: 2.8359 Lr: 0.00020
[2025-04-08 13:51:43,354 INFO misc.py line 113 3298914] Train: [1/100][53/2402] Data 0.003 (0.003) Batch 0.511 (0.481) Remain 32:04:07 loss: 2.3525 Lr: 0.00020
[2025-04-08 13:51:43,760 INFO misc.py line 113 3298914] Train: [1/100][54/2402] Data 0.004 (0.003) Batch 0.406 (0.479) Remain 31:58:15 loss: 2.7592 Lr: 0.00020
[2025-04-08 13:51:44,298 INFO misc.py line 113 3298914] Train: [1/100][55/2402] Data 0.004 (0.004) Batch 0.537 (0.480) Remain 32:02:43 loss: 2.4060 Lr: 0.00020
[2025-04-08 13:51:44,779 INFO misc.py line 113 3298914] Train: [1/100][56/2402] Data 0.003 (0.003) Batch 0.481 (0.480) Remain 32:02:45 loss: 2.3642 Lr: 0.00020
[2025-04-08 13:51:45,277 INFO misc.py line 113 3298914] Train: [1/100][57/2402] Data 0.004 (0.003) Batch 0.498 (0.481) Remain 32:04:02 loss: 2.3738 Lr: 0.00020
[2025-04-08 13:51:45,862 INFO misc.py line 113 3298914] Train: [1/100][58/2402] Data 0.003 (0.003) Batch 0.585 (0.483) Remain 32:11:36 loss: 2.3344 Lr: 0.00020
[2025-04-08 13:51:46,225 INFO misc.py line 113 3298914] Train: [1/100][59/2402] Data 0.004 (0.004) Batch 0.364 (0.480) Remain 32:03:05 loss: 2.2604 Lr: 0.00020
[2025-04-08 13:51:46,808 INFO misc.py line 113 3298914] Train: [1/100][60/2402] Data 0.003 (0.004) Batch 0.583 (0.482) Remain 32:10:15 loss: 2.2781 Lr: 0.00020
[2025-04-08 13:51:47,339 INFO misc.py line 113 3298914] Train: [1/100][61/2402] Data 0.003 (0.003) Batch 0.532 (0.483) Remain 32:13:39 loss: 2.4575 Lr: 0.00020
[2025-04-08 13:51:47,905 INFO misc.py line 113 3298914] Train: [1/100][62/2402] Data 0.003 (0.003) Batch 0.566 (0.485) Remain 32:19:16 loss: 2.4224 Lr: 0.00020
[2025-04-08 13:51:48,365 INFO misc.py line 113 3298914] Train: [1/100][63/2402] Data 0.003 (0.003) Batch 0.459 (0.484) Remain 32:17:35 loss: 2.4316 Lr: 0.00020
[2025-04-08 13:51:48,894 INFO misc.py line 113 3298914] Train: [1/100][64/2402] Data 0.003 (0.003) Batch 0.529 (0.485) Remain 32:20:31 loss: 2.4755 Lr: 0.00020
[2025-04-08 13:51:49,372 INFO misc.py line 113 3298914] Train: [1/100][65/2402] Data 0.004 (0.003) Batch 0.478 (0.485) Remain 32:20:04 loss: 2.0971 Lr: 0.00020
[2025-04-08 13:51:49,879 INFO misc.py line 113 3298914] Train: [1/100][66/2402] Data 0.003 (0.003) Batch 0.507 (0.485) Remain 32:21:28 loss: 2.5108 Lr: 0.00020
[2025-04-08 13:51:50,348 INFO misc.py line 113 3298914] Train: [1/100][67/2402] Data 0.003 (0.003) Batch 0.469 (0.485) Remain 32:20:27 loss: 2.6103 Lr: 0.00020
[2025-04-08 13:51:50,904 INFO misc.py line 113 3298914] Train: [1/100][68/2402] Data 0.004 (0.003) Batch 0.556 (0.486) Remain 32:24:50 loss: 2.5347 Lr: 0.00020
[2025-04-08 13:51:51,607 INFO misc.py line 113 3298914] Train: [1/100][69/2402] Data 0.003 (0.003) Batch 0.703 (0.489) Remain 32:37:58 loss: 2.9256 Lr: 0.00020
[2025-04-08 13:51:52,073 INFO misc.py line 113 3298914] Train: [1/100][70/2402] Data 0.004 (0.003) Batch 0.467 (0.489) Remain 32:36:38 loss: 2.0460 Lr: 0.00020
[2025-04-08 13:51:52,543 INFO misc.py line 113 3298914] Train: [1/100][71/2402] Data 0.004 (0.003) Batch 0.470 (0.489) Remain 32:35:29 loss: 2.2587 Lr: 0.00020
[2025-04-08 13:51:53,052 INFO misc.py line 113 3298914] Train: [1/100][72/2402] Data 0.004 (0.003) Batch 0.508 (0.489) Remain 32:36:37 loss: 2.3761 Lr: 0.00020
[2025-04-08 13:51:53,465 INFO misc.py line 113 3298914] Train: [1/100][73/2402] Data 0.004 (0.004) Batch 0.413 (0.488) Remain 32:32:17 loss: 2.1371 Lr: 0.00020
[2025-04-08 13:51:54,001 INFO misc.py line 113 3298914] Train: [1/100][74/2402] Data 0.003 (0.004) Batch 0.536 (0.488) Remain 32:35:00 loss: 2.5981 Lr: 0.00020
[2025-04-08 13:51:54,513 INFO misc.py line 113 3298914] Train: [1/100][75/2402] Data 0.004 (0.004) Batch 0.513 (0.489) Remain 32:36:20 loss: 2.1668 Lr: 0.00020
[2025-04-08 13:51:55,013 INFO misc.py line 113 3298914] Train: [1/100][76/2402] Data 0.003 (0.003) Batch 0.500 (0.489) Remain 32:36:55 loss: 2.6750 Lr: 0.00020
[2025-04-08 13:51:55,520 INFO misc.py line 113 3298914] Train: [1/100][77/2402] Data 0.004 (0.003) Batch 0.507 (0.489) Remain 32:37:53 loss: 2.1681 Lr: 0.00020
[2025-04-08 13:51:56,058 INFO misc.py line 113 3298914] Train: [1/100][78/2402] Data 0.003 (0.003) Batch 0.538 (0.490) Remain 32:40:30 loss: 2.5075 Lr: 0.00020
[2025-04-08 13:51:56,490 INFO misc.py line 113 3298914] Train: [1/100][79/2402] Data 0.004 (0.003) Batch 0.431 (0.489) Remain 32:37:24 loss: 2.7990 Lr: 0.00020
[2025-04-08 13:51:56,928 INFO misc.py line 113 3298914] Train: [1/100][80/2402] Data 0.004 (0.004) Batch 0.438 (0.488) Remain 32:34:46 loss: 2.7011 Lr: 0.00020
[2025-04-08 13:51:57,424 INFO misc.py line 113 3298914] Train: [1/100][81/2402] Data 0.004 (0.004) Batch 0.496 (0.489) Remain 32:35:09 loss: 2.5857 Lr: 0.00020
[2025-04-08 13:51:57,835 INFO misc.py line 113 3298914] Train: [1/100][82/2402] Data 0.004 (0.004) Batch 0.411 (0.488) Remain 32:31:12 loss: 2.3401 Lr: 0.00020
[2025-04-08 13:51:58,304 INFO misc.py line 113 3298914] Train: [1/100][83/2402] Data 0.003 (0.004) Batch 0.469 (0.487) Remain 32:30:15 loss: 2.4185 Lr: 0.00020
[2025-04-08 13:51:58,748 INFO misc.py line 113 3298914] Train: [1/100][84/2402] Data 0.004 (0.004) Batch 0.444 (0.487) Remain 32:28:06 loss: 2.5745 Lr: 0.00020
[2025-04-08 13:51:59,331 INFO misc.py line 113 3298914] Train: [1/100][85/2402] Data 0.003 (0.004) Batch 0.583 (0.488) Remain 32:32:48 loss: 2.1089 Lr: 0.00020
[2025-04-08 13:51:59,853 INFO misc.py line 113 3298914] Train: [1/100][86/2402] Data 0.004 (0.004) Batch 0.522 (0.488) Remain 32:34:26 loss: 2.4404 Lr: 0.00020
[2025-04-08 13:52:00,378 INFO misc.py line 113 3298914] Train: [1/100][87/2402] Data 0.004 (0.004) Batch 0.525 (0.489) Remain 32:36:10 loss: 2.6194 Lr: 0.00020
[2025-04-08 13:52:00,854 INFO misc.py line 113 3298914] Train: [1/100][88/2402] Data 0.004 (0.004) Batch 0.476 (0.489) Remain 32:35:33 loss: 2.7674 Lr: 0.00020
[2025-04-08 13:52:01,341 INFO misc.py line 113 3298914] Train: [1/100][89/2402] Data 0.004 (0.004) Batch 0.487 (0.489) Remain 32:35:28 loss: 2.2038 Lr: 0.00020
[2025-04-08 13:52:01,704 INFO misc.py line 113 3298914] Train: [1/100][90/2402] Data 0.003 (0.004) Batch 0.363 (0.487) Remain 32:29:41 loss: 2.6749 Lr: 0.00020
[2025-04-08 13:52:02,101 INFO misc.py line 113 3298914] Train: [1/100][91/2402] Data 0.004 (0.004) Batch 0.397 (0.486) Remain 32:25:35 loss: 2.4488 Lr: 0.00020
[2025-04-08 13:52:02,587 INFO misc.py line 113 3298914] Train: [1/100][92/2402] Data 0.004 (0.004) Batch 0.485 (0.486) Remain 32:25:33 loss: 2.1547 Lr: 0.00020
[2025-04-08 13:52:03,059 INFO misc.py line 113 3298914] Train: [1/100][93/2402] Data 0.003 (0.004) Batch 0.473 (0.486) Remain 32:24:56 loss: 2.3354 Lr: 0.00020
[2025-04-08 13:52:03,629 INFO misc.py line 113 3298914] Train: [1/100][94/2402] Data 0.003 (0.004) Batch 0.569 (0.487) Remain 32:28:36 loss: 2.2789 Lr: 0.00020
[2025-04-08 13:52:04,126 INFO misc.py line 113 3298914] Train: [1/100][95/2402] Data 0.003 (0.004) Batch 0.498 (0.487) Remain 32:29:03 loss: 2.1510 Lr: 0.00020
[2025-04-08 13:52:04,559 INFO misc.py line 113 3298914] Train: [1/100][96/2402] Data 0.004 (0.004) Batch 0.433 (0.486) Remain 32:26:43 loss: 2.3572 Lr: 0.00020
[2025-04-08 13:52:05,158 INFO misc.py line 113 3298914] Train: [1/100][97/2402] Data 0.004 (0.004) Batch 0.598 (0.488) Remain 32:31:28 loss: 2.1831 Lr: 0.00020
[2025-04-08 13:52:05,576 INFO misc.py line 113 3298914] Train: [1/100][98/2402] Data 0.004 (0.004) Batch 0.419 (0.487) Remain 32:28:34 loss: 2.0214 Lr: 0.00020
[2025-04-08 13:52:06,122 INFO misc.py line 113 3298914] Train: [1/100][99/2402] Data 0.003 (0.004) Batch 0.546 (0.488) Remain 32:31:00 loss: 2.4810 Lr: 0.00020
[2025-04-08 13:52:06,678 INFO misc.py line 113 3298914] Train: [1/100][100/2402] Data 0.004 (0.004) Batch 0.556 (0.488) Remain 32:33:49 loss: 2.0371 Lr: 0.00020
[2025-04-08 13:52:07,240 INFO misc.py line 113 3298914] Train: [1/100][101/2402] Data 0.004 (0.004) Batch 0.562 (0.489) Remain 32:36:50 loss: 2.1805 Lr: 0.00020
[2025-04-08 13:52:07,713 INFO misc.py line 113 3298914] Train: [1/100][102/2402] Data 0.004 (0.004) Batch 0.472 (0.489) Remain 32:36:09 loss: 2.2460 Lr: 0.00020
[2025-04-08 13:52:08,198 INFO misc.py line 113 3298914] Train: [1/100][103/2402] Data 0.004 (0.004) Batch 0.485 (0.489) Remain 32:35:59 loss: 2.6230 Lr: 0.00020
[2025-04-08 13:52:08,780 INFO misc.py line 113 3298914] Train: [1/100][104/2402] Data 0.004 (0.004) Batch 0.582 (0.490) Remain 32:39:40 loss: 2.0526 Lr: 0.00020
[2025-04-08 13:52:09,112 INFO misc.py line 113 3298914] Train: [1/100][105/2402] Data 0.003 (0.004) Batch 0.332 (0.488) Remain 32:33:28 loss: 2.7798 Lr: 0.00020
[2025-04-08 13:52:09,525 INFO misc.py line 113 3298914] Train: [1/100][106/2402] Data 0.003 (0.004) Batch 0.413 (0.487) Remain 32:30:34 loss: 2.4078 Lr: 0.00020
[2025-04-08 13:52:10,039 INFO misc.py line 113 3298914] Train: [1/100][107/2402] Data 0.004 (0.004) Batch 0.514 (0.488) Remain 32:31:34 loss: 2.3529 Lr: 0.00020
[2025-04-08 13:52:10,618 INFO misc.py line 113 3298914] Train: [1/100][108/2402] Data 0.003 (0.004) Batch 0.580 (0.489) Remain 32:35:04 loss: 2.0794 Lr: 0.00020
[2025-04-08 13:52:11,057 INFO misc.py line 113 3298914] Train: [1/100][109/2402] Data 0.003 (0.004) Batch 0.439 (0.488) Remain 32:33:10 loss: 1.9196 Lr: 0.00020
[2025-04-08 13:52:11,502 INFO misc.py line 113 3298914] Train: [1/100][110/2402] Data 0.003 (0.004) Batch 0.445 (0.488) Remain 32:31:33 loss: 2.4981 Lr: 0.00020
[2025-04-08 13:52:12,032 INFO misc.py line 113 3298914] Train: [1/100][111/2402] Data 0.003 (0.004) Batch 0.530 (0.488) Remain 32:33:06 loss: 2.1326 Lr: 0.00020
[2025-04-08 13:52:12,524 INFO misc.py line 113 3298914] Train: [1/100][112/2402] Data 0.004 (0.004) Batch 0.492 (0.488) Remain 32:33:14 loss: 2.7699 Lr: 0.00020
[2025-04-08 13:52:12,990 INFO misc.py line 113 3298914] Train: [1/100][113/2402] Data 0.003 (0.004) Batch 0.466 (0.488) Remain 32:32:25 loss: 2.4145 Lr: 0.00020
[2025-04-08 13:52:13,533 INFO misc.py line 113 3298914] Train: [1/100][114/2402] Data 0.004 (0.004) Batch 0.543 (0.488) Remain 32:34:24 loss: 2.0861 Lr: 0.00020
[2025-04-08 13:52:14,052 INFO misc.py line 113 3298914] Train: [1/100][115/2402] Data 0.003 (0.004) Batch 0.519 (0.489) Remain 32:35:30 loss: 2.6269 Lr: 0.00020
[2025-04-08 13:52:14,496 INFO misc.py line 113 3298914] Train: [1/100][116/2402] Data 0.003 (0.004) Batch 0.444 (0.488) Remain 32:33:53 loss: 1.9810 Lr: 0.00020
[2025-04-08 13:52:15,014 INFO misc.py line 113 3298914] Train: [1/100][117/2402] Data 0.004 (0.004) Batch 0.518 (0.489) Remain 32:34:56 loss: 2.4191 Lr: 0.00020
[2025-04-08 13:52:15,505 INFO misc.py line 113 3298914] Train: [1/100][118/2402] Data 0.003 (0.004) Batch 0.491 (0.489) Remain 32:34:59 loss: 2.8030 Lr: 0.00020
[2025-04-08 13:52:16,047 INFO misc.py line 113 3298914] Train: [1/100][119/2402] Data 0.004 (0.004) Batch 0.542 (0.489) Remain 32:36:50 loss: 2.5506 Lr: 0.00020
[2025-04-08 13:52:16,583 INFO misc.py line 113 3298914] Train: [1/100][120/2402] Data 0.003 (0.004) Batch 0.537 (0.489) Remain 32:38:27 loss: 2.1069 Lr: 0.00020
[2025-04-08 13:52:16,873 INFO misc.py line 113 3298914] Train: [1/100][121/2402] Data 0.004 (0.004) Batch 0.290 (0.488) Remain 32:31:40 loss: 3.0051 Lr: 0.00020
[2025-04-08 13:52:17,230 INFO misc.py line 113 3298914] Train: [1/100][122/2402] Data 0.003 (0.004) Batch 0.358 (0.487) Remain 32:27:16 loss: 2.5271 Lr: 0.00020
[2025-04-08 13:52:17,794 INFO misc.py line 113 3298914] Train: [1/100][123/2402] Data 0.003 (0.004) Batch 0.563 (0.487) Remain 32:29:49 loss: 2.0545 Lr: 0.00020
[2025-04-08 13:52:18,293 INFO misc.py line 113 3298914] Train: [1/100][124/2402] Data 0.004 (0.004) Batch 0.499 (0.487) Remain 32:30:12 loss: 2.4346 Lr: 0.00020
[2025-04-08 13:52:18,809 INFO misc.py line 113 3298914] Train: [1/100][125/2402] Data 0.004 (0.004) Batch 0.516 (0.488) Remain 32:31:08 loss: 2.1771 Lr: 0.00020
[2025-04-08 13:52:19,371 INFO misc.py line 113 3298914] Train: [1/100][126/2402] Data 0.004 (0.004) Batch 0.562 (0.488) Remain 32:33:32 loss: 2.3891 Lr: 0.00020
[2025-04-08 13:52:19,806 INFO misc.py line 113 3298914] Train: [1/100][127/2402] Data 0.004 (0.004) Batch 0.435 (0.488) Remain 32:31:49 loss: 1.9257 Lr: 0.00020
[2025-04-08 13:52:20,303 INFO misc.py line 113 3298914] Train: [1/100][128/2402] Data 0.004 (0.004) Batch 0.497 (0.488) Remain 32:32:06 loss: 1.8928 Lr: 0.00020
[2025-04-08 13:52:20,766 INFO misc.py line 113 3298914] Train: [1/100][129/2402] Data 0.003 (0.004) Batch 0.463 (0.488) Remain 32:31:18 loss: 2.4060 Lr: 0.00020
[2025-04-08 13:52:21,335 INFO misc.py line 113 3298914] Train: [1/100][130/2402] Data 0.004 (0.004) Batch 0.569 (0.488) Remain 32:33:52 loss: 2.2116 Lr: 0.00020
[2025-04-08 13:52:21,849 INFO misc.py line 113 3298914] Train: [1/100][131/2402] Data 0.004 (0.004) Batch 0.514 (0.489) Remain 32:34:40 loss: 2.3295 Lr: 0.00020
[2025-04-08 13:52:22,334 INFO misc.py line 113 3298914] Train: [1/100][132/2402] Data 0.003 (0.004) Batch 0.485 (0.488) Remain 32:34:32 loss: 2.0396 Lr: 0.00020
[2025-04-08 13:52:22,819 INFO misc.py line 113 3298914] Train: [1/100][133/2402] Data 0.004 (0.004) Batch 0.485 (0.488) Remain 32:34:26 loss: 2.0326 Lr: 0.00020
[2025-04-08 13:52:23,307 INFO misc.py line 113 3298914] Train: [1/100][134/2402] Data 0.004 (0.004) Batch 0.488 (0.488) Remain 32:34:24 loss: 2.9553 Lr: 0.00020
[2025-04-08 13:52:23,821 INFO misc.py line 113 3298914] Train: [1/100][135/2402] Data 0.003 (0.004) Batch 0.514 (0.489) Remain 32:35:10 loss: 2.3967 Lr: 0.00020
[2025-04-08 13:52:24,361 INFO misc.py line 113 3298914] Train: [1/100][136/2402] Data 0.004 (0.004) Batch 0.540 (0.489) Remain 32:36:42 loss: 2.2316 Lr: 0.00020
[2025-04-08 13:52:24,714 INFO misc.py line 113 3298914] Train: [1/100][137/2402] Data 0.004 (0.004) Batch 0.353 (0.488) Remain 32:32:38 loss: 2.5265 Lr: 0.00020
[2025-04-08 13:52:25,129 INFO misc.py line 113 3298914] Train: [1/100][138/2402] Data 0.004 (0.004) Batch 0.415 (0.487) Remain 32:30:28 loss: 2.2705 Lr: 0.00020
[2025-04-08 13:52:25,565 INFO misc.py line 113 3298914] Train: [1/100][139/2402] Data 0.003 (0.004) Batch 0.436 (0.487) Remain 32:28:57 loss: 2.4920 Lr: 0.00020
[2025-04-08 13:52:26,078 INFO misc.py line 113 3298914] Train: [1/100][140/2402] Data 0.003 (0.004) Batch 0.512 (0.487) Remain 32:29:41 loss: 2.0970 Lr: 0.00020
[2025-04-08 13:52:26,548 INFO misc.py line 113 3298914] Train: [1/100][141/2402] Data 0.004 (0.004) Batch 0.469 (0.487) Remain 32:29:09 loss: 2.3454 Lr: 0.00020
[2025-04-08 13:52:27,040 INFO misc.py line 113 3298914] Train: [1/100][142/2402] Data 0.004 (0.004) Batch 0.493 (0.487) Remain 32:29:19 loss: 1.9732 Lr: 0.00020
[2025-04-08 13:52:27,522 INFO misc.py line 113 3298914] Train: [1/100][143/2402] Data 0.003 (0.004) Batch 0.481 (0.487) Remain 32:29:09 loss: 2.0821 Lr: 0.00020
[2025-04-08 13:52:27,984 INFO misc.py line 113 3298914] Train: [1/100][144/2402] Data 0.003 (0.004) Batch 0.462 (0.487) Remain 32:28:25 loss: 2.2262 Lr: 0.00020
[2025-04-08 13:52:28,506 INFO misc.py line 113 3298914] Train: [1/100][145/2402] Data 0.004 (0.004) Batch 0.522 (0.487) Remain 32:29:25 loss: 1.9720 Lr: 0.00020
[2025-04-08 13:52:29,037 INFO misc.py line 113 3298914] Train: [1/100][146/2402] Data 0.003 (0.004) Batch 0.530 (0.488) Remain 32:30:37 loss: 2.1131 Lr: 0.00020
[2025-04-08 13:52:29,580 INFO misc.py line 113 3298914] Train: [1/100][147/2402] Data 0.003 (0.004) Batch 0.543 (0.488) Remain 32:32:08 loss: 2.1488 Lr: 0.00020
[2025-04-08 13:52:29,954 INFO misc.py line 113 3298914] Train: [1/100][148/2402] Data 0.003 (0.004) Batch 0.374 (0.487) Remain 32:28:59 loss: 2.3631 Lr: 0.00020
[2025-04-08 13:52:30,486 INFO misc.py line 113 3298914] Train: [1/100][149/2402] Data 0.004 (0.004) Batch 0.532 (0.487) Remain 32:30:13 loss: 2.1515 Lr: 0.00020
[2025-04-08 13:52:30,952 INFO misc.py line 113 3298914] Train: [1/100][150/2402] Data 0.003 (0.004) Batch 0.466 (0.487) Remain 32:29:37 loss: 1.9273 Lr: 0.00020
[2025-04-08 13:52:31,481 INFO misc.py line 113 3298914] Train: [1/100][151/2402] Data 0.004 (0.004) Batch 0.529 (0.488) Remain 32:30:44 loss: 2.4521 Lr: 0.00020
[2025-04-08 13:52:31,892 INFO misc.py line 113 3298914] Train: [1/100][152/2402] Data 0.004 (0.004) Batch 0.412 (0.487) Remain 32:28:42 loss: 2.4830 Lr: 0.00020
[2025-04-08 13:52:32,431 INFO misc.py line 113 3298914] Train: [1/100][153/2402] Data 0.004 (0.004) Batch 0.539 (0.487) Remain 32:30:04 loss: 2.1464 Lr: 0.00020
[2025-04-08 13:52:32,892 INFO misc.py line 113 3298914] Train: [1/100][154/2402] Data 0.003 (0.004) Batch 0.460 (0.487) Remain 32:29:21 loss: 2.2345 Lr: 0.00020
[2025-04-08 13:52:33,477 INFO misc.py line 113 3298914] Train: [1/100][155/2402] Data 0.004 (0.004) Batch 0.585 (0.488) Remain 32:31:55 loss: 2.0822 Lr: 0.00020
[2025-04-08 13:52:33,862 INFO misc.py line 113 3298914] Train: [1/100][156/2402] Data 0.003 (0.004) Batch 0.385 (0.487) Remain 32:29:13 loss: 2.1914 Lr: 0.00020
[2025-04-08 13:52:34,354 INFO misc.py line 113 3298914] Train: [1/100][157/2402] Data 0.004 (0.004) Batch 0.492 (0.487) Remain 32:29:20 loss: 2.1785 Lr: 0.00020
[2025-04-08 13:52:34,817 INFO misc.py line 113 3298914] Train: [1/100][158/2402] Data 0.003 (0.004) Batch 0.463 (0.487) Remain 32:28:42 loss: 2.2870 Lr: 0.00020
[2025-04-08 13:52:35,235 INFO misc.py line 113 3298914] Train: [1/100][159/2402] Data 0.004 (0.004) Batch 0.418 (0.487) Remain 32:26:56 loss: 2.9018 Lr: 0.00020
[2025-04-08 13:52:35,808 INFO misc.py line 113 3298914] Train: [1/100][160/2402] Data 0.004 (0.004) Batch 0.572 (0.487) Remain 32:29:06 loss: 1.8693 Lr: 0.00020
[2025-04-08 13:52:36,315 INFO misc.py line 113 3298914] Train: [1/100][161/2402] Data 0.003 (0.004) Batch 0.507 (0.487) Remain 32:29:36 loss: 2.1399 Lr: 0.00020
[2025-04-08 13:52:36,828 INFO misc.py line 113 3298914] Train: [1/100][162/2402] Data 0.004 (0.004) Batch 0.513 (0.487) Remain 32:30:15 loss: 2.3715 Lr: 0.00020
[2025-04-08 13:52:37,309 INFO misc.py line 113 3298914] Train: [1/100][163/2402] Data 0.003 (0.004) Batch 0.481 (0.487) Remain 32:30:05 loss: 2.5568 Lr: 0.00020
[2025-04-08 13:52:37,805 INFO misc.py line 113 3298914] Train: [1/100][164/2402] Data 0.003 (0.004) Batch 0.496 (0.488) Remain 32:30:17 loss: 2.0611 Lr: 0.00020
[2025-04-08 13:52:38,314 INFO misc.py line 113 3298914] Train: [1/100][165/2402] Data 0.004 (0.004) Batch 0.509 (0.488) Remain 32:30:49 loss: 2.2047 Lr: 0.00020
[2025-04-08 13:52:38,868 INFO misc.py line 113 3298914] Train: [1/100][166/2402] Data 0.003 (0.004) Batch 0.554 (0.488) Remain 32:32:26 loss: 2.4974 Lr: 0.00020
[2025-04-08 13:52:39,290 INFO misc.py line 113 3298914] Train: [1/100][167/2402] Data 0.003 (0.004) Batch 0.422 (0.488) Remain 32:30:48 loss: 2.4802 Lr: 0.00020
[2025-04-08 13:52:39,640 INFO misc.py line 113 3298914] Train: [1/100][168/2402] Data 0.004 (0.004) Batch 0.350 (0.487) Remain 32:27:28 loss: 2.2664 Lr: 0.00020
[2025-04-08 13:52:40,118 INFO misc.py line 113 3298914] Train: [1/100][169/2402] Data 0.004 (0.004) Batch 0.477 (0.487) Remain 32:27:13 loss: 2.1655 Lr: 0.00020
[2025-04-08 13:52:40,547 INFO misc.py line 113 3298914] Train: [1/100][170/2402] Data 0.005 (0.004) Batch 0.430 (0.486) Remain 32:25:51 loss: 2.2157 Lr: 0.00020
[2025-04-08 13:52:40,990 INFO misc.py line 113 3298914] Train: [1/100][171/2402] Data 0.003 (0.004) Batch 0.443 (0.486) Remain 32:24:48 loss: 1.8117 Lr: 0.00020
[2025-04-08 13:52:41,508 INFO misc.py line 113 3298914] Train: [1/100][172/2402] Data 0.003 (0.004) Batch 0.518 (0.486) Remain 32:25:33 loss: 2.2486 Lr: 0.00020
[2025-04-08 13:52:42,079 INFO misc.py line 113 3298914] Train: [1/100][173/2402] Data 0.004 (0.004) Batch 0.571 (0.487) Remain 32:27:32 loss: 2.3735 Lr: 0.00020
[2025-04-08 13:52:42,458 INFO misc.py line 113 3298914] Train: [1/100][174/2402] Data 0.003 (0.004) Batch 0.378 (0.486) Remain 32:24:59 loss: 1.6373 Lr: 0.00020
[2025-04-08 13:52:42,976 INFO misc.py line 113 3298914] Train: [1/100][175/2402] Data 0.004 (0.004) Batch 0.519 (0.486) Remain 32:25:44 loss: 2.3401 Lr: 0.00020
[2025-04-08 13:52:43,408 INFO misc.py line 113 3298914] Train: [1/100][176/2402] Data 0.004 (0.004) Batch 0.432 (0.486) Remain 32:24:28 loss: 1.7820 Lr: 0.00020
[2025-04-08 13:52:43,952 INFO misc.py line 113 3298914] Train: [1/100][177/2402] Data 0.004 (0.004) Batch 0.544 (0.486) Remain 32:25:48 loss: 2.5048 Lr: 0.00020
[2025-04-08 13:52:44,346 INFO misc.py line 113 3298914] Train: [1/100][178/2402] Data 0.003 (0.004) Batch 0.394 (0.486) Remain 32:23:40 loss: 2.3196 Lr: 0.00020
[2025-04-08 13:52:44,811 INFO misc.py line 113 3298914] Train: [1/100][179/2402] Data 0.004 (0.004) Batch 0.465 (0.486) Remain 32:23:11 loss: 1.9231 Lr: 0.00020
[2025-04-08 13:52:45,182 INFO misc.py line 113 3298914] Train: [1/100][180/2402] Data 0.004 (0.004) Batch 0.371 (0.485) Remain 32:20:35 loss: 1.9188 Lr: 0.00020
[2025-04-08 13:52:45,729 INFO misc.py line 113 3298914] Train: [1/100][181/2402] Data 0.004 (0.004) Batch 0.547 (0.485) Remain 32:21:59 loss: 2.4323 Lr: 0.00020
[2025-04-08 13:52:46,125 INFO misc.py line 113 3298914] Train: [1/100][182/2402] Data 0.003 (0.004) Batch 0.396 (0.485) Remain 32:19:58 loss: 2.5483 Lr: 0.00020
[2025-04-08 13:52:46,571 INFO misc.py line 113 3298914] Train: [1/100][183/2402] Data 0.003 (0.004) Batch 0.446 (0.485) Remain 32:19:06 loss: 2.0238 Lr: 0.00020
[2025-04-08 13:52:47,075 INFO misc.py line 113 3298914] Train: [1/100][184/2402] Data 0.003 (0.004) Batch 0.504 (0.485) Remain 32:19:31 loss: 1.9951 Lr: 0.00020
[2025-04-08 13:52:47,579 INFO misc.py line 113 3298914] Train: [1/100][185/2402] Data 0.003 (0.004) Batch 0.503 (0.485) Remain 32:19:55 loss: 1.8083 Lr: 0.00020
[2025-04-08 13:52:48,107 INFO misc.py line 113 3298914] Train: [1/100][186/2402] Data 0.004 (0.004) Batch 0.528 (0.485) Remain 32:20:51 loss: 2.1508 Lr: 0.00020
[2025-04-08 13:52:48,566 INFO misc.py line 113 3298914] Train: [1/100][187/2402] Data 0.003 (0.004) Batch 0.459 (0.485) Remain 32:20:16 loss: 2.0513 Lr: 0.00020
[2025-04-08 13:52:48,987 INFO misc.py line 113 3298914] Train: [1/100][188/2402] Data 0.004 (0.004) Batch 0.421 (0.485) Remain 32:18:53 loss: 2.5199 Lr: 0.00020
[2025-04-08 13:52:49,456 INFO misc.py line 113 3298914] Train: [1/100][189/2402] Data 0.004 (0.004) Batch 0.469 (0.485) Remain 32:18:32 loss: 2.2124 Lr: 0.00020
[2025-04-08 13:52:49,895 INFO misc.py line 113 3298914] Train: [1/100][190/2402] Data 0.004 (0.004) Batch 0.440 (0.484) Remain 32:17:34 loss: 1.7450 Lr: 0.00020
[2025-04-08 13:52:50,309 INFO misc.py line 113 3298914] Train: [1/100][191/2402] Data 0.003 (0.004) Batch 0.413 (0.484) Remain 32:16:02 loss: 2.2462 Lr: 0.00020
[2025-04-08 13:52:50,802 INFO misc.py line 113 3298914] Train: [1/100][192/2402] Data 0.004 (0.004) Batch 0.493 (0.484) Remain 32:16:14 loss: 1.6036 Lr: 0.00020
[2025-04-08 13:52:51,276 INFO misc.py line 113 3298914] Train: [1/100][193/2402] Data 0.003 (0.004) Batch 0.474 (0.484) Remain 32:16:01 loss: 2.3353 Lr: 0.00020
[2025-04-08 13:52:51,812 INFO misc.py line 113 3298914] Train: [1/100][194/2402] Data 0.004 (0.004) Batch 0.536 (0.484) Remain 32:17:06 loss: 2.1454 Lr: 0.00020
[2025-04-08 13:52:52,312 INFO misc.py line 113 3298914] Train: [1/100][195/2402] Data 0.004 (0.004) Batch 0.500 (0.484) Remain 32:17:25 loss: 1.8203 Lr: 0.00020
[2025-04-08 13:52:52,731 INFO misc.py line 113 3298914] Train: [1/100][196/2402] Data 0.003 (0.004) Batch 0.419 (0.484) Remain 32:16:03 loss: 2.3993 Lr: 0.00020
[2025-04-08 13:52:53,198 INFO misc.py line 113 3298914] Train: [1/100][197/2402] Data 0.004 (0.004) Batch 0.467 (0.484) Remain 32:15:41 loss: 1.8702 Lr: 0.00020
[2025-04-08 13:52:53,685 INFO misc.py line 113 3298914] Train: [1/100][198/2402] Data 0.004 (0.004) Batch 0.488 (0.484) Remain 32:15:45 loss: 1.9854 Lr: 0.00020
[2025-04-08 13:52:54,107 INFO misc.py line 113 3298914] Train: [1/100][199/2402] Data 0.003 (0.004) Batch 0.422 (0.484) Remain 32:14:28 loss: 2.3669 Lr: 0.00020
[2025-04-08 13:52:54,526 INFO misc.py line 113 3298914] Train: [1/100][200/2402] Data 0.003 (0.004) Batch 0.419 (0.483) Remain 32:13:09 loss: 1.9186 Lr: 0.00020
[2025-04-08 13:52:55,108 INFO misc.py line 113 3298914] Train: [1/100][201/2402] Data 0.003 (0.004) Batch 0.582 (0.484) Remain 32:15:08 loss: 2.4202 Lr: 0.00020
[2025-04-08 13:52:55,502 INFO misc.py line 113 3298914] Train: [1/100][202/2402] Data 0.003 (0.004) Batch 0.394 (0.483) Remain 32:13:20 loss: 1.8629 Lr: 0.00020
[2025-04-08 13:52:55,990 INFO misc.py line 113 3298914] Train: [1/100][203/2402] Data 0.003 (0.004) Batch 0.488 (0.483) Remain 32:13:24 loss: 2.4427 Lr: 0.00020
[2025-04-08 13:52:56,497 INFO misc.py line 113 3298914] Train: [1/100][204/2402] Data 0.003 (0.004) Batch 0.507 (0.483) Remain 32:13:53 loss: 1.9063 Lr: 0.00020
[2025-04-08 13:52:57,040 INFO misc.py line 113 3298914] Train: [1/100][205/2402] Data 0.004 (0.004) Batch 0.543 (0.484) Remain 32:15:03 loss: 2.2047 Lr: 0.00020
[2025-04-08 13:52:57,509 INFO misc.py line 113 3298914] Train: [1/100][206/2402] Data 0.004 (0.004) Batch 0.469 (0.484) Remain 32:14:45 loss: 2.4184 Lr: 0.00020
[2025-04-08 13:52:57,984 INFO misc.py line 113 3298914] Train: [1/100][207/2402] Data 0.004 (0.004) Batch 0.475 (0.484) Remain 32:14:34 loss: 2.3180 Lr: 0.00020
[2025-04-08 13:52:58,395 INFO misc.py line 113 3298914] Train: [1/100][208/2402] Data 0.004 (0.004) Batch 0.411 (0.483) Remain 32:13:08 loss: 2.4715 Lr: 0.00020
[2025-04-08 13:52:58,701 INFO misc.py line 113 3298914] Train: [1/100][209/2402] Data 0.004 (0.004) Batch 0.306 (0.482) Remain 32:09:42 loss: 1.9341 Lr: 0.00020
[2025-04-08 13:52:59,228 INFO misc.py line 113 3298914] Train: [1/100][210/2402] Data 0.003 (0.004) Batch 0.527 (0.483) Remain 32:10:33 loss: 2.2145 Lr: 0.00020
[2025-04-08 13:52:59,694 INFO misc.py line 113 3298914] Train: [1/100][211/2402] Data 0.003 (0.004) Batch 0.466 (0.483) Remain 32:10:13 loss: 1.9035 Lr: 0.00020
[2025-04-08 13:53:00,230 INFO misc.py line 113 3298914] Train: [1/100][212/2402] Data 0.003 (0.004) Batch 0.536 (0.483) Remain 32:11:14 loss: 2.2924 Lr: 0.00020
[2025-04-08 13:53:00,615 INFO misc.py line 113 3298914] Train: [1/100][213/2402] Data 0.003 (0.004) Batch 0.385 (0.482) Remain 32:09:21 loss: 2.3318 Lr: 0.00020
[2025-04-08 13:53:01,058 INFO misc.py line 113 3298914] Train: [1/100][214/2402] Data 0.004 (0.004) Batch 0.444 (0.482) Remain 32:08:37 loss: 2.1195 Lr: 0.00020
[2025-04-08 13:53:01,565 INFO misc.py line 113 3298914] Train: [1/100][215/2402] Data 0.003 (0.004) Batch 0.507 (0.482) Remain 32:09:04 loss: 2.6372 Lr: 0.00020
[2025-04-08 13:53:01,948 INFO misc.py line 113 3298914] Train: [1/100][216/2402] Data 0.003 (0.004) Batch 0.383 (0.482) Remain 32:07:12 loss: 2.3237 Lr: 0.00020
[2025-04-08 13:53:02,423 INFO misc.py line 113 3298914] Train: [1/100][217/2402] Data 0.003 (0.004) Batch 0.474 (0.482) Remain 32:07:03 loss: 2.5398 Lr: 0.00020
[2025-04-08 13:53:02,891 INFO misc.py line 113 3298914] Train: [1/100][218/2402] Data 0.004 (0.004) Batch 0.468 (0.482) Remain 32:06:47 loss: 2.3418 Lr: 0.00020
[2025-04-08 13:53:03,382 INFO misc.py line 113 3298914] Train: [1/100][219/2402] Data 0.004 (0.004) Batch 0.491 (0.482) Remain 32:06:57 loss: 2.1938 Lr: 0.00020
[2025-04-08 13:53:03,869 INFO misc.py line 113 3298914] Train: [1/100][220/2402] Data 0.004 (0.004) Batch 0.487 (0.482) Remain 32:07:02 loss: 2.0901 Lr: 0.00020
[2025-04-08 13:53:04,398 INFO misc.py line 113 3298914] Train: [1/100][221/2402] Data 0.004 (0.004) Batch 0.529 (0.482) Remain 32:07:53 loss: 2.3315 Lr: 0.00020
[2025-04-08 13:53:04,910 INFO misc.py line 113 3298914] Train: [1/100][222/2402] Data 0.004 (0.004) Batch 0.512 (0.482) Remain 32:08:26 loss: 2.3809 Lr: 0.00020
[2025-04-08 13:53:05,308 INFO misc.py line 113 3298914] Train: [1/100][223/2402] Data 0.004 (0.004) Batch 0.399 (0.482) Remain 32:06:55 loss: 2.3600 Lr: 0.00020
[2025-04-08 13:53:05,774 INFO misc.py line 113 3298914] Train: [1/100][224/2402] Data 0.003 (0.004) Batch 0.465 (0.482) Remain 32:06:36 loss: 1.9018 Lr: 0.00020
[2025-04-08 13:53:06,168 INFO misc.py line 113 3298914] Train: [1/100][225/2402] Data 0.004 (0.004) Batch 0.394 (0.481) Remain 32:05:01 loss: 2.1334 Lr: 0.00020
[2025-04-08 13:53:06,654 INFO misc.py line 113 3298914] Train: [1/100][226/2402] Data 0.003 (0.004) Batch 0.486 (0.481) Remain 32:05:06 loss: 2.5006 Lr: 0.00020
[2025-04-08 13:53:07,145 INFO misc.py line 113 3298914] Train: [1/100][227/2402] Data 0.003 (0.004) Batch 0.491 (0.481) Remain 32:05:15 loss: 2.5127 Lr: 0.00020
[2025-04-08 13:53:07,651 INFO misc.py line 113 3298914] Train: [1/100][228/2402] Data 0.004 (0.004) Batch 0.507 (0.481) Remain 32:05:42 loss: 2.0461 Lr: 0.00020
[2025-04-08 13:53:08,073 INFO misc.py line 113 3298914] Train: [1/100][229/2402] Data 0.003 (0.004) Batch 0.421 (0.481) Remain 32:04:37 loss: 2.2933 Lr: 0.00020
[2025-04-08 13:53:08,394 INFO misc.py line 113 3298914] Train: [1/100][230/2402] Data 0.003 (0.004) Batch 0.322 (0.481) Remain 32:01:48 loss: 2.2736 Lr: 0.00020
[2025-04-08 13:53:08,874 INFO misc.py line 113 3298914] Train: [1/100][231/2402] Data 0.004 (0.004) Batch 0.480 (0.481) Remain 32:01:47 loss: 1.8475 Lr: 0.00020
[2025-04-08 13:53:09,409 INFO misc.py line 113 3298914] Train: [1/100][232/2402] Data 0.004 (0.004) Batch 0.535 (0.481) Remain 32:02:43 loss: 2.3796 Lr: 0.00020
[2025-04-08 13:53:09,971 INFO misc.py line 113 3298914] Train: [1/100][233/2402] Data 0.004 (0.004) Batch 0.562 (0.481) Remain 32:04:08 loss: 2.0422 Lr: 0.00020
[2025-04-08 13:53:10,376 INFO misc.py line 113 3298914] Train: [1/100][234/2402] Data 0.003 (0.004) Batch 0.405 (0.481) Remain 32:02:48 loss: 2.2379 Lr: 0.00020
[2025-04-08 13:53:10,880 INFO misc.py line 113 3298914] Train: [1/100][235/2402] Data 0.003 (0.004) Batch 0.504 (0.481) Remain 32:03:12 loss: 2.0171 Lr: 0.00020
[2025-04-08 13:53:11,235 INFO misc.py line 113 3298914] Train: [1/100][236/2402] Data 0.003 (0.004) Batch 0.355 (0.480) Remain 32:01:02 loss: 1.9584 Lr: 0.00020
[2025-04-08 13:53:11,681 INFO misc.py line 113 3298914] Train: [1/100][237/2402] Data 0.004 (0.004) Batch 0.445 (0.480) Remain 32:00:25 loss: 2.1029 Lr: 0.00020
[2025-04-08 13:53:12,073 INFO misc.py line 113 3298914] Train: [1/100][238/2402] Data 0.003 (0.004) Batch 0.392 (0.480) Remain 31:58:55 loss: 1.6723 Lr: 0.00020
[2025-04-08 13:53:12,603 INFO misc.py line 113 3298914] Train: [1/100][239/2402] Data 0.004 (0.004) Batch 0.530 (0.480) Remain 31:59:46 loss: 2.2568 Lr: 0.00020
[2025-04-08 13:53:13,121 INFO misc.py line 113 3298914] Train: [1/100][240/2402] Data 0.004 (0.004) Batch 0.519 (0.480) Remain 32:00:24 loss: 2.4388 Lr: 0.00020
[2025-04-08 13:53:13,554 INFO misc.py line 113 3298914] Train: [1/100][241/2402] Data 0.004 (0.004) Batch 0.432 (0.480) Remain 31:59:36 loss: 2.7560 Lr: 0.00020
[2025-04-08 13:53:14,023 INFO misc.py line 113 3298914] Train: [1/100][242/2402] Data 0.003 (0.004) Batch 0.469 (0.480) Remain 31:59:24 loss: 2.4679 Lr: 0.00020
[2025-04-08 13:53:14,470 INFO misc.py line 113 3298914] Train: [1/100][243/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:58:50 loss: 2.0222 Lr: 0.00020
[2025-04-08 13:53:14,939 INFO misc.py line 113 3298914] Train: [1/100][244/2402] Data 0.004 (0.004) Batch 0.469 (0.480) Remain 31:58:40 loss: 1.7442 Lr: 0.00020
[2025-04-08 13:53:15,292 INFO misc.py line 113 3298914] Train: [1/100][245/2402] Data 0.003 (0.004) Batch 0.353 (0.479) Remain 31:56:34 loss: 2.3778 Lr: 0.00020
[2025-04-08 13:53:15,772 INFO misc.py line 113 3298914] Train: [1/100][246/2402] Data 0.003 (0.004) Batch 0.480 (0.479) Remain 31:56:34 loss: 2.0654 Lr: 0.00020
[2025-04-08 13:53:16,273 INFO misc.py line 113 3298914] Train: [1/100][247/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:56:55 loss: 1.8639 Lr: 0.00020
[2025-04-08 13:53:16,802 INFO misc.py line 113 3298914] Train: [1/100][248/2402] Data 0.004 (0.004) Batch 0.529 (0.480) Remain 31:57:43 loss: 2.5242 Lr: 0.00020
[2025-04-08 13:53:17,238 INFO misc.py line 113 3298914] Train: [1/100][249/2402] Data 0.003 (0.004) Batch 0.436 (0.479) Remain 31:57:00 loss: 2.1669 Lr: 0.00020
[2025-04-08 13:53:17,730 INFO misc.py line 113 3298914] Train: [1/100][250/2402] Data 0.004 (0.004) Batch 0.492 (0.479) Remain 31:57:12 loss: 2.2104 Lr: 0.00020
[2025-04-08 13:53:18,199 INFO misc.py line 113 3298914] Train: [1/100][251/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:57:02 loss: 2.5232 Lr: 0.00020
[2025-04-08 13:53:18,727 INFO misc.py line 113 3298914] Train: [1/100][252/2402] Data 0.003 (0.004) Batch 0.527 (0.480) Remain 31:57:47 loss: 2.0643 Lr: 0.00020
[2025-04-08 13:53:19,241 INFO misc.py line 113 3298914] Train: [1/100][253/2402] Data 0.003 (0.004) Batch 0.515 (0.480) Remain 31:58:21 loss: 2.4078 Lr: 0.00020
[2025-04-08 13:53:19,714 INFO misc.py line 113 3298914] Train: [1/100][254/2402] Data 0.004 (0.004) Batch 0.473 (0.480) Remain 31:58:14 loss: 2.1772 Lr: 0.00020
[2025-04-08 13:53:20,211 INFO misc.py line 113 3298914] Train: [1/100][255/2402] Data 0.004 (0.004) Batch 0.497 (0.480) Remain 31:58:30 loss: 2.0910 Lr: 0.00020
[2025-04-08 13:53:20,765 INFO misc.py line 113 3298914] Train: [1/100][256/2402] Data 0.003 (0.004) Batch 0.553 (0.480) Remain 31:59:39 loss: 1.7990 Lr: 0.00020
[2025-04-08 13:53:21,251 INFO misc.py line 113 3298914] Train: [1/100][257/2402] Data 0.003 (0.004) Batch 0.486 (0.480) Remain 31:59:44 loss: 1.8732 Lr: 0.00020
[2025-04-08 13:53:21,782 INFO misc.py line 113 3298914] Train: [1/100][258/2402] Data 0.004 (0.004) Batch 0.532 (0.480) Remain 32:00:32 loss: 2.1339 Lr: 0.00020
[2025-04-08 13:53:22,184 INFO misc.py line 113 3298914] Train: [1/100][259/2402] Data 0.004 (0.004) Batch 0.402 (0.480) Remain 31:59:18 loss: 1.5600 Lr: 0.00020
[2025-04-08 13:53:22,679 INFO misc.py line 113 3298914] Train: [1/100][260/2402] Data 0.004 (0.004) Batch 0.495 (0.480) Remain 31:59:32 loss: 1.8090 Lr: 0.00020
[2025-04-08 13:53:23,143 INFO misc.py line 113 3298914] Train: [1/100][261/2402] Data 0.004 (0.004) Batch 0.464 (0.480) Remain 31:59:16 loss: 1.7500 Lr: 0.00020
[2025-04-08 13:53:23,488 INFO misc.py line 113 3298914] Train: [1/100][262/2402] Data 0.003 (0.004) Batch 0.345 (0.479) Remain 31:57:10 loss: 2.3483 Lr: 0.00020
[2025-04-08 13:53:23,958 INFO misc.py line 113 3298914] Train: [1/100][263/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:57:02 loss: 2.0067 Lr: 0.00020
[2025-04-08 13:53:24,348 INFO misc.py line 113 3298914] Train: [1/100][264/2402] Data 0.004 (0.004) Batch 0.390 (0.479) Remain 31:55:39 loss: 2.3409 Lr: 0.00020
[2025-04-08 13:53:24,706 INFO misc.py line 113 3298914] Train: [1/100][265/2402] Data 0.003 (0.004) Batch 0.358 (0.479) Remain 31:53:48 loss: 2.0083 Lr: 0.00020
[2025-04-08 13:53:25,179 INFO misc.py line 113 3298914] Train: [1/100][266/2402] Data 0.004 (0.004) Batch 0.473 (0.479) Remain 31:53:42 loss: 2.1322 Lr: 0.00020
[2025-04-08 13:53:25,681 INFO misc.py line 113 3298914] Train: [1/100][267/2402] Data 0.003 (0.004) Batch 0.502 (0.479) Remain 31:54:03 loss: 2.2761 Lr: 0.00020
[2025-04-08 13:53:26,155 INFO misc.py line 113 3298914] Train: [1/100][268/2402] Data 0.003 (0.004) Batch 0.474 (0.479) Remain 31:53:58 loss: 2.0339 Lr: 0.00020
[2025-04-08 13:53:26,644 INFO misc.py line 113 3298914] Train: [1/100][269/2402] Data 0.004 (0.004) Batch 0.489 (0.479) Remain 31:54:07 loss: 2.0776 Lr: 0.00020
[2025-04-08 13:53:27,090 INFO misc.py line 113 3298914] Train: [1/100][270/2402] Data 0.004 (0.004) Batch 0.445 (0.479) Remain 31:53:37 loss: 2.0964 Lr: 0.00020
[2025-04-08 13:53:27,516 INFO misc.py line 113 3298914] Train: [1/100][271/2402] Data 0.003 (0.004) Batch 0.426 (0.478) Remain 31:52:50 loss: 2.4108 Lr: 0.00020
[2025-04-08 13:53:28,017 INFO misc.py line 113 3298914] Train: [1/100][272/2402] Data 0.004 (0.004) Batch 0.501 (0.478) Remain 31:53:09 loss: 2.0534 Lr: 0.00020
[2025-04-08 13:53:28,551 INFO misc.py line 113 3298914] Train: [1/100][273/2402] Data 0.004 (0.004) Batch 0.534 (0.479) Remain 31:53:59 loss: 2.0012 Lr: 0.00020
[2025-04-08 13:53:28,946 INFO misc.py line 113 3298914] Train: [1/100][274/2402] Data 0.004 (0.004) Batch 0.395 (0.478) Remain 31:52:44 loss: 1.9477 Lr: 0.00020
[2025-04-08 13:53:29,364 INFO misc.py line 113 3298914] Train: [1/100][275/2402] Data 0.003 (0.004) Batch 0.418 (0.478) Remain 31:51:50 loss: 2.5346 Lr: 0.00020
[2025-04-08 13:53:29,842 INFO misc.py line 113 3298914] Train: [1/100][276/2402] Data 0.004 (0.004) Batch 0.478 (0.478) Remain 31:51:50 loss: 2.1033 Lr: 0.00020
[2025-04-08 13:53:30,296 INFO misc.py line 113 3298914] Train: [1/100][277/2402] Data 0.004 (0.004) Batch 0.453 (0.478) Remain 31:51:27 loss: 1.9862 Lr: 0.00020
[2025-04-08 13:53:30,732 INFO misc.py line 113 3298914] Train: [1/100][278/2402] Data 0.004 (0.004) Batch 0.436 (0.478) Remain 31:50:51 loss: 2.0548 Lr: 0.00020
[2025-04-08 13:53:31,262 INFO misc.py line 113 3298914] Train: [1/100][279/2402] Data 0.003 (0.004) Batch 0.530 (0.478) Remain 31:51:36 loss: 2.1837 Lr: 0.00020
[2025-04-08 13:53:31,677 INFO misc.py line 113 3298914] Train: [1/100][280/2402] Data 0.004 (0.004) Batch 0.414 (0.478) Remain 31:50:40 loss: 1.8671 Lr: 0.00020
[2025-04-08 13:53:32,161 INFO misc.py line 113 3298914] Train: [1/100][281/2402] Data 0.004 (0.004) Batch 0.485 (0.478) Remain 31:50:45 loss: 1.7815 Lr: 0.00020
[2025-04-08 13:53:32,502 INFO misc.py line 113 3298914] Train: [1/100][282/2402] Data 0.003 (0.004) Batch 0.341 (0.477) Remain 31:48:47 loss: 2.2665 Lr: 0.00020
[2025-04-08 13:53:33,039 INFO misc.py line 113 3298914] Train: [1/100][283/2402] Data 0.003 (0.004) Batch 0.537 (0.478) Remain 31:49:38 loss: 2.3887 Lr: 0.00020
[2025-04-08 13:53:33,531 INFO misc.py line 113 3298914] Train: [1/100][284/2402] Data 0.003 (0.004) Batch 0.492 (0.478) Remain 31:49:50 loss: 1.5462 Lr: 0.00020
[2025-04-08 13:53:34,068 INFO misc.py line 113 3298914] Train: [1/100][285/2402] Data 0.004 (0.004) Batch 0.537 (0.478) Remain 31:50:40 loss: 2.0454 Lr: 0.00020
[2025-04-08 13:53:34,615 INFO misc.py line 113 3298914] Train: [1/100][286/2402] Data 0.003 (0.004) Batch 0.546 (0.478) Remain 31:51:38 loss: 1.8809 Lr: 0.00020
[2025-04-08 13:53:35,096 INFO misc.py line 113 3298914] Train: [1/100][287/2402] Data 0.004 (0.004) Batch 0.481 (0.478) Remain 31:51:40 loss: 2.0043 Lr: 0.00020
[2025-04-08 13:53:35,554 INFO misc.py line 113 3298914] Train: [1/100][288/2402] Data 0.003 (0.004) Batch 0.458 (0.478) Remain 31:51:22 loss: 1.6671 Lr: 0.00020
[2025-04-08 13:53:36,061 INFO misc.py line 113 3298914] Train: [1/100][289/2402] Data 0.003 (0.004) Batch 0.507 (0.478) Remain 31:51:46 loss: 2.1881 Lr: 0.00020
[2025-04-08 13:53:36,504 INFO misc.py line 113 3298914] Train: [1/100][290/2402] Data 0.003 (0.004) Batch 0.443 (0.478) Remain 31:51:16 loss: 2.7462 Lr: 0.00020
[2025-04-08 13:53:36,929 INFO misc.py line 113 3298914] Train: [1/100][291/2402] Data 0.004 (0.004) Batch 0.426 (0.478) Remain 31:50:32 loss: 2.2891 Lr: 0.00020
[2025-04-08 13:53:37,545 INFO misc.py line 113 3298914] Train: [1/100][292/2402] Data 0.003 (0.004) Batch 0.615 (0.478) Remain 31:52:26 loss: 1.9480 Lr: 0.00020
[2025-04-08 13:53:38,004 INFO misc.py line 113 3298914] Train: [1/100][293/2402] Data 0.004 (0.004) Batch 0.460 (0.478) Remain 31:52:10 loss: 1.8723 Lr: 0.00020
[2025-04-08 13:53:38,421 INFO misc.py line 113 3298914] Train: [1/100][294/2402] Data 0.003 (0.004) Batch 0.416 (0.478) Remain 31:51:18 loss: 1.8178 Lr: 0.00020
[2025-04-08 13:53:38,774 INFO misc.py line 113 3298914] Train: [1/100][295/2402] Data 0.003 (0.004) Batch 0.353 (0.478) Remain 31:49:35 loss: 2.1607 Lr: 0.00020
[2025-04-08 13:53:39,258 INFO misc.py line 113 3298914] Train: [1/100][296/2402] Data 0.004 (0.004) Batch 0.485 (0.478) Remain 31:49:41 loss: 2.0615 Lr: 0.00020
[2025-04-08 13:53:39,776 INFO misc.py line 113 3298914] Train: [1/100][297/2402] Data 0.004 (0.004) Batch 0.517 (0.478) Remain 31:50:13 loss: 2.3233 Lr: 0.00020
[2025-04-08 13:53:40,293 INFO misc.py line 113 3298914] Train: [1/100][298/2402] Data 0.003 (0.004) Batch 0.517 (0.478) Remain 31:50:44 loss: 1.6638 Lr: 0.00020
[2025-04-08 13:53:40,723 INFO misc.py line 113 3298914] Train: [1/100][299/2402] Data 0.004 (0.004) Batch 0.430 (0.478) Remain 31:50:05 loss: 2.0711 Lr: 0.00020
[2025-04-08 13:53:41,221 INFO misc.py line 113 3298914] Train: [1/100][300/2402] Data 0.003 (0.004) Batch 0.498 (0.478) Remain 31:50:21 loss: 2.1265 Lr: 0.00020
[2025-04-08 13:53:41,664 INFO misc.py line 113 3298914] Train: [1/100][301/2402] Data 0.004 (0.004) Batch 0.443 (0.478) Remain 31:49:52 loss: 1.9910 Lr: 0.00020
[2025-04-08 13:53:42,019 INFO misc.py line 113 3298914] Train: [1/100][302/2402] Data 0.004 (0.004) Batch 0.355 (0.477) Remain 31:48:13 loss: 1.8513 Lr: 0.00020
[2025-04-08 13:53:42,427 INFO misc.py line 113 3298914] Train: [1/100][303/2402] Data 0.003 (0.004) Batch 0.408 (0.477) Remain 31:47:18 loss: 1.8593 Lr: 0.00020
[2025-04-08 13:53:42,915 INFO misc.py line 113 3298914] Train: [1/100][304/2402] Data 0.004 (0.004) Batch 0.487 (0.477) Remain 31:47:25 loss: 2.1583 Lr: 0.00020
[2025-04-08 13:53:43,453 INFO misc.py line 113 3298914] Train: [1/100][305/2402] Data 0.004 (0.004) Batch 0.539 (0.477) Remain 31:48:14 loss: 1.7056 Lr: 0.00020
[2025-04-08 13:53:43,971 INFO misc.py line 113 3298914] Train: [1/100][306/2402] Data 0.003 (0.004) Batch 0.518 (0.477) Remain 31:48:45 loss: 1.6363 Lr: 0.00020
[2025-04-08 13:53:44,406 INFO misc.py line 113 3298914] Train: [1/100][307/2402] Data 0.004 (0.004) Batch 0.435 (0.477) Remain 31:48:12 loss: 2.1513 Lr: 0.00020
[2025-04-08 13:53:44,848 INFO misc.py line 113 3298914] Train: [1/100][308/2402] Data 0.004 (0.004) Batch 0.442 (0.477) Remain 31:47:44 loss: 1.5975 Lr: 0.00020
[2025-04-08 13:53:45,367 INFO misc.py line 113 3298914] Train: [1/100][309/2402] Data 0.004 (0.004) Batch 0.519 (0.477) Remain 31:48:16 loss: 1.6456 Lr: 0.00020
[2025-04-08 13:53:45,865 INFO misc.py line 113 3298914] Train: [1/100][310/2402] Data 0.004 (0.004) Batch 0.498 (0.477) Remain 31:48:31 loss: 2.1328 Lr: 0.00020
[2025-04-08 13:53:46,371 INFO misc.py line 113 3298914] Train: [1/100][311/2402] Data 0.003 (0.004) Batch 0.506 (0.477) Remain 31:48:53 loss: 2.1386 Lr: 0.00020
[2025-04-08 13:53:46,911 INFO misc.py line 113 3298914] Train: [1/100][312/2402] Data 0.004 (0.004) Batch 0.540 (0.478) Remain 31:49:41 loss: 1.8623 Lr: 0.00020
[2025-04-08 13:53:47,386 INFO misc.py line 113 3298914] Train: [1/100][313/2402] Data 0.004 (0.004) Batch 0.476 (0.478) Remain 31:49:39 loss: 2.0585 Lr: 0.00020
[2025-04-08 13:53:47,923 INFO misc.py line 113 3298914] Train: [1/100][314/2402] Data 0.003 (0.004) Batch 0.537 (0.478) Remain 31:50:24 loss: 2.2297 Lr: 0.00020
[2025-04-08 13:53:48,335 INFO misc.py line 113 3298914] Train: [1/100][315/2402] Data 0.004 (0.004) Batch 0.412 (0.478) Remain 31:49:33 loss: 2.2602 Lr: 0.00020
[2025-04-08 13:53:48,818 INFO misc.py line 113 3298914] Train: [1/100][316/2402] Data 0.003 (0.004) Batch 0.482 (0.478) Remain 31:49:36 loss: 2.1539 Lr: 0.00020
[2025-04-08 13:53:49,366 INFO misc.py line 113 3298914] Train: [1/100][317/2402] Data 0.004 (0.004) Batch 0.549 (0.478) Remain 31:50:30 loss: 2.4297 Lr: 0.00020
[2025-04-08 13:53:49,916 INFO misc.py line 113 3298914] Train: [1/100][318/2402] Data 0.004 (0.004) Batch 0.550 (0.478) Remain 31:51:25 loss: 2.2474 Lr: 0.00020
[2025-04-08 13:53:50,408 INFO misc.py line 113 3298914] Train: [1/100][319/2402] Data 0.004 (0.004) Batch 0.492 (0.478) Remain 31:51:34 loss: 2.3127 Lr: 0.00020
[2025-04-08 13:53:50,873 INFO misc.py line 113 3298914] Train: [1/100][320/2402] Data 0.004 (0.004) Batch 0.465 (0.478) Remain 31:51:24 loss: 2.1322 Lr: 0.00020
[2025-04-08 13:53:51,350 INFO misc.py line 113 3298914] Train: [1/100][321/2402] Data 0.003 (0.004) Batch 0.477 (0.478) Remain 31:51:22 loss: 1.8231 Lr: 0.00020
[2025-04-08 13:53:51,833 INFO misc.py line 113 3298914] Train: [1/100][322/2402] Data 0.004 (0.004) Batch 0.483 (0.478) Remain 31:51:26 loss: 1.8797 Lr: 0.00020
[2025-04-08 13:53:52,350 INFO misc.py line 113 3298914] Train: [1/100][323/2402] Data 0.004 (0.004) Batch 0.517 (0.478) Remain 31:51:55 loss: 2.4652 Lr: 0.00020
[2025-04-08 13:53:52,792 INFO misc.py line 113 3298914] Train: [1/100][324/2402] Data 0.003 (0.004) Batch 0.442 (0.478) Remain 31:51:27 loss: 2.3757 Lr: 0.00020
[2025-04-08 13:53:53,310 INFO misc.py line 113 3298914] Train: [1/100][325/2402] Data 0.003 (0.004) Batch 0.519 (0.478) Remain 31:51:57 loss: 1.6186 Lr: 0.00020
[2025-04-08 13:53:53,768 INFO misc.py line 113 3298914] Train: [1/100][326/2402] Data 0.004 (0.004) Batch 0.457 (0.478) Remain 31:51:40 loss: 2.3237 Lr: 0.00020
[2025-04-08 13:53:54,256 INFO misc.py line 113 3298914] Train: [1/100][327/2402] Data 0.003 (0.004) Batch 0.488 (0.478) Remain 31:51:47 loss: 2.0840 Lr: 0.00020
[2025-04-08 13:53:54,802 INFO misc.py line 113 3298914] Train: [1/100][328/2402] Data 0.004 (0.004) Batch 0.547 (0.478) Remain 31:52:37 loss: 2.3057 Lr: 0.00020
[2025-04-08 13:53:55,261 INFO misc.py line 113 3298914] Train: [1/100][329/2402] Data 0.004 (0.004) Batch 0.459 (0.478) Remain 31:52:23 loss: 1.5070 Lr: 0.00020
[2025-04-08 13:53:55,742 INFO misc.py line 113 3298914] Train: [1/100][330/2402] Data 0.003 (0.004) Batch 0.481 (0.478) Remain 31:52:24 loss: 1.9597 Lr: 0.00020
[2025-04-08 13:53:56,210 INFO misc.py line 113 3298914] Train: [1/100][331/2402] Data 0.003 (0.004) Batch 0.468 (0.478) Remain 31:52:16 loss: 2.2173 Lr: 0.00020
[2025-04-08 13:53:56,716 INFO misc.py line 113 3298914] Train: [1/100][332/2402] Data 0.003 (0.004) Batch 0.506 (0.478) Remain 31:52:35 loss: 2.2942 Lr: 0.00020
[2025-04-08 13:53:57,120 INFO misc.py line 113 3298914] Train: [1/100][333/2402] Data 0.004 (0.004) Batch 0.404 (0.478) Remain 31:51:41 loss: 2.8374 Lr: 0.00020
[2025-04-08 13:53:57,623 INFO misc.py line 113 3298914] Train: [1/100][334/2402] Data 0.003 (0.004) Batch 0.503 (0.478) Remain 31:51:58 loss: 2.0146 Lr: 0.00020
[2025-04-08 13:53:58,125 INFO misc.py line 113 3298914] Train: [1/100][335/2402] Data 0.003 (0.004) Batch 0.502 (0.478) Remain 31:52:15 loss: 2.1912 Lr: 0.00020
[2025-04-08 13:53:58,534 INFO misc.py line 113 3298914] Train: [1/100][336/2402] Data 0.004 (0.004) Batch 0.409 (0.478) Remain 31:51:25 loss: 1.8819 Lr: 0.00020
[2025-04-08 13:53:59,016 INFO misc.py line 113 3298914] Train: [1/100][337/2402] Data 0.003 (0.004) Batch 0.482 (0.478) Remain 31:51:27 loss: 2.1358 Lr: 0.00020
[2025-04-08 13:53:59,520 INFO misc.py line 113 3298914] Train: [1/100][338/2402] Data 0.004 (0.004) Batch 0.504 (0.478) Remain 31:51:45 loss: 2.0919 Lr: 0.00020
[2025-04-08 13:53:59,895 INFO misc.py line 113 3298914] Train: [1/100][339/2402] Data 0.004 (0.004) Batch 0.375 (0.478) Remain 31:50:31 loss: 1.7960 Lr: 0.00020
[2025-04-08 13:54:00,327 INFO misc.py line 113 3298914] Train: [1/100][340/2402] Data 0.003 (0.004) Batch 0.432 (0.478) Remain 31:49:58 loss: 2.2302 Lr: 0.00020
[2025-04-08 13:54:00,775 INFO misc.py line 113 3298914] Train: [1/100][341/2402] Data 0.003 (0.004) Batch 0.448 (0.478) Remain 31:49:36 loss: 2.5345 Lr: 0.00020
[2025-04-08 13:54:01,406 INFO misc.py line 113 3298914] Train: [1/100][342/2402] Data 0.004 (0.004) Batch 0.631 (0.478) Remain 31:51:24 loss: 2.1028 Lr: 0.00020
[2025-04-08 13:54:01,819 INFO misc.py line 113 3298914] Train: [1/100][343/2402] Data 0.003 (0.004) Batch 0.413 (0.478) Remain 31:50:38 loss: 2.1977 Lr: 0.00020
[2025-04-08 13:54:02,320 INFO misc.py line 113 3298914] Train: [1/100][344/2402] Data 0.004 (0.004) Batch 0.500 (0.478) Remain 31:50:53 loss: 1.6925 Lr: 0.00020
[2025-04-08 13:54:02,743 INFO misc.py line 113 3298914] Train: [1/100][345/2402] Data 0.004 (0.004) Batch 0.424 (0.478) Remain 31:50:14 loss: 2.3092 Lr: 0.00020
[2025-04-08 13:54:03,202 INFO misc.py line 113 3298914] Train: [1/100][346/2402] Data 0.003 (0.004) Batch 0.459 (0.478) Remain 31:50:01 loss: 2.1526 Lr: 0.00020
[2025-04-08 13:54:03,698 INFO misc.py line 113 3298914] Train: [1/100][347/2402] Data 0.003 (0.004) Batch 0.495 (0.478) Remain 31:50:13 loss: 1.9152 Lr: 0.00020
[2025-04-08 13:54:04,230 INFO misc.py line 113 3298914] Train: [1/100][348/2402] Data 0.003 (0.004) Batch 0.532 (0.478) Remain 31:50:50 loss: 1.9629 Lr: 0.00020
[2025-04-08 13:54:04,717 INFO misc.py line 113 3298914] Train: [1/100][349/2402] Data 0.004 (0.004) Batch 0.487 (0.478) Remain 31:50:56 loss: 2.2089 Lr: 0.00020
[2025-04-08 13:54:05,133 INFO misc.py line 113 3298914] Train: [1/100][350/2402] Data 0.003 (0.004) Batch 0.416 (0.478) Remain 31:50:13 loss: 2.0536 Lr: 0.00020
[2025-04-08 13:54:05,569 INFO misc.py line 113 3298914] Train: [1/100][351/2402] Data 0.003 (0.004) Batch 0.436 (0.478) Remain 31:49:43 loss: 2.1267 Lr: 0.00020
[2025-04-08 13:54:06,062 INFO misc.py line 113 3298914] Train: [1/100][352/2402] Data 0.004 (0.004) Batch 0.493 (0.478) Remain 31:49:54 loss: 1.8974 Lr: 0.00020
[2025-04-08 13:54:06,616 INFO misc.py line 113 3298914] Train: [1/100][353/2402] Data 0.003 (0.004) Batch 0.554 (0.478) Remain 31:50:45 loss: 2.0268 Lr: 0.00020
[2025-04-08 13:54:06,996 INFO misc.py line 113 3298914] Train: [1/100][354/2402] Data 0.003 (0.004) Batch 0.380 (0.478) Remain 31:49:38 loss: 2.4812 Lr: 0.00020
[2025-04-08 13:54:07,446 INFO misc.py line 113 3298914] Train: [1/100][355/2402] Data 0.004 (0.004) Batch 0.450 (0.478) Remain 31:49:18 loss: 2.4387 Lr: 0.00020
[2025-04-08 13:54:07,938 INFO misc.py line 113 3298914] Train: [1/100][356/2402] Data 0.003 (0.004) Batch 0.492 (0.478) Remain 31:49:27 loss: 1.8053 Lr: 0.00020
[2025-04-08 13:54:08,455 INFO misc.py line 113 3298914] Train: [1/100][357/2402] Data 0.003 (0.004) Batch 0.517 (0.478) Remain 31:49:53 loss: 2.4903 Lr: 0.00020
[2025-04-08 13:54:08,887 INFO misc.py line 113 3298914] Train: [1/100][358/2402] Data 0.003 (0.004) Batch 0.432 (0.478) Remain 31:49:22 loss: 2.0063 Lr: 0.00020
[2025-04-08 13:54:09,376 INFO misc.py line 113 3298914] Train: [1/100][359/2402] Data 0.004 (0.004) Batch 0.489 (0.478) Remain 31:49:30 loss: 1.8057 Lr: 0.00020
[2025-04-08 13:54:09,866 INFO misc.py line 113 3298914] Train: [1/100][360/2402] Data 0.003 (0.004) Batch 0.489 (0.478) Remain 31:49:37 loss: 1.9759 Lr: 0.00020
[2025-04-08 13:54:10,365 INFO misc.py line 113 3298914] Train: [1/100][361/2402] Data 0.004 (0.004) Batch 0.499 (0.478) Remain 31:49:51 loss: 2.1359 Lr: 0.00020
[2025-04-08 13:54:10,818 INFO misc.py line 113 3298914] Train: [1/100][362/2402] Data 0.004 (0.004) Batch 0.454 (0.478) Remain 31:49:34 loss: 2.1565 Lr: 0.00020
[2025-04-08 13:54:11,375 INFO misc.py line 113 3298914] Train: [1/100][363/2402] Data 0.003 (0.004) Batch 0.557 (0.478) Remain 31:50:26 loss: 2.2881 Lr: 0.00020
[2025-04-08 13:54:11,875 INFO misc.py line 113 3298914] Train: [1/100][364/2402] Data 0.004 (0.004) Batch 0.500 (0.478) Remain 31:50:40 loss: 2.0762 Lr: 0.00020
[2025-04-08 13:54:12,391 INFO misc.py line 113 3298914] Train: [1/100][365/2402] Data 0.003 (0.004) Batch 0.516 (0.478) Remain 31:51:05 loss: 2.2011 Lr: 0.00020
[2025-04-08 13:54:12,916 INFO misc.py line 113 3298914] Train: [1/100][366/2402] Data 0.004 (0.004) Batch 0.525 (0.478) Remain 31:51:35 loss: 2.4762 Lr: 0.00020
[2025-04-08 13:54:13,421 INFO misc.py line 113 3298914] Train: [1/100][367/2402] Data 0.004 (0.004) Batch 0.505 (0.478) Remain 31:51:53 loss: 2.5606 Lr: 0.00020
[2025-04-08 13:54:13,946 INFO misc.py line 113 3298914] Train: [1/100][368/2402] Data 0.004 (0.004) Batch 0.524 (0.478) Remain 31:52:22 loss: 1.7797 Lr: 0.00020
[2025-04-08 13:54:14,353 INFO misc.py line 113 3298914] Train: [1/100][369/2402] Data 0.004 (0.004) Batch 0.408 (0.478) Remain 31:51:36 loss: 2.0065 Lr: 0.00020
[2025-04-08 13:54:14,819 INFO misc.py line 113 3298914] Train: [1/100][370/2402] Data 0.003 (0.004) Batch 0.467 (0.478) Remain 31:51:28 loss: 2.1085 Lr: 0.00020
[2025-04-08 13:54:15,284 INFO misc.py line 113 3298914] Train: [1/100][371/2402] Data 0.003 (0.004) Batch 0.464 (0.478) Remain 31:51:18 loss: 1.6346 Lr: 0.00020
[2025-04-08 13:54:15,903 INFO misc.py line 113 3298914] Train: [1/100][372/2402] Data 0.004 (0.004) Batch 0.619 (0.479) Remain 31:52:49 loss: 2.4100 Lr: 0.00020
[2025-04-08 13:54:16,330 INFO misc.py line 113 3298914] Train: [1/100][373/2402] Data 0.004 (0.004) Batch 0.427 (0.478) Remain 31:52:15 loss: 1.9975 Lr: 0.00020
[2025-04-08 13:54:16,760 INFO misc.py line 113 3298914] Train: [1/100][374/2402] Data 0.004 (0.004) Batch 0.430 (0.478) Remain 31:51:43 loss: 1.7834 Lr: 0.00020
[2025-04-08 13:54:17,146 INFO misc.py line 113 3298914] Train: [1/100][375/2402] Data 0.004 (0.004) Batch 0.387 (0.478) Remain 31:50:44 loss: 2.2273 Lr: 0.00020
[2025-04-08 13:54:17,672 INFO misc.py line 113 3298914] Train: [1/100][376/2402] Data 0.003 (0.004) Batch 0.526 (0.478) Remain 31:51:14 loss: 2.1018 Lr: 0.00020
[2025-04-08 13:54:18,156 INFO misc.py line 113 3298914] Train: [1/100][377/2402] Data 0.003 (0.004) Batch 0.484 (0.478) Remain 31:51:17 loss: 1.9943 Lr: 0.00020
[2025-04-08 13:54:18,678 INFO misc.py line 113 3298914] Train: [1/100][378/2402] Data 0.004 (0.004) Batch 0.521 (0.478) Remain 31:51:44 loss: 1.8307 Lr: 0.00020
[2025-04-08 13:54:19,098 INFO misc.py line 113 3298914] Train: [1/100][379/2402] Data 0.003 (0.004) Batch 0.421 (0.478) Remain 31:51:07 loss: 1.7583 Lr: 0.00020
[2025-04-08 13:54:19,540 INFO misc.py line 113 3298914] Train: [1/100][380/2402] Data 0.003 (0.004) Batch 0.441 (0.478) Remain 31:50:43 loss: 2.4761 Lr: 0.00020
[2025-04-08 13:54:20,052 INFO misc.py line 113 3298914] Train: [1/100][381/2402] Data 0.004 (0.004) Batch 0.512 (0.478) Remain 31:51:05 loss: 1.9334 Lr: 0.00020
[2025-04-08 13:54:20,553 INFO misc.py line 113 3298914] Train: [1/100][382/2402] Data 0.004 (0.004) Batch 0.501 (0.478) Remain 31:51:18 loss: 2.0051 Lr: 0.00020
[2025-04-08 13:54:21,053 INFO misc.py line 113 3298914] Train: [1/100][383/2402] Data 0.004 (0.004) Batch 0.500 (0.478) Remain 31:51:32 loss: 1.2926 Lr: 0.00020
[2025-04-08 13:54:21,572 INFO misc.py line 113 3298914] Train: [1/100][384/2402] Data 0.003 (0.004) Batch 0.519 (0.478) Remain 31:51:57 loss: 1.9571 Lr: 0.00020
[2025-04-08 13:54:22,145 INFO misc.py line 113 3298914] Train: [1/100][385/2402] Data 0.004 (0.004) Batch 0.573 (0.479) Remain 31:52:56 loss: 2.6834 Lr: 0.00020
[2025-04-08 13:54:22,605 INFO misc.py line 113 3298914] Train: [1/100][386/2402] Data 0.003 (0.004) Batch 0.459 (0.479) Remain 31:52:44 loss: 2.0398 Lr: 0.00020
[2025-04-08 13:54:23,090 INFO misc.py line 113 3298914] Train: [1/100][387/2402] Data 0.004 (0.004) Batch 0.486 (0.479) Remain 31:52:47 loss: 1.8572 Lr: 0.00020
[2025-04-08 13:54:23,643 INFO misc.py line 113 3298914] Train: [1/100][388/2402] Data 0.003 (0.004) Batch 0.553 (0.479) Remain 31:53:33 loss: 2.2402 Lr: 0.00020
[2025-04-08 13:54:24,228 INFO misc.py line 113 3298914] Train: [1/100][389/2402] Data 0.003 (0.004) Batch 0.585 (0.479) Remain 31:54:39 loss: 1.8736 Lr: 0.00020
[2025-04-08 13:54:24,626 INFO misc.py line 113 3298914] Train: [1/100][390/2402] Data 0.004 (0.004) Batch 0.398 (0.479) Remain 31:53:48 loss: 2.1140 Lr: 0.00020
[2025-04-08 13:54:25,023 INFO misc.py line 113 3298914] Train: [1/100][391/2402] Data 0.004 (0.004) Batch 0.396 (0.479) Remain 31:52:57 loss: 2.2229 Lr: 0.00020
[2025-04-08 13:54:25,481 INFO misc.py line 113 3298914] Train: [1/100][392/2402] Data 0.004 (0.004) Batch 0.459 (0.479) Remain 31:52:44 loss: 2.0442 Lr: 0.00020
[2025-04-08 13:54:25,972 INFO misc.py line 113 3298914] Train: [1/100][393/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:52:51 loss: 2.3462 Lr: 0.00020
[2025-04-08 13:54:26,606 INFO misc.py line 113 3298914] Train: [1/100][394/2402] Data 0.004 (0.004) Batch 0.634 (0.479) Remain 31:54:26 loss: 2.4080 Lr: 0.00020
[2025-04-08 13:54:27,148 INFO misc.py line 113 3298914] Train: [1/100][395/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:55:04 loss: 2.3652 Lr: 0.00020
[2025-04-08 13:54:27,651 INFO misc.py line 113 3298914] Train: [1/100][396/2402] Data 0.004 (0.004) Batch 0.503 (0.479) Remain 31:55:18 loss: 2.3039 Lr: 0.00020
[2025-04-08 13:54:27,983 INFO misc.py line 113 3298914] Train: [1/100][397/2402] Data 0.004 (0.004) Batch 0.332 (0.479) Remain 31:53:48 loss: 1.7641 Lr: 0.00020
[2025-04-08 13:54:28,505 INFO misc.py line 113 3298914] Train: [1/100][398/2402] Data 0.003 (0.004) Batch 0.521 (0.479) Remain 31:54:14 loss: 2.4176 Lr: 0.00020
[2025-04-08 13:54:28,938 INFO misc.py line 113 3298914] Train: [1/100][399/2402] Data 0.003 (0.004) Batch 0.434 (0.479) Remain 31:53:46 loss: 1.8696 Lr: 0.00020
[2025-04-08 13:54:29,400 INFO misc.py line 113 3298914] Train: [1/100][400/2402] Data 0.003 (0.004) Batch 0.461 (0.479) Remain 31:53:34 loss: 2.2142 Lr: 0.00020
[2025-04-08 13:54:29,845 INFO misc.py line 113 3298914] Train: [1/100][401/2402] Data 0.004 (0.004) Batch 0.446 (0.479) Remain 31:53:14 loss: 1.8529 Lr: 0.00020
[2025-04-08 13:54:30,348 INFO misc.py line 113 3298914] Train: [1/100][402/2402] Data 0.003 (0.004) Batch 0.502 (0.479) Remain 31:53:28 loss: 2.0978 Lr: 0.00020
[2025-04-08 13:54:30,777 INFO misc.py line 113 3298914] Train: [1/100][403/2402] Data 0.004 (0.004) Batch 0.429 (0.479) Remain 31:52:58 loss: 2.1806 Lr: 0.00020
[2025-04-08 13:54:31,284 INFO misc.py line 113 3298914] Train: [1/100][404/2402] Data 0.004 (0.004) Batch 0.507 (0.479) Remain 31:53:14 loss: 2.0687 Lr: 0.00020
[2025-04-08 13:54:31,695 INFO misc.py line 113 3298914] Train: [1/100][405/2402] Data 0.003 (0.004) Batch 0.411 (0.479) Remain 31:52:33 loss: 2.4249 Lr: 0.00020
[2025-04-08 13:54:32,254 INFO misc.py line 113 3298914] Train: [1/100][406/2402] Data 0.004 (0.004) Batch 0.559 (0.479) Remain 31:53:20 loss: 2.0293 Lr: 0.00021
[2025-04-08 13:54:32,827 INFO misc.py line 113 3298914] Train: [1/100][407/2402] Data 0.004 (0.004) Batch 0.573 (0.479) Remain 31:54:16 loss: 2.1237 Lr: 0.00021
[2025-04-08 13:54:33,384 INFO misc.py line 113 3298914] Train: [1/100][408/2402] Data 0.003 (0.004) Batch 0.557 (0.479) Remain 31:55:02 loss: 1.6663 Lr: 0.00021
[2025-04-08 13:54:33,902 INFO misc.py line 113 3298914] Train: [1/100][409/2402] Data 0.003 (0.004) Batch 0.518 (0.479) Remain 31:55:24 loss: 2.2726 Lr: 0.00021
[2025-04-08 13:54:34,424 INFO misc.py line 113 3298914] Train: [1/100][410/2402] Data 0.004 (0.004) Batch 0.522 (0.479) Remain 31:55:49 loss: 2.0468 Lr: 0.00021
[2025-04-08 13:54:34,876 INFO misc.py line 113 3298914] Train: [1/100][411/2402] Data 0.003 (0.004) Batch 0.452 (0.479) Remain 31:55:32 loss: 2.0413 Lr: 0.00021
[2025-04-08 13:54:35,349 INFO misc.py line 113 3298914] Train: [1/100][412/2402] Data 0.003 (0.004) Batch 0.473 (0.479) Remain 31:55:28 loss: 2.0837 Lr: 0.00021
[2025-04-08 13:54:35,688 INFO misc.py line 113 3298914] Train: [1/100][413/2402] Data 0.004 (0.004) Batch 0.338 (0.479) Remain 31:54:05 loss: 2.1421 Lr: 0.00021
[2025-04-08 13:54:36,146 INFO misc.py line 113 3298914] Train: [1/100][414/2402] Data 0.004 (0.004) Batch 0.458 (0.479) Remain 31:53:53 loss: 2.2013 Lr: 0.00021
[2025-04-08 13:54:36,688 INFO misc.py line 113 3298914] Train: [1/100][415/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:54:30 loss: 1.8799 Lr: 0.00021
[2025-04-08 13:54:37,191 INFO misc.py line 113 3298914] Train: [1/100][416/2402] Data 0.003 (0.004) Batch 0.502 (0.479) Remain 31:54:43 loss: 1.9730 Lr: 0.00021
[2025-04-08 13:54:37,601 INFO misc.py line 113 3298914] Train: [1/100][417/2402] Data 0.003 (0.004) Batch 0.410 (0.479) Remain 31:54:02 loss: 2.1259 Lr: 0.00021
[2025-04-08 13:54:38,018 INFO misc.py line 113 3298914] Train: [1/100][418/2402] Data 0.004 (0.004) Batch 0.417 (0.479) Remain 31:53:26 loss: 1.7925 Lr: 0.00021
[2025-04-08 13:54:38,420 INFO misc.py line 113 3298914] Train: [1/100][419/2402] Data 0.004 (0.004) Batch 0.402 (0.479) Remain 31:52:41 loss: 2.2403 Lr: 0.00021
[2025-04-08 13:54:38,903 INFO misc.py line 113 3298914] Train: [1/100][420/2402] Data 0.003 (0.004) Batch 0.483 (0.479) Remain 31:52:43 loss: 1.9446 Lr: 0.00021
[2025-04-08 13:54:39,330 INFO misc.py line 113 3298914] Train: [1/100][421/2402] Data 0.004 (0.004) Batch 0.427 (0.478) Remain 31:52:13 loss: 1.8344 Lr: 0.00021
[2025-04-08 13:54:39,780 INFO misc.py line 113 3298914] Train: [1/100][422/2402] Data 0.004 (0.004) Batch 0.449 (0.478) Remain 31:51:56 loss: 1.9156 Lr: 0.00021
[2025-04-08 13:54:40,289 INFO misc.py line 113 3298914] Train: [1/100][423/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:52:13 loss: 1.8499 Lr: 0.00021
[2025-04-08 13:54:40,744 INFO misc.py line 113 3298914] Train: [1/100][424/2402] Data 0.004 (0.004) Batch 0.456 (0.478) Remain 31:52:00 loss: 2.1312 Lr: 0.00021
[2025-04-08 13:54:41,190 INFO misc.py line 113 3298914] Train: [1/100][425/2402] Data 0.004 (0.004) Batch 0.445 (0.478) Remain 31:51:40 loss: 2.2861 Lr: 0.00021
[2025-04-08 13:54:41,722 INFO misc.py line 113 3298914] Train: [1/100][426/2402] Data 0.004 (0.004) Batch 0.533 (0.478) Remain 31:52:10 loss: 2.1313 Lr: 0.00021
[2025-04-08 13:54:42,289 INFO misc.py line 113 3298914] Train: [1/100][427/2402] Data 0.004 (0.004) Batch 0.567 (0.479) Remain 31:53:00 loss: 2.0444 Lr: 0.00021
[2025-04-08 13:54:42,853 INFO misc.py line 113 3298914] Train: [1/100][428/2402] Data 0.004 (0.004) Batch 0.564 (0.479) Remain 31:53:48 loss: 2.0501 Lr: 0.00021
[2025-04-08 13:54:43,347 INFO misc.py line 113 3298914] Train: [1/100][429/2402] Data 0.004 (0.004) Batch 0.494 (0.479) Remain 31:53:56 loss: 2.2824 Lr: 0.00021
[2025-04-08 13:54:43,831 INFO misc.py line 113 3298914] Train: [1/100][430/2402] Data 0.004 (0.004) Batch 0.483 (0.479) Remain 31:53:58 loss: 2.0781 Lr: 0.00021
[2025-04-08 13:54:44,245 INFO misc.py line 113 3298914] Train: [1/100][431/2402] Data 0.003 (0.004) Batch 0.414 (0.479) Remain 31:53:21 loss: 2.0932 Lr: 0.00021
[2025-04-08 13:54:44,630 INFO misc.py line 113 3298914] Train: [1/100][432/2402] Data 0.003 (0.004) Batch 0.385 (0.479) Remain 31:52:28 loss: 2.4224 Lr: 0.00021
[2025-04-08 13:54:44,922 INFO misc.py line 113 3298914] Train: [1/100][433/2402] Data 0.004 (0.004) Batch 0.292 (0.478) Remain 31:50:44 loss: 2.7209 Lr: 0.00021
[2025-04-08 13:54:45,455 INFO misc.py line 113 3298914] Train: [1/100][434/2402] Data 0.004 (0.004) Batch 0.532 (0.478) Remain 31:51:13 loss: 1.9451 Lr: 0.00021
[2025-04-08 13:54:45,847 INFO misc.py line 113 3298914] Train: [1/100][435/2402] Data 0.004 (0.004) Batch 0.393 (0.478) Remain 31:50:26 loss: 1.9430 Lr: 0.00021
[2025-04-08 13:54:46,385 INFO misc.py line 113 3298914] Train: [1/100][436/2402] Data 0.004 (0.004) Batch 0.538 (0.478) Remain 31:50:58 loss: 2.0664 Lr: 0.00021
[2025-04-08 13:54:46,885 INFO misc.py line 113 3298914] Train: [1/100][437/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:51:09 loss: 2.0857 Lr: 0.00021
[2025-04-08 13:54:47,278 INFO misc.py line 113 3298914] Train: [1/100][438/2402] Data 0.004 (0.004) Batch 0.394 (0.478) Remain 31:50:22 loss: 1.8239 Lr: 0.00021
[2025-04-08 13:54:47,826 INFO misc.py line 113 3298914] Train: [1/100][439/2402] Data 0.003 (0.004) Batch 0.548 (0.478) Remain 31:51:00 loss: 2.1001 Lr: 0.00021
[2025-04-08 13:54:48,352 INFO misc.py line 113 3298914] Train: [1/100][440/2402] Data 0.003 (0.004) Batch 0.526 (0.478) Remain 31:51:26 loss: 2.0777 Lr: 0.00021
[2025-04-08 13:54:48,815 INFO misc.py line 113 3298914] Train: [1/100][441/2402] Data 0.004 (0.004) Batch 0.463 (0.478) Remain 31:51:17 loss: 2.0867 Lr: 0.00021
[2025-04-08 13:54:49,294 INFO misc.py line 113 3298914] Train: [1/100][442/2402] Data 0.003 (0.004) Batch 0.479 (0.478) Remain 31:51:17 loss: 1.7331 Lr: 0.00021
[2025-04-08 13:54:49,634 INFO misc.py line 113 3298914] Train: [1/100][443/2402] Data 0.004 (0.004) Batch 0.339 (0.478) Remain 31:50:01 loss: 1.9460 Lr: 0.00021
[2025-04-08 13:54:50,099 INFO misc.py line 113 3298914] Train: [1/100][444/2402] Data 0.004 (0.004) Batch 0.465 (0.478) Remain 31:49:53 loss: 1.2745 Lr: 0.00021
[2025-04-08 13:54:50,591 INFO misc.py line 113 3298914] Train: [1/100][445/2402] Data 0.003 (0.004) Batch 0.492 (0.478) Remain 31:50:00 loss: 1.9157 Lr: 0.00021
[2025-04-08 13:54:51,038 INFO misc.py line 113 3298914] Train: [1/100][446/2402] Data 0.003 (0.004) Batch 0.447 (0.478) Remain 31:49:43 loss: 2.0606 Lr: 0.00021
[2025-04-08 13:54:51,545 INFO misc.py line 113 3298914] Train: [1/100][447/2402] Data 0.004 (0.004) Batch 0.507 (0.478) Remain 31:49:59 loss: 2.2885 Lr: 0.00021
[2025-04-08 13:54:51,958 INFO misc.py line 113 3298914] Train: [1/100][448/2402] Data 0.003 (0.004) Batch 0.413 (0.478) Remain 31:49:23 loss: 2.0375 Lr: 0.00021
[2025-04-08 13:54:52,379 INFO misc.py line 113 3298914] Train: [1/100][449/2402] Data 0.004 (0.004) Batch 0.420 (0.478) Remain 31:48:52 loss: 2.2375 Lr: 0.00021
[2025-04-08 13:54:52,890 INFO misc.py line 113 3298914] Train: [1/100][450/2402] Data 0.004 (0.004) Batch 0.512 (0.478) Remain 31:49:10 loss: 1.9728 Lr: 0.00021
[2025-04-08 13:54:53,507 INFO misc.py line 113 3298914] Train: [1/100][451/2402] Data 0.003 (0.004) Batch 0.617 (0.478) Remain 31:50:24 loss: 2.0617 Lr: 0.00021
[2025-04-08 13:54:54,054 INFO misc.py line 113 3298914] Train: [1/100][452/2402] Data 0.004 (0.004) Batch 0.547 (0.478) Remain 31:51:00 loss: 1.8896 Lr: 0.00021
[2025-04-08 13:54:54,488 INFO misc.py line 113 3298914] Train: [1/100][453/2402] Data 0.003 (0.004) Batch 0.434 (0.478) Remain 31:50:36 loss: 2.0843 Lr: 0.00021
[2025-04-08 13:54:55,046 INFO misc.py line 113 3298914] Train: [1/100][454/2402] Data 0.003 (0.004) Batch 0.558 (0.478) Remain 31:51:18 loss: 1.9320 Lr: 0.00021
[2025-04-08 13:54:55,466 INFO misc.py line 113 3298914] Train: [1/100][455/2402] Data 0.004 (0.004) Batch 0.420 (0.478) Remain 31:50:46 loss: 1.9781 Lr: 0.00021
[2025-04-08 13:54:55,897 INFO misc.py line 113 3298914] Train: [1/100][456/2402] Data 0.004 (0.004) Batch 0.431 (0.478) Remain 31:50:21 loss: 1.9396 Lr: 0.00021
[2025-04-08 13:54:56,389 INFO misc.py line 113 3298914] Train: [1/100][457/2402] Data 0.004 (0.004) Batch 0.492 (0.478) Remain 31:50:27 loss: 1.8172 Lr: 0.00021
[2025-04-08 13:54:56,771 INFO misc.py line 113 3298914] Train: [1/100][458/2402] Data 0.004 (0.004) Batch 0.382 (0.478) Remain 31:49:36 loss: 1.9400 Lr: 0.00021
[2025-04-08 13:54:57,278 INFO misc.py line 113 3298914] Train: [1/100][459/2402] Data 0.004 (0.004) Batch 0.508 (0.478) Remain 31:49:51 loss: 2.2136 Lr: 0.00021
[2025-04-08 13:54:57,774 INFO misc.py line 113 3298914] Train: [1/100][460/2402] Data 0.003 (0.004) Batch 0.496 (0.478) Remain 31:50:00 loss: 2.2731 Lr: 0.00021
[2025-04-08 13:54:58,218 INFO misc.py line 113 3298914] Train: [1/100][461/2402] Data 0.003 (0.004) Batch 0.444 (0.478) Remain 31:49:42 loss: 1.6381 Lr: 0.00021
[2025-04-08 13:54:58,697 INFO misc.py line 113 3298914] Train: [1/100][462/2402] Data 0.004 (0.004) Batch 0.479 (0.478) Remain 31:49:42 loss: 1.8411 Lr: 0.00021
[2025-04-08 13:54:59,196 INFO misc.py line 113 3298914] Train: [1/100][463/2402] Data 0.003 (0.004) Batch 0.498 (0.478) Remain 31:49:52 loss: 1.9891 Lr: 0.00021
[2025-04-08 13:54:59,585 INFO misc.py line 113 3298914] Train: [1/100][464/2402] Data 0.004 (0.004) Batch 0.390 (0.478) Remain 31:49:06 loss: 2.1687 Lr: 0.00021
[2025-04-08 13:55:00,065 INFO misc.py line 113 3298914] Train: [1/100][465/2402] Data 0.004 (0.004) Batch 0.479 (0.478) Remain 31:49:06 loss: 1.9071 Lr: 0.00021
[2025-04-08 13:55:00,620 INFO misc.py line 113 3298914] Train: [1/100][466/2402] Data 0.004 (0.004) Batch 0.555 (0.478) Remain 31:49:46 loss: 2.5773 Lr: 0.00021
[2025-04-08 13:55:01,139 INFO misc.py line 113 3298914] Train: [1/100][467/2402] Data 0.004 (0.004) Batch 0.520 (0.478) Remain 31:50:07 loss: 1.8353 Lr: 0.00021
[2025-04-08 13:55:01,559 INFO misc.py line 113 3298914] Train: [1/100][468/2402] Data 0.003 (0.004) Batch 0.420 (0.478) Remain 31:49:36 loss: 1.9128 Lr: 0.00021
[2025-04-08 13:55:02,006 INFO misc.py line 113 3298914] Train: [1/100][469/2402] Data 0.004 (0.004) Batch 0.446 (0.478) Remain 31:49:20 loss: 1.6702 Lr: 0.00021
[2025-04-08 13:55:02,550 INFO misc.py line 113 3298914] Train: [1/100][470/2402] Data 0.004 (0.004) Batch 0.544 (0.478) Remain 31:49:53 loss: 2.1297 Lr: 0.00021
[2025-04-08 13:55:02,835 INFO misc.py line 113 3298914] Train: [1/100][471/2402] Data 0.003 (0.004) Batch 0.285 (0.478) Remain 31:48:14 loss: 2.1105 Lr: 0.00021
[2025-04-08 13:55:03,354 INFO misc.py line 113 3298914] Train: [1/100][472/2402] Data 0.004 (0.004) Batch 0.519 (0.478) Remain 31:48:34 loss: 1.9397 Lr: 0.00021
[2025-04-08 13:55:03,954 INFO misc.py line 113 3298914] Train: [1/100][473/2402] Data 0.004 (0.004) Batch 0.601 (0.478) Remain 31:49:37 loss: 2.1093 Lr: 0.00021
[2025-04-08 13:55:04,405 INFO misc.py line 113 3298914] Train: [1/100][474/2402] Data 0.004 (0.004) Batch 0.451 (0.478) Remain 31:49:22 loss: 2.0346 Lr: 0.00021
[2025-04-08 13:55:04,776 INFO misc.py line 113 3298914] Train: [1/100][475/2402] Data 0.004 (0.004) Batch 0.371 (0.478) Remain 31:48:28 loss: 1.9899 Lr: 0.00021
[2025-04-08 13:55:05,227 INFO misc.py line 113 3298914] Train: [1/100][476/2402] Data 0.003 (0.004) Batch 0.451 (0.478) Remain 31:48:13 loss: 1.9762 Lr: 0.00021
[2025-04-08 13:55:05,751 INFO misc.py line 113 3298914] Train: [1/100][477/2402] Data 0.004 (0.004) Batch 0.524 (0.478) Remain 31:48:37 loss: 2.0394 Lr: 0.00021
[2025-04-08 13:55:06,244 INFO misc.py line 113 3298914] Train: [1/100][478/2402] Data 0.004 (0.004) Batch 0.493 (0.478) Remain 31:48:44 loss: 1.5990 Lr: 0.00021
[2025-04-08 13:55:06,738 INFO misc.py line 113 3298914] Train: [1/100][479/2402] Data 0.003 (0.004) Batch 0.493 (0.478) Remain 31:48:51 loss: 1.7757 Lr: 0.00021
[2025-04-08 13:55:07,251 INFO misc.py line 113 3298914] Train: [1/100][480/2402] Data 0.003 (0.004) Batch 0.513 (0.478) Remain 31:49:09 loss: 2.2368 Lr: 0.00021
[2025-04-08 13:55:07,811 INFO misc.py line 113 3298914] Train: [1/100][481/2402] Data 0.004 (0.004) Batch 0.561 (0.478) Remain 31:49:50 loss: 2.0120 Lr: 0.00021
[2025-04-08 13:55:08,281 INFO misc.py line 113 3298914] Train: [1/100][482/2402] Data 0.004 (0.004) Batch 0.470 (0.478) Remain 31:49:45 loss: 2.2658 Lr: 0.00021
[2025-04-08 13:55:08,844 INFO misc.py line 113 3298914] Train: [1/100][483/2402] Data 0.004 (0.004) Batch 0.562 (0.478) Remain 31:50:27 loss: 1.7255 Lr: 0.00021
[2025-04-08 13:55:09,354 INFO misc.py line 113 3298914] Train: [1/100][484/2402] Data 0.004 (0.004) Batch 0.510 (0.478) Remain 31:50:42 loss: 1.0272 Lr: 0.00021
[2025-04-08 13:55:09,821 INFO misc.py line 113 3298914] Train: [1/100][485/2402] Data 0.003 (0.004) Batch 0.467 (0.478) Remain 31:50:36 loss: 2.0912 Lr: 0.00021
[2025-04-08 13:55:10,417 INFO misc.py line 113 3298914] Train: [1/100][486/2402] Data 0.003 (0.004) Batch 0.597 (0.478) Remain 31:51:34 loss: 2.3023 Lr: 0.00021
[2025-04-08 13:55:10,877 INFO misc.py line 113 3298914] Train: [1/100][487/2402] Data 0.004 (0.004) Batch 0.460 (0.478) Remain 31:51:25 loss: 1.8834 Lr: 0.00021
[2025-04-08 13:55:11,353 INFO misc.py line 113 3298914] Train: [1/100][488/2402] Data 0.003 (0.004) Batch 0.476 (0.478) Remain 31:51:23 loss: 2.2423 Lr: 0.00021
[2025-04-08 13:55:11,812 INFO misc.py line 113 3298914] Train: [1/100][489/2402] Data 0.003 (0.004) Batch 0.459 (0.478) Remain 31:51:13 loss: 2.2851 Lr: 0.00021
[2025-04-08 13:55:12,239 INFO misc.py line 113 3298914] Train: [1/100][490/2402] Data 0.004 (0.004) Batch 0.427 (0.478) Remain 31:50:47 loss: 1.6622 Lr: 0.00021
[2025-04-08 13:55:12,721 INFO misc.py line 113 3298914] Train: [1/100][491/2402] Data 0.004 (0.004) Batch 0.482 (0.478) Remain 31:50:48 loss: 1.8563 Lr: 0.00021
[2025-04-08 13:55:13,203 INFO misc.py line 113 3298914] Train: [1/100][492/2402] Data 0.004 (0.004) Batch 0.483 (0.478) Remain 31:50:50 loss: 2.0493 Lr: 0.00021
[2025-04-08 13:55:13,772 INFO misc.py line 113 3298914] Train: [1/100][493/2402] Data 0.004 (0.004) Batch 0.568 (0.478) Remain 31:51:33 loss: 2.3313 Lr: 0.00021
[2025-04-08 13:55:14,304 INFO misc.py line 113 3298914] Train: [1/100][494/2402] Data 0.004 (0.004) Batch 0.532 (0.479) Remain 31:51:59 loss: 2.1124 Lr: 0.00021
[2025-04-08 13:55:14,811 INFO misc.py line 113 3298914] Train: [1/100][495/2402] Data 0.004 (0.004) Batch 0.508 (0.479) Remain 31:52:13 loss: 1.9501 Lr: 0.00021
[2025-04-08 13:55:15,300 INFO misc.py line 113 3298914] Train: [1/100][496/2402] Data 0.004 (0.004) Batch 0.488 (0.479) Remain 31:52:17 loss: 2.1597 Lr: 0.00021
[2025-04-08 13:55:15,792 INFO misc.py line 113 3298914] Train: [1/100][497/2402] Data 0.003 (0.004) Batch 0.493 (0.479) Remain 31:52:23 loss: 2.0790 Lr: 0.00021
[2025-04-08 13:55:16,300 INFO misc.py line 113 3298914] Train: [1/100][498/2402] Data 0.003 (0.004) Batch 0.508 (0.479) Remain 31:52:37 loss: 2.1493 Lr: 0.00021
[2025-04-08 13:55:16,719 INFO misc.py line 113 3298914] Train: [1/100][499/2402] Data 0.004 (0.004) Batch 0.419 (0.479) Remain 31:52:08 loss: 1.9364 Lr: 0.00021
[2025-04-08 13:55:17,282 INFO misc.py line 113 3298914] Train: [1/100][500/2402] Data 0.003 (0.004) Batch 0.564 (0.479) Remain 31:52:48 loss: 2.2014 Lr: 0.00021
[2025-04-08 13:55:17,832 INFO misc.py line 113 3298914] Train: [1/100][501/2402] Data 0.003 (0.004) Batch 0.549 (0.479) Remain 31:53:22 loss: 1.8625 Lr: 0.00021
[2025-04-08 13:55:18,307 INFO misc.py line 113 3298914] Train: [1/100][502/2402] Data 0.004 (0.004) Batch 0.474 (0.479) Remain 31:53:19 loss: 2.4214 Lr: 0.00021
[2025-04-08 13:55:18,832 INFO misc.py line 113 3298914] Train: [1/100][503/2402] Data 0.004 (0.004) Batch 0.526 (0.479) Remain 31:53:41 loss: 1.7188 Lr: 0.00021
[2025-04-08 13:55:19,313 INFO misc.py line 113 3298914] Train: [1/100][504/2402] Data 0.004 (0.004) Batch 0.481 (0.479) Remain 31:53:41 loss: 1.9178 Lr: 0.00021
[2025-04-08 13:55:19,856 INFO misc.py line 113 3298914] Train: [1/100][505/2402] Data 0.003 (0.004) Batch 0.543 (0.479) Remain 31:54:11 loss: 2.0635 Lr: 0.00021
[2025-04-08 13:55:20,575 INFO misc.py line 113 3298914] Train: [1/100][506/2402] Data 0.004 (0.004) Batch 0.719 (0.480) Remain 31:56:05 loss: 2.0135 Lr: 0.00021
[2025-04-08 13:55:21,061 INFO misc.py line 113 3298914] Train: [1/100][507/2402] Data 0.003 (0.004) Batch 0.486 (0.480) Remain 31:56:08 loss: 1.8226 Lr: 0.00021
[2025-04-08 13:55:21,476 INFO misc.py line 113 3298914] Train: [1/100][508/2402] Data 0.004 (0.004) Batch 0.415 (0.480) Remain 31:55:36 loss: 2.0605 Lr: 0.00021
[2025-04-08 13:55:21,971 INFO misc.py line 113 3298914] Train: [1/100][509/2402] Data 0.004 (0.004) Batch 0.495 (0.480) Remain 31:55:43 loss: 1.7823 Lr: 0.00021
[2025-04-08 13:55:22,366 INFO misc.py line 113 3298914] Train: [1/100][510/2402] Data 0.003 (0.004) Batch 0.395 (0.479) Remain 31:55:03 loss: 1.5936 Lr: 0.00021
[2025-04-08 13:55:22,822 INFO misc.py line 113 3298914] Train: [1/100][511/2402] Data 0.004 (0.004) Batch 0.456 (0.479) Remain 31:54:51 loss: 2.1058 Lr: 0.00021
[2025-04-08 13:55:23,302 INFO misc.py line 113 3298914] Train: [1/100][512/2402] Data 0.003 (0.004) Batch 0.480 (0.479) Remain 31:54:51 loss: 1.6758 Lr: 0.00021
[2025-04-08 13:55:23,762 INFO misc.py line 113 3298914] Train: [1/100][513/2402] Data 0.003 (0.004) Batch 0.460 (0.479) Remain 31:54:42 loss: 2.1594 Lr: 0.00021
[2025-04-08 13:55:24,263 INFO misc.py line 113 3298914] Train: [1/100][514/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:54:51 loss: 1.7577 Lr: 0.00021
[2025-04-08 13:55:24,811 INFO misc.py line 113 3298914] Train: [1/100][515/2402] Data 0.004 (0.004) Batch 0.548 (0.479) Remain 31:55:23 loss: 1.8362 Lr: 0.00021
[2025-04-08 13:55:25,232 INFO misc.py line 113 3298914] Train: [1/100][516/2402] Data 0.004 (0.004) Batch 0.421 (0.479) Remain 31:54:55 loss: 1.8713 Lr: 0.00021
[2025-04-08 13:55:25,768 INFO misc.py line 113 3298914] Train: [1/100][517/2402] Data 0.004 (0.004) Batch 0.536 (0.479) Remain 31:55:21 loss: 1.6390 Lr: 0.00021
[2025-04-08 13:55:26,245 INFO misc.py line 113 3298914] Train: [1/100][518/2402] Data 0.004 (0.004) Batch 0.477 (0.479) Remain 31:55:20 loss: 2.3123 Lr: 0.00021
[2025-04-08 13:55:26,703 INFO misc.py line 113 3298914] Train: [1/100][519/2402] Data 0.004 (0.004) Batch 0.458 (0.479) Remain 31:55:09 loss: 1.8817 Lr: 0.00021
[2025-04-08 13:55:27,169 INFO misc.py line 113 3298914] Train: [1/100][520/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:55:03 loss: 1.9350 Lr: 0.00021
[2025-04-08 13:55:27,573 INFO misc.py line 113 3298914] Train: [1/100][521/2402] Data 0.003 (0.004) Batch 0.404 (0.479) Remain 31:54:27 loss: 2.0466 Lr: 0.00021
[2025-04-08 13:55:27,985 INFO misc.py line 113 3298914] Train: [1/100][522/2402] Data 0.004 (0.004) Batch 0.412 (0.479) Remain 31:53:55 loss: 2.0985 Lr: 0.00021
[2025-04-08 13:55:28,435 INFO misc.py line 113 3298914] Train: [1/100][523/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:53:42 loss: 1.8930 Lr: 0.00021
[2025-04-08 13:55:28,749 INFO misc.py line 113 3298914] Train: [1/100][524/2402] Data 0.003 (0.004) Batch 0.313 (0.479) Remain 31:52:25 loss: 2.2503 Lr: 0.00021
[2025-04-08 13:55:29,319 INFO misc.py line 113 3298914] Train: [1/100][525/2402] Data 0.004 (0.004) Batch 0.570 (0.479) Remain 31:53:07 loss: 1.9665 Lr: 0.00021
[2025-04-08 13:55:29,715 INFO misc.py line 113 3298914] Train: [1/100][526/2402] Data 0.004 (0.004) Batch 0.396 (0.479) Remain 31:52:28 loss: 1.4580 Lr: 0.00021
[2025-04-08 13:55:30,233 INFO misc.py line 113 3298914] Train: [1/100][527/2402] Data 0.003 (0.004) Batch 0.518 (0.479) Remain 31:52:45 loss: 1.9397 Lr: 0.00021
[2025-04-08 13:55:30,689 INFO misc.py line 113 3298914] Train: [1/100][528/2402] Data 0.003 (0.004) Batch 0.456 (0.479) Remain 31:52:35 loss: 1.8507 Lr: 0.00021
[2025-04-08 13:55:31,130 INFO misc.py line 113 3298914] Train: [1/100][529/2402] Data 0.004 (0.004) Batch 0.441 (0.479) Remain 31:52:17 loss: 1.9505 Lr: 0.00021
[2025-04-08 13:55:31,647 INFO misc.py line 113 3298914] Train: [1/100][530/2402] Data 0.003 (0.004) Batch 0.517 (0.479) Remain 31:52:34 loss: 1.9336 Lr: 0.00021
[2025-04-08 13:55:32,114 INFO misc.py line 113 3298914] Train: [1/100][531/2402] Data 0.003 (0.004) Batch 0.467 (0.479) Remain 31:52:28 loss: 1.8912 Lr: 0.00021
[2025-04-08 13:55:32,506 INFO misc.py line 113 3298914] Train: [1/100][532/2402] Data 0.004 (0.004) Batch 0.392 (0.479) Remain 31:51:48 loss: 1.9911 Lr: 0.00021
[2025-04-08 13:55:32,852 INFO misc.py line 113 3298914] Train: [1/100][533/2402] Data 0.003 (0.004) Batch 0.346 (0.478) Remain 31:50:48 loss: 2.2718 Lr: 0.00021
[2025-04-08 13:55:33,307 INFO misc.py line 113 3298914] Train: [1/100][534/2402] Data 0.003 (0.004) Batch 0.455 (0.478) Remain 31:50:37 loss: 2.2695 Lr: 0.00021
[2025-04-08 13:55:33,769 INFO misc.py line 113 3298914] Train: [1/100][535/2402] Data 0.004 (0.004) Batch 0.461 (0.478) Remain 31:50:29 loss: 2.2007 Lr: 0.00021
[2025-04-08 13:55:34,188 INFO misc.py line 113 3298914] Train: [1/100][536/2402] Data 0.004 (0.004) Batch 0.419 (0.478) Remain 31:50:02 loss: 2.5083 Lr: 0.00021
[2025-04-08 13:55:34,624 INFO misc.py line 113 3298914] Train: [1/100][537/2402] Data 0.004 (0.004) Batch 0.436 (0.478) Remain 31:49:42 loss: 2.1276 Lr: 0.00021
[2025-04-08 13:55:35,174 INFO misc.py line 113 3298914] Train: [1/100][538/2402] Data 0.004 (0.004) Batch 0.550 (0.478) Remain 31:50:14 loss: 2.0510 Lr: 0.00021
[2025-04-08 13:55:35,653 INFO misc.py line 113 3298914] Train: [1/100][539/2402] Data 0.003 (0.004) Batch 0.478 (0.478) Remain 31:50:14 loss: 1.9774 Lr: 0.00021
[2025-04-08 13:55:36,155 INFO misc.py line 113 3298914] Train: [1/100][540/2402] Data 0.004 (0.004) Batch 0.502 (0.478) Remain 31:50:24 loss: 1.8574 Lr: 0.00021
[2025-04-08 13:55:36,541 INFO misc.py line 113 3298914] Train: [1/100][541/2402] Data 0.003 (0.004) Batch 0.386 (0.478) Remain 31:49:43 loss: 1.9709 Lr: 0.00021
[2025-04-08 13:55:37,053 INFO misc.py line 113 3298914] Train: [1/100][542/2402] Data 0.003 (0.004) Batch 0.512 (0.478) Remain 31:49:57 loss: 2.6471 Lr: 0.00021
[2025-04-08 13:55:37,523 INFO misc.py line 113 3298914] Train: [1/100][543/2402] Data 0.003 (0.004) Batch 0.469 (0.478) Remain 31:49:53 loss: 2.0353 Lr: 0.00021
[2025-04-08 13:55:38,006 INFO misc.py line 113 3298914] Train: [1/100][544/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:49:55 loss: 1.9267 Lr: 0.00021
[2025-04-08 13:55:38,582 INFO misc.py line 113 3298914] Train: [1/100][545/2402] Data 0.003 (0.004) Batch 0.576 (0.478) Remain 31:50:37 loss: 1.6005 Lr: 0.00021
[2025-04-08 13:55:39,133 INFO misc.py line 113 3298914] Train: [1/100][546/2402] Data 0.004 (0.004) Batch 0.552 (0.478) Remain 31:51:09 loss: 1.5785 Lr: 0.00021
[2025-04-08 13:55:39,598 INFO misc.py line 113 3298914] Train: [1/100][547/2402] Data 0.003 (0.004) Batch 0.464 (0.478) Remain 31:51:03 loss: 1.9610 Lr: 0.00021
[2025-04-08 13:55:40,081 INFO misc.py line 113 3298914] Train: [1/100][548/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:51:04 loss: 2.1971 Lr: 0.00021
[2025-04-08 13:55:40,575 INFO misc.py line 113 3298914] Train: [1/100][549/2402] Data 0.003 (0.004) Batch 0.495 (0.478) Remain 31:51:11 loss: 2.4078 Lr: 0.00021
[2025-04-08 13:55:41,078 INFO misc.py line 113 3298914] Train: [1/100][550/2402] Data 0.005 (0.004) Batch 0.503 (0.479) Remain 31:51:21 loss: 2.2353 Lr: 0.00021
[2025-04-08 13:55:41,565 INFO misc.py line 113 3298914] Train: [1/100][551/2402] Data 0.003 (0.004) Batch 0.487 (0.479) Remain 31:51:24 loss: 2.1167 Lr: 0.00021
[2025-04-08 13:55:41,991 INFO misc.py line 113 3298914] Train: [1/100][552/2402] Data 0.003 (0.004) Batch 0.427 (0.478) Remain 31:51:01 loss: 2.0825 Lr: 0.00021
[2025-04-08 13:55:42,536 INFO misc.py line 113 3298914] Train: [1/100][553/2402] Data 0.005 (0.004) Batch 0.545 (0.479) Remain 31:51:29 loss: 1.7240 Lr: 0.00021
[2025-04-08 13:55:43,090 INFO misc.py line 113 3298914] Train: [1/100][554/2402] Data 0.004 (0.004) Batch 0.554 (0.479) Remain 31:52:01 loss: 1.7523 Lr: 0.00021
[2025-04-08 13:55:43,687 INFO misc.py line 113 3298914] Train: [1/100][555/2402] Data 0.004 (0.004) Batch 0.597 (0.479) Remain 31:52:52 loss: 2.1606 Lr: 0.00021
[2025-04-08 13:55:44,141 INFO misc.py line 113 3298914] Train: [1/100][556/2402] Data 0.003 (0.004) Batch 0.454 (0.479) Remain 31:52:41 loss: 1.6333 Lr: 0.00021
[2025-04-08 13:55:44,649 INFO misc.py line 113 3298914] Train: [1/100][557/2402] Data 0.003 (0.004) Batch 0.507 (0.479) Remain 31:52:53 loss: 2.1760 Lr: 0.00021
[2025-04-08 13:55:44,987 INFO misc.py line 113 3298914] Train: [1/100][558/2402] Data 0.004 (0.004) Batch 0.338 (0.479) Remain 31:51:52 loss: 1.9427 Lr: 0.00021
[2025-04-08 13:55:45,343 INFO misc.py line 113 3298914] Train: [1/100][559/2402] Data 0.004 (0.004) Batch 0.356 (0.478) Remain 31:50:58 loss: 1.7906 Lr: 0.00021
[2025-04-08 13:55:45,827 INFO misc.py line 113 3298914] Train: [1/100][560/2402] Data 0.004 (0.004) Batch 0.484 (0.478) Remain 31:51:00 loss: 1.9864 Lr: 0.00021
[2025-04-08 13:55:46,340 INFO misc.py line 113 3298914] Train: [1/100][561/2402] Data 0.004 (0.004) Batch 0.514 (0.479) Remain 31:51:15 loss: 1.8564 Lr: 0.00021
[2025-04-08 13:55:46,763 INFO misc.py line 113 3298914] Train: [1/100][562/2402] Data 0.004 (0.004) Batch 0.423 (0.478) Remain 31:50:51 loss: 1.9984 Lr: 0.00021
[2025-04-08 13:55:47,284 INFO misc.py line 113 3298914] Train: [1/100][563/2402] Data 0.003 (0.004) Batch 0.520 (0.479) Remain 31:51:08 loss: 1.6028 Lr: 0.00021
[2025-04-08 13:55:47,738 INFO misc.py line 113 3298914] Train: [1/100][564/2402] Data 0.004 (0.004) Batch 0.455 (0.478) Remain 31:50:57 loss: 2.0093 Lr: 0.00021
[2025-04-08 13:55:48,175 INFO misc.py line 113 3298914] Train: [1/100][565/2402] Data 0.003 (0.004) Batch 0.437 (0.478) Remain 31:50:39 loss: 1.9513 Lr: 0.00021
[2025-04-08 13:55:48,712 INFO misc.py line 113 3298914] Train: [1/100][566/2402] Data 0.004 (0.004) Batch 0.536 (0.478) Remain 31:51:03 loss: 2.0185 Lr: 0.00021
[2025-04-08 13:55:49,113 INFO misc.py line 113 3298914] Train: [1/100][567/2402] Data 0.003 (0.004) Batch 0.401 (0.478) Remain 31:50:30 loss: 1.8257 Lr: 0.00021
[2025-04-08 13:55:49,641 INFO misc.py line 113 3298914] Train: [1/100][568/2402] Data 0.003 (0.004) Batch 0.528 (0.478) Remain 31:50:51 loss: 1.5738 Lr: 0.00021
[2025-04-08 13:55:50,153 INFO misc.py line 113 3298914] Train: [1/100][569/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:51:04 loss: 1.7870 Lr: 0.00021
[2025-04-08 13:55:50,715 INFO misc.py line 113 3298914] Train: [1/100][570/2402] Data 0.003 (0.004) Batch 0.562 (0.479) Remain 31:51:39 loss: 1.8564 Lr: 0.00021
[2025-04-08 13:55:51,154 INFO misc.py line 113 3298914] Train: [1/100][571/2402] Data 0.004 (0.004) Batch 0.439 (0.479) Remain 31:51:22 loss: 1.9641 Lr: 0.00021
[2025-04-08 13:55:51,584 INFO misc.py line 113 3298914] Train: [1/100][572/2402] Data 0.004 (0.004) Batch 0.430 (0.478) Remain 31:51:01 loss: 2.2628 Lr: 0.00021
[2025-04-08 13:55:52,053 INFO misc.py line 113 3298914] Train: [1/100][573/2402] Data 0.004 (0.004) Batch 0.470 (0.478) Remain 31:50:57 loss: 2.0980 Lr: 0.00021
[2025-04-08 13:55:52,625 INFO misc.py line 113 3298914] Train: [1/100][574/2402] Data 0.003 (0.004) Batch 0.572 (0.479) Remain 31:51:36 loss: 2.6894 Lr: 0.00021
[2025-04-08 13:55:53,123 INFO misc.py line 113 3298914] Train: [1/100][575/2402] Data 0.003 (0.004) Batch 0.498 (0.479) Remain 31:51:43 loss: 2.1164 Lr: 0.00021
[2025-04-08 13:55:53,682 INFO misc.py line 113 3298914] Train: [1/100][576/2402] Data 0.004 (0.004) Batch 0.559 (0.479) Remain 31:52:16 loss: 1.3904 Lr: 0.00021
[2025-04-08 13:55:54,096 INFO misc.py line 113 3298914] Train: [1/100][577/2402] Data 0.003 (0.004) Batch 0.414 (0.479) Remain 31:51:49 loss: 1.6733 Lr: 0.00021
[2025-04-08 13:55:54,534 INFO misc.py line 113 3298914] Train: [1/100][578/2402] Data 0.003 (0.004) Batch 0.438 (0.479) Remain 31:51:31 loss: 2.5212 Lr: 0.00021
[2025-04-08 13:55:54,922 INFO misc.py line 113 3298914] Train: [1/100][579/2402] Data 0.004 (0.004) Batch 0.387 (0.478) Remain 31:50:53 loss: 2.3215 Lr: 0.00021
[2025-04-08 13:55:55,376 INFO misc.py line 113 3298914] Train: [1/100][580/2402] Data 0.004 (0.004) Batch 0.454 (0.478) Remain 31:50:42 loss: 1.8070 Lr: 0.00021
[2025-04-08 13:55:55,875 INFO misc.py line 113 3298914] Train: [1/100][581/2402] Data 0.004 (0.004) Batch 0.499 (0.478) Remain 31:50:50 loss: 2.1161 Lr: 0.00021
[2025-04-08 13:55:56,287 INFO misc.py line 113 3298914] Train: [1/100][582/2402] Data 0.004 (0.004) Batch 0.412 (0.478) Remain 31:50:22 loss: 2.3702 Lr: 0.00021
[2025-04-08 13:55:56,757 INFO misc.py line 113 3298914] Train: [1/100][583/2402] Data 0.004 (0.004) Batch 0.470 (0.478) Remain 31:50:18 loss: 1.9246 Lr: 0.00021
[2025-04-08 13:55:57,291 INFO misc.py line 113 3298914] Train: [1/100][584/2402] Data 0.003 (0.004) Batch 0.534 (0.478) Remain 31:50:41 loss: 2.0763 Lr: 0.00021
[2025-04-08 13:55:57,783 INFO misc.py line 113 3298914] Train: [1/100][585/2402] Data 0.004 (0.004) Batch 0.492 (0.478) Remain 31:50:46 loss: 2.0744 Lr: 0.00021
[2025-04-08 13:55:58,126 INFO misc.py line 113 3298914] Train: [1/100][586/2402] Data 0.003 (0.004) Batch 0.342 (0.478) Remain 31:49:50 loss: 2.1320 Lr: 0.00021
[2025-04-08 13:55:58,625 INFO misc.py line 113 3298914] Train: [1/100][587/2402] Data 0.004 (0.004) Batch 0.499 (0.478) Remain 31:49:58 loss: 2.3741 Lr: 0.00021
[2025-04-08 13:55:59,178 INFO misc.py line 113 3298914] Train: [1/100][588/2402] Data 0.003 (0.004) Batch 0.553 (0.478) Remain 31:50:28 loss: 1.7610 Lr: 0.00021
[2025-04-08 13:55:59,639 INFO misc.py line 113 3298914] Train: [1/100][589/2402] Data 0.003 (0.004) Batch 0.461 (0.478) Remain 31:50:20 loss: 1.8328 Lr: 0.00021
[2025-04-08 13:56:00,073 INFO misc.py line 113 3298914] Train: [1/100][590/2402] Data 0.004 (0.004) Batch 0.434 (0.478) Remain 31:50:02 loss: 1.6870 Lr: 0.00021
[2025-04-08 13:56:00,483 INFO misc.py line 113 3298914] Train: [1/100][591/2402] Data 0.003 (0.004) Batch 0.410 (0.478) Remain 31:49:34 loss: 1.5875 Lr: 0.00021
[2025-04-08 13:56:00,967 INFO misc.py line 113 3298914] Train: [1/100][592/2402] Data 0.004 (0.004) Batch 0.484 (0.478) Remain 31:49:36 loss: 2.0741 Lr: 0.00021
[2025-04-08 13:56:01,445 INFO misc.py line 113 3298914] Train: [1/100][593/2402] Data 0.003 (0.004) Batch 0.477 (0.478) Remain 31:49:35 loss: 1.6910 Lr: 0.00021
[2025-04-08 13:56:01,837 INFO misc.py line 113 3298914] Train: [1/100][594/2402] Data 0.003 (0.004) Batch 0.393 (0.478) Remain 31:49:00 loss: 1.9014 Lr: 0.00021
[2025-04-08 13:56:02,277 INFO misc.py line 113 3298914] Train: [1/100][595/2402] Data 0.003 (0.004) Batch 0.439 (0.478) Remain 31:48:44 loss: 2.2904 Lr: 0.00021
[2025-04-08 13:56:02,828 INFO misc.py line 113 3298914] Train: [1/100][596/2402] Data 0.004 (0.004) Batch 0.551 (0.478) Remain 31:49:13 loss: 1.8584 Lr: 0.00021
[2025-04-08 13:56:03,314 INFO misc.py line 113 3298914] Train: [1/100][597/2402] Data 0.004 (0.004) Batch 0.486 (0.478) Remain 31:49:15 loss: 2.3445 Lr: 0.00021
[2025-04-08 13:56:03,689 INFO misc.py line 113 3298914] Train: [1/100][598/2402] Data 0.004 (0.004) Batch 0.375 (0.478) Remain 31:48:33 loss: 1.9222 Lr: 0.00021
[2025-04-08 13:56:04,204 INFO misc.py line 113 3298914] Train: [1/100][599/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:48:48 loss: 1.8212 Lr: 0.00021
[2025-04-08 13:56:04,707 INFO misc.py line 113 3298914] Train: [1/100][600/2402] Data 0.003 (0.004) Batch 0.503 (0.478) Remain 31:48:57 loss: 2.3351 Lr: 0.00021
[2025-04-08 13:56:05,142 INFO misc.py line 113 3298914] Train: [1/100][601/2402] Data 0.004 (0.004) Batch 0.435 (0.478) Remain 31:48:40 loss: 1.7320 Lr: 0.00021
[2025-04-08 13:56:05,623 INFO misc.py line 113 3298914] Train: [1/100][602/2402] Data 0.003 (0.004) Batch 0.481 (0.478) Remain 31:48:40 loss: 2.1703 Lr: 0.00021
[2025-04-08 13:56:06,117 INFO misc.py line 113 3298914] Train: [1/100][603/2402] Data 0.003 (0.004) Batch 0.494 (0.478) Remain 31:48:46 loss: 2.1359 Lr: 0.00021
[2025-04-08 13:56:06,555 INFO misc.py line 113 3298914] Train: [1/100][604/2402] Data 0.004 (0.004) Batch 0.438 (0.478) Remain 31:48:30 loss: 1.4906 Lr: 0.00021
[2025-04-08 13:56:07,100 INFO misc.py line 113 3298914] Train: [1/100][605/2402] Data 0.004 (0.004) Batch 0.546 (0.478) Remain 31:48:56 loss: 2.0078 Lr: 0.00021
[2025-04-08 13:56:07,601 INFO misc.py line 113 3298914] Train: [1/100][606/2402] Data 0.003 (0.004) Batch 0.500 (0.478) Remain 31:49:05 loss: 2.2946 Lr: 0.00021
[2025-04-08 13:56:08,098 INFO misc.py line 113 3298914] Train: [1/100][607/2402] Data 0.004 (0.004) Batch 0.497 (0.478) Remain 31:49:12 loss: 1.9516 Lr: 0.00021
[2025-04-08 13:56:08,643 INFO misc.py line 113 3298914] Train: [1/100][608/2402] Data 0.004 (0.004) Batch 0.545 (0.478) Remain 31:49:38 loss: 2.1230 Lr: 0.00021
[2025-04-08 13:56:09,204 INFO misc.py line 113 3298914] Train: [1/100][609/2402] Data 0.004 (0.004) Batch 0.560 (0.478) Remain 31:50:10 loss: 1.6385 Lr: 0.00021
[2025-04-08 13:56:09,766 INFO misc.py line 113 3298914] Train: [1/100][610/2402] Data 0.004 (0.004) Batch 0.562 (0.478) Remain 31:50:42 loss: 2.2307 Lr: 0.00021
[2025-04-08 13:56:10,237 INFO misc.py line 113 3298914] Train: [1/100][611/2402] Data 0.003 (0.004) Batch 0.471 (0.478) Remain 31:50:39 loss: 1.9869 Lr: 0.00021
[2025-04-08 13:56:10,794 INFO misc.py line 113 3298914] Train: [1/100][612/2402] Data 0.004 (0.004) Batch 0.558 (0.479) Remain 31:51:10 loss: 1.8726 Lr: 0.00021
[2025-04-08 13:56:11,229 INFO misc.py line 113 3298914] Train: [1/100][613/2402] Data 0.004 (0.004) Batch 0.434 (0.479) Remain 31:50:52 loss: 1.6659 Lr: 0.00021
[2025-04-08 13:56:11,659 INFO misc.py line 113 3298914] Train: [1/100][614/2402] Data 0.003 (0.004) Batch 0.430 (0.478) Remain 31:50:32 loss: 1.8734 Lr: 0.00021
[2025-04-08 13:56:12,156 INFO misc.py line 113 3298914] Train: [1/100][615/2402] Data 0.004 (0.004) Batch 0.497 (0.478) Remain 31:50:39 loss: 2.0110 Lr: 0.00021
[2025-04-08 13:56:12,692 INFO misc.py line 113 3298914] Train: [1/100][616/2402] Data 0.003 (0.004) Batch 0.536 (0.479) Remain 31:51:01 loss: 2.2463 Lr: 0.00021
[2025-04-08 13:56:13,229 INFO misc.py line 113 3298914] Train: [1/100][617/2402] Data 0.004 (0.004) Batch 0.537 (0.479) Remain 31:51:23 loss: 1.9210 Lr: 0.00021
[2025-04-08 13:56:13,776 INFO misc.py line 113 3298914] Train: [1/100][618/2402] Data 0.003 (0.004) Batch 0.547 (0.479) Remain 31:51:50 loss: 1.8941 Lr: 0.00021
[2025-04-08 13:56:14,208 INFO misc.py line 113 3298914] Train: [1/100][619/2402] Data 0.004 (0.004) Batch 0.432 (0.479) Remain 31:51:31 loss: 1.5163 Lr: 0.00021
[2025-04-08 13:56:14,671 INFO misc.py line 113 3298914] Train: [1/100][620/2402] Data 0.003 (0.004) Batch 0.463 (0.479) Remain 31:51:24 loss: 1.9757 Lr: 0.00021
[2025-04-08 13:56:15,189 INFO misc.py line 113 3298914] Train: [1/100][621/2402] Data 0.003 (0.004) Batch 0.518 (0.479) Remain 31:51:39 loss: 1.9521 Lr: 0.00021
[2025-04-08 13:56:15,671 INFO misc.py line 113 3298914] Train: [1/100][622/2402] Data 0.004 (0.004) Batch 0.482 (0.479) Remain 31:51:40 loss: 1.9174 Lr: 0.00021
[2025-04-08 13:56:16,191 INFO misc.py line 113 3298914] Train: [1/100][623/2402] Data 0.004 (0.004) Batch 0.520 (0.479) Remain 31:51:55 loss: 1.6780 Lr: 0.00021
[2025-04-08 13:56:16,574 INFO misc.py line 113 3298914] Train: [1/100][624/2402] Data 0.004 (0.004) Batch 0.383 (0.479) Remain 31:51:18 loss: 2.0787 Lr: 0.00021
[2025-04-08 13:56:17,046 INFO misc.py line 113 3298914] Train: [1/100][625/2402] Data 0.004 (0.004) Batch 0.472 (0.479) Remain 31:51:15 loss: 1.8213 Lr: 0.00021
[2025-04-08 13:56:17,522 INFO misc.py line 113 3298914] Train: [1/100][626/2402] Data 0.003 (0.004) Batch 0.476 (0.479) Remain 31:51:13 loss: 1.8058 Lr: 0.00021
[2025-04-08 13:56:18,006 INFO misc.py line 113 3298914] Train: [1/100][627/2402] Data 0.004 (0.004) Batch 0.484 (0.479) Remain 31:51:15 loss: 2.2008 Lr: 0.00021
[2025-04-08 13:56:18,573 INFO misc.py line 113 3298914] Train: [1/100][628/2402] Data 0.004 (0.004) Batch 0.567 (0.479) Remain 31:51:48 loss: 2.0461 Lr: 0.00021
[2025-04-08 13:56:19,122 INFO misc.py line 113 3298914] Train: [1/100][629/2402] Data 0.004 (0.004) Batch 0.549 (0.479) Remain 31:52:15 loss: 1.9536 Lr: 0.00021
[2025-04-08 13:56:19,539 INFO misc.py line 113 3298914] Train: [1/100][630/2402] Data 0.004 (0.004) Batch 0.417 (0.479) Remain 31:51:51 loss: 2.2442 Lr: 0.00021
[2025-04-08 13:56:20,121 INFO misc.py line 113 3298914] Train: [1/100][631/2402] Data 0.003 (0.004) Batch 0.582 (0.479) Remain 31:52:29 loss: 2.2721 Lr: 0.00021
[2025-04-08 13:56:20,640 INFO misc.py line 113 3298914] Train: [1/100][632/2402] Data 0.004 (0.004) Batch 0.518 (0.479) Remain 31:52:44 loss: 1.6705 Lr: 0.00021
[2025-04-08 13:56:21,036 INFO misc.py line 113 3298914] Train: [1/100][633/2402] Data 0.003 (0.004) Batch 0.396 (0.479) Remain 31:52:12 loss: 1.7777 Lr: 0.00021
[2025-04-08 13:56:21,580 INFO misc.py line 113 3298914] Train: [1/100][634/2402] Data 0.003 (0.004) Batch 0.544 (0.479) Remain 31:52:36 loss: 2.0138 Lr: 0.00021
[2025-04-08 13:56:22,126 INFO misc.py line 113 3298914] Train: [1/100][635/2402] Data 0.004 (0.004) Batch 0.546 (0.479) Remain 31:53:01 loss: 1.6332 Lr: 0.00021
[2025-04-08 13:56:22,551 INFO misc.py line 113 3298914] Train: [1/100][636/2402] Data 0.003 (0.004) Batch 0.425 (0.479) Remain 31:52:40 loss: 1.4390 Lr: 0.00021
[2025-04-08 13:56:23,005 INFO misc.py line 113 3298914] Train: [1/100][637/2402] Data 0.003 (0.004) Batch 0.454 (0.479) Remain 31:52:30 loss: 1.6714 Lr: 0.00021
[2025-04-08 13:56:23,466 INFO misc.py line 113 3298914] Train: [1/100][638/2402] Data 0.004 (0.004) Batch 0.462 (0.479) Remain 31:52:23 loss: 2.1238 Lr: 0.00021
[2025-04-08 13:56:24,016 INFO misc.py line 113 3298914] Train: [1/100][639/2402] Data 0.003 (0.004) Batch 0.549 (0.479) Remain 31:52:49 loss: 1.9575 Lr: 0.00021
[2025-04-08 13:56:24,506 INFO misc.py line 113 3298914] Train: [1/100][640/2402] Data 0.004 (0.004) Batch 0.491 (0.479) Remain 31:52:53 loss: 2.1750 Lr: 0.00021
[2025-04-08 13:56:24,883 INFO misc.py line 113 3298914] Train: [1/100][641/2402] Data 0.003 (0.004) Batch 0.377 (0.479) Remain 31:52:14 loss: 1.9519 Lr: 0.00021
[2025-04-08 13:56:25,440 INFO misc.py line 113 3298914] Train: [1/100][642/2402] Data 0.004 (0.004) Batch 0.558 (0.479) Remain 31:52:43 loss: 2.2012 Lr: 0.00021
[2025-04-08 13:56:25,955 INFO misc.py line 113 3298914] Train: [1/100][643/2402] Data 0.004 (0.004) Batch 0.514 (0.479) Remain 31:52:56 loss: 2.3149 Lr: 0.00021
[2025-04-08 13:56:26,397 INFO misc.py line 113 3298914] Train: [1/100][644/2402] Data 0.003 (0.004) Batch 0.443 (0.479) Remain 31:52:42 loss: 1.5192 Lr: 0.00021
[2025-04-08 13:56:26,978 INFO misc.py line 113 3298914] Train: [1/100][645/2402] Data 0.003 (0.004) Batch 0.581 (0.479) Remain 31:53:19 loss: 2.1233 Lr: 0.00021
[2025-04-08 13:56:27,362 INFO misc.py line 113 3298914] Train: [1/100][646/2402] Data 0.004 (0.004) Batch 0.384 (0.479) Remain 31:52:43 loss: 1.3279 Lr: 0.00021
[2025-04-08 13:56:27,863 INFO misc.py line 113 3298914] Train: [1/100][647/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:52:51 loss: 1.4448 Lr: 0.00021
[2025-04-08 13:56:28,406 INFO misc.py line 113 3298914] Train: [1/100][648/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:53:14 loss: 1.6473 Lr: 0.00021
[2025-04-08 13:56:28,871 INFO misc.py line 113 3298914] Train: [1/100][649/2402] Data 0.003 (0.004) Batch 0.465 (0.479) Remain 31:53:08 loss: 2.0524 Lr: 0.00021
[2025-04-08 13:56:29,336 INFO misc.py line 113 3298914] Train: [1/100][650/2402] Data 0.003 (0.004) Batch 0.465 (0.479) Remain 31:53:03 loss: 1.7054 Lr: 0.00021
[2025-04-08 13:56:29,947 INFO misc.py line 113 3298914] Train: [1/100][651/2402] Data 0.004 (0.004) Batch 0.611 (0.479) Remain 31:53:51 loss: 1.9652 Lr: 0.00021
[2025-04-08 13:56:30,419 INFO misc.py line 113 3298914] Train: [1/100][652/2402] Data 0.003 (0.004) Batch 0.472 (0.479) Remain 31:53:48 loss: 2.0902 Lr: 0.00021
[2025-04-08 13:56:30,833 INFO misc.py line 113 3298914] Train: [1/100][653/2402] Data 0.003 (0.004) Batch 0.414 (0.479) Remain 31:53:23 loss: 1.7201 Lr: 0.00021
[2025-04-08 13:56:31,442 INFO misc.py line 113 3298914] Train: [1/100][654/2402] Data 0.003 (0.004) Batch 0.609 (0.479) Remain 31:54:10 loss: 2.1844 Lr: 0.00021
[2025-04-08 13:56:31,853 INFO misc.py line 113 3298914] Train: [1/100][655/2402] Data 0.004 (0.004) Batch 0.412 (0.479) Remain 31:53:45 loss: 2.0240 Lr: 0.00021
[2025-04-08 13:56:32,285 INFO misc.py line 113 3298914] Train: [1/100][656/2402] Data 0.003 (0.004) Batch 0.432 (0.479) Remain 31:53:27 loss: 2.1631 Lr: 0.00021
[2025-04-08 13:56:32,831 INFO misc.py line 113 3298914] Train: [1/100][657/2402] Data 0.003 (0.004) Batch 0.546 (0.479) Remain 31:53:51 loss: 1.5791 Lr: 0.00021
[2025-04-08 13:56:33,388 INFO misc.py line 113 3298914] Train: [1/100][658/2402] Data 0.004 (0.004) Batch 0.556 (0.479) Remain 31:54:19 loss: 2.0926 Lr: 0.00021
[2025-04-08 13:56:33,903 INFO misc.py line 113 3298914] Train: [1/100][659/2402] Data 0.003 (0.004) Batch 0.515 (0.480) Remain 31:54:31 loss: 1.8750 Lr: 0.00021
[2025-04-08 13:56:34,263 INFO misc.py line 113 3298914] Train: [1/100][660/2402] Data 0.004 (0.004) Batch 0.360 (0.479) Remain 31:53:47 loss: 2.1896 Lr: 0.00021
[2025-04-08 13:56:34,751 INFO misc.py line 113 3298914] Train: [1/100][661/2402] Data 0.004 (0.004) Batch 0.488 (0.479) Remain 31:53:50 loss: 1.6395 Lr: 0.00021
[2025-04-08 13:56:35,240 INFO misc.py line 113 3298914] Train: [1/100][662/2402] Data 0.004 (0.004) Batch 0.489 (0.479) Remain 31:53:53 loss: 1.9945 Lr: 0.00021
[2025-04-08 13:56:35,777 INFO misc.py line 113 3298914] Train: [1/100][663/2402] Data 0.003 (0.004) Batch 0.536 (0.479) Remain 31:54:13 loss: 1.5767 Lr: 0.00021
[2025-04-08 13:56:36,250 INFO misc.py line 113 3298914] Train: [1/100][664/2402] Data 0.004 (0.004) Batch 0.474 (0.479) Remain 31:54:10 loss: 2.0746 Lr: 0.00021
[2025-04-08 13:56:36,707 INFO misc.py line 113 3298914] Train: [1/100][665/2402] Data 0.003 (0.004) Batch 0.458 (0.479) Remain 31:54:02 loss: 1.8020 Lr: 0.00021
[2025-04-08 13:56:37,163 INFO misc.py line 113 3298914] Train: [1/100][666/2402] Data 0.003 (0.004) Batch 0.456 (0.479) Remain 31:53:53 loss: 2.4017 Lr: 0.00021
[2025-04-08 13:56:37,624 INFO misc.py line 113 3298914] Train: [1/100][667/2402] Data 0.004 (0.004) Batch 0.461 (0.479) Remain 31:53:46 loss: 1.6462 Lr: 0.00021
[2025-04-08 13:56:38,186 INFO misc.py line 113 3298914] Train: [1/100][668/2402] Data 0.003 (0.004) Batch 0.562 (0.480) Remain 31:54:15 loss: 2.0119 Lr: 0.00021
[2025-04-08 13:56:38,646 INFO misc.py line 113 3298914] Train: [1/100][669/2402] Data 0.004 (0.004) Batch 0.459 (0.479) Remain 31:54:07 loss: 1.7913 Lr: 0.00021
[2025-04-08 13:56:39,078 INFO misc.py line 113 3298914] Train: [1/100][670/2402] Data 0.004 (0.004) Batch 0.432 (0.479) Remain 31:53:50 loss: 2.1442 Lr: 0.00021
[2025-04-08 13:56:39,519 INFO misc.py line 113 3298914] Train: [1/100][671/2402] Data 0.004 (0.004) Batch 0.441 (0.479) Remain 31:53:36 loss: 1.8529 Lr: 0.00021
[2025-04-08 13:56:39,992 INFO misc.py line 113 3298914] Train: [1/100][672/2402] Data 0.004 (0.004) Batch 0.473 (0.479) Remain 31:53:33 loss: 1.9263 Lr: 0.00021
[2025-04-08 13:56:40,478 INFO misc.py line 113 3298914] Train: [1/100][673/2402] Data 0.003 (0.004) Batch 0.487 (0.479) Remain 31:53:35 loss: 1.9253 Lr: 0.00021
[2025-04-08 13:56:41,006 INFO misc.py line 113 3298914] Train: [1/100][674/2402] Data 0.003 (0.004) Batch 0.527 (0.479) Remain 31:53:52 loss: 1.8760 Lr: 0.00021
[2025-04-08 13:56:41,426 INFO misc.py line 113 3298914] Train: [1/100][675/2402] Data 0.004 (0.004) Batch 0.420 (0.479) Remain 31:53:30 loss: 1.7295 Lr: 0.00021
[2025-04-08 13:56:41,804 INFO misc.py line 113 3298914] Train: [1/100][676/2402] Data 0.004 (0.004) Batch 0.378 (0.479) Remain 31:52:54 loss: 1.9647 Lr: 0.00021
[2025-04-08 13:56:42,284 INFO misc.py line 113 3298914] Train: [1/100][677/2402] Data 0.003 (0.004) Batch 0.480 (0.479) Remain 31:52:53 loss: 2.2425 Lr: 0.00021
[2025-04-08 13:56:42,787 INFO misc.py line 113 3298914] Train: [1/100][678/2402] Data 0.004 (0.004) Batch 0.503 (0.479) Remain 31:53:01 loss: 1.8281 Lr: 0.00021
[2025-04-08 13:56:43,300 INFO misc.py line 113 3298914] Train: [1/100][679/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:53:13 loss: 1.9144 Lr: 0.00021
[2025-04-08 13:56:43,828 INFO misc.py line 113 3298914] Train: [1/100][680/2402] Data 0.004 (0.004) Batch 0.528 (0.479) Remain 31:53:30 loss: 2.3403 Lr: 0.00021
[2025-04-08 13:56:44,218 INFO misc.py line 113 3298914] Train: [1/100][681/2402] Data 0.003 (0.004) Batch 0.390 (0.479) Remain 31:52:58 loss: 1.6949 Lr: 0.00021
[2025-04-08 13:56:44,740 INFO misc.py line 113 3298914] Train: [1/100][682/2402] Data 0.003 (0.004) Batch 0.522 (0.479) Remain 31:53:12 loss: 1.8039 Lr: 0.00021
[2025-04-08 13:56:45,261 INFO misc.py line 113 3298914] Train: [1/100][683/2402] Data 0.004 (0.004) Batch 0.521 (0.479) Remain 31:53:26 loss: 1.4325 Lr: 0.00021
[2025-04-08 13:56:45,618 INFO misc.py line 113 3298914] Train: [1/100][684/2402] Data 0.003 (0.004) Batch 0.357 (0.479) Remain 31:52:43 loss: 2.1416 Lr: 0.00021
[2025-04-08 13:56:46,110 INFO misc.py line 113 3298914] Train: [1/100][685/2402] Data 0.003 (0.004) Batch 0.492 (0.479) Remain 31:52:47 loss: 1.9116 Lr: 0.00021
[2025-04-08 13:56:46,527 INFO misc.py line 113 3298914] Train: [1/100][686/2402] Data 0.003 (0.004) Batch 0.417 (0.479) Remain 31:52:25 loss: 2.0042 Lr: 0.00021
[2025-04-08 13:56:47,070 INFO misc.py line 113 3298914] Train: [1/100][687/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:52:46 loss: 1.7403 Lr: 0.00021
[2025-04-08 13:56:47,525 INFO misc.py line 113 3298914] Train: [1/100][688/2402] Data 0.004 (0.004) Batch 0.456 (0.479) Remain 31:52:38 loss: 1.5844 Lr: 0.00021
[2025-04-08 13:56:47,958 INFO misc.py line 113 3298914] Train: [1/100][689/2402] Data 0.003 (0.004) Batch 0.433 (0.479) Remain 31:52:21 loss: 1.9071 Lr: 0.00021
[2025-04-08 13:56:48,415 INFO misc.py line 113 3298914] Train: [1/100][690/2402] Data 0.003 (0.004) Batch 0.457 (0.479) Remain 31:52:13 loss: 1.9138 Lr: 0.00021
[2025-04-08 13:56:48,925 INFO misc.py line 113 3298914] Train: [1/100][691/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:52:23 loss: 2.1261 Lr: 0.00021
[2025-04-08 13:56:49,395 INFO misc.py line 113 3298914] Train: [1/100][692/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:52:20 loss: 1.8527 Lr: 0.00021
[2025-04-08 13:56:49,893 INFO misc.py line 113 3298914] Train: [1/100][693/2402] Data 0.003 (0.004) Batch 0.498 (0.479) Remain 31:52:26 loss: 2.0173 Lr: 0.00021
[2025-04-08 13:56:50,343 INFO misc.py line 113 3298914] Train: [1/100][694/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:52:15 loss: 1.7604 Lr: 0.00021
[2025-04-08 13:56:50,789 INFO misc.py line 113 3298914] Train: [1/100][695/2402] Data 0.003 (0.004) Batch 0.446 (0.479) Remain 31:52:03 loss: 1.7813 Lr: 0.00021
[2025-04-08 13:56:51,380 INFO misc.py line 113 3298914] Train: [1/100][696/2402] Data 0.004 (0.004) Batch 0.591 (0.479) Remain 31:52:42 loss: 2.1871 Lr: 0.00021
[2025-04-08 13:56:51,927 INFO misc.py line 113 3298914] Train: [1/100][697/2402] Data 0.003 (0.004) Batch 0.547 (0.479) Remain 31:53:04 loss: 2.0176 Lr: 0.00021
[2025-04-08 13:56:52,387 INFO misc.py line 113 3298914] Train: [1/100][698/2402] Data 0.004 (0.004) Batch 0.460 (0.479) Remain 31:52:57 loss: 1.9995 Lr: 0.00021
[2025-04-08 13:56:52,869 INFO misc.py line 113 3298914] Train: [1/100][699/2402] Data 0.003 (0.004) Batch 0.482 (0.479) Remain 31:52:58 loss: 1.9321 Lr: 0.00021
[2025-04-08 13:56:53,291 INFO misc.py line 113 3298914] Train: [1/100][700/2402] Data 0.003 (0.004) Batch 0.423 (0.479) Remain 31:52:38 loss: 2.0123 Lr: 0.00021
[2025-04-08 13:56:53,722 INFO misc.py line 113 3298914] Train: [1/100][701/2402] Data 0.004 (0.004) Batch 0.431 (0.479) Remain 31:52:21 loss: 2.0592 Lr: 0.00022
[2025-04-08 13:56:54,178 INFO misc.py line 113 3298914] Train: [1/100][702/2402] Data 0.004 (0.004) Batch 0.455 (0.479) Remain 31:52:12 loss: 1.9046 Lr: 0.00022
[2025-04-08 13:56:54,723 INFO misc.py line 113 3298914] Train: [1/100][703/2402] Data 0.004 (0.004) Batch 0.545 (0.479) Remain 31:52:34 loss: 2.1314 Lr: 0.00022
[2025-04-08 13:56:55,141 INFO misc.py line 113 3298914] Train: [1/100][704/2402] Data 0.004 (0.004) Batch 0.418 (0.479) Remain 31:52:13 loss: 1.9460 Lr: 0.00022
[2025-04-08 13:56:55,509 INFO misc.py line 113 3298914] Train: [1/100][705/2402] Data 0.004 (0.004) Batch 0.368 (0.479) Remain 31:51:34 loss: 1.6071 Lr: 0.00022
[2025-04-08 13:56:56,037 INFO misc.py line 113 3298914] Train: [1/100][706/2402] Data 0.004 (0.004) Batch 0.528 (0.479) Remain 31:51:51 loss: 1.8713 Lr: 0.00022
[2025-04-08 13:56:56,492 INFO misc.py line 113 3298914] Train: [1/100][707/2402] Data 0.004 (0.004) Batch 0.455 (0.479) Remain 31:51:42 loss: 2.1182 Lr: 0.00022
[2025-04-08 13:56:56,925 INFO misc.py line 113 3298914] Train: [1/100][708/2402] Data 0.004 (0.004) Batch 0.433 (0.479) Remain 31:51:26 loss: 1.8238 Lr: 0.00022
[2025-04-08 13:56:57,435 INFO misc.py line 113 3298914] Train: [1/100][709/2402] Data 0.003 (0.004) Batch 0.510 (0.479) Remain 31:51:36 loss: 1.5868 Lr: 0.00022
[2025-04-08 13:56:57,904 INFO misc.py line 113 3298914] Train: [1/100][710/2402] Data 0.004 (0.004) Batch 0.469 (0.479) Remain 31:51:32 loss: 2.0375 Lr: 0.00022
[2025-04-08 13:56:58,388 INFO misc.py line 113 3298914] Train: [1/100][711/2402] Data 0.004 (0.004) Batch 0.484 (0.479) Remain 31:51:33 loss: 1.9967 Lr: 0.00022
[2025-04-08 13:56:58,953 INFO misc.py line 113 3298914] Train: [1/100][712/2402] Data 0.003 (0.004) Batch 0.565 (0.479) Remain 31:52:02 loss: 1.7387 Lr: 0.00022
[2025-04-08 13:56:59,490 INFO misc.py line 113 3298914] Train: [1/100][713/2402] Data 0.004 (0.004) Batch 0.537 (0.479) Remain 31:52:21 loss: 1.9808 Lr: 0.00022
[2025-04-08 13:56:59,991 INFO misc.py line 113 3298914] Train: [1/100][714/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:52:28 loss: 1.9659 Lr: 0.00022
[2025-04-08 13:57:00,467 INFO misc.py line 113 3298914] Train: [1/100][715/2402] Data 0.003 (0.004) Batch 0.476 (0.479) Remain 31:52:26 loss: 1.8868 Lr: 0.00022
[2025-04-08 13:57:00,892 INFO misc.py line 113 3298914] Train: [1/100][716/2402] Data 0.003 (0.004) Batch 0.426 (0.479) Remain 31:52:08 loss: 1.7477 Lr: 0.00022
[2025-04-08 13:57:01,354 INFO misc.py line 113 3298914] Train: [1/100][717/2402] Data 0.003 (0.004) Batch 0.462 (0.479) Remain 31:52:02 loss: 1.6804 Lr: 0.00022
[2025-04-08 13:57:01,756 INFO misc.py line 113 3298914] Train: [1/100][718/2402] Data 0.004 (0.004) Batch 0.402 (0.479) Remain 31:51:35 loss: 1.9537 Lr: 0.00022
[2025-04-08 13:57:02,323 INFO misc.py line 113 3298914] Train: [1/100][719/2402] Data 0.003 (0.004) Batch 0.566 (0.479) Remain 31:52:04 loss: 1.9379 Lr: 0.00022
[2025-04-08 13:57:02,895 INFO misc.py line 113 3298914] Train: [1/100][720/2402] Data 0.003 (0.004) Batch 0.572 (0.479) Remain 31:52:35 loss: 2.3610 Lr: 0.00022
[2025-04-08 13:57:03,309 INFO misc.py line 113 3298914] Train: [1/100][721/2402] Data 0.004 (0.004) Batch 0.414 (0.479) Remain 31:52:13 loss: 1.8728 Lr: 0.00022
[2025-04-08 13:57:03,759 INFO misc.py line 113 3298914] Train: [1/100][722/2402] Data 0.004 (0.004) Batch 0.450 (0.479) Remain 31:52:03 loss: 1.9501 Lr: 0.00022
[2025-04-08 13:57:04,326 INFO misc.py line 113 3298914] Train: [1/100][723/2402] Data 0.003 (0.004) Batch 0.567 (0.479) Remain 31:52:31 loss: 2.0486 Lr: 0.00022
[2025-04-08 13:57:04,853 INFO misc.py line 113 3298914] Train: [1/100][724/2402] Data 0.003 (0.004) Batch 0.527 (0.479) Remain 31:52:47 loss: 2.1321 Lr: 0.00022
[2025-04-08 13:57:05,344 INFO misc.py line 113 3298914] Train: [1/100][725/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:52:50 loss: 1.8889 Lr: 0.00022
[2025-04-08 13:57:05,867 INFO misc.py line 113 3298914] Train: [1/100][726/2402] Data 0.003 (0.004) Batch 0.523 (0.479) Remain 31:53:04 loss: 1.3879 Lr: 0.00022
[2025-04-08 13:57:06,387 INFO misc.py line 113 3298914] Train: [1/100][727/2402] Data 0.004 (0.004) Batch 0.520 (0.479) Remain 31:53:17 loss: 1.7941 Lr: 0.00022
[2025-04-08 13:57:06,926 INFO misc.py line 113 3298914] Train: [1/100][728/2402] Data 0.003 (0.004) Batch 0.539 (0.479) Remain 31:53:36 loss: 2.0796 Lr: 0.00022
[2025-04-08 13:57:07,392 INFO misc.py line 113 3298914] Train: [1/100][729/2402] Data 0.004 (0.004) Batch 0.466 (0.479) Remain 31:53:31 loss: 1.9867 Lr: 0.00022
[2025-04-08 13:57:07,965 INFO misc.py line 113 3298914] Train: [1/100][730/2402] Data 0.004 (0.004) Batch 0.573 (0.480) Remain 31:54:02 loss: 1.8351 Lr: 0.00022
[2025-04-08 13:57:08,364 INFO misc.py line 113 3298914] Train: [1/100][731/2402] Data 0.003 (0.004) Batch 0.399 (0.479) Remain 31:53:35 loss: 1.9116 Lr: 0.00022
[2025-04-08 13:57:08,759 INFO misc.py line 113 3298914] Train: [1/100][732/2402] Data 0.004 (0.004) Batch 0.395 (0.479) Remain 31:53:06 loss: 1.9959 Lr: 0.00022
[2025-04-08 13:57:09,097 INFO misc.py line 113 3298914] Train: [1/100][733/2402] Data 0.003 (0.004) Batch 0.338 (0.479) Remain 31:52:20 loss: 2.2471 Lr: 0.00022
[2025-04-08 13:57:09,609 INFO misc.py line 113 3298914] Train: [1/100][734/2402] Data 0.003 (0.004) Batch 0.512 (0.479) Remain 31:52:30 loss: 2.2015 Lr: 0.00022
[2025-04-08 13:57:10,118 INFO misc.py line 113 3298914] Train: [1/100][735/2402] Data 0.004 (0.004) Batch 0.508 (0.479) Remain 31:52:39 loss: 1.4422 Lr: 0.00022
[2025-04-08 13:57:10,549 INFO misc.py line 113 3298914] Train: [1/100][736/2402] Data 0.004 (0.004) Batch 0.432 (0.479) Remain 31:52:23 loss: 2.1246 Lr: 0.00022
[2025-04-08 13:57:10,949 INFO misc.py line 113 3298914] Train: [1/100][737/2402] Data 0.003 (0.004) Batch 0.400 (0.479) Remain 31:51:57 loss: 1.9425 Lr: 0.00022
[2025-04-08 13:57:11,384 INFO misc.py line 113 3298914] Train: [1/100][738/2402] Data 0.003 (0.004) Batch 0.434 (0.479) Remain 31:51:42 loss: 1.8917 Lr: 0.00022
[2025-04-08 13:57:11,894 INFO misc.py line 113 3298914] Train: [1/100][739/2402] Data 0.004 (0.004) Batch 0.510 (0.479) Remain 31:51:51 loss: 1.8803 Lr: 0.00022
[2025-04-08 13:57:12,320 INFO misc.py line 113 3298914] Train: [1/100][740/2402] Data 0.003 (0.004) Batch 0.426 (0.479) Remain 31:51:34 loss: 2.1042 Lr: 0.00022
[2025-04-08 13:57:12,851 INFO misc.py line 113 3298914] Train: [1/100][741/2402] Data 0.003 (0.004) Batch 0.531 (0.479) Remain 31:51:50 loss: 1.8590 Lr: 0.00022
[2025-04-08 13:57:13,400 INFO misc.py line 113 3298914] Train: [1/100][742/2402] Data 0.004 (0.004) Batch 0.550 (0.479) Remain 31:52:12 loss: 2.0642 Lr: 0.00022
[2025-04-08 13:57:13,827 INFO misc.py line 113 3298914] Train: [1/100][743/2402] Data 0.003 (0.004) Batch 0.426 (0.479) Remain 31:51:55 loss: 1.6104 Lr: 0.00022
[2025-04-08 13:57:14,241 INFO misc.py line 113 3298914] Train: [1/100][744/2402] Data 0.003 (0.004) Batch 0.414 (0.479) Remain 31:51:33 loss: 1.6779 Lr: 0.00022
[2025-04-08 13:57:14,656 INFO misc.py line 113 3298914] Train: [1/100][745/2402] Data 0.004 (0.004) Batch 0.415 (0.479) Remain 31:51:12 loss: 2.0354 Lr: 0.00022
[2025-04-08 13:57:15,093 INFO misc.py line 113 3298914] Train: [1/100][746/2402] Data 0.003 (0.004) Batch 0.436 (0.479) Remain 31:50:58 loss: 2.1956 Lr: 0.00022
[2025-04-08 13:57:15,565 INFO misc.py line 113 3298914] Train: [1/100][747/2402] Data 0.003 (0.004) Batch 0.472 (0.479) Remain 31:50:56 loss: 1.6264 Lr: 0.00022
[2025-04-08 13:57:16,231 INFO misc.py line 113 3298914] Train: [1/100][748/2402] Data 0.004 (0.004) Batch 0.666 (0.479) Remain 31:51:55 loss: 1.6934 Lr: 0.00022
[2025-04-08 13:57:16,651 INFO misc.py line 113 3298914] Train: [1/100][749/2402] Data 0.004 (0.004) Batch 0.421 (0.479) Remain 31:51:36 loss: 1.9668 Lr: 0.00022
[2025-04-08 13:57:17,122 INFO misc.py line 113 3298914] Train: [1/100][750/2402] Data 0.004 (0.004) Batch 0.471 (0.479) Remain 31:51:33 loss: 1.9722 Lr: 0.00022
[2025-04-08 13:57:17,597 INFO misc.py line 113 3298914] Train: [1/100][751/2402] Data 0.003 (0.004) Batch 0.475 (0.479) Remain 31:51:31 loss: 1.8133 Lr: 0.00022
[2025-04-08 13:57:18,100 INFO misc.py line 113 3298914] Train: [1/100][752/2402] Data 0.004 (0.004) Batch 0.503 (0.479) Remain 31:51:38 loss: 2.1578 Lr: 0.00022
[2025-04-08 13:57:18,509 INFO misc.py line 113 3298914] Train: [1/100][753/2402] Data 0.004 (0.004) Batch 0.409 (0.479) Remain 31:51:16 loss: 1.7922 Lr: 0.00022
[2025-04-08 13:57:19,005 INFO misc.py line 113 3298914] Train: [1/100][754/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:51:20 loss: 1.8102 Lr: 0.00022
[2025-04-08 13:57:19,582 INFO misc.py line 113 3298914] Train: [1/100][755/2402] Data 0.003 (0.004) Batch 0.576 (0.479) Remain 31:51:51 loss: 1.9978 Lr: 0.00022
[2025-04-08 13:57:20,085 INFO misc.py line 113 3298914] Train: [1/100][756/2402] Data 0.004 (0.004) Batch 0.503 (0.479) Remain 31:51:58 loss: 2.0719 Lr: 0.00022
[2025-04-08 13:57:20,655 INFO misc.py line 113 3298914] Train: [1/100][757/2402] Data 0.003 (0.004) Batch 0.570 (0.479) Remain 31:52:27 loss: 1.5865 Lr: 0.00022
[2025-04-08 13:57:21,066 INFO misc.py line 113 3298914] Train: [1/100][758/2402] Data 0.003 (0.004) Batch 0.411 (0.479) Remain 31:52:04 loss: 2.1663 Lr: 0.00022
[2025-04-08 13:57:21,583 INFO misc.py line 113 3298914] Train: [1/100][759/2402] Data 0.004 (0.004) Batch 0.517 (0.479) Remain 31:52:16 loss: 2.2344 Lr: 0.00022
[2025-04-08 13:57:22,087 INFO misc.py line 113 3298914] Train: [1/100][760/2402] Data 0.003 (0.004) Batch 0.504 (0.479) Remain 31:52:24 loss: 1.7030 Lr: 0.00022
[2025-04-08 13:57:22,683 INFO misc.py line 113 3298914] Train: [1/100][761/2402] Data 0.003 (0.004) Batch 0.596 (0.479) Remain 31:53:00 loss: 1.9732 Lr: 0.00022
[2025-04-08 13:57:23,185 INFO misc.py line 113 3298914] Train: [1/100][762/2402] Data 0.004 (0.004) Batch 0.502 (0.479) Remain 31:53:07 loss: 1.6473 Lr: 0.00022
[2025-04-08 13:57:23,656 INFO misc.py line 113 3298914] Train: [1/100][763/2402] Data 0.003 (0.004) Batch 0.471 (0.479) Remain 31:53:04 loss: 2.0337 Lr: 0.00022
[2025-04-08 13:57:24,076 INFO misc.py line 113 3298914] Train: [1/100][764/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:52:44 loss: 1.8407 Lr: 0.00022
[2025-04-08 13:57:24,557 INFO misc.py line 113 3298914] Train: [1/100][765/2402] Data 0.004 (0.004) Batch 0.481 (0.479) Remain 31:52:44 loss: 1.9696 Lr: 0.00022
[2025-04-08 13:57:24,985 INFO misc.py line 113 3298914] Train: [1/100][766/2402] Data 0.003 (0.004) Batch 0.428 (0.479) Remain 31:52:28 loss: 2.0422 Lr: 0.00022
[2025-04-08 13:57:25,525 INFO misc.py line 113 3298914] Train: [1/100][767/2402] Data 0.004 (0.004) Batch 0.540 (0.479) Remain 31:52:46 loss: 1.8881 Lr: 0.00022
[2025-04-08 13:57:25,974 INFO misc.py line 113 3298914] Train: [1/100][768/2402] Data 0.004 (0.004) Batch 0.448 (0.479) Remain 31:52:36 loss: 2.1691 Lr: 0.00022
[2025-04-08 13:57:26,582 INFO misc.py line 113 3298914] Train: [1/100][769/2402] Data 0.004 (0.004) Batch 0.609 (0.479) Remain 31:53:16 loss: 2.1474 Lr: 0.00022
[2025-04-08 13:57:26,999 INFO misc.py line 113 3298914] Train: [1/100][770/2402] Data 0.004 (0.004) Batch 0.417 (0.479) Remain 31:52:56 loss: 1.5858 Lr: 0.00022
[2025-04-08 13:57:27,505 INFO misc.py line 113 3298914] Train: [1/100][771/2402] Data 0.004 (0.004) Batch 0.506 (0.479) Remain 31:53:04 loss: 1.8022 Lr: 0.00022
[2025-04-08 13:57:27,941 INFO misc.py line 113 3298914] Train: [1/100][772/2402] Data 0.003 (0.004) Batch 0.435 (0.479) Remain 31:52:50 loss: 1.7685 Lr: 0.00022
[2025-04-08 13:57:28,500 INFO misc.py line 113 3298914] Train: [1/100][773/2402] Data 0.004 (0.004) Batch 0.559 (0.479) Remain 31:53:14 loss: 2.0040 Lr: 0.00022
[2025-04-08 13:57:28,911 INFO misc.py line 113 3298914] Train: [1/100][774/2402] Data 0.003 (0.004) Batch 0.411 (0.479) Remain 31:52:53 loss: 1.7431 Lr: 0.00022
[2025-04-08 13:57:29,437 INFO misc.py line 113 3298914] Train: [1/100][775/2402] Data 0.003 (0.004) Batch 0.525 (0.479) Remain 31:53:06 loss: 1.8720 Lr: 0.00022
[2025-04-08 13:57:29,857 INFO misc.py line 113 3298914] Train: [1/100][776/2402] Data 0.004 (0.004) Batch 0.421 (0.479) Remain 31:52:48 loss: 1.6452 Lr: 0.00022
[2025-04-08 13:57:30,370 INFO misc.py line 113 3298914] Train: [1/100][777/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:52:58 loss: 1.8266 Lr: 0.00022
[2025-04-08 13:57:30,791 INFO misc.py line 113 3298914] Train: [1/100][778/2402] Data 0.003 (0.004) Batch 0.421 (0.479) Remain 31:52:39 loss: 1.8605 Lr: 0.00022
[2025-04-08 13:57:31,276 INFO misc.py line 113 3298914] Train: [1/100][779/2402] Data 0.003 (0.004) Batch 0.485 (0.479) Remain 31:52:40 loss: 1.8154 Lr: 0.00022
[2025-04-08 13:57:31,786 INFO misc.py line 113 3298914] Train: [1/100][780/2402] Data 0.004 (0.004) Batch 0.510 (0.479) Remain 31:52:49 loss: 2.3460 Lr: 0.00022
[2025-04-08 13:57:32,179 INFO misc.py line 113 3298914] Train: [1/100][781/2402] Data 0.004 (0.004) Batch 0.393 (0.479) Remain 31:52:22 loss: 2.0672 Lr: 0.00022
[2025-04-08 13:57:32,707 INFO misc.py line 113 3298914] Train: [1/100][782/2402] Data 0.004 (0.004) Batch 0.529 (0.479) Remain 31:52:37 loss: 2.3507 Lr: 0.00022
[2025-04-08 13:57:33,202 INFO misc.py line 113 3298914] Train: [1/100][783/2402] Data 0.003 (0.004) Batch 0.495 (0.479) Remain 31:52:41 loss: 1.4729 Lr: 0.00022
[2025-04-08 13:57:33,697 INFO misc.py line 113 3298914] Train: [1/100][784/2402] Data 0.003 (0.004) Batch 0.495 (0.479) Remain 31:52:45 loss: 1.7164 Lr: 0.00022
[2025-04-08 13:57:34,197 INFO misc.py line 113 3298914] Train: [1/100][785/2402] Data 0.003 (0.004) Batch 0.500 (0.479) Remain 31:52:51 loss: 2.1687 Lr: 0.00022
[2025-04-08 13:57:34,765 INFO misc.py line 113 3298914] Train: [1/100][786/2402] Data 0.004 (0.004) Batch 0.568 (0.479) Remain 31:53:18 loss: 1.5674 Lr: 0.00022
[2025-04-08 13:57:35,204 INFO misc.py line 113 3298914] Train: [1/100][787/2402] Data 0.003 (0.004) Batch 0.439 (0.479) Remain 31:53:05 loss: 1.4793 Lr: 0.00022
[2025-04-08 13:57:35,653 INFO misc.py line 113 3298914] Train: [1/100][788/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:52:55 loss: 1.7862 Lr: 0.00022
[2025-04-08 13:57:36,154 INFO misc.py line 113 3298914] Train: [1/100][789/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:53:01 loss: 1.6468 Lr: 0.00022
[2025-04-08 13:57:36,778 INFO misc.py line 113 3298914] Train: [1/100][790/2402] Data 0.004 (0.004) Batch 0.625 (0.480) Remain 31:53:45 loss: 1.9890 Lr: 0.00022
[2025-04-08 13:57:37,292 INFO misc.py line 113 3298914] Train: [1/100][791/2402] Data 0.003 (0.004) Batch 0.513 (0.480) Remain 31:53:55 loss: 1.5593 Lr: 0.00022
[2025-04-08 13:57:37,717 INFO misc.py line 113 3298914] Train: [1/100][792/2402] Data 0.004 (0.004) Batch 0.425 (0.480) Remain 31:53:38 loss: 1.9088 Lr: 0.00022
[2025-04-08 13:57:38,196 INFO misc.py line 113 3298914] Train: [1/100][793/2402] Data 0.004 (0.004) Batch 0.478 (0.480) Remain 31:53:37 loss: 1.8004 Lr: 0.00022
[2025-04-08 13:57:38,747 INFO misc.py line 113 3298914] Train: [1/100][794/2402] Data 0.004 (0.004) Batch 0.551 (0.480) Remain 31:53:58 loss: 1.6519 Lr: 0.00022
[2025-04-08 13:57:39,179 INFO misc.py line 113 3298914] Train: [1/100][795/2402] Data 0.004 (0.004) Batch 0.432 (0.480) Remain 31:53:43 loss: 2.0124 Lr: 0.00022
[2025-04-08 13:57:39,619 INFO misc.py line 113 3298914] Train: [1/100][796/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:53:31 loss: 1.9263 Lr: 0.00022
[2025-04-08 13:57:40,150 INFO misc.py line 113 3298914] Train: [1/100][797/2402] Data 0.004 (0.004) Batch 0.531 (0.480) Remain 31:53:46 loss: 2.1267 Lr: 0.00022
[2025-04-08 13:57:40,625 INFO misc.py line 113 3298914] Train: [1/100][798/2402] Data 0.004 (0.004) Batch 0.475 (0.480) Remain 31:53:44 loss: 2.1551 Lr: 0.00022
[2025-04-08 13:57:41,144 INFO misc.py line 113 3298914] Train: [1/100][799/2402] Data 0.003 (0.004) Batch 0.519 (0.480) Remain 31:53:55 loss: 1.9472 Lr: 0.00022
[2025-04-08 13:57:41,659 INFO misc.py line 113 3298914] Train: [1/100][800/2402] Data 0.003 (0.004) Batch 0.514 (0.480) Remain 31:54:05 loss: 1.8033 Lr: 0.00022
[2025-04-08 13:57:42,123 INFO misc.py line 113 3298914] Train: [1/100][801/2402] Data 0.004 (0.004) Batch 0.464 (0.480) Remain 31:54:00 loss: 2.0723 Lr: 0.00022
[2025-04-08 13:57:42,518 INFO misc.py line 113 3298914] Train: [1/100][802/2402] Data 0.003 (0.004) Batch 0.395 (0.480) Remain 31:53:34 loss: 1.9251 Lr: 0.00022
[2025-04-08 13:57:43,104 INFO misc.py line 113 3298914] Train: [1/100][803/2402] Data 0.004 (0.004) Batch 0.586 (0.480) Remain 31:54:06 loss: 1.5413 Lr: 0.00022
[2025-04-08 13:57:43,574 INFO misc.py line 113 3298914] Train: [1/100][804/2402] Data 0.003 (0.004) Batch 0.470 (0.480) Remain 31:54:02 loss: 2.2553 Lr: 0.00022
[2025-04-08 13:57:44,069 INFO misc.py line 113 3298914] Train: [1/100][805/2402] Data 0.004 (0.004) Batch 0.494 (0.480) Remain 31:54:06 loss: 2.0169 Lr: 0.00022
[2025-04-08 13:57:44,606 INFO misc.py line 113 3298914] Train: [1/100][806/2402] Data 0.003 (0.004) Batch 0.537 (0.480) Remain 31:54:23 loss: 2.1432 Lr: 0.00022
[2025-04-08 13:57:45,066 INFO misc.py line 113 3298914] Train: [1/100][807/2402] Data 0.004 (0.004) Batch 0.460 (0.480) Remain 31:54:17 loss: 1.6939 Lr: 0.00022
[2025-04-08 13:57:45,580 INFO misc.py line 113 3298914] Train: [1/100][808/2402] Data 0.003 (0.004) Batch 0.514 (0.480) Remain 31:54:26 loss: 1.8179 Lr: 0.00022
[2025-04-08 13:57:46,070 INFO misc.py line 113 3298914] Train: [1/100][809/2402] Data 0.004 (0.004) Batch 0.490 (0.480) Remain 31:54:29 loss: 1.7326 Lr: 0.00022
[2025-04-08 13:57:46,537 INFO misc.py line 113 3298914] Train: [1/100][810/2402] Data 0.003 (0.004) Batch 0.467 (0.480) Remain 31:54:25 loss: 1.6611 Lr: 0.00022
[2025-04-08 13:57:46,943 INFO misc.py line 113 3298914] Train: [1/100][811/2402] Data 0.003 (0.004) Batch 0.406 (0.480) Remain 31:54:02 loss: 1.7244 Lr: 0.00022
[2025-04-08 13:57:47,521 INFO misc.py line 113 3298914] Train: [1/100][812/2402] Data 0.003 (0.004) Batch 0.579 (0.480) Remain 31:54:31 loss: 1.6663 Lr: 0.00022
[2025-04-08 13:57:48,011 INFO misc.py line 113 3298914] Train: [1/100][813/2402] Data 0.004 (0.004) Batch 0.490 (0.480) Remain 31:54:33 loss: 2.0611 Lr: 0.00022
[2025-04-08 13:57:48,526 INFO misc.py line 113 3298914] Train: [1/100][814/2402] Data 0.003 (0.004) Batch 0.515 (0.480) Remain 31:54:43 loss: 1.5464 Lr: 0.00022
[2025-04-08 13:57:49,071 INFO misc.py line 113 3298914] Train: [1/100][815/2402] Data 0.004 (0.004) Batch 0.545 (0.480) Remain 31:55:02 loss: 1.7199 Lr: 0.00022
[2025-04-08 13:57:49,609 INFO misc.py line 113 3298914] Train: [1/100][816/2402] Data 0.003 (0.004) Batch 0.538 (0.480) Remain 31:55:18 loss: 1.4492 Lr: 0.00022
[2025-04-08 13:57:50,156 INFO misc.py line 113 3298914] Train: [1/100][817/2402] Data 0.004 (0.004) Batch 0.548 (0.480) Remain 31:55:38 loss: 2.0354 Lr: 0.00022
[2025-04-08 13:57:50,625 INFO misc.py line 113 3298914] Train: [1/100][818/2402] Data 0.003 (0.004) Batch 0.468 (0.480) Remain 31:55:34 loss: 1.6407 Lr: 0.00022
[2025-04-08 13:57:51,138 INFO misc.py line 113 3298914] Train: [1/100][819/2402] Data 0.004 (0.004) Batch 0.514 (0.480) Remain 31:55:43 loss: 1.9561 Lr: 0.00022
[2025-04-08 13:57:51,648 INFO misc.py line 113 3298914] Train: [1/100][820/2402] Data 0.003 (0.004) Batch 0.510 (0.480) Remain 31:55:52 loss: 1.9054 Lr: 0.00022
[2025-04-08 13:57:52,115 INFO misc.py line 113 3298914] Train: [1/100][821/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:55:47 loss: 2.0085 Lr: 0.00022
[2025-04-08 13:57:52,590 INFO misc.py line 113 3298914] Train: [1/100][822/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:55:45 loss: 1.8483 Lr: 0.00022
[2025-04-08 13:57:53,035 INFO misc.py line 113 3298914] Train: [1/100][823/2402] Data 0.004 (0.004) Batch 0.445 (0.480) Remain 31:55:34 loss: 1.8814 Lr: 0.00022
[2025-04-08 13:57:53,612 INFO misc.py line 113 3298914] Train: [1/100][824/2402] Data 0.003 (0.004) Batch 0.578 (0.480) Remain 31:56:02 loss: 1.6322 Lr: 0.00022
[2025-04-08 13:57:54,045 INFO misc.py line 113 3298914] Train: [1/100][825/2402] Data 0.004 (0.004) Batch 0.432 (0.480) Remain 31:55:48 loss: 1.8212 Lr: 0.00022
[2025-04-08 13:57:54,501 INFO misc.py line 113 3298914] Train: [1/100][826/2402] Data 0.003 (0.004) Batch 0.456 (0.480) Remain 31:55:40 loss: 1.7731 Lr: 0.00022
[2025-04-08 13:57:54,983 INFO misc.py line 113 3298914] Train: [1/100][827/2402] Data 0.003 (0.004) Batch 0.483 (0.480) Remain 31:55:40 loss: 1.6614 Lr: 0.00022
[2025-04-08 13:57:55,519 INFO misc.py line 113 3298914] Train: [1/100][828/2402] Data 0.004 (0.004) Batch 0.535 (0.480) Remain 31:55:56 loss: 1.5108 Lr: 0.00022
[2025-04-08 13:57:55,969 INFO misc.py line 113 3298914] Train: [1/100][829/2402] Data 0.004 (0.004) Batch 0.450 (0.480) Remain 31:55:47 loss: 1.5460 Lr: 0.00022
[2025-04-08 13:57:56,514 INFO misc.py line 113 3298914] Train: [1/100][830/2402] Data 0.003 (0.004) Batch 0.546 (0.480) Remain 31:56:05 loss: 2.0226 Lr: 0.00022
[2025-04-08 13:57:56,989 INFO misc.py line 113 3298914] Train: [1/100][831/2402] Data 0.003 (0.004) Batch 0.475 (0.480) Remain 31:56:03 loss: 1.9126 Lr: 0.00022
[2025-04-08 13:57:57,381 INFO misc.py line 113 3298914] Train: [1/100][832/2402] Data 0.004 (0.004) Batch 0.393 (0.480) Remain 31:55:37 loss: 1.7766 Lr: 0.00022
[2025-04-08 13:57:57,891 INFO misc.py line 113 3298914] Train: [1/100][833/2402] Data 0.004 (0.004) Batch 0.510 (0.480) Remain 31:55:45 loss: 1.4672 Lr: 0.00022
[2025-04-08 13:57:58,349 INFO misc.py line 113 3298914] Train: [1/100][834/2402] Data 0.003 (0.004) Batch 0.458 (0.480) Remain 31:55:38 loss: 1.6126 Lr: 0.00022
[2025-04-08 13:57:58,785 INFO misc.py line 113 3298914] Train: [1/100][835/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:55:25 loss: 1.9973 Lr: 0.00022
[2025-04-08 13:57:59,251 INFO misc.py line 113 3298914] Train: [1/100][836/2402] Data 0.004 (0.004) Batch 0.466 (0.480) Remain 31:55:21 loss: 1.9712 Lr: 0.00022
[2025-04-08 13:57:59,749 INFO misc.py line 113 3298914] Train: [1/100][837/2402] Data 0.004 (0.004) Batch 0.498 (0.480) Remain 31:55:25 loss: 2.1374 Lr: 0.00022
[2025-04-08 13:58:00,234 INFO misc.py line 113 3298914] Train: [1/100][838/2402] Data 0.003 (0.004) Batch 0.485 (0.480) Remain 31:55:26 loss: 1.9953 Lr: 0.00022
[2025-04-08 13:58:00,820 INFO misc.py line 113 3298914] Train: [1/100][839/2402] Data 0.004 (0.004) Batch 0.586 (0.480) Remain 31:55:56 loss: 1.9845 Lr: 0.00022
[2025-04-08 13:58:01,240 INFO misc.py line 113 3298914] Train: [1/100][840/2402] Data 0.003 (0.004) Batch 0.420 (0.480) Remain 31:55:38 loss: 2.0964 Lr: 0.00022
[2025-04-08 13:58:01,628 INFO misc.py line 113 3298914] Train: [1/100][841/2402] Data 0.004 (0.004) Batch 0.387 (0.480) Remain 31:55:11 loss: 1.7935 Lr: 0.00022
[2025-04-08 13:58:02,077 INFO misc.py line 113 3298914] Train: [1/100][842/2402] Data 0.004 (0.004) Batch 0.449 (0.480) Remain 31:55:02 loss: 1.9400 Lr: 0.00022
[2025-04-08 13:58:02,480 INFO misc.py line 113 3298914] Train: [1/100][843/2402] Data 0.003 (0.004) Batch 0.403 (0.480) Remain 31:54:40 loss: 1.3131 Lr: 0.00022
[2025-04-08 13:58:02,993 INFO misc.py line 113 3298914] Train: [1/100][844/2402] Data 0.003 (0.004) Batch 0.513 (0.480) Remain 31:54:49 loss: 1.6600 Lr: 0.00022
[2025-04-08 13:58:03,376 INFO misc.py line 113 3298914] Train: [1/100][845/2402] Data 0.003 (0.004) Batch 0.384 (0.480) Remain 31:54:21 loss: 1.4152 Lr: 0.00022
[2025-04-08 13:58:03,828 INFO misc.py line 113 3298914] Train: [1/100][846/2402] Data 0.003 (0.004) Batch 0.452 (0.480) Remain 31:54:12 loss: 2.0850 Lr: 0.00022
[2025-04-08 13:58:04,313 INFO misc.py line 113 3298914] Train: [1/100][847/2402] Data 0.017 (0.004) Batch 0.485 (0.480) Remain 31:54:13 loss: 1.5026 Lr: 0.00022
[2025-04-08 13:58:04,781 INFO misc.py line 113 3298914] Train: [1/100][848/2402] Data 0.003 (0.004) Batch 0.468 (0.480) Remain 31:54:09 loss: 1.9915 Lr: 0.00022
[2025-04-08 13:58:05,225 INFO misc.py line 113 3298914] Train: [1/100][849/2402] Data 0.003 (0.004) Batch 0.444 (0.480) Remain 31:53:59 loss: 1.3725 Lr: 0.00022
[2025-04-08 13:58:05,640 INFO misc.py line 113 3298914] Train: [1/100][850/2402] Data 0.003 (0.004) Batch 0.415 (0.480) Remain 31:53:40 loss: 1.9912 Lr: 0.00022
[2025-04-08 13:58:06,128 INFO misc.py line 113 3298914] Train: [1/100][851/2402] Data 0.004 (0.004) Batch 0.488 (0.480) Remain 31:53:42 loss: 1.9595 Lr: 0.00022
[2025-04-08 13:58:06,644 INFO misc.py line 113 3298914] Train: [1/100][852/2402] Data 0.004 (0.004) Batch 0.516 (0.480) Remain 31:53:51 loss: 1.7622 Lr: 0.00022
[2025-04-08 13:58:07,087 INFO misc.py line 113 3298914] Train: [1/100][853/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:53:41 loss: 2.0247 Lr: 0.00022
[2025-04-08 13:58:07,520 INFO misc.py line 113 3298914] Train: [1/100][854/2402] Data 0.003 (0.004) Batch 0.433 (0.480) Remain 31:53:27 loss: 1.8078 Lr: 0.00022
[2025-04-08 13:58:07,917 INFO misc.py line 113 3298914] Train: [1/100][855/2402] Data 0.003 (0.004) Batch 0.397 (0.480) Remain 31:53:03 loss: 1.8345 Lr: 0.00022
[2025-04-08 13:58:08,398 INFO misc.py line 113 3298914] Train: [1/100][856/2402] Data 0.004 (0.004) Batch 0.481 (0.480) Remain 31:53:03 loss: 1.6555 Lr: 0.00022
[2025-04-08 13:58:08,832 INFO misc.py line 113 3298914] Train: [1/100][857/2402] Data 0.003 (0.004) Batch 0.434 (0.480) Remain 31:52:50 loss: 1.6552 Lr: 0.00022
[2025-04-08 13:58:09,364 INFO misc.py line 113 3298914] Train: [1/100][858/2402] Data 0.004 (0.004) Batch 0.532 (0.480) Remain 31:53:04 loss: 1.8470 Lr: 0.00022
[2025-04-08 13:58:09,867 INFO misc.py line 113 3298914] Train: [1/100][859/2402] Data 0.004 (0.004) Batch 0.503 (0.480) Remain 31:53:10 loss: 1.4817 Lr: 0.00022
[2025-04-08 13:58:10,248 INFO misc.py line 113 3298914] Train: [1/100][860/2402] Data 0.004 (0.004) Batch 0.381 (0.479) Remain 31:52:42 loss: 2.1157 Lr: 0.00022
[2025-04-08 13:58:10,678 INFO misc.py line 113 3298914] Train: [1/100][861/2402] Data 0.003 (0.004) Batch 0.430 (0.479) Remain 31:52:28 loss: 1.9370 Lr: 0.00022
[2025-04-08 13:58:11,208 INFO misc.py line 113 3298914] Train: [1/100][862/2402] Data 0.004 (0.004) Batch 0.530 (0.479) Remain 31:52:42 loss: 1.4686 Lr: 0.00022
[2025-04-08 13:58:11,760 INFO misc.py line 113 3298914] Train: [1/100][863/2402] Data 0.004 (0.004) Batch 0.552 (0.480) Remain 31:53:01 loss: 1.7794 Lr: 0.00022
[2025-04-08 13:58:12,196 INFO misc.py line 113 3298914] Train: [1/100][864/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:52:49 loss: 1.8236 Lr: 0.00022
[2025-04-08 13:58:12,762 INFO misc.py line 113 3298914] Train: [1/100][865/2402] Data 0.004 (0.004) Batch 0.566 (0.480) Remain 31:53:12 loss: 1.8940 Lr: 0.00022
[2025-04-08 13:58:13,276 INFO misc.py line 113 3298914] Train: [1/100][866/2402] Data 0.003 (0.004) Batch 0.514 (0.480) Remain 31:53:21 loss: 2.0973 Lr: 0.00022
[2025-04-08 13:58:13,757 INFO misc.py line 113 3298914] Train: [1/100][867/2402] Data 0.003 (0.004) Batch 0.481 (0.480) Remain 31:53:21 loss: 2.0182 Lr: 0.00022
[2025-04-08 13:58:14,285 INFO misc.py line 113 3298914] Train: [1/100][868/2402] Data 0.003 (0.004) Batch 0.528 (0.480) Remain 31:53:34 loss: 2.0140 Lr: 0.00022
[2025-04-08 13:58:14,736 INFO misc.py line 113 3298914] Train: [1/100][869/2402] Data 0.003 (0.004) Batch 0.450 (0.480) Remain 31:53:26 loss: 2.0103 Lr: 0.00022
[2025-04-08 13:58:15,238 INFO misc.py line 113 3298914] Train: [1/100][870/2402] Data 0.003 (0.004) Batch 0.503 (0.480) Remain 31:53:31 loss: 1.8654 Lr: 0.00022
[2025-04-08 13:58:15,760 INFO misc.py line 113 3298914] Train: [1/100][871/2402] Data 0.003 (0.004) Batch 0.521 (0.480) Remain 31:53:42 loss: 1.7092 Lr: 0.00022
[2025-04-08 13:58:16,236 INFO misc.py line 113 3298914] Train: [1/100][872/2402] Data 0.003 (0.004) Batch 0.476 (0.480) Remain 31:53:41 loss: 1.9004 Lr: 0.00022
[2025-04-08 13:58:16,669 INFO misc.py line 113 3298914] Train: [1/100][873/2402] Data 0.003 (0.004) Batch 0.433 (0.480) Remain 31:53:28 loss: 1.6502 Lr: 0.00022
[2025-04-08 13:58:17,160 INFO misc.py line 113 3298914] Train: [1/100][874/2402] Data 0.004 (0.004) Batch 0.491 (0.480) Remain 31:53:30 loss: 2.0639 Lr: 0.00022
[2025-04-08 13:58:17,680 INFO misc.py line 113 3298914] Train: [1/100][875/2402] Data 0.004 (0.004) Batch 0.520 (0.480) Remain 31:53:41 loss: 2.4835 Lr: 0.00022
[2025-04-08 13:58:18,159 INFO misc.py line 113 3298914] Train: [1/100][876/2402] Data 0.003 (0.004) Batch 0.479 (0.480) Remain 31:53:40 loss: 1.9073 Lr: 0.00022
[2025-04-08 13:58:18,584 INFO misc.py line 113 3298914] Train: [1/100][877/2402] Data 0.004 (0.004) Batch 0.425 (0.480) Remain 31:53:25 loss: 2.2122 Lr: 0.00022
[2025-04-08 13:58:19,101 INFO misc.py line 113 3298914] Train: [1/100][878/2402] Data 0.003 (0.004) Batch 0.518 (0.480) Remain 31:53:34 loss: 1.6439 Lr: 0.00022
[2025-04-08 13:58:19,567 INFO misc.py line 113 3298914] Train: [1/100][879/2402] Data 0.003 (0.004) Batch 0.465 (0.480) Remain 31:53:30 loss: 1.7328 Lr: 0.00022
[2025-04-08 13:58:20,020 INFO misc.py line 113 3298914] Train: [1/100][880/2402] Data 0.004 (0.004) Batch 0.453 (0.480) Remain 31:53:22 loss: 1.6633 Lr: 0.00022
[2025-04-08 13:58:20,430 INFO misc.py line 113 3298914] Train: [1/100][881/2402] Data 0.004 (0.004) Batch 0.411 (0.480) Remain 31:53:03 loss: 1.5725 Lr: 0.00022
[2025-04-08 13:58:20,878 INFO misc.py line 113 3298914] Train: [1/100][882/2402] Data 0.003 (0.004) Batch 0.448 (0.480) Remain 31:52:54 loss: 1.6321 Lr: 0.00022
[2025-04-08 13:58:21,344 INFO misc.py line 113 3298914] Train: [1/100][883/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:52:50 loss: 2.1779 Lr: 0.00022
[2025-04-08 13:58:21,895 INFO misc.py line 113 3298914] Train: [1/100][884/2402] Data 0.003 (0.004) Batch 0.551 (0.480) Remain 31:53:08 loss: 2.1017 Lr: 0.00022
[2025-04-08 13:58:22,364 INFO misc.py line 113 3298914] Train: [1/100][885/2402] Data 0.004 (0.004) Batch 0.469 (0.480) Remain 31:53:05 loss: 1.4199 Lr: 0.00022
[2025-04-08 13:58:22,949 INFO misc.py line 113 3298914] Train: [1/100][886/2402] Data 0.003 (0.004) Batch 0.585 (0.480) Remain 31:53:33 loss: 1.6705 Lr: 0.00022
[2025-04-08 13:58:23,447 INFO misc.py line 113 3298914] Train: [1/100][887/2402] Data 0.004 (0.004) Batch 0.498 (0.480) Remain 31:53:38 loss: 1.8155 Lr: 0.00022
[2025-04-08 13:58:24,013 INFO misc.py line 113 3298914] Train: [1/100][888/2402] Data 0.003 (0.004) Batch 0.566 (0.480) Remain 31:54:01 loss: 1.5702 Lr: 0.00022
[2025-04-08 13:58:24,456 INFO misc.py line 113 3298914] Train: [1/100][889/2402] Data 0.003 (0.004) Batch 0.442 (0.480) Remain 31:53:50 loss: 1.8934 Lr: 0.00022
[2025-04-08 13:58:25,001 INFO misc.py line 113 3298914] Train: [1/100][890/2402] Data 0.004 (0.004) Batch 0.545 (0.480) Remain 31:54:07 loss: 1.9737 Lr: 0.00022
[2025-04-08 13:58:25,484 INFO misc.py line 113 3298914] Train: [1/100][891/2402] Data 0.003 (0.004) Batch 0.483 (0.480) Remain 31:54:07 loss: 1.8595 Lr: 0.00022
[2025-04-08 13:58:25,971 INFO misc.py line 113 3298914] Train: [1/100][892/2402] Data 0.003 (0.004) Batch 0.488 (0.480) Remain 31:54:09 loss: 1.9552 Lr: 0.00022
[2025-04-08 13:58:26,517 INFO misc.py line 113 3298914] Train: [1/100][893/2402] Data 0.003 (0.004) Batch 0.546 (0.480) Remain 31:54:26 loss: 1.5942 Lr: 0.00022
[2025-04-08 13:58:27,099 INFO misc.py line 113 3298914] Train: [1/100][894/2402] Data 0.004 (0.004) Batch 0.581 (0.480) Remain 31:54:53 loss: 2.1036 Lr: 0.00022
[2025-04-08 13:58:27,542 INFO misc.py line 113 3298914] Train: [1/100][895/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:54:43 loss: 1.8075 Lr: 0.00022
[2025-04-08 13:58:28,109 INFO misc.py line 113 3298914] Train: [1/100][896/2402] Data 0.003 (0.004) Batch 0.568 (0.480) Remain 31:55:06 loss: 1.9061 Lr: 0.00022
[2025-04-08 13:58:28,587 INFO misc.py line 113 3298914] Train: [1/100][897/2402] Data 0.004 (0.004) Batch 0.477 (0.480) Remain 31:55:04 loss: 2.0885 Lr: 0.00022
[2025-04-08 13:58:29,059 INFO misc.py line 113 3298914] Train: [1/100][898/2402] Data 0.003 (0.004) Batch 0.473 (0.480) Remain 31:55:02 loss: 2.1402 Lr: 0.00022
[2025-04-08 13:58:29,526 INFO misc.py line 113 3298914] Train: [1/100][899/2402] Data 0.003 (0.004) Batch 0.467 (0.480) Remain 31:54:58 loss: 2.0479 Lr: 0.00022
[2025-04-08 13:58:29,964 INFO misc.py line 113 3298914] Train: [1/100][900/2402] Data 0.004 (0.004) Batch 0.438 (0.480) Remain 31:54:46 loss: 1.9945 Lr: 0.00022
[2025-04-08 13:58:30,475 INFO misc.py line 113 3298914] Train: [1/100][901/2402] Data 0.004 (0.004) Batch 0.511 (0.480) Remain 31:54:54 loss: 1.4257 Lr: 0.00022
[2025-04-08 13:58:30,863 INFO misc.py line 113 3298914] Train: [1/100][902/2402] Data 0.003 (0.004) Batch 0.388 (0.480) Remain 31:54:29 loss: 2.3821 Lr: 0.00022
[2025-04-08 13:58:31,447 INFO misc.py line 113 3298914] Train: [1/100][903/2402] Data 0.004 (0.004) Batch 0.584 (0.480) Remain 31:54:56 loss: 1.9669 Lr: 0.00022
[2025-04-08 13:58:31,882 INFO misc.py line 113 3298914] Train: [1/100][904/2402] Data 0.003 (0.004) Batch 0.436 (0.480) Remain 31:54:44 loss: 1.8940 Lr: 0.00022
[2025-04-08 13:58:32,286 INFO misc.py line 113 3298914] Train: [1/100][905/2402] Data 0.003 (0.004) Batch 0.404 (0.480) Remain 31:54:23 loss: 1.5966 Lr: 0.00022
[2025-04-08 13:58:32,786 INFO misc.py line 113 3298914] Train: [1/100][906/2402] Data 0.003 (0.004) Batch 0.499 (0.480) Remain 31:54:28 loss: 1.4124 Lr: 0.00022
[2025-04-08 13:58:33,214 INFO misc.py line 113 3298914] Train: [1/100][907/2402] Data 0.003 (0.004) Batch 0.428 (0.480) Remain 31:54:14 loss: 1.6986 Lr: 0.00023
[2025-04-08 13:58:33,709 INFO misc.py line 113 3298914] Train: [1/100][908/2402] Data 0.005 (0.004) Batch 0.495 (0.480) Remain 31:54:17 loss: 1.3254 Lr: 0.00023
[2025-04-08 13:58:34,294 INFO misc.py line 113 3298914] Train: [1/100][909/2402] Data 0.004 (0.004) Batch 0.585 (0.480) Remain 31:54:44 loss: 1.6302 Lr: 0.00023
[2025-04-08 13:58:34,787 INFO misc.py line 113 3298914] Train: [1/100][910/2402] Data 0.003 (0.004) Batch 0.493 (0.480) Remain 31:54:47 loss: 1.9694 Lr: 0.00023
[2025-04-08 13:58:35,196 INFO misc.py line 113 3298914] Train: [1/100][911/2402] Data 0.003 (0.004) Batch 0.408 (0.480) Remain 31:54:28 loss: 1.7370 Lr: 0.00023
[2025-04-08 13:58:35,745 INFO misc.py line 113 3298914] Train: [1/100][912/2402] Data 0.004 (0.004) Batch 0.549 (0.480) Remain 31:54:46 loss: 1.9983 Lr: 0.00023
[2025-04-08 13:58:36,314 INFO misc.py line 113 3298914] Train: [1/100][913/2402] Data 0.004 (0.004) Batch 0.569 (0.480) Remain 31:55:08 loss: 1.7837 Lr: 0.00023
[2025-04-08 13:58:36,905 INFO misc.py line 113 3298914] Train: [1/100][914/2402] Data 0.004 (0.004) Batch 0.591 (0.480) Remain 31:55:37 loss: 1.8089 Lr: 0.00023
[2025-04-08 13:58:37,374 INFO misc.py line 113 3298914] Train: [1/100][915/2402] Data 0.004 (0.004) Batch 0.469 (0.480) Remain 31:55:34 loss: 1.7720 Lr: 0.00023
[2025-04-08 13:58:37,881 INFO misc.py line 113 3298914] Train: [1/100][916/2402] Data 0.003 (0.004) Batch 0.506 (0.480) Remain 31:55:40 loss: 1.7181 Lr: 0.00023
[2025-04-08 13:58:38,309 INFO misc.py line 113 3298914] Train: [1/100][917/2402] Data 0.003 (0.004) Batch 0.428 (0.480) Remain 31:55:26 loss: 1.9686 Lr: 0.00023
[2025-04-08 13:58:38,651 INFO misc.py line 113 3298914] Train: [1/100][918/2402] Data 0.004 (0.004) Batch 0.343 (0.480) Remain 31:54:49 loss: 2.1469 Lr: 0.00023
[2025-04-08 13:58:39,130 INFO misc.py line 113 3298914] Train: [1/100][919/2402] Data 0.003 (0.004) Batch 0.478 (0.480) Remain 31:54:48 loss: 1.8314 Lr: 0.00023
[2025-04-08 13:58:39,595 INFO misc.py line 113 3298914] Train: [1/100][920/2402] Data 0.004 (0.004) Batch 0.465 (0.480) Remain 31:54:44 loss: 2.1498 Lr: 0.00023
[2025-04-08 13:58:39,946 INFO misc.py line 113 3298914] Train: [1/100][921/2402] Data 0.004 (0.004) Batch 0.351 (0.480) Remain 31:54:10 loss: 1.9788 Lr: 0.00023
[2025-04-08 13:58:40,399 INFO misc.py line 113 3298914] Train: [1/100][922/2402] Data 0.003 (0.004) Batch 0.453 (0.480) Remain 31:54:03 loss: 1.7824 Lr: 0.00023
[2025-04-08 13:58:40,948 INFO misc.py line 113 3298914] Train: [1/100][923/2402] Data 0.003 (0.004) Batch 0.549 (0.480) Remain 31:54:20 loss: 1.5212 Lr: 0.00023
[2025-04-08 13:58:41,428 INFO misc.py line 113 3298914] Train: [1/100][924/2402] Data 0.004 (0.004) Batch 0.479 (0.480) Remain 31:54:19 loss: 1.7270 Lr: 0.00023
[2025-04-08 13:58:42,030 INFO misc.py line 113 3298914] Train: [1/100][925/2402] Data 0.004 (0.004) Batch 0.602 (0.480) Remain 31:54:51 loss: 2.0655 Lr: 0.00023
[2025-04-08 13:58:42,440 INFO misc.py line 113 3298914] Train: [1/100][926/2402] Data 0.004 (0.004) Batch 0.410 (0.480) Remain 31:54:32 loss: 1.7167 Lr: 0.00023
[2025-04-08 13:58:42,888 INFO misc.py line 113 3298914] Train: [1/100][927/2402] Data 0.004 (0.004) Batch 0.448 (0.480) Remain 31:54:23 loss: 1.9471 Lr: 0.00023
[2025-04-08 13:58:43,431 INFO misc.py line 113 3298914] Train: [1/100][928/2402] Data 0.003 (0.004) Batch 0.543 (0.480) Remain 31:54:39 loss: 1.9813 Lr: 0.00023
[2025-04-08 13:58:43,928 INFO misc.py line 113 3298914] Train: [1/100][929/2402] Data 0.004 (0.004) Batch 0.497 (0.480) Remain 31:54:43 loss: 1.8881 Lr: 0.00023
[2025-04-08 13:58:44,443 INFO misc.py line 113 3298914] Train: [1/100][930/2402] Data 0.003 (0.004) Batch 0.515 (0.480) Remain 31:54:51 loss: 1.9966 Lr: 0.00023
[2025-04-08 13:58:44,910 INFO misc.py line 113 3298914] Train: [1/100][931/2402] Data 0.004 (0.004) Batch 0.468 (0.480) Remain 31:54:48 loss: 1.8760 Lr: 0.00023
[2025-04-08 13:58:45,291 INFO misc.py line 113 3298914] Train: [1/100][932/2402] Data 0.003 (0.004) Batch 0.380 (0.480) Remain 31:54:21 loss: 1.8711 Lr: 0.00023
[2025-04-08 13:58:45,750 INFO misc.py line 113 3298914] Train: [1/100][933/2402] Data 0.003 (0.004) Batch 0.460 (0.480) Remain 31:54:16 loss: 1.8295 Lr: 0.00023
[2025-04-08 13:58:46,193 INFO misc.py line 113 3298914] Train: [1/100][934/2402] Data 0.003 (0.004) Batch 0.442 (0.480) Remain 31:54:06 loss: 1.3531 Lr: 0.00023
[2025-04-08 13:58:46,690 INFO misc.py line 113 3298914] Train: [1/100][935/2402] Data 0.003 (0.004) Batch 0.497 (0.480) Remain 31:54:09 loss: 2.5465 Lr: 0.00023
[2025-04-08 13:58:47,182 INFO misc.py line 113 3298914] Train: [1/100][936/2402] Data 0.003 (0.004) Batch 0.492 (0.480) Remain 31:54:12 loss: 1.8434 Lr: 0.00023
[2025-04-08 13:58:47,735 INFO misc.py line 113 3298914] Train: [1/100][937/2402] Data 0.004 (0.004) Batch 0.554 (0.480) Remain 31:54:30 loss: 1.5998 Lr: 0.00023
[2025-04-08 13:58:48,144 INFO misc.py line 113 3298914] Train: [1/100][938/2402] Data 0.003 (0.004) Batch 0.409 (0.480) Remain 31:54:12 loss: 1.9467 Lr: 0.00023
[2025-04-08 13:58:48,696 INFO misc.py line 113 3298914] Train: [1/100][939/2402] Data 0.003 (0.004) Batch 0.552 (0.480) Remain 31:54:30 loss: 1.4092 Lr: 0.00023
[2025-04-08 13:58:49,117 INFO misc.py line 113 3298914] Train: [1/100][940/2402] Data 0.003 (0.004) Batch 0.421 (0.480) Remain 31:54:14 loss: 1.7038 Lr: 0.00023
[2025-04-08 13:58:49,573 INFO misc.py line 113 3298914] Train: [1/100][941/2402] Data 0.003 (0.004) Batch 0.456 (0.480) Remain 31:54:07 loss: 2.0621 Lr: 0.00023
[2025-04-08 13:58:50,126 INFO misc.py line 113 3298914] Train: [1/100][942/2402] Data 0.003 (0.004) Batch 0.553 (0.480) Remain 31:54:26 loss: 1.8520 Lr: 0.00023
[2025-04-08 13:58:50,635 INFO misc.py line 113 3298914] Train: [1/100][943/2402] Data 0.004 (0.004) Batch 0.508 (0.480) Remain 31:54:32 loss: 1.6884 Lr: 0.00023
[2025-04-08 13:58:51,087 INFO misc.py line 113 3298914] Train: [1/100][944/2402] Data 0.004 (0.004) Batch 0.452 (0.480) Remain 31:54:25 loss: 1.2001 Lr: 0.00023
[2025-04-08 13:58:51,584 INFO misc.py line 113 3298914] Train: [1/100][945/2402] Data 0.004 (0.004) Batch 0.497 (0.480) Remain 31:54:28 loss: 1.8945 Lr: 0.00023
[2025-04-08 13:58:52,149 INFO misc.py line 113 3298914] Train: [1/100][946/2402] Data 0.004 (0.004) Batch 0.565 (0.480) Remain 31:54:50 loss: 1.5374 Lr: 0.00023
[2025-04-08 13:58:52,548 INFO misc.py line 113 3298914] Train: [1/100][947/2402] Data 0.003 (0.004) Batch 0.399 (0.480) Remain 31:54:28 loss: 1.4233 Lr: 0.00023
[2025-04-08 13:58:52,997 INFO misc.py line 113 3298914] Train: [1/100][948/2402] Data 0.003 (0.004) Batch 0.449 (0.480) Remain 31:54:20 loss: 1.9132 Lr: 0.00023
[2025-04-08 13:58:53,555 INFO misc.py line 113 3298914] Train: [1/100][949/2402] Data 0.004 (0.004) Batch 0.558 (0.480) Remain 31:54:39 loss: 2.0094 Lr: 0.00023
[2025-04-08 13:58:54,029 INFO misc.py line 113 3298914] Train: [1/100][950/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:54:37 loss: 2.2684 Lr: 0.00023
[2025-04-08 13:58:54,458 INFO misc.py line 113 3298914] Train: [1/100][951/2402] Data 0.003 (0.004) Batch 0.429 (0.480) Remain 31:54:24 loss: 1.7664 Lr: 0.00023
[2025-04-08 13:58:54,970 INFO misc.py line 113 3298914] Train: [1/100][952/2402] Data 0.003 (0.004) Batch 0.512 (0.480) Remain 31:54:31 loss: 1.5993 Lr: 0.00023
[2025-04-08 13:58:55,337 INFO misc.py line 113 3298914] Train: [1/100][953/2402] Data 0.004 (0.004) Batch 0.368 (0.480) Remain 31:54:03 loss: 1.6545 Lr: 0.00023
[2025-04-08 13:58:55,756 INFO misc.py line 113 3298914] Train: [1/100][954/2402] Data 0.004 (0.004) Batch 0.418 (0.480) Remain 31:53:47 loss: 1.3351 Lr: 0.00023
[2025-04-08 13:58:56,163 INFO misc.py line 113 3298914] Train: [1/100][955/2402] Data 0.003 (0.004) Batch 0.407 (0.480) Remain 31:53:28 loss: 2.2003 Lr: 0.00023
[2025-04-08 13:58:56,668 INFO misc.py line 113 3298914] Train: [1/100][956/2402] Data 0.003 (0.004) Batch 0.505 (0.480) Remain 31:53:34 loss: 1.8509 Lr: 0.00023
[2025-04-08 13:58:57,037 INFO misc.py line 113 3298914] Train: [1/100][957/2402] Data 0.004 (0.004) Batch 0.369 (0.480) Remain 31:53:05 loss: 1.4568 Lr: 0.00023
[2025-04-08 13:58:57,476 INFO misc.py line 113 3298914] Train: [1/100][958/2402] Data 0.003 (0.004) Batch 0.439 (0.480) Remain 31:52:55 loss: 1.5201 Lr: 0.00023
[2025-04-08 13:58:57,904 INFO misc.py line 113 3298914] Train: [1/100][959/2402] Data 0.003 (0.004) Batch 0.428 (0.480) Remain 31:52:41 loss: 1.7146 Lr: 0.00023
[2025-04-08 13:58:58,344 INFO misc.py line 113 3298914] Train: [1/100][960/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:52:31 loss: 1.4752 Lr: 0.00023
[2025-04-08 13:58:58,901 INFO misc.py line 113 3298914] Train: [1/100][961/2402] Data 0.003 (0.004) Batch 0.557 (0.480) Remain 31:52:50 loss: 1.6133 Lr: 0.00023
[2025-04-08 13:58:59,531 INFO misc.py line 113 3298914] Train: [1/100][962/2402] Data 0.004 (0.004) Batch 0.630 (0.480) Remain 31:53:27 loss: 1.9351 Lr: 0.00023
[2025-04-08 13:58:59,967 INFO misc.py line 113 3298914] Train: [1/100][963/2402] Data 0.003 (0.004) Batch 0.436 (0.480) Remain 31:53:15 loss: 1.5584 Lr: 0.00023
[2025-04-08 13:59:00,495 INFO misc.py line 113 3298914] Train: [1/100][964/2402] Data 0.004 (0.004) Batch 0.528 (0.480) Remain 31:53:27 loss: 1.7126 Lr: 0.00023
[2025-04-08 13:59:00,994 INFO misc.py line 113 3298914] Train: [1/100][965/2402] Data 0.003 (0.004) Batch 0.499 (0.480) Remain 31:53:31 loss: 1.8026 Lr: 0.00023
[2025-04-08 13:59:01,567 INFO misc.py line 113 3298914] Train: [1/100][966/2402] Data 0.004 (0.004) Batch 0.573 (0.480) Remain 31:53:54 loss: 1.7724 Lr: 0.00023
[2025-04-08 13:59:01,959 INFO misc.py line 113 3298914] Train: [1/100][967/2402] Data 0.003 (0.004) Batch 0.392 (0.480) Remain 31:53:31 loss: 2.1485 Lr: 0.00023
[2025-04-08 13:59:02,403 INFO misc.py line 113 3298914] Train: [1/100][968/2402] Data 0.003 (0.004) Batch 0.444 (0.480) Remain 31:53:22 loss: 1.4944 Lr: 0.00023
[2025-04-08 13:59:02,842 INFO misc.py line 113 3298914] Train: [1/100][969/2402] Data 0.003 (0.004) Batch 0.438 (0.480) Remain 31:53:11 loss: 1.7554 Lr: 0.00023
[2025-04-08 13:59:03,380 INFO misc.py line 113 3298914] Train: [1/100][970/2402] Data 0.004 (0.004) Batch 0.538 (0.480) Remain 31:53:25 loss: 1.7701 Lr: 0.00023
[2025-04-08 13:59:03,844 INFO misc.py line 113 3298914] Train: [1/100][971/2402] Data 0.004 (0.004) Batch 0.464 (0.480) Remain 31:53:21 loss: 1.7597 Lr: 0.00023
[2025-04-08 13:59:04,326 INFO misc.py line 113 3298914] Train: [1/100][972/2402] Data 0.003 (0.004) Batch 0.482 (0.480) Remain 31:53:21 loss: 2.0739 Lr: 0.00023
[2025-04-08 13:59:04,847 INFO misc.py line 113 3298914] Train: [1/100][973/2402] Data 0.004 (0.004) Batch 0.521 (0.480) Remain 31:53:31 loss: 1.8295 Lr: 0.00023
[2025-04-08 13:59:05,221 INFO misc.py line 113 3298914] Train: [1/100][974/2402] Data 0.003 (0.004) Batch 0.374 (0.480) Remain 31:53:04 loss: 1.7591 Lr: 0.00023
[2025-04-08 13:59:05,792 INFO misc.py line 113 3298914] Train: [1/100][975/2402] Data 0.004 (0.004) Batch 0.571 (0.480) Remain 31:53:26 loss: 1.8950 Lr: 0.00023
[2025-04-08 13:59:06,309 INFO misc.py line 113 3298914] Train: [1/100][976/2402] Data 0.004 (0.004) Batch 0.517 (0.480) Remain 31:53:35 loss: 1.9951 Lr: 0.00023
[2025-04-08 13:59:06,756 INFO misc.py line 113 3298914] Train: [1/100][977/2402] Data 0.003 (0.004) Batch 0.448 (0.480) Remain 31:53:26 loss: 1.7228 Lr: 0.00023
[2025-04-08 13:59:07,203 INFO misc.py line 113 3298914] Train: [1/100][978/2402] Data 0.003 (0.004) Batch 0.447 (0.480) Remain 31:53:18 loss: 1.2653 Lr: 0.00023
[2025-04-08 13:59:07,545 INFO misc.py line 113 3298914] Train: [1/100][979/2402] Data 0.003 (0.004) Batch 0.342 (0.480) Remain 31:52:43 loss: 1.6346 Lr: 0.00023
[2025-04-08 13:59:08,029 INFO misc.py line 113 3298914] Train: [1/100][980/2402] Data 0.003 (0.004) Batch 0.484 (0.480) Remain 31:52:44 loss: 2.3986 Lr: 0.00023
[2025-04-08 13:59:08,453 INFO misc.py line 113 3298914] Train: [1/100][981/2402] Data 0.003 (0.004) Batch 0.424 (0.480) Remain 31:52:30 loss: 1.7088 Lr: 0.00023
[2025-04-08 13:59:09,009 INFO misc.py line 113 3298914] Train: [1/100][982/2402] Data 0.004 (0.004) Batch 0.556 (0.480) Remain 31:52:48 loss: 2.0984 Lr: 0.00023
[2025-04-08 13:59:09,526 INFO misc.py line 113 3298914] Train: [1/100][983/2402] Data 0.004 (0.004) Batch 0.517 (0.480) Remain 31:52:57 loss: 1.6923 Lr: 0.00023
[2025-04-08 13:59:09,959 INFO misc.py line 113 3298914] Train: [1/100][984/2402] Data 0.004 (0.004) Batch 0.433 (0.480) Remain 31:52:45 loss: 1.7577 Lr: 0.00023
[2025-04-08 13:59:10,445 INFO misc.py line 113 3298914] Train: [1/100][985/2402] Data 0.003 (0.004) Batch 0.486 (0.480) Remain 31:52:46 loss: 1.6129 Lr: 0.00023
[2025-04-08 13:59:10,996 INFO misc.py line 113 3298914] Train: [1/100][986/2402] Data 0.004 (0.004) Batch 0.551 (0.480) Remain 31:53:02 loss: 2.1082 Lr: 0.00023
[2025-04-08 13:59:11,557 INFO misc.py line 113 3298914] Train: [1/100][987/2402] Data 0.003 (0.004) Batch 0.561 (0.480) Remain 31:53:22 loss: 1.8967 Lr: 0.00023
[2025-04-08 13:59:11,947 INFO misc.py line 113 3298914] Train: [1/100][988/2402] Data 0.004 (0.004) Batch 0.390 (0.480) Remain 31:53:00 loss: 1.6233 Lr: 0.00023
[2025-04-08 13:59:12,325 INFO misc.py line 113 3298914] Train: [1/100][989/2402] Data 0.003 (0.004) Batch 0.378 (0.480) Remain 31:52:34 loss: 1.8852 Lr: 0.00023
[2025-04-08 13:59:12,679 INFO misc.py line 113 3298914] Train: [1/100][990/2402] Data 0.003 (0.004) Batch 0.354 (0.480) Remain 31:52:03 loss: 1.8590 Lr: 0.00023
[2025-04-08 13:59:13,116 INFO misc.py line 113 3298914] Train: [1/100][991/2402] Data 0.004 (0.004) Batch 0.437 (0.480) Remain 31:51:52 loss: 1.8833 Lr: 0.00023
[2025-04-08 13:59:13,602 INFO misc.py line 113 3298914] Train: [1/100][992/2402] Data 0.004 (0.004) Batch 0.487 (0.480) Remain 31:51:54 loss: 1.8108 Lr: 0.00023
[2025-04-08 13:59:14,074 INFO misc.py line 113 3298914] Train: [1/100][993/2402] Data 0.004 (0.004) Batch 0.472 (0.480) Remain 31:51:51 loss: 1.8484 Lr: 0.00023
[2025-04-08 13:59:14,532 INFO misc.py line 113 3298914] Train: [1/100][994/2402] Data 0.003 (0.004) Batch 0.458 (0.480) Remain 31:51:46 loss: 1.5504 Lr: 0.00023
[2025-04-08 13:59:15,041 INFO misc.py line 113 3298914] Train: [1/100][995/2402] Data 0.004 (0.004) Batch 0.509 (0.480) Remain 31:51:52 loss: 2.1374 Lr: 0.00023
[2025-04-08 13:59:15,436 INFO misc.py line 113 3298914] Train: [1/100][996/2402] Data 0.003 (0.004) Batch 0.394 (0.479) Remain 31:51:31 loss: 2.4571 Lr: 0.00023
[2025-04-08 13:59:15,957 INFO misc.py line 113 3298914] Train: [1/100][997/2402] Data 0.004 (0.004) Batch 0.521 (0.480) Remain 31:51:41 loss: 1.4778 Lr: 0.00023
[2025-04-08 13:59:16,381 INFO misc.py line 113 3298914] Train: [1/100][998/2402] Data 0.004 (0.004) Batch 0.424 (0.479) Remain 31:51:27 loss: 1.4380 Lr: 0.00023
[2025-04-08 13:59:16,856 INFO misc.py line 113 3298914] Train: [1/100][999/2402] Data 0.003 (0.004) Batch 0.475 (0.479) Remain 31:51:25 loss: 1.9185 Lr: 0.00023
[2025-04-08 13:59:17,320 INFO misc.py line 113 3298914] Train: [1/100][1000/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:51:21 loss: 1.9004 Lr: 0.00023
[2025-04-08 13:59:17,817 INFO misc.py line 113 3298914] Train: [1/100][1001/2402] Data 0.004 (0.004) Batch 0.498 (0.479) Remain 31:51:25 loss: 1.5739 Lr: 0.00023
[2025-04-08 13:59:18,390 INFO misc.py line 113 3298914] Train: [1/100][1002/2402] Data 0.003 (0.004) Batch 0.573 (0.480) Remain 31:51:47 loss: 1.7182 Lr: 0.00023
[2025-04-08 13:59:18,847 INFO misc.py line 113 3298914] Train: [1/100][1003/2402] Data 0.003 (0.004) Batch 0.457 (0.480) Remain 31:51:41 loss: 1.7590 Lr: 0.00023
[2025-04-08 13:59:19,296 INFO misc.py line 113 3298914] Train: [1/100][1004/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:51:33 loss: 1.7122 Lr: 0.00023
[2025-04-08 13:59:19,838 INFO misc.py line 113 3298914] Train: [1/100][1005/2402] Data 0.003 (0.004) Batch 0.541 (0.480) Remain 31:51:48 loss: 2.1681 Lr: 0.00023
[2025-04-08 13:59:20,264 INFO misc.py line 113 3298914] Train: [1/100][1006/2402] Data 0.004 (0.004) Batch 0.426 (0.480) Remain 31:51:34 loss: 1.5008 Lr: 0.00023
[2025-04-08 13:59:20,703 INFO misc.py line 113 3298914] Train: [1/100][1007/2402] Data 0.003 (0.004) Batch 0.438 (0.479) Remain 31:51:24 loss: 1.4997 Lr: 0.00023
[2025-04-08 13:59:21,245 INFO misc.py line 113 3298914] Train: [1/100][1008/2402] Data 0.004 (0.004) Batch 0.542 (0.480) Remain 31:51:39 loss: 1.5935 Lr: 0.00023
[2025-04-08 13:59:21,642 INFO misc.py line 113 3298914] Train: [1/100][1009/2402] Data 0.003 (0.004) Batch 0.398 (0.479) Remain 31:51:19 loss: 1.6101 Lr: 0.00023
[2025-04-08 13:59:22,206 INFO misc.py line 113 3298914] Train: [1/100][1010/2402] Data 0.003 (0.004) Batch 0.564 (0.480) Remain 31:51:38 loss: 1.8870 Lr: 0.00023
[2025-04-08 13:59:22,659 INFO misc.py line 113 3298914] Train: [1/100][1011/2402] Data 0.004 (0.004) Batch 0.453 (0.480) Remain 31:51:32 loss: 1.8245 Lr: 0.00023
[2025-04-08 13:59:23,146 INFO misc.py line 113 3298914] Train: [1/100][1012/2402] Data 0.003 (0.004) Batch 0.487 (0.480) Remain 31:51:33 loss: 2.2048 Lr: 0.00023
[2025-04-08 13:59:23,548 INFO misc.py line 113 3298914] Train: [1/100][1013/2402] Data 0.003 (0.004) Batch 0.401 (0.479) Remain 31:51:14 loss: 1.4359 Lr: 0.00023
[2025-04-08 13:59:24,095 INFO misc.py line 113 3298914] Train: [1/100][1014/2402] Data 0.004 (0.004) Batch 0.548 (0.480) Remain 31:51:29 loss: 1.9653 Lr: 0.00023
[2025-04-08 13:59:24,565 INFO misc.py line 113 3298914] Train: [1/100][1015/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:51:27 loss: 1.8325 Lr: 0.00023
[2025-04-08 13:59:25,098 INFO misc.py line 113 3298914] Train: [1/100][1016/2402] Data 0.004 (0.004) Batch 0.533 (0.480) Remain 31:51:39 loss: 1.8820 Lr: 0.00023
[2025-04-08 13:59:25,633 INFO misc.py line 113 3298914] Train: [1/100][1017/2402] Data 0.003 (0.004) Batch 0.534 (0.480) Remain 31:51:51 loss: 1.7263 Lr: 0.00023
[2025-04-08 13:59:26,154 INFO misc.py line 113 3298914] Train: [1/100][1018/2402] Data 0.004 (0.004) Batch 0.522 (0.480) Remain 31:52:01 loss: 1.6071 Lr: 0.00023
[2025-04-08 13:59:26,610 INFO misc.py line 113 3298914] Train: [1/100][1019/2402] Data 0.004 (0.004) Batch 0.457 (0.480) Remain 31:51:55 loss: 1.9018 Lr: 0.00023
[2025-04-08 13:59:27,163 INFO misc.py line 113 3298914] Train: [1/100][1020/2402] Data 0.003 (0.004) Batch 0.553 (0.480) Remain 31:52:12 loss: 1.9590 Lr: 0.00023
[2025-04-08 13:59:27,638 INFO misc.py line 113 3298914] Train: [1/100][1021/2402] Data 0.004 (0.004) Batch 0.474 (0.480) Remain 31:52:10 loss: 1.6104 Lr: 0.00023
[2025-04-08 13:59:28,084 INFO misc.py line 113 3298914] Train: [1/100][1022/2402] Data 0.003 (0.004) Batch 0.447 (0.480) Remain 31:52:02 loss: 1.7217 Lr: 0.00023
[2025-04-08 13:59:28,476 INFO misc.py line 113 3298914] Train: [1/100][1023/2402] Data 0.003 (0.004) Batch 0.392 (0.480) Remain 31:51:40 loss: 1.7177 Lr: 0.00023
[2025-04-08 13:59:28,977 INFO misc.py line 113 3298914] Train: [1/100][1024/2402] Data 0.003 (0.004) Batch 0.501 (0.480) Remain 31:51:45 loss: 1.3272 Lr: 0.00023
[2025-04-08 13:59:29,355 INFO misc.py line 113 3298914] Train: [1/100][1025/2402] Data 0.003 (0.004) Batch 0.378 (0.479) Remain 31:51:21 loss: 1.3424 Lr: 0.00023
[2025-04-08 13:59:29,814 INFO misc.py line 113 3298914] Train: [1/100][1026/2402] Data 0.004 (0.004) Batch 0.459 (0.479) Remain 31:51:15 loss: 1.4494 Lr: 0.00023
[2025-04-08 13:59:30,355 INFO misc.py line 113 3298914] Train: [1/100][1027/2402] Data 0.003 (0.004) Batch 0.541 (0.480) Remain 31:51:29 loss: 1.5258 Lr: 0.00023
[2025-04-08 13:59:30,845 INFO misc.py line 113 3298914] Train: [1/100][1028/2402] Data 0.003 (0.004) Batch 0.490 (0.480) Remain 31:51:31 loss: 1.7451 Lr: 0.00023
[2025-04-08 13:59:31,311 INFO misc.py line 113 3298914] Train: [1/100][1029/2402] Data 0.004 (0.004) Batch 0.466 (0.480) Remain 31:51:28 loss: 1.7483 Lr: 0.00023
[2025-04-08 13:59:31,775 INFO misc.py line 113 3298914] Train: [1/100][1030/2402] Data 0.003 (0.004) Batch 0.464 (0.480) Remain 31:51:24 loss: 1.6924 Lr: 0.00023
[2025-04-08 13:59:32,203 INFO misc.py line 113 3298914] Train: [1/100][1031/2402] Data 0.003 (0.004) Batch 0.428 (0.479) Remain 31:51:11 loss: 2.1599 Lr: 0.00023
[2025-04-08 13:59:32,685 INFO misc.py line 113 3298914] Train: [1/100][1032/2402] Data 0.004 (0.004) Batch 0.482 (0.479) Remain 31:51:11 loss: 2.3451 Lr: 0.00023
[2025-04-08 13:59:33,252 INFO misc.py line 113 3298914] Train: [1/100][1033/2402] Data 0.003 (0.004) Batch 0.567 (0.480) Remain 31:51:31 loss: 1.8858 Lr: 0.00023
[2025-04-08 13:59:33,639 INFO misc.py line 113 3298914] Train: [1/100][1034/2402] Data 0.004 (0.004) Batch 0.387 (0.479) Remain 31:51:09 loss: 2.1726 Lr: 0.00023
[2025-04-08 13:59:34,105 INFO misc.py line 113 3298914] Train: [1/100][1035/2402] Data 0.004 (0.004) Batch 0.466 (0.479) Remain 31:51:06 loss: 1.6583 Lr: 0.00023
[2025-04-08 13:59:34,668 INFO misc.py line 113 3298914] Train: [1/100][1036/2402] Data 0.003 (0.004) Batch 0.562 (0.480) Remain 31:51:24 loss: 1.5891 Lr: 0.00023
[2025-04-08 13:59:35,103 INFO misc.py line 113 3298914] Train: [1/100][1037/2402] Data 0.004 (0.004) Batch 0.436 (0.479) Remain 31:51:14 loss: 1.1005 Lr: 0.00023
[2025-04-08 13:59:35,648 INFO misc.py line 113 3298914] Train: [1/100][1038/2402] Data 0.004 (0.004) Batch 0.545 (0.480) Remain 31:51:28 loss: 1.8253 Lr: 0.00023
[2025-04-08 13:59:36,169 INFO misc.py line 113 3298914] Train: [1/100][1039/2402] Data 0.003 (0.004) Batch 0.521 (0.480) Remain 31:51:37 loss: 1.3327 Lr: 0.00023
[2025-04-08 13:59:36,651 INFO misc.py line 113 3298914] Train: [1/100][1040/2402] Data 0.004 (0.004) Batch 0.482 (0.480) Remain 31:51:38 loss: 1.8316 Lr: 0.00023
[2025-04-08 13:59:37,170 INFO misc.py line 113 3298914] Train: [1/100][1041/2402] Data 0.003 (0.004) Batch 0.519 (0.480) Remain 31:51:46 loss: 1.8731 Lr: 0.00023
[2025-04-08 13:59:37,697 INFO misc.py line 113 3298914] Train: [1/100][1042/2402] Data 0.004 (0.004) Batch 0.527 (0.480) Remain 31:51:56 loss: 1.8865 Lr: 0.00023
[2025-04-08 13:59:38,171 INFO misc.py line 113 3298914] Train: [1/100][1043/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:51:55 loss: 1.6677 Lr: 0.00023
[2025-04-08 13:59:38,606 INFO misc.py line 113 3298914] Train: [1/100][1044/2402] Data 0.004 (0.004) Batch 0.435 (0.480) Remain 31:51:44 loss: 1.6101 Lr: 0.00023
[2025-04-08 13:59:39,181 INFO misc.py line 113 3298914] Train: [1/100][1045/2402] Data 0.003 (0.004) Batch 0.575 (0.480) Remain 31:52:05 loss: 1.8007 Lr: 0.00023
[2025-04-08 13:59:39,679 INFO misc.py line 113 3298914] Train: [1/100][1046/2402] Data 0.003 (0.004) Batch 0.498 (0.480) Remain 31:52:09 loss: 1.8218 Lr: 0.00023
[2025-04-08 13:59:40,228 INFO misc.py line 113 3298914] Train: [1/100][1047/2402] Data 0.003 (0.004) Batch 0.549 (0.480) Remain 31:52:24 loss: 1.7428 Lr: 0.00023
[2025-04-08 13:59:40,669 INFO misc.py line 113 3298914] Train: [1/100][1048/2402] Data 0.004 (0.004) Batch 0.441 (0.480) Remain 31:52:15 loss: 1.6634 Lr: 0.00023
[2025-04-08 13:59:41,097 INFO misc.py line 113 3298914] Train: [1/100][1049/2402] Data 0.003 (0.004) Batch 0.428 (0.480) Remain 31:52:03 loss: 2.0472 Lr: 0.00023
[2025-04-08 13:59:41,522 INFO misc.py line 113 3298914] Train: [1/100][1050/2402] Data 0.003 (0.004) Batch 0.424 (0.480) Remain 31:51:50 loss: 1.8099 Lr: 0.00023
[2025-04-08 13:59:41,958 INFO misc.py line 113 3298914] Train: [1/100][1051/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:51:39 loss: 1.3417 Lr: 0.00023
[2025-04-08 13:59:42,424 INFO misc.py line 113 3298914] Train: [1/100][1052/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:51:36 loss: 2.1180 Lr: 0.00023
[2025-04-08 13:59:42,823 INFO misc.py line 113 3298914] Train: [1/100][1053/2402] Data 0.003 (0.004) Batch 0.399 (0.480) Remain 31:51:17 loss: 1.3605 Lr: 0.00023
[2025-04-08 13:59:43,251 INFO misc.py line 113 3298914] Train: [1/100][1054/2402] Data 0.004 (0.004) Batch 0.428 (0.479) Remain 31:51:05 loss: 1.6013 Lr: 0.00023
[2025-04-08 13:59:43,773 INFO misc.py line 113 3298914] Train: [1/100][1055/2402] Data 0.004 (0.004) Batch 0.522 (0.480) Remain 31:51:14 loss: 1.8549 Lr: 0.00023
[2025-04-08 13:59:44,172 INFO misc.py line 113 3298914] Train: [1/100][1056/2402] Data 0.003 (0.004) Batch 0.399 (0.479) Remain 31:50:55 loss: 1.5904 Lr: 0.00023
[2025-04-08 13:59:44,643 INFO misc.py line 113 3298914] Train: [1/100][1057/2402] Data 0.003 (0.004) Batch 0.471 (0.479) Remain 31:50:53 loss: 1.8957 Lr: 0.00023
[2025-04-08 13:59:45,175 INFO misc.py line 113 3298914] Train: [1/100][1058/2402] Data 0.003 (0.004) Batch 0.532 (0.479) Remain 31:51:04 loss: 1.8877 Lr: 0.00023
[2025-04-08 13:59:45,527 INFO misc.py line 113 3298914] Train: [1/100][1059/2402] Data 0.004 (0.004) Batch 0.352 (0.479) Remain 31:50:35 loss: 1.8727 Lr: 0.00023
[2025-04-08 13:59:46,095 INFO misc.py line 113 3298914] Train: [1/100][1060/2402] Data 0.003 (0.004) Batch 0.566 (0.479) Remain 31:50:54 loss: 2.0530 Lr: 0.00023
[2025-04-08 13:59:46,594 INFO misc.py line 113 3298914] Train: [1/100][1061/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:50:59 loss: 1.6565 Lr: 0.00023
[2025-04-08 13:59:47,063 INFO misc.py line 113 3298914] Train: [1/100][1062/2402] Data 0.003 (0.004) Batch 0.468 (0.479) Remain 31:50:56 loss: 1.8082 Lr: 0.00023
[2025-04-08 13:59:47,444 INFO misc.py line 113 3298914] Train: [1/100][1063/2402] Data 0.003 (0.004) Batch 0.381 (0.479) Remain 31:50:33 loss: 1.7337 Lr: 0.00023
[2025-04-08 13:59:48,022 INFO misc.py line 113 3298914] Train: [1/100][1064/2402] Data 0.003 (0.004) Batch 0.578 (0.479) Remain 31:50:55 loss: 1.7753 Lr: 0.00023
[2025-04-08 13:59:48,417 INFO misc.py line 113 3298914] Train: [1/100][1065/2402] Data 0.003 (0.004) Batch 0.395 (0.479) Remain 31:50:35 loss: 1.8097 Lr: 0.00023
[2025-04-08 13:59:48,911 INFO misc.py line 113 3298914] Train: [1/100][1066/2402] Data 0.003 (0.004) Batch 0.494 (0.479) Remain 31:50:38 loss: 1.4055 Lr: 0.00023
[2025-04-08 13:59:49,385 INFO misc.py line 113 3298914] Train: [1/100][1067/2402] Data 0.004 (0.004) Batch 0.474 (0.479) Remain 31:50:36 loss: 1.8435 Lr: 0.00023
[2025-04-08 13:59:49,801 INFO misc.py line 113 3298914] Train: [1/100][1068/2402] Data 0.003 (0.004) Batch 0.416 (0.479) Remain 31:50:22 loss: 1.8233 Lr: 0.00023
[2025-04-08 13:59:50,236 INFO misc.py line 113 3298914] Train: [1/100][1069/2402] Data 0.003 (0.004) Batch 0.435 (0.479) Remain 31:50:11 loss: 1.9660 Lr: 0.00023
[2025-04-08 13:59:50,727 INFO misc.py line 113 3298914] Train: [1/100][1070/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:50:13 loss: 1.7150 Lr: 0.00023
[2025-04-08 13:59:51,239 INFO misc.py line 113 3298914] Train: [1/100][1071/2402] Data 0.003 (0.004) Batch 0.512 (0.479) Remain 31:50:20 loss: 1.6470 Lr: 0.00023
[2025-04-08 13:59:51,760 INFO misc.py line 113 3298914] Train: [1/100][1072/2402] Data 0.004 (0.004) Batch 0.521 (0.479) Remain 31:50:29 loss: 1.9764 Lr: 0.00023
[2025-04-08 13:59:52,191 INFO misc.py line 113 3298914] Train: [1/100][1073/2402] Data 0.003 (0.004) Batch 0.431 (0.479) Remain 31:50:18 loss: 1.4576 Lr: 0.00024
[2025-04-08 13:59:52,676 INFO misc.py line 113 3298914] Train: [1/100][1074/2402] Data 0.003 (0.004) Batch 0.485 (0.479) Remain 31:50:18 loss: 2.2571 Lr: 0.00024
[2025-04-08 13:59:53,177 INFO misc.py line 113 3298914] Train: [1/100][1075/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:50:23 loss: 2.1303 Lr: 0.00024
[2025-04-08 13:59:53,689 INFO misc.py line 113 3298914] Train: [1/100][1076/2402] Data 0.003 (0.004) Batch 0.512 (0.479) Remain 31:50:30 loss: 1.7469 Lr: 0.00024
[2025-04-08 13:59:54,160 INFO misc.py line 113 3298914] Train: [1/100][1077/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:50:27 loss: 1.8400 Lr: 0.00024
[2025-04-08 13:59:54,533 INFO misc.py line 113 3298914] Train: [1/100][1078/2402] Data 0.003 (0.004) Batch 0.373 (0.479) Remain 31:50:03 loss: 1.7352 Lr: 0.00024
[2025-04-08 13:59:55,120 INFO misc.py line 113 3298914] Train: [1/100][1079/2402] Data 0.003 (0.004) Batch 0.587 (0.479) Remain 31:50:27 loss: 1.8153 Lr: 0.00024
[2025-04-08 13:59:55,671 INFO misc.py line 113 3298914] Train: [1/100][1080/2402] Data 0.004 (0.004) Batch 0.551 (0.479) Remain 31:50:42 loss: 1.8622 Lr: 0.00024
[2025-04-08 13:59:56,194 INFO misc.py line 113 3298914] Train: [1/100][1081/2402] Data 0.003 (0.004) Batch 0.522 (0.479) Remain 31:50:51 loss: 1.8220 Lr: 0.00024
[2025-04-08 13:59:56,714 INFO misc.py line 113 3298914] Train: [1/100][1082/2402] Data 0.003 (0.004) Batch 0.520 (0.480) Remain 31:51:00 loss: 1.6110 Lr: 0.00024
[2025-04-08 13:59:57,201 INFO misc.py line 113 3298914] Train: [1/100][1083/2402] Data 0.003 (0.004) Batch 0.487 (0.480) Remain 31:51:01 loss: 1.9609 Lr: 0.00024
[2025-04-08 13:59:57,701 INFO misc.py line 113 3298914] Train: [1/100][1084/2402] Data 0.004 (0.004) Batch 0.500 (0.480) Remain 31:51:05 loss: 1.9450 Lr: 0.00024
[2025-04-08 13:59:58,151 INFO misc.py line 113 3298914] Train: [1/100][1085/2402] Data 0.003 (0.004) Batch 0.450 (0.480) Remain 31:50:58 loss: 1.5261 Lr: 0.00024
[2025-04-08 13:59:58,553 INFO misc.py line 113 3298914] Train: [1/100][1086/2402] Data 0.004 (0.004) Batch 0.402 (0.479) Remain 31:50:40 loss: 1.0400 Lr: 0.00024
[2025-04-08 13:59:59,093 INFO misc.py line 113 3298914] Train: [1/100][1087/2402] Data 0.004 (0.004) Batch 0.540 (0.479) Remain 31:50:53 loss: 1.6155 Lr: 0.00024
[2025-04-08 13:59:59,624 INFO misc.py line 113 3298914] Train: [1/100][1088/2402] Data 0.003 (0.004) Batch 0.531 (0.480) Remain 31:51:04 loss: 2.0261 Lr: 0.00024
[2025-04-08 14:00:00,095 INFO misc.py line 113 3298914] Train: [1/100][1089/2402] Data 0.003 (0.004) Batch 0.471 (0.480) Remain 31:51:02 loss: 1.3820 Lr: 0.00024
[2025-04-08 14:00:00,564 INFO misc.py line 113 3298914] Train: [1/100][1090/2402] Data 0.003 (0.004) Batch 0.469 (0.480) Remain 31:50:59 loss: 1.8107 Lr: 0.00024
[2025-04-08 14:00:01,081 INFO misc.py line 113 3298914] Train: [1/100][1091/2402] Data 0.004 (0.004) Batch 0.517 (0.480) Remain 31:51:07 loss: 1.4989 Lr: 0.00024
[2025-04-08 14:00:01,628 INFO misc.py line 113 3298914] Train: [1/100][1092/2402] Data 0.003 (0.004) Batch 0.547 (0.480) Remain 31:51:21 loss: 1.9369 Lr: 0.00024
[2025-04-08 14:00:02,087 INFO misc.py line 113 3298914] Train: [1/100][1093/2402] Data 0.003 (0.004) Batch 0.459 (0.480) Remain 31:51:16 loss: 1.8362 Lr: 0.00024
[2025-04-08 14:00:02,629 INFO misc.py line 113 3298914] Train: [1/100][1094/2402] Data 0.003 (0.004) Batch 0.542 (0.480) Remain 31:51:29 loss: 1.4896 Lr: 0.00024
[2025-04-08 14:00:03,063 INFO misc.py line 113 3298914] Train: [1/100][1095/2402] Data 0.004 (0.004) Batch 0.435 (0.480) Remain 31:51:19 loss: 2.0839 Lr: 0.00024
[2025-04-08 14:00:03,431 INFO misc.py line 113 3298914] Train: [1/100][1096/2402] Data 0.004 (0.004) Batch 0.368 (0.480) Remain 31:50:54 loss: 2.0415 Lr: 0.00024
[2025-04-08 14:00:03,873 INFO misc.py line 113 3298914] Train: [1/100][1097/2402] Data 0.003 (0.004) Batch 0.442 (0.479) Remain 31:50:45 loss: 1.8227 Lr: 0.00024
[2025-04-08 14:00:04,258 INFO misc.py line 113 3298914] Train: [1/100][1098/2402] Data 0.004 (0.004) Batch 0.385 (0.479) Remain 31:50:24 loss: 1.6361 Lr: 0.00024
[2025-04-08 14:00:04,777 INFO misc.py line 113 3298914] Train: [1/100][1099/2402] Data 0.003 (0.004) Batch 0.519 (0.479) Remain 31:50:32 loss: 2.0172 Lr: 0.00024
[2025-04-08 14:00:05,277 INFO misc.py line 113 3298914] Train: [1/100][1100/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:50:36 loss: 1.6803 Lr: 0.00024
[2025-04-08 14:00:05,870 INFO misc.py line 113 3298914] Train: [1/100][1101/2402] Data 0.003 (0.004) Batch 0.593 (0.480) Remain 31:51:00 loss: 1.5544 Lr: 0.00024
[2025-04-08 14:00:06,285 INFO misc.py line 113 3298914] Train: [1/100][1102/2402] Data 0.003 (0.004) Batch 0.415 (0.479) Remain 31:50:46 loss: 1.9063 Lr: 0.00024
[2025-04-08 14:00:06,826 INFO misc.py line 113 3298914] Train: [1/100][1103/2402] Data 0.003 (0.004) Batch 0.541 (0.480) Remain 31:50:59 loss: 1.3144 Lr: 0.00024
[2025-04-08 14:00:07,219 INFO misc.py line 113 3298914] Train: [1/100][1104/2402] Data 0.003 (0.004) Batch 0.393 (0.479) Remain 31:50:40 loss: 1.5277 Lr: 0.00024
[2025-04-08 14:00:07,617 INFO misc.py line 113 3298914] Train: [1/100][1105/2402] Data 0.004 (0.004) Batch 0.398 (0.479) Remain 31:50:21 loss: 1.9282 Lr: 0.00024
[2025-04-08 14:00:08,145 INFO misc.py line 113 3298914] Train: [1/100][1106/2402] Data 0.003 (0.004) Batch 0.527 (0.479) Remain 31:50:31 loss: 1.8307 Lr: 0.00024
[2025-04-08 14:00:08,695 INFO misc.py line 113 3298914] Train: [1/100][1107/2402] Data 0.003 (0.004) Batch 0.551 (0.480) Remain 31:50:46 loss: 1.5033 Lr: 0.00024
[2025-04-08 14:00:09,253 INFO misc.py line 113 3298914] Train: [1/100][1108/2402] Data 0.004 (0.004) Batch 0.557 (0.480) Remain 31:51:03 loss: 1.6653 Lr: 0.00024
[2025-04-08 14:00:09,757 INFO misc.py line 113 3298914] Train: [1/100][1109/2402] Data 0.003 (0.004) Batch 0.504 (0.480) Remain 31:51:07 loss: 1.3824 Lr: 0.00024
[2025-04-08 14:00:10,251 INFO misc.py line 113 3298914] Train: [1/100][1110/2402] Data 0.003 (0.004) Batch 0.494 (0.480) Remain 31:51:10 loss: 1.5572 Lr: 0.00024
[2025-04-08 14:00:10,782 INFO misc.py line 113 3298914] Train: [1/100][1111/2402] Data 0.004 (0.004) Batch 0.532 (0.480) Remain 31:51:21 loss: 2.0010 Lr: 0.00024
[2025-04-08 14:00:11,252 INFO misc.py line 113 3298914] Train: [1/100][1112/2402] Data 0.004 (0.004) Batch 0.469 (0.480) Remain 31:51:18 loss: 2.1522 Lr: 0.00024
[2025-04-08 14:00:11,769 INFO misc.py line 113 3298914] Train: [1/100][1113/2402] Data 0.003 (0.004) Batch 0.517 (0.480) Remain 31:51:26 loss: 1.9507 Lr: 0.00024
[2025-04-08 14:00:12,153 INFO misc.py line 113 3298914] Train: [1/100][1114/2402] Data 0.003 (0.004) Batch 0.384 (0.480) Remain 31:51:05 loss: 1.8423 Lr: 0.00024
[2025-04-08 14:00:12,566 INFO misc.py line 113 3298914] Train: [1/100][1115/2402] Data 0.003 (0.004) Batch 0.413 (0.480) Remain 31:50:50 loss: 1.4752 Lr: 0.00024
[2025-04-08 14:00:13,054 INFO misc.py line 113 3298914] Train: [1/100][1116/2402] Data 0.004 (0.004) Batch 0.488 (0.480) Remain 31:50:51 loss: 1.7424 Lr: 0.00024
[2025-04-08 14:00:13,586 INFO misc.py line 113 3298914] Train: [1/100][1117/2402] Data 0.003 (0.004) Batch 0.532 (0.480) Remain 31:51:02 loss: 1.8098 Lr: 0.00024
[2025-04-08 14:00:13,969 INFO misc.py line 113 3298914] Train: [1/100][1118/2402] Data 0.004 (0.004) Batch 0.383 (0.480) Remain 31:50:41 loss: 1.8101 Lr: 0.00024
[2025-04-08 14:00:14,388 INFO misc.py line 113 3298914] Train: [1/100][1119/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:50:27 loss: 1.8424 Lr: 0.00024
[2025-04-08 14:00:14,838 INFO misc.py line 113 3298914] Train: [1/100][1120/2402] Data 0.003 (0.004) Batch 0.449 (0.479) Remain 31:50:20 loss: 2.0536 Lr: 0.00024
[2025-04-08 14:00:15,285 INFO misc.py line 113 3298914] Train: [1/100][1121/2402] Data 0.004 (0.004) Batch 0.448 (0.479) Remain 31:50:13 loss: 2.6040 Lr: 0.00024
[2025-04-08 14:00:15,696 INFO misc.py line 113 3298914] Train: [1/100][1122/2402] Data 0.003 (0.004) Batch 0.411 (0.479) Remain 31:49:58 loss: 1.8466 Lr: 0.00024
[2025-04-08 14:00:16,197 INFO misc.py line 113 3298914] Train: [1/100][1123/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:50:02 loss: 1.8093 Lr: 0.00024
[2025-04-08 14:00:16,647 INFO misc.py line 113 3298914] Train: [1/100][1124/2402] Data 0.004 (0.004) Batch 0.450 (0.479) Remain 31:49:55 loss: 2.0533 Lr: 0.00024
[2025-04-08 14:00:17,149 INFO misc.py line 113 3298914] Train: [1/100][1125/2402] Data 0.004 (0.004) Batch 0.502 (0.479) Remain 31:50:00 loss: 1.9099 Lr: 0.00024
[2025-04-08 14:00:17,648 INFO misc.py line 113 3298914] Train: [1/100][1126/2402] Data 0.004 (0.004) Batch 0.499 (0.479) Remain 31:50:04 loss: 1.9415 Lr: 0.00024
[2025-04-08 14:00:17,998 INFO misc.py line 113 3298914] Train: [1/100][1127/2402] Data 0.004 (0.004) Batch 0.350 (0.479) Remain 31:49:36 loss: 1.8915 Lr: 0.00024
[2025-04-08 14:00:18,446 INFO misc.py line 113 3298914] Train: [1/100][1128/2402] Data 0.004 (0.004) Batch 0.448 (0.479) Remain 31:49:28 loss: 2.1201 Lr: 0.00024
[2025-04-08 14:00:18,850 INFO misc.py line 113 3298914] Train: [1/100][1129/2402] Data 0.003 (0.004) Batch 0.405 (0.479) Remain 31:49:12 loss: 1.8597 Lr: 0.00024
[2025-04-08 14:00:19,243 INFO misc.py line 113 3298914] Train: [1/100][1130/2402] Data 0.003 (0.004) Batch 0.393 (0.479) Remain 31:48:53 loss: 1.8024 Lr: 0.00024
[2025-04-08 14:00:19,759 INFO misc.py line 113 3298914] Train: [1/100][1131/2402] Data 0.003 (0.004) Batch 0.516 (0.479) Remain 31:49:01 loss: 1.8775 Lr: 0.00024
[2025-04-08 14:00:20,394 INFO misc.py line 113 3298914] Train: [1/100][1132/2402] Data 0.003 (0.004) Batch 0.636 (0.479) Remain 31:49:33 loss: 1.5625 Lr: 0.00024
[2025-04-08 14:00:20,870 INFO misc.py line 113 3298914] Train: [1/100][1133/2402] Data 0.003 (0.004) Batch 0.475 (0.479) Remain 31:49:32 loss: 1.3985 Lr: 0.00024
[2025-04-08 14:00:21,382 INFO misc.py line 113 3298914] Train: [1/100][1134/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:49:38 loss: 1.5968 Lr: 0.00024
[2025-04-08 14:00:21,891 INFO misc.py line 113 3298914] Train: [1/100][1135/2402] Data 0.003 (0.004) Batch 0.509 (0.479) Remain 31:49:44 loss: 1.6441 Lr: 0.00024
[2025-04-08 14:00:22,404 INFO misc.py line 113 3298914] Train: [1/100][1136/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:49:51 loss: 2.0348 Lr: 0.00024
[2025-04-08 14:00:22,969 INFO misc.py line 113 3298914] Train: [1/100][1137/2402] Data 0.003 (0.004) Batch 0.565 (0.479) Remain 31:50:08 loss: 2.1251 Lr: 0.00024
[2025-04-08 14:00:23,373 INFO misc.py line 113 3298914] Train: [1/100][1138/2402] Data 0.003 (0.004) Batch 0.404 (0.479) Remain 31:49:52 loss: 1.8233 Lr: 0.00024
[2025-04-08 14:00:23,964 INFO misc.py line 113 3298914] Train: [1/100][1139/2402] Data 0.003 (0.004) Batch 0.591 (0.479) Remain 31:50:15 loss: 1.6986 Lr: 0.00024
[2025-04-08 14:00:24,307 INFO misc.py line 113 3298914] Train: [1/100][1140/2402] Data 0.004 (0.004) Batch 0.343 (0.479) Remain 31:49:46 loss: 1.9474 Lr: 0.00024
[2025-04-08 14:00:24,680 INFO misc.py line 113 3298914] Train: [1/100][1141/2402] Data 0.003 (0.004) Batch 0.374 (0.479) Remain 31:49:23 loss: 1.8613 Lr: 0.00024
[2025-04-08 14:00:25,172 INFO misc.py line 113 3298914] Train: [1/100][1142/2402] Data 0.003 (0.004) Batch 0.492 (0.479) Remain 31:49:25 loss: 1.7650 Lr: 0.00024
[2025-04-08 14:00:25,599 INFO misc.py line 113 3298914] Train: [1/100][1143/2402] Data 0.004 (0.004) Batch 0.427 (0.479) Remain 31:49:14 loss: 1.8001 Lr: 0.00024
[2025-04-08 14:00:26,019 INFO misc.py line 113 3298914] Train: [1/100][1144/2402] Data 0.004 (0.004) Batch 0.420 (0.479) Remain 31:49:01 loss: 2.0782 Lr: 0.00024
[2025-04-08 14:00:26,527 INFO misc.py line 113 3298914] Train: [1/100][1145/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:49:07 loss: 1.4067 Lr: 0.00024
[2025-04-08 14:00:26,917 INFO misc.py line 113 3298914] Train: [1/100][1146/2402] Data 0.004 (0.004) Batch 0.389 (0.479) Remain 31:48:47 loss: 1.7000 Lr: 0.00024
[2025-04-08 14:00:27,340 INFO misc.py line 113 3298914] Train: [1/100][1147/2402] Data 0.003 (0.004) Batch 0.423 (0.479) Remain 31:48:35 loss: 1.4303 Lr: 0.00024
[2025-04-08 14:00:27,749 INFO misc.py line 113 3298914] Train: [1/100][1148/2402] Data 0.004 (0.004) Batch 0.410 (0.479) Remain 31:48:20 loss: 1.4241 Lr: 0.00024
[2025-04-08 14:00:28,318 INFO misc.py line 113 3298914] Train: [1/100][1149/2402] Data 0.003 (0.004) Batch 0.568 (0.479) Remain 31:48:38 loss: 1.6214 Lr: 0.00024
[2025-04-08 14:00:28,826 INFO misc.py line 113 3298914] Train: [1/100][1150/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:48:44 loss: 1.5206 Lr: 0.00024
[2025-04-08 14:00:29,339 INFO misc.py line 113 3298914] Train: [1/100][1151/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:48:50 loss: 1.2801 Lr: 0.00024
[2025-04-08 14:00:29,818 INFO misc.py line 113 3298914] Train: [1/100][1152/2402] Data 0.004 (0.004) Batch 0.478 (0.479) Remain 31:48:50 loss: 1.8211 Lr: 0.00024
[2025-04-08 14:00:30,349 INFO misc.py line 113 3298914] Train: [1/100][1153/2402] Data 0.004 (0.004) Batch 0.532 (0.479) Remain 31:49:00 loss: 1.4273 Lr: 0.00024
[2025-04-08 14:00:30,696 INFO misc.py line 113 3298914] Train: [1/100][1154/2402] Data 0.004 (0.004) Batch 0.347 (0.479) Remain 31:48:32 loss: 1.1978 Lr: 0.00024
[2025-04-08 14:00:31,255 INFO misc.py line 113 3298914] Train: [1/100][1155/2402] Data 0.003 (0.004) Batch 0.558 (0.479) Remain 31:48:48 loss: 2.0754 Lr: 0.00024
[2025-04-08 14:00:31,619 INFO misc.py line 113 3298914] Train: [1/100][1156/2402] Data 0.004 (0.004) Batch 0.364 (0.479) Remain 31:48:24 loss: 1.7995 Lr: 0.00024
[2025-04-08 14:00:32,071 INFO misc.py line 113 3298914] Train: [1/100][1157/2402] Data 0.003 (0.004) Batch 0.451 (0.479) Remain 31:48:18 loss: 1.5982 Lr: 0.00024
[2025-04-08 14:00:32,610 INFO misc.py line 113 3298914] Train: [1/100][1158/2402] Data 0.004 (0.004) Batch 0.539 (0.479) Remain 31:48:30 loss: 1.8313 Lr: 0.00024
[2025-04-08 14:00:33,105 INFO misc.py line 113 3298914] Train: [1/100][1159/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:48:33 loss: 1.2737 Lr: 0.00024
[2025-04-08 14:00:33,543 INFO misc.py line 113 3298914] Train: [1/100][1160/2402] Data 0.004 (0.004) Batch 0.438 (0.479) Remain 31:48:24 loss: 2.1505 Lr: 0.00024
[2025-04-08 14:00:34,024 INFO misc.py line 113 3298914] Train: [1/100][1161/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:48:24 loss: 1.2962 Lr: 0.00024
[2025-04-08 14:00:34,486 INFO misc.py line 113 3298914] Train: [1/100][1162/2402] Data 0.003 (0.004) Batch 0.462 (0.479) Remain 31:48:20 loss: 1.8605 Lr: 0.00024
[2025-04-08 14:00:34,980 INFO misc.py line 113 3298914] Train: [1/100][1163/2402] Data 0.004 (0.004) Batch 0.494 (0.479) Remain 31:48:22 loss: 1.8263 Lr: 0.00024
[2025-04-08 14:00:35,456 INFO misc.py line 113 3298914] Train: [1/100][1164/2402] Data 0.003 (0.004) Batch 0.476 (0.479) Remain 31:48:21 loss: 1.8189 Lr: 0.00024
[2025-04-08 14:00:35,885 INFO misc.py line 113 3298914] Train: [1/100][1165/2402] Data 0.003 (0.004) Batch 0.429 (0.479) Remain 31:48:10 loss: 1.4544 Lr: 0.00024
[2025-04-08 14:00:36,360 INFO misc.py line 113 3298914] Train: [1/100][1166/2402] Data 0.004 (0.004) Batch 0.475 (0.479) Remain 31:48:09 loss: 2.2012 Lr: 0.00024
[2025-04-08 14:00:36,796 INFO misc.py line 113 3298914] Train: [1/100][1167/2402] Data 0.003 (0.004) Batch 0.437 (0.479) Remain 31:48:00 loss: 1.5994 Lr: 0.00024
[2025-04-08 14:00:37,246 INFO misc.py line 113 3298914] Train: [1/100][1168/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:47:54 loss: 1.7381 Lr: 0.00024
[2025-04-08 14:00:37,733 INFO misc.py line 113 3298914] Train: [1/100][1169/2402] Data 0.003 (0.004) Batch 0.486 (0.479) Remain 31:47:55 loss: 1.8162 Lr: 0.00024
[2025-04-08 14:00:38,210 INFO misc.py line 113 3298914] Train: [1/100][1170/2402] Data 0.003 (0.004) Batch 0.477 (0.479) Remain 31:47:54 loss: 1.4865 Lr: 0.00024
[2025-04-08 14:00:38,725 INFO misc.py line 113 3298914] Train: [1/100][1171/2402] Data 0.003 (0.004) Batch 0.515 (0.479) Remain 31:48:01 loss: 1.8511 Lr: 0.00024
[2025-04-08 14:00:39,170 INFO misc.py line 113 3298914] Train: [1/100][1172/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:47:53 loss: 2.1634 Lr: 0.00024
[2025-04-08 14:00:39,689 INFO misc.py line 113 3298914] Train: [1/100][1173/2402] Data 0.004 (0.004) Batch 0.519 (0.479) Remain 31:48:01 loss: 1.4637 Lr: 0.00024
[2025-04-08 14:00:40,159 INFO misc.py line 113 3298914] Train: [1/100][1174/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:47:59 loss: 2.1568 Lr: 0.00024
[2025-04-08 14:00:40,731 INFO misc.py line 113 3298914] Train: [1/100][1175/2402] Data 0.003 (0.004) Batch 0.571 (0.479) Remain 31:48:17 loss: 1.6196 Lr: 0.00024
[2025-04-08 14:00:41,157 INFO misc.py line 113 3298914] Train: [1/100][1176/2402] Data 0.004 (0.004) Batch 0.426 (0.479) Remain 31:48:06 loss: 1.7339 Lr: 0.00024
[2025-04-08 14:00:41,642 INFO misc.py line 113 3298914] Train: [1/100][1177/2402] Data 0.004 (0.004) Batch 0.485 (0.479) Remain 31:48:07 loss: 1.5124 Lr: 0.00024
[2025-04-08 14:00:42,073 INFO misc.py line 113 3298914] Train: [1/100][1178/2402] Data 0.003 (0.004) Batch 0.431 (0.479) Remain 31:47:56 loss: 1.6967 Lr: 0.00024
[2025-04-08 14:00:42,613 INFO misc.py line 113 3298914] Train: [1/100][1179/2402] Data 0.003 (0.004) Batch 0.540 (0.479) Remain 31:48:08 loss: 1.9176 Lr: 0.00024
[2025-04-08 14:00:43,053 INFO misc.py line 113 3298914] Train: [1/100][1180/2402] Data 0.003 (0.004) Batch 0.439 (0.479) Remain 31:48:00 loss: 1.6066 Lr: 0.00024
[2025-04-08 14:00:43,526 INFO misc.py line 113 3298914] Train: [1/100][1181/2402] Data 0.003 (0.004) Batch 0.473 (0.479) Remain 31:47:58 loss: 1.6522 Lr: 0.00024
[2025-04-08 14:00:43,941 INFO misc.py line 113 3298914] Train: [1/100][1182/2402] Data 0.004 (0.004) Batch 0.415 (0.479) Remain 31:47:45 loss: 1.4637 Lr: 0.00024
[2025-04-08 14:00:44,513 INFO misc.py line 113 3298914] Train: [1/100][1183/2402] Data 0.003 (0.004) Batch 0.572 (0.479) Remain 31:48:03 loss: 1.9753 Lr: 0.00024
[2025-04-08 14:00:44,970 INFO misc.py line 113 3298914] Train: [1/100][1184/2402] Data 0.003 (0.004) Batch 0.457 (0.479) Remain 31:47:58 loss: 1.9270 Lr: 0.00024
[2025-04-08 14:00:45,608 INFO misc.py line 113 3298914] Train: [1/100][1185/2402] Data 0.003 (0.004) Batch 0.638 (0.479) Remain 31:48:30 loss: 1.7389 Lr: 0.00024
[2025-04-08 14:00:46,121 INFO misc.py line 113 3298914] Train: [1/100][1186/2402] Data 0.003 (0.004) Batch 0.514 (0.479) Remain 31:48:36 loss: 1.4819 Lr: 0.00024
[2025-04-08 14:00:46,637 INFO misc.py line 113 3298914] Train: [1/100][1187/2402] Data 0.003 (0.004) Batch 0.515 (0.479) Remain 31:48:43 loss: 2.0282 Lr: 0.00024
[2025-04-08 14:00:47,135 INFO misc.py line 113 3298914] Train: [1/100][1188/2402] Data 0.004 (0.004) Batch 0.498 (0.479) Remain 31:48:47 loss: 1.9826 Lr: 0.00024
[2025-04-08 14:00:47,611 INFO misc.py line 113 3298914] Train: [1/100][1189/2402] Data 0.004 (0.004) Batch 0.476 (0.479) Remain 31:48:45 loss: 1.6215 Lr: 0.00024
[2025-04-08 14:00:48,140 INFO misc.py line 113 3298914] Train: [1/100][1190/2402] Data 0.003 (0.004) Batch 0.530 (0.479) Remain 31:48:55 loss: 1.6188 Lr: 0.00024
[2025-04-08 14:00:48,550 INFO misc.py line 113 3298914] Train: [1/100][1191/2402] Data 0.003 (0.004) Batch 0.409 (0.479) Remain 31:48:41 loss: 1.7202 Lr: 0.00024
[2025-04-08 14:00:48,979 INFO misc.py line 113 3298914] Train: [1/100][1192/2402] Data 0.003 (0.004) Batch 0.429 (0.479) Remain 31:48:30 loss: 1.4262 Lr: 0.00024
[2025-04-08 14:00:49,448 INFO misc.py line 113 3298914] Train: [1/100][1193/2402] Data 0.004 (0.004) Batch 0.469 (0.479) Remain 31:48:28 loss: 1.9652 Lr: 0.00024
[2025-04-08 14:00:49,904 INFO misc.py line 113 3298914] Train: [1/100][1194/2402] Data 0.003 (0.004) Batch 0.456 (0.479) Remain 31:48:22 loss: 1.3993 Lr: 0.00024
[2025-04-08 14:00:50,415 INFO misc.py line 113 3298914] Train: [1/100][1195/2402] Data 0.004 (0.004) Batch 0.511 (0.479) Remain 31:48:28 loss: 1.6748 Lr: 0.00024
[2025-04-08 14:00:50,900 INFO misc.py line 113 3298914] Train: [1/100][1196/2402] Data 0.004 (0.004) Batch 0.485 (0.479) Remain 31:48:29 loss: 1.6908 Lr: 0.00024
[2025-04-08 14:00:51,412 INFO misc.py line 113 3298914] Train: [1/100][1197/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:48:35 loss: 1.8387 Lr: 0.00024
[2025-04-08 14:00:51,923 INFO misc.py line 113 3298914] Train: [1/100][1198/2402] Data 0.004 (0.004) Batch 0.511 (0.479) Remain 31:48:41 loss: 1.4746 Lr: 0.00024
[2025-04-08 14:00:52,381 INFO misc.py line 113 3298914] Train: [1/100][1199/2402] Data 0.004 (0.004) Batch 0.457 (0.479) Remain 31:48:36 loss: 1.7094 Lr: 0.00024
[2025-04-08 14:00:52,899 INFO misc.py line 113 3298914] Train: [1/100][1200/2402] Data 0.004 (0.004) Batch 0.519 (0.479) Remain 31:48:44 loss: 1.7321 Lr: 0.00024
[2025-04-08 14:00:53,376 INFO misc.py line 113 3298914] Train: [1/100][1201/2402] Data 0.004 (0.004) Batch 0.477 (0.479) Remain 31:48:43 loss: 1.7684 Lr: 0.00024
[2025-04-08 14:00:53,784 INFO misc.py line 113 3298914] Train: [1/100][1202/2402] Data 0.003 (0.004) Batch 0.408 (0.479) Remain 31:48:28 loss: 1.7337 Lr: 0.00024
[2025-04-08 14:00:54,211 INFO misc.py line 113 3298914] Train: [1/100][1203/2402] Data 0.004 (0.004) Batch 0.427 (0.479) Remain 31:48:17 loss: 1.8731 Lr: 0.00024
[2025-04-08 14:00:54,674 INFO misc.py line 113 3298914] Train: [1/100][1204/2402] Data 0.003 (0.004) Batch 0.463 (0.479) Remain 31:48:14 loss: 1.7371 Lr: 0.00024
[2025-04-08 14:00:55,089 INFO misc.py line 113 3298914] Train: [1/100][1205/2402] Data 0.003 (0.004) Batch 0.415 (0.479) Remain 31:48:00 loss: 1.6881 Lr: 0.00024
[2025-04-08 14:00:55,657 INFO misc.py line 113 3298914] Train: [1/100][1206/2402] Data 0.003 (0.004) Batch 0.568 (0.479) Remain 31:48:17 loss: 1.8752 Lr: 0.00024
[2025-04-08 14:00:56,077 INFO misc.py line 113 3298914] Train: [1/100][1207/2402] Data 0.004 (0.004) Batch 0.421 (0.479) Remain 31:48:05 loss: 1.7396 Lr: 0.00024
[2025-04-08 14:00:56,366 INFO misc.py line 113 3298914] Train: [1/100][1208/2402] Data 0.003 (0.004) Batch 0.288 (0.479) Remain 31:47:27 loss: 1.8501 Lr: 0.00024
[2025-04-08 14:00:56,719 INFO misc.py line 113 3298914] Train: [1/100][1209/2402] Data 0.003 (0.004) Batch 0.353 (0.479) Remain 31:47:02 loss: 1.6322 Lr: 0.00024
[2025-04-08 14:00:57,220 INFO misc.py line 113 3298914] Train: [1/100][1210/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:47:06 loss: 1.6789 Lr: 0.00024
[2025-04-08 14:00:57,704 INFO misc.py line 113 3298914] Train: [1/100][1211/2402] Data 0.003 (0.004) Batch 0.484 (0.479) Remain 31:47:06 loss: 1.8395 Lr: 0.00024
[2025-04-08 14:00:58,086 INFO misc.py line 113 3298914] Train: [1/100][1212/2402] Data 0.003 (0.004) Batch 0.382 (0.479) Remain 31:46:47 loss: 1.4269 Lr: 0.00024
[2025-04-08 14:00:58,617 INFO misc.py line 113 3298914] Train: [1/100][1213/2402] Data 0.004 (0.004) Batch 0.531 (0.479) Remain 31:46:56 loss: 1.7745 Lr: 0.00024
[2025-04-08 14:00:59,086 INFO misc.py line 113 3298914] Train: [1/100][1214/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:46:54 loss: 1.4936 Lr: 0.00024
[2025-04-08 14:00:59,491 INFO misc.py line 113 3298914] Train: [1/100][1215/2402] Data 0.003 (0.004) Batch 0.405 (0.479) Remain 31:46:39 loss: 1.7504 Lr: 0.00024
[2025-04-08 14:00:59,935 INFO misc.py line 113 3298914] Train: [1/100][1216/2402] Data 0.003 (0.004) Batch 0.444 (0.479) Remain 31:46:32 loss: 1.5989 Lr: 0.00024
[2025-04-08 14:01:00,465 INFO misc.py line 113 3298914] Train: [1/100][1217/2402] Data 0.004 (0.004) Batch 0.529 (0.479) Remain 31:46:41 loss: 1.8982 Lr: 0.00025
[2025-04-08 14:01:00,916 INFO misc.py line 113 3298914] Train: [1/100][1218/2402] Data 0.003 (0.004) Batch 0.452 (0.479) Remain 31:46:35 loss: 1.6487 Lr: 0.00025
[2025-04-08 14:01:01,392 INFO misc.py line 113 3298914] Train: [1/100][1219/2402] Data 0.003 (0.004) Batch 0.475 (0.479) Remain 31:46:34 loss: 1.4635 Lr: 0.00025
[2025-04-08 14:01:01,813 INFO misc.py line 113 3298914] Train: [1/100][1220/2402] Data 0.004 (0.004) Batch 0.421 (0.479) Remain 31:46:23 loss: 1.6949 Lr: 0.00025
[2025-04-08 14:01:02,123 INFO misc.py line 113 3298914] Train: [1/100][1221/2402] Data 0.003 (0.004) Batch 0.310 (0.478) Remain 31:45:49 loss: 1.4676 Lr: 0.00025
[2025-04-08 14:01:02,541 INFO misc.py line 113 3298914] Train: [1/100][1222/2402] Data 0.004 (0.004) Batch 0.418 (0.478) Remain 31:45:37 loss: 1.6121 Lr: 0.00025
[2025-04-08 14:01:03,008 INFO misc.py line 113 3298914] Train: [1/100][1223/2402] Data 0.003 (0.004) Batch 0.467 (0.478) Remain 31:45:34 loss: 1.2305 Lr: 0.00025
[2025-04-08 14:01:03,485 INFO misc.py line 113 3298914] Train: [1/100][1224/2402] Data 0.004 (0.004) Batch 0.477 (0.478) Remain 31:45:33 loss: 1.8333 Lr: 0.00025
[2025-04-08 14:01:03,928 INFO misc.py line 113 3298914] Train: [1/100][1225/2402] Data 0.003 (0.004) Batch 0.443 (0.478) Remain 31:45:26 loss: 1.8380 Lr: 0.00025
[2025-04-08 14:01:04,425 INFO misc.py line 113 3298914] Train: [1/100][1226/2402] Data 0.004 (0.004) Batch 0.496 (0.478) Remain 31:45:29 loss: 1.5907 Lr: 0.00025
[2025-04-08 14:01:04,898 INFO misc.py line 113 3298914] Train: [1/100][1227/2402] Data 0.004 (0.004) Batch 0.473 (0.478) Remain 31:45:27 loss: 1.7151 Lr: 0.00025
[2025-04-08 14:01:05,400 INFO misc.py line 113 3298914] Train: [1/100][1228/2402] Data 0.003 (0.004) Batch 0.502 (0.478) Remain 31:45:32 loss: 1.8713 Lr: 0.00025
[2025-04-08 14:01:05,941 INFO misc.py line 113 3298914] Train: [1/100][1229/2402] Data 0.003 (0.004) Batch 0.541 (0.478) Remain 31:45:43 loss: 1.8964 Lr: 0.00025
[2025-04-08 14:01:06,361 INFO misc.py line 113 3298914] Train: [1/100][1230/2402] Data 0.004 (0.004) Batch 0.420 (0.478) Remain 31:45:31 loss: 1.8029 Lr: 0.00025
[2025-04-08 14:01:06,847 INFO misc.py line 113 3298914] Train: [1/100][1231/2402] Data 0.004 (0.004) Batch 0.486 (0.478) Remain 31:45:32 loss: 1.8773 Lr: 0.00025
[2025-04-08 14:01:07,364 INFO misc.py line 113 3298914] Train: [1/100][1232/2402] Data 0.003 (0.004) Batch 0.517 (0.478) Remain 31:45:39 loss: 1.6996 Lr: 0.00025
[2025-04-08 14:01:07,902 INFO misc.py line 113 3298914] Train: [1/100][1233/2402] Data 0.004 (0.004) Batch 0.538 (0.479) Remain 31:45:50 loss: 1.9847 Lr: 0.00025
[2025-04-08 14:01:08,302 INFO misc.py line 113 3298914] Train: [1/100][1234/2402] Data 0.003 (0.004) Batch 0.400 (0.478) Remain 31:45:35 loss: 2.0672 Lr: 0.00025
[2025-04-08 14:01:08,753 INFO misc.py line 113 3298914] Train: [1/100][1235/2402] Data 0.003 (0.004) Batch 0.450 (0.478) Remain 31:45:29 loss: 1.5197 Lr: 0.00025
[2025-04-08 14:01:09,225 INFO misc.py line 113 3298914] Train: [1/100][1236/2402] Data 0.004 (0.004) Batch 0.472 (0.478) Remain 31:45:27 loss: 1.4074 Lr: 0.00025
[2025-04-08 14:01:09,790 INFO misc.py line 113 3298914] Train: [1/100][1237/2402] Data 0.003 (0.004) Batch 0.566 (0.479) Remain 31:45:44 loss: 1.4237 Lr: 0.00025
[2025-04-08 14:01:10,258 INFO misc.py line 113 3298914] Train: [1/100][1238/2402] Data 0.003 (0.004) Batch 0.468 (0.478) Remain 31:45:41 loss: 1.8914 Lr: 0.00025
[2025-04-08 14:01:10,610 INFO misc.py line 113 3298914] Train: [1/100][1239/2402] Data 0.004 (0.004) Batch 0.352 (0.478) Remain 31:45:16 loss: 1.6378 Lr: 0.00025
[2025-04-08 14:01:11,112 INFO misc.py line 113 3298914] Train: [1/100][1240/2402] Data 0.003 (0.004) Batch 0.502 (0.478) Remain 31:45:20 loss: 1.6666 Lr: 0.00025
[2025-04-08 14:01:11,627 INFO misc.py line 113 3298914] Train: [1/100][1241/2402] Data 0.003 (0.004) Batch 0.515 (0.478) Remain 31:45:27 loss: 1.9188 Lr: 0.00025
[2025-04-08 14:01:12,099 INFO misc.py line 113 3298914] Train: [1/100][1242/2402] Data 0.003 (0.004) Batch 0.472 (0.478) Remain 31:45:25 loss: 1.6680 Lr: 0.00025
[2025-04-08 14:01:12,457 INFO misc.py line 113 3298914] Train: [1/100][1243/2402] Data 0.003 (0.004) Batch 0.357 (0.478) Remain 31:45:01 loss: 1.4922 Lr: 0.00025
[2025-04-08 14:01:12,925 INFO misc.py line 113 3298914] Train: [1/100][1244/2402] Data 0.003 (0.004) Batch 0.469 (0.478) Remain 31:44:59 loss: 1.8732 Lr: 0.00025
[2025-04-08 14:01:13,356 INFO misc.py line 113 3298914] Train: [1/100][1245/2402] Data 0.004 (0.004) Batch 0.431 (0.478) Remain 31:44:49 loss: 1.5782 Lr: 0.00025
[2025-04-08 14:01:13,728 INFO misc.py line 113 3298914] Train: [1/100][1246/2402] Data 0.003 (0.004) Batch 0.372 (0.478) Remain 31:44:28 loss: 1.5488 Lr: 0.00025
[2025-04-08 14:01:14,154 INFO misc.py line 113 3298914] Train: [1/100][1247/2402] Data 0.003 (0.004) Batch 0.426 (0.478) Remain 31:44:18 loss: 2.1756 Lr: 0.00025
[2025-04-08 14:01:14,602 INFO misc.py line 113 3298914] Train: [1/100][1248/2402] Data 0.003 (0.004) Batch 0.448 (0.478) Remain 31:44:12 loss: 1.7458 Lr: 0.00025
[2025-04-08 14:01:15,067 INFO misc.py line 113 3298914] Train: [1/100][1249/2402] Data 0.003 (0.004) Batch 0.464 (0.478) Remain 31:44:09 loss: 1.7270 Lr: 0.00025
[2025-04-08 14:01:15,573 INFO misc.py line 113 3298914] Train: [1/100][1250/2402] Data 0.004 (0.004) Batch 0.506 (0.478) Remain 31:44:13 loss: 1.9006 Lr: 0.00025
[2025-04-08 14:01:16,079 INFO misc.py line 113 3298914] Train: [1/100][1251/2402] Data 0.003 (0.004) Batch 0.506 (0.478) Remain 31:44:18 loss: 1.3750 Lr: 0.00025
[2025-04-08 14:01:16,480 INFO misc.py line 113 3298914] Train: [1/100][1252/2402] Data 0.004 (0.004) Batch 0.402 (0.478) Remain 31:44:03 loss: 1.1701 Lr: 0.00025
[2025-04-08 14:01:17,015 INFO misc.py line 113 3298914] Train: [1/100][1253/2402] Data 0.004 (0.004) Batch 0.535 (0.478) Remain 31:44:14 loss: 1.6399 Lr: 0.00025
[2025-04-08 14:01:17,438 INFO misc.py line 113 3298914] Train: [1/100][1254/2402] Data 0.003 (0.004) Batch 0.422 (0.478) Remain 31:44:02 loss: 1.2209 Lr: 0.00025
[2025-04-08 14:01:17,838 INFO misc.py line 113 3298914] Train: [1/100][1255/2402] Data 0.004 (0.004) Batch 0.400 (0.478) Remain 31:43:47 loss: 1.8046 Lr: 0.00025
[2025-04-08 14:01:18,325 INFO misc.py line 113 3298914] Train: [1/100][1256/2402] Data 0.004 (0.004) Batch 0.487 (0.478) Remain 31:43:48 loss: 1.7106 Lr: 0.00025
[2025-04-08 14:01:18,648 INFO misc.py line 113 3298914] Train: [1/100][1257/2402] Data 0.003 (0.004) Batch 0.323 (0.478) Remain 31:43:18 loss: 1.7168 Lr: 0.00025
[2025-04-08 14:01:19,123 INFO misc.py line 113 3298914] Train: [1/100][1258/2402] Data 0.004 (0.004) Batch 0.475 (0.478) Remain 31:43:17 loss: 1.5819 Lr: 0.00025
[2025-04-08 14:01:19,653 INFO misc.py line 113 3298914] Train: [1/100][1259/2402] Data 0.003 (0.004) Batch 0.531 (0.478) Remain 31:43:27 loss: 1.3967 Lr: 0.00025
[2025-04-08 14:01:20,075 INFO misc.py line 113 3298914] Train: [1/100][1260/2402] Data 0.003 (0.004) Batch 0.422 (0.478) Remain 31:43:16 loss: 1.5952 Lr: 0.00025
[2025-04-08 14:01:20,651 INFO misc.py line 113 3298914] Train: [1/100][1261/2402] Data 0.004 (0.004) Batch 0.576 (0.478) Remain 31:43:34 loss: 1.9908 Lr: 0.00025
[2025-04-08 14:01:21,035 INFO misc.py line 113 3298914] Train: [1/100][1262/2402] Data 0.003 (0.004) Batch 0.383 (0.478) Remain 31:43:15 loss: 1.3505 Lr: 0.00025
[2025-04-08 14:01:21,480 INFO misc.py line 113 3298914] Train: [1/100][1263/2402] Data 0.004 (0.004) Batch 0.446 (0.478) Remain 31:43:09 loss: 1.7483 Lr: 0.00025
[2025-04-08 14:01:21,919 INFO misc.py line 113 3298914] Train: [1/100][1264/2402] Data 0.004 (0.004) Batch 0.439 (0.478) Remain 31:43:01 loss: 1.6218 Lr: 0.00025
[2025-04-08 14:01:22,305 INFO misc.py line 113 3298914] Train: [1/100][1265/2402] Data 0.003 (0.004) Batch 0.385 (0.478) Remain 31:42:43 loss: 1.6812 Lr: 0.00025
[2025-04-08 14:01:22,980 INFO misc.py line 113 3298914] Train: [1/100][1266/2402] Data 0.004 (0.004) Batch 0.676 (0.478) Remain 31:43:20 loss: 1.4913 Lr: 0.00025
[2025-04-08 14:01:23,549 INFO misc.py line 113 3298914] Train: [1/100][1267/2402] Data 0.004 (0.004) Batch 0.569 (0.478) Remain 31:43:36 loss: 1.3432 Lr: 0.00025
[2025-04-08 14:01:24,057 INFO misc.py line 113 3298914] Train: [1/100][1268/2402] Data 0.004 (0.004) Batch 0.508 (0.478) Remain 31:43:42 loss: 1.7812 Lr: 0.00025
[2025-04-08 14:01:24,570 INFO misc.py line 113 3298914] Train: [1/100][1269/2402] Data 0.004 (0.004) Batch 0.512 (0.478) Remain 31:43:48 loss: 1.6072 Lr: 0.00025
[2025-04-08 14:01:25,069 INFO misc.py line 113 3298914] Train: [1/100][1270/2402] Data 0.004 (0.004) Batch 0.500 (0.478) Remain 31:43:51 loss: 1.8952 Lr: 0.00025
[2025-04-08 14:01:25,519 INFO misc.py line 113 3298914] Train: [1/100][1271/2402] Data 0.004 (0.004) Batch 0.451 (0.478) Remain 31:43:46 loss: 1.5048 Lr: 0.00025
[2025-04-08 14:01:26,044 INFO misc.py line 113 3298914] Train: [1/100][1272/2402] Data 0.003 (0.004) Batch 0.525 (0.478) Remain 31:43:54 loss: 1.8651 Lr: 0.00025
[2025-04-08 14:01:26,343 INFO misc.py line 113 3298914] Train: [1/100][1273/2402] Data 0.003 (0.004) Batch 0.298 (0.478) Remain 31:43:20 loss: 1.6391 Lr: 0.00025
[2025-04-08 14:01:26,824 INFO misc.py line 113 3298914] Train: [1/100][1274/2402] Data 0.003 (0.004) Batch 0.481 (0.478) Remain 31:43:20 loss: 1.5184 Lr: 0.00025
[2025-04-08 14:01:27,305 INFO misc.py line 113 3298914] Train: [1/100][1275/2402] Data 0.004 (0.004) Batch 0.481 (0.478) Remain 31:43:20 loss: 1.6616 Lr: 0.00025
[2025-04-08 14:01:27,842 INFO misc.py line 113 3298914] Train: [1/100][1276/2402] Data 0.003 (0.004) Batch 0.537 (0.478) Remain 31:43:30 loss: 1.9741 Lr: 0.00025
[2025-04-08 14:01:28,368 INFO misc.py line 113 3298914] Train: [1/100][1277/2402] Data 0.004 (0.004) Batch 0.526 (0.478) Remain 31:43:39 loss: 2.0313 Lr: 0.00025
[2025-04-08 14:01:28,834 INFO misc.py line 113 3298914] Train: [1/100][1278/2402] Data 0.003 (0.004) Batch 0.466 (0.478) Remain 31:43:36 loss: 1.9919 Lr: 0.00025
[2025-04-08 14:01:29,516 INFO misc.py line 113 3298914] Train: [1/100][1279/2402] Data 0.003 (0.004) Batch 0.683 (0.478) Remain 31:44:14 loss: 1.7408 Lr: 0.00025
[2025-04-08 14:01:30,060 INFO misc.py line 113 3298914] Train: [1/100][1280/2402] Data 0.003 (0.004) Batch 0.543 (0.478) Remain 31:44:26 loss: 1.7457 Lr: 0.00025
[2025-04-08 14:01:30,529 INFO misc.py line 113 3298914] Train: [1/100][1281/2402] Data 0.004 (0.004) Batch 0.469 (0.478) Remain 31:44:23 loss: 1.3440 Lr: 0.00025
[2025-04-08 14:01:31,056 INFO misc.py line 113 3298914] Train: [1/100][1282/2402] Data 0.004 (0.004) Batch 0.528 (0.478) Remain 31:44:32 loss: 1.5726 Lr: 0.00025
[2025-04-08 14:01:31,610 INFO misc.py line 113 3298914] Train: [1/100][1283/2402] Data 0.003 (0.004) Batch 0.554 (0.478) Remain 31:44:46 loss: 1.7621 Lr: 0.00025
[2025-04-08 14:01:32,176 INFO misc.py line 113 3298914] Train: [1/100][1284/2402] Data 0.004 (0.004) Batch 0.566 (0.478) Remain 31:45:02 loss: 1.9095 Lr: 0.00025
[2025-04-08 14:01:32,710 INFO misc.py line 113 3298914] Train: [1/100][1285/2402] Data 0.003 (0.004) Batch 0.534 (0.478) Remain 31:45:12 loss: 1.8699 Lr: 0.00025
[2025-04-08 14:01:33,278 INFO misc.py line 113 3298914] Train: [1/100][1286/2402] Data 0.004 (0.004) Batch 0.568 (0.479) Remain 31:45:28 loss: 1.9130 Lr: 0.00025
[2025-04-08 14:01:33,801 INFO misc.py line 113 3298914] Train: [1/100][1287/2402] Data 0.003 (0.004) Batch 0.523 (0.479) Remain 31:45:36 loss: 1.0684 Lr: 0.00025
[2025-04-08 14:01:34,399 INFO misc.py line 113 3298914] Train: [1/100][1288/2402] Data 0.004 (0.004) Batch 0.597 (0.479) Remain 31:45:57 loss: 1.1446 Lr: 0.00025
[2025-04-08 14:01:34,817 INFO misc.py line 113 3298914] Train: [1/100][1289/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:45:46 loss: 1.6426 Lr: 0.00025
[2025-04-08 14:01:35,294 INFO misc.py line 113 3298914] Train: [1/100][1290/2402] Data 0.004 (0.004) Batch 0.476 (0.479) Remain 31:45:45 loss: 1.9117 Lr: 0.00025
[2025-04-08 14:01:35,713 INFO misc.py line 113 3298914] Train: [1/100][1291/2402] Data 0.003 (0.004) Batch 0.420 (0.479) Remain 31:45:33 loss: 1.8644 Lr: 0.00025
[2025-04-08 14:01:36,183 INFO misc.py line 113 3298914] Train: [1/100][1292/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:45:31 loss: 1.4154 Lr: 0.00025
[2025-04-08 14:01:36,583 INFO misc.py line 113 3298914] Train: [1/100][1293/2402] Data 0.003 (0.004) Batch 0.400 (0.478) Remain 31:45:16 loss: 1.3402 Lr: 0.00025
[2025-04-08 14:01:37,062 INFO misc.py line 113 3298914] Train: [1/100][1294/2402] Data 0.004 (0.004) Batch 0.479 (0.478) Remain 31:45:16 loss: 1.8197 Lr: 0.00025
[2025-04-08 14:01:37,529 INFO misc.py line 113 3298914] Train: [1/100][1295/2402] Data 0.004 (0.004) Batch 0.467 (0.478) Remain 31:45:13 loss: 1.8711 Lr: 0.00025
[2025-04-08 14:01:38,004 INFO misc.py line 113 3298914] Train: [1/100][1296/2402] Data 0.003 (0.004) Batch 0.474 (0.478) Remain 31:45:12 loss: 1.6445 Lr: 0.00025
[2025-04-08 14:01:38,432 INFO misc.py line 113 3298914] Train: [1/100][1297/2402] Data 0.004 (0.004) Batch 0.428 (0.478) Remain 31:45:02 loss: 1.5150 Lr: 0.00025
[2025-04-08 14:01:38,995 INFO misc.py line 113 3298914] Train: [1/100][1298/2402] Data 0.004 (0.004) Batch 0.563 (0.479) Remain 31:45:17 loss: 2.0174 Lr: 0.00025
[2025-04-08 14:01:39,485 INFO misc.py line 113 3298914] Train: [1/100][1299/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:45:19 loss: 1.8526 Lr: 0.00025
[2025-04-08 14:01:40,063 INFO misc.py line 113 3298914] Train: [1/100][1300/2402] Data 0.004 (0.004) Batch 0.579 (0.479) Remain 31:45:37 loss: 1.7962 Lr: 0.00025
[2025-04-08 14:01:40,529 INFO misc.py line 113 3298914] Train: [1/100][1301/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:45:34 loss: 1.8027 Lr: 0.00025
[2025-04-08 14:01:41,000 INFO misc.py line 113 3298914] Train: [1/100][1302/2402] Data 0.003 (0.004) Batch 0.471 (0.479) Remain 31:45:32 loss: 1.3373 Lr: 0.00025
[2025-04-08 14:01:41,459 INFO misc.py line 113 3298914] Train: [1/100][1303/2402] Data 0.004 (0.004) Batch 0.458 (0.479) Remain 31:45:28 loss: 1.4641 Lr: 0.00025
[2025-04-08 14:01:41,905 INFO misc.py line 113 3298914] Train: [1/100][1304/2402] Data 0.003 (0.004) Batch 0.446 (0.479) Remain 31:45:22 loss: 1.8527 Lr: 0.00025
[2025-04-08 14:01:42,435 INFO misc.py line 113 3298914] Train: [1/100][1305/2402] Data 0.003 (0.004) Batch 0.530 (0.479) Remain 31:45:31 loss: 1.6497 Lr: 0.00025
[2025-04-08 14:01:43,045 INFO misc.py line 113 3298914] Train: [1/100][1306/2402] Data 0.004 (0.004) Batch 0.610 (0.479) Remain 31:45:54 loss: 1.5159 Lr: 0.00025
[2025-04-08 14:01:43,467 INFO misc.py line 113 3298914] Train: [1/100][1307/2402] Data 0.003 (0.004) Batch 0.422 (0.479) Remain 31:45:43 loss: 1.8193 Lr: 0.00025
[2025-04-08 14:01:43,942 INFO misc.py line 113 3298914] Train: [1/100][1308/2402] Data 0.004 (0.004) Batch 0.475 (0.479) Remain 31:45:42 loss: 1.5700 Lr: 0.00025
[2025-04-08 14:01:44,367 INFO misc.py line 113 3298914] Train: [1/100][1309/2402] Data 0.004 (0.004) Batch 0.425 (0.479) Remain 31:45:32 loss: 1.3164 Lr: 0.00025
[2025-04-08 14:01:44,860 INFO misc.py line 113 3298914] Train: [1/100][1310/2402] Data 0.003 (0.004) Batch 0.494 (0.479) Remain 31:45:34 loss: 1.7963 Lr: 0.00025
[2025-04-08 14:01:45,324 INFO misc.py line 113 3298914] Train: [1/100][1311/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:45:31 loss: 1.9033 Lr: 0.00025
[2025-04-08 14:01:45,765 INFO misc.py line 113 3298914] Train: [1/100][1312/2402] Data 0.003 (0.004) Batch 0.441 (0.479) Remain 31:45:24 loss: 1.3162 Lr: 0.00025
[2025-04-08 14:01:46,239 INFO misc.py line 113 3298914] Train: [1/100][1313/2402] Data 0.004 (0.004) Batch 0.473 (0.479) Remain 31:45:22 loss: 1.6177 Lr: 0.00025
[2025-04-08 14:01:46,741 INFO misc.py line 113 3298914] Train: [1/100][1314/2402] Data 0.003 (0.004) Batch 0.503 (0.479) Remain 31:45:26 loss: 1.8723 Lr: 0.00025
[2025-04-08 14:01:47,206 INFO misc.py line 113 3298914] Train: [1/100][1315/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:45:23 loss: 1.4303 Lr: 0.00025
[2025-04-08 14:01:47,679 INFO misc.py line 113 3298914] Train: [1/100][1316/2402] Data 0.004 (0.004) Batch 0.474 (0.479) Remain 31:45:22 loss: 1.7314 Lr: 0.00025
[2025-04-08 14:01:48,032 INFO misc.py line 113 3298914] Train: [1/100][1317/2402] Data 0.003 (0.004) Batch 0.352 (0.478) Remain 31:44:58 loss: 1.4858 Lr: 0.00025
[2025-04-08 14:01:48,472 INFO misc.py line 113 3298914] Train: [1/100][1318/2402] Data 0.003 (0.004) Batch 0.440 (0.478) Remain 31:44:51 loss: 1.3774 Lr: 0.00025
[2025-04-08 14:01:48,887 INFO misc.py line 113 3298914] Train: [1/100][1319/2402] Data 0.003 (0.004) Batch 0.415 (0.478) Remain 31:44:39 loss: 1.1722 Lr: 0.00025
[2025-04-08 14:01:49,369 INFO misc.py line 113 3298914] Train: [1/100][1320/2402] Data 0.003 (0.004) Batch 0.482 (0.478) Remain 31:44:39 loss: 1.2942 Lr: 0.00025
[2025-04-08 14:01:49,954 INFO misc.py line 113 3298914] Train: [1/100][1321/2402] Data 0.004 (0.004) Batch 0.584 (0.478) Remain 31:44:58 loss: 1.9535 Lr: 0.00025
[2025-04-08 14:01:50,412 INFO misc.py line 113 3298914] Train: [1/100][1322/2402] Data 0.003 (0.004) Batch 0.459 (0.478) Remain 31:44:54 loss: 1.6585 Lr: 0.00025
[2025-04-08 14:01:50,917 INFO misc.py line 113 3298914] Train: [1/100][1323/2402] Data 0.003 (0.004) Batch 0.505 (0.478) Remain 31:44:58 loss: 1.3447 Lr: 0.00025
[2025-04-08 14:01:51,354 INFO misc.py line 113 3298914] Train: [1/100][1324/2402] Data 0.004 (0.004) Batch 0.437 (0.478) Remain 31:44:50 loss: 1.7624 Lr: 0.00025
[2025-04-08 14:01:51,776 INFO misc.py line 113 3298914] Train: [1/100][1325/2402] Data 0.004 (0.004) Batch 0.422 (0.478) Remain 31:44:39 loss: 1.5501 Lr: 0.00025
[2025-04-08 14:01:52,208 INFO misc.py line 113 3298914] Train: [1/100][1326/2402] Data 0.003 (0.004) Batch 0.432 (0.478) Remain 31:44:30 loss: 1.5544 Lr: 0.00025
[2025-04-08 14:01:52,634 INFO misc.py line 113 3298914] Train: [1/100][1327/2402] Data 0.004 (0.004) Batch 0.426 (0.478) Remain 31:44:21 loss: 1.7334 Lr: 0.00025
[2025-04-08 14:01:53,356 INFO misc.py line 113 3298914] Train: [1/100][1328/2402] Data 0.004 (0.004) Batch 0.721 (0.479) Remain 31:45:04 loss: 1.5479 Lr: 0.00025
[2025-04-08 14:01:53,901 INFO misc.py line 113 3298914] Train: [1/100][1329/2402] Data 0.004 (0.004) Batch 0.545 (0.479) Remain 31:45:15 loss: 2.0857 Lr: 0.00025
[2025-04-08 14:01:54,350 INFO misc.py line 113 3298914] Train: [1/100][1330/2402] Data 0.003 (0.004) Batch 0.449 (0.479) Remain 31:45:10 loss: 1.8267 Lr: 0.00025
[2025-04-08 14:01:54,840 INFO misc.py line 113 3298914] Train: [1/100][1331/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:45:11 loss: 2.1389 Lr: 0.00025
[2025-04-08 14:01:55,260 INFO misc.py line 113 3298914] Train: [1/100][1332/2402] Data 0.004 (0.004) Batch 0.421 (0.479) Remain 31:45:00 loss: 1.5101 Lr: 0.00025
[2025-04-08 14:01:55,857 INFO misc.py line 113 3298914] Train: [1/100][1333/2402] Data 0.003 (0.004) Batch 0.597 (0.479) Remain 31:45:21 loss: 1.5425 Lr: 0.00025
[2025-04-08 14:01:56,353 INFO misc.py line 113 3298914] Train: [1/100][1334/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:45:24 loss: 1.6763 Lr: 0.00025
[2025-04-08 14:01:56,805 INFO misc.py line 113 3298914] Train: [1/100][1335/2402] Data 0.004 (0.004) Batch 0.452 (0.479) Remain 31:45:18 loss: 1.6893 Lr: 0.00025
[2025-04-08 14:01:57,260 INFO misc.py line 113 3298914] Train: [1/100][1336/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:45:14 loss: 1.9999 Lr: 0.00025
[2025-04-08 14:01:57,798 INFO misc.py line 113 3298914] Train: [1/100][1337/2402] Data 0.003 (0.004) Batch 0.538 (0.479) Remain 31:45:24 loss: 1.3799 Lr: 0.00025
[2025-04-08 14:01:58,365 INFO misc.py line 113 3298914] Train: [1/100][1338/2402] Data 0.004 (0.004) Batch 0.567 (0.479) Remain 31:45:39 loss: 1.7209 Lr: 0.00025
[2025-04-08 14:01:58,772 INFO misc.py line 113 3298914] Train: [1/100][1339/2402] Data 0.003 (0.004) Batch 0.407 (0.479) Remain 31:45:26 loss: 1.8392 Lr: 0.00025
[2025-04-08 14:01:59,244 INFO misc.py line 113 3298914] Train: [1/100][1340/2402] Data 0.003 (0.004) Batch 0.472 (0.479) Remain 31:45:24 loss: 1.5532 Lr: 0.00025
[2025-04-08 14:01:59,800 INFO misc.py line 113 3298914] Train: [1/100][1341/2402] Data 0.004 (0.004) Batch 0.556 (0.479) Remain 31:45:38 loss: 1.1367 Lr: 0.00025
[2025-04-08 14:02:00,325 INFO misc.py line 113 3298914] Train: [1/100][1342/2402] Data 0.003 (0.004) Batch 0.525 (0.479) Remain 31:45:45 loss: 1.5328 Lr: 0.00025
[2025-04-08 14:02:00,863 INFO misc.py line 113 3298914] Train: [1/100][1343/2402] Data 0.004 (0.004) Batch 0.538 (0.479) Remain 31:45:55 loss: 1.2519 Lr: 0.00025
[2025-04-08 14:02:01,352 INFO misc.py line 113 3298914] Train: [1/100][1344/2402] Data 0.003 (0.004) Batch 0.489 (0.479) Remain 31:45:57 loss: 1.5480 Lr: 0.00025
[2025-04-08 14:02:01,942 INFO misc.py line 113 3298914] Train: [1/100][1345/2402] Data 0.004 (0.004) Batch 0.591 (0.479) Remain 31:46:16 loss: 2.0932 Lr: 0.00025
[2025-04-08 14:02:02,426 INFO misc.py line 113 3298914] Train: [1/100][1346/2402] Data 0.003 (0.004) Batch 0.484 (0.479) Remain 31:46:17 loss: 1.7710 Lr: 0.00025
[2025-04-08 14:02:02,823 INFO misc.py line 113 3298914] Train: [1/100][1347/2402] Data 0.004 (0.004) Batch 0.397 (0.479) Remain 31:46:02 loss: 1.8885 Lr: 0.00026
[2025-04-08 14:02:03,273 INFO misc.py line 113 3298914] Train: [1/100][1348/2402] Data 0.004 (0.004) Batch 0.450 (0.479) Remain 31:45:56 loss: 1.4337 Lr: 0.00026
[2025-04-08 14:02:03,672 INFO misc.py line 113 3298914] Train: [1/100][1349/2402] Data 0.003 (0.004) Batch 0.399 (0.479) Remain 31:45:41 loss: 1.2634 Lr: 0.00026
[2025-04-08 14:02:04,115 INFO misc.py line 113 3298914] Train: [1/100][1350/2402] Data 0.004 (0.004) Batch 0.443 (0.479) Remain 31:45:34 loss: 1.8448 Lr: 0.00026
[2025-04-08 14:02:04,657 INFO misc.py line 113 3298914] Train: [1/100][1351/2402] Data 0.003 (0.004) Batch 0.542 (0.479) Remain 31:45:45 loss: 2.3751 Lr: 0.00026
[2025-04-08 14:02:05,006 INFO misc.py line 113 3298914] Train: [1/100][1352/2402] Data 0.003 (0.004) Batch 0.349 (0.479) Remain 31:45:22 loss: 1.7079 Lr: 0.00026
[2025-04-08 14:02:05,495 INFO misc.py line 113 3298914] Train: [1/100][1353/2402] Data 0.004 (0.004) Batch 0.489 (0.479) Remain 31:45:23 loss: 1.8442 Lr: 0.00026
[2025-04-08 14:02:05,941 INFO misc.py line 113 3298914] Train: [1/100][1354/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:45:17 loss: 1.5764 Lr: 0.00026
[2025-04-08 14:02:06,388 INFO misc.py line 113 3298914] Train: [1/100][1355/2402] Data 0.003 (0.004) Batch 0.448 (0.479) Remain 31:45:11 loss: 1.8618 Lr: 0.00026
[2025-04-08 14:02:06,932 INFO misc.py line 113 3298914] Train: [1/100][1356/2402] Data 0.004 (0.004) Batch 0.544 (0.479) Remain 31:45:22 loss: 2.0061 Lr: 0.00026
[2025-04-08 14:02:07,367 INFO misc.py line 113 3298914] Train: [1/100][1357/2402] Data 0.003 (0.004) Batch 0.435 (0.479) Remain 31:45:14 loss: 2.0268 Lr: 0.00026
[2025-04-08 14:02:07,909 INFO misc.py line 113 3298914] Train: [1/100][1358/2402] Data 0.003 (0.004) Batch 0.542 (0.479) Remain 31:45:24 loss: 1.7113 Lr: 0.00026
[2025-04-08 14:02:08,419 INFO misc.py line 113 3298914] Train: [1/100][1359/2402] Data 0.004 (0.004) Batch 0.510 (0.479) Remain 31:45:29 loss: 1.6714 Lr: 0.00026
[2025-04-08 14:02:08,927 INFO misc.py line 113 3298914] Train: [1/100][1360/2402] Data 0.003 (0.004) Batch 0.508 (0.479) Remain 31:45:34 loss: 1.3728 Lr: 0.00026
[2025-04-08 14:02:09,423 INFO misc.py line 113 3298914] Train: [1/100][1361/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:45:37 loss: 1.7823 Lr: 0.00026
[2025-04-08 14:02:09,856 INFO misc.py line 113 3298914] Train: [1/100][1362/2402] Data 0.003 (0.004) Batch 0.433 (0.479) Remain 31:45:28 loss: 1.9383 Lr: 0.00026
[2025-04-08 14:02:10,406 INFO misc.py line 113 3298914] Train: [1/100][1363/2402] Data 0.003 (0.004) Batch 0.550 (0.479) Remain 31:45:40 loss: 1.5953 Lr: 0.00026
[2025-04-08 14:02:10,796 INFO misc.py line 113 3298914] Train: [1/100][1364/2402] Data 0.003 (0.004) Batch 0.389 (0.479) Remain 31:45:24 loss: 1.7833 Lr: 0.00026
[2025-04-08 14:02:11,275 INFO misc.py line 113 3298914] Train: [1/100][1365/2402] Data 0.003 (0.004) Batch 0.479 (0.479) Remain 31:45:24 loss: 1.8492 Lr: 0.00026
[2025-04-08 14:02:11,697 INFO misc.py line 113 3298914] Train: [1/100][1366/2402] Data 0.004 (0.004) Batch 0.422 (0.479) Remain 31:45:13 loss: 1.4330 Lr: 0.00026
[2025-04-08 14:02:12,218 INFO misc.py line 113 3298914] Train: [1/100][1367/2402] Data 0.003 (0.004) Batch 0.521 (0.479) Remain 31:45:20 loss: 1.7236 Lr: 0.00026
[2025-04-08 14:02:12,683 INFO misc.py line 113 3298914] Train: [1/100][1368/2402] Data 0.003 (0.004) Batch 0.465 (0.479) Remain 31:45:17 loss: 2.2672 Lr: 0.00026
[2025-04-08 14:02:13,253 INFO misc.py line 113 3298914] Train: [1/100][1369/2402] Data 0.003 (0.004) Batch 0.570 (0.479) Remain 31:45:33 loss: 1.8026 Lr: 0.00026
[2025-04-08 14:02:13,743 INFO misc.py line 113 3298914] Train: [1/100][1370/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:45:34 loss: 1.6608 Lr: 0.00026
[2025-04-08 14:02:14,248 INFO misc.py line 113 3298914] Train: [1/100][1371/2402] Data 0.004 (0.004) Batch 0.505 (0.479) Remain 31:45:38 loss: 1.4890 Lr: 0.00026
[2025-04-08 14:02:14,765 INFO misc.py line 113 3298914] Train: [1/100][1372/2402] Data 0.003 (0.004) Batch 0.517 (0.479) Remain 31:45:45 loss: 1.3258 Lr: 0.00026
[2025-04-08 14:02:15,330 INFO misc.py line 113 3298914] Train: [1/100][1373/2402] Data 0.004 (0.004) Batch 0.565 (0.479) Remain 31:45:59 loss: 1.9351 Lr: 0.00026
[2025-04-08 14:02:15,873 INFO misc.py line 113 3298914] Train: [1/100][1374/2402] Data 0.003 (0.004) Batch 0.543 (0.479) Remain 31:46:10 loss: 1.7382 Lr: 0.00026
[2025-04-08 14:02:16,325 INFO misc.py line 113 3298914] Train: [1/100][1375/2402] Data 0.003 (0.004) Batch 0.452 (0.479) Remain 31:46:05 loss: 1.7792 Lr: 0.00026
[2025-04-08 14:02:16,778 INFO misc.py line 113 3298914] Train: [1/100][1376/2402] Data 0.003 (0.004) Batch 0.454 (0.479) Remain 31:46:00 loss: 1.7183 Lr: 0.00026
[2025-04-08 14:02:17,314 INFO misc.py line 113 3298914] Train: [1/100][1377/2402] Data 0.004 (0.004) Batch 0.536 (0.479) Remain 31:46:09 loss: 1.7184 Lr: 0.00026
[2025-04-08 14:02:17,688 INFO misc.py line 113 3298914] Train: [1/100][1378/2402] Data 0.003 (0.004) Batch 0.374 (0.479) Remain 31:45:51 loss: 1.7168 Lr: 0.00026
[2025-04-08 14:02:18,129 INFO misc.py line 113 3298914] Train: [1/100][1379/2402] Data 0.003 (0.004) Batch 0.441 (0.479) Remain 31:45:44 loss: 1.7627 Lr: 0.00026
[2025-04-08 14:02:18,615 INFO misc.py line 113 3298914] Train: [1/100][1380/2402] Data 0.004 (0.004) Batch 0.486 (0.479) Remain 31:45:44 loss: 1.7468 Lr: 0.00026
[2025-04-08 14:02:19,086 INFO misc.py line 113 3298914] Train: [1/100][1381/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:45:42 loss: 1.7002 Lr: 0.00026
[2025-04-08 14:02:19,623 INFO misc.py line 113 3298914] Train: [1/100][1382/2402] Data 0.004 (0.004) Batch 0.537 (0.479) Remain 31:45:52 loss: 1.7295 Lr: 0.00026
[2025-04-08 14:02:20,187 INFO misc.py line 113 3298914] Train: [1/100][1383/2402] Data 0.004 (0.004) Batch 0.564 (0.479) Remain 31:46:06 loss: 1.8325 Lr: 0.00026
[2025-04-08 14:02:20,728 INFO misc.py line 113 3298914] Train: [1/100][1384/2402] Data 0.004 (0.004) Batch 0.541 (0.479) Remain 31:46:17 loss: 1.8923 Lr: 0.00026
[2025-04-08 14:02:21,278 INFO misc.py line 113 3298914] Train: [1/100][1385/2402] Data 0.003 (0.004) Batch 0.550 (0.479) Remain 31:46:28 loss: 1.7006 Lr: 0.00026
[2025-04-08 14:02:21,638 INFO misc.py line 113 3298914] Train: [1/100][1386/2402] Data 0.004 (0.004) Batch 0.360 (0.479) Remain 31:46:07 loss: 1.7129 Lr: 0.00026
[2025-04-08 14:02:22,056 INFO misc.py line 113 3298914] Train: [1/100][1387/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:45:56 loss: 1.5803 Lr: 0.00026
[2025-04-08 14:02:22,452 INFO misc.py line 113 3298914] Train: [1/100][1388/2402] Data 0.004 (0.004) Batch 0.396 (0.479) Remain 31:45:42 loss: 1.6408 Lr: 0.00026
[2025-04-08 14:02:22,934 INFO misc.py line 113 3298914] Train: [1/100][1389/2402] Data 0.003 (0.004) Batch 0.482 (0.479) Remain 31:45:42 loss: 1.1867 Lr: 0.00026
[2025-04-08 14:02:23,390 INFO misc.py line 113 3298914] Train: [1/100][1390/2402] Data 0.004 (0.004) Batch 0.455 (0.479) Remain 31:45:37 loss: 1.1647 Lr: 0.00026
[2025-04-08 14:02:23,874 INFO misc.py line 113 3298914] Train: [1/100][1391/2402] Data 0.004 (0.004) Batch 0.484 (0.479) Remain 31:45:38 loss: 1.7085 Lr: 0.00026
[2025-04-08 14:02:24,331 INFO misc.py line 113 3298914] Train: [1/100][1392/2402] Data 0.003 (0.004) Batch 0.456 (0.479) Remain 31:45:33 loss: 1.7771 Lr: 0.00026
[2025-04-08 14:02:24,864 INFO misc.py line 113 3298914] Train: [1/100][1393/2402] Data 0.004 (0.004) Batch 0.534 (0.479) Remain 31:45:42 loss: 1.8288 Lr: 0.00026
[2025-04-08 14:02:25,215 INFO misc.py line 113 3298914] Train: [1/100][1394/2402] Data 0.004 (0.004) Batch 0.351 (0.479) Remain 31:45:20 loss: 2.1884 Lr: 0.00026
[2025-04-08 14:02:25,723 INFO misc.py line 113 3298914] Train: [1/100][1395/2402] Data 0.003 (0.004) Batch 0.508 (0.479) Remain 31:45:24 loss: 1.4891 Lr: 0.00026
[2025-04-08 14:02:26,162 INFO misc.py line 113 3298914] Train: [1/100][1396/2402] Data 0.003 (0.004) Batch 0.439 (0.479) Remain 31:45:17 loss: 1.7333 Lr: 0.00026
[2025-04-08 14:02:26,521 INFO misc.py line 113 3298914] Train: [1/100][1397/2402] Data 0.003 (0.004) Batch 0.359 (0.479) Remain 31:44:56 loss: 1.3531 Lr: 0.00026
[2025-04-08 14:02:27,050 INFO misc.py line 113 3298914] Train: [1/100][1398/2402] Data 0.003 (0.004) Batch 0.528 (0.479) Remain 31:45:04 loss: 1.3886 Lr: 0.00026
[2025-04-08 14:02:27,501 INFO misc.py line 113 3298914] Train: [1/100][1399/2402] Data 0.004 (0.004) Batch 0.452 (0.479) Remain 31:44:59 loss: 1.8045 Lr: 0.00026
[2025-04-08 14:02:27,916 INFO misc.py line 113 3298914] Train: [1/100][1400/2402] Data 0.004 (0.004) Batch 0.415 (0.479) Remain 31:44:48 loss: 1.7693 Lr: 0.00026
[2025-04-08 14:02:28,450 INFO misc.py line 113 3298914] Train: [1/100][1401/2402] Data 0.004 (0.004) Batch 0.534 (0.479) Remain 31:44:57 loss: 1.7393 Lr: 0.00026
[2025-04-08 14:02:28,854 INFO misc.py line 113 3298914] Train: [1/100][1402/2402] Data 0.003 (0.004) Batch 0.404 (0.479) Remain 31:44:43 loss: 2.1908 Lr: 0.00026
[2025-04-08 14:02:29,269 INFO misc.py line 113 3298914] Train: [1/100][1403/2402] Data 0.003 (0.004) Batch 0.415 (0.479) Remain 31:44:32 loss: 1.6498 Lr: 0.00026
[2025-04-08 14:02:29,744 INFO misc.py line 113 3298914] Train: [1/100][1404/2402] Data 0.004 (0.004) Batch 0.475 (0.479) Remain 31:44:31 loss: 1.7051 Lr: 0.00026
[2025-04-08 14:02:30,280 INFO misc.py line 113 3298914] Train: [1/100][1405/2402] Data 0.004 (0.004) Batch 0.536 (0.479) Remain 31:44:40 loss: 1.3140 Lr: 0.00026
[2025-04-08 14:02:30,860 INFO misc.py line 113 3298914] Train: [1/100][1406/2402] Data 0.003 (0.004) Batch 0.579 (0.479) Remain 31:44:57 loss: 1.8225 Lr: 0.00026
[2025-04-08 14:02:31,312 INFO misc.py line 113 3298914] Train: [1/100][1407/2402] Data 0.004 (0.004) Batch 0.453 (0.479) Remain 31:44:52 loss: 1.7848 Lr: 0.00026
[2025-04-08 14:02:31,804 INFO misc.py line 113 3298914] Train: [1/100][1408/2402] Data 0.003 (0.004) Batch 0.492 (0.479) Remain 31:44:54 loss: 1.5412 Lr: 0.00026
[2025-04-08 14:02:32,217 INFO misc.py line 113 3298914] Train: [1/100][1409/2402] Data 0.004 (0.004) Batch 0.412 (0.479) Remain 31:44:42 loss: 2.0835 Lr: 0.00026
[2025-04-08 14:02:32,661 INFO misc.py line 113 3298914] Train: [1/100][1410/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:44:36 loss: 1.4307 Lr: 0.00026
[2025-04-08 14:02:33,100 INFO misc.py line 113 3298914] Train: [1/100][1411/2402] Data 0.003 (0.004) Batch 0.439 (0.479) Remain 31:44:29 loss: 1.3217 Lr: 0.00026
[2025-04-08 14:02:33,573 INFO misc.py line 113 3298914] Train: [1/100][1412/2402] Data 0.004 (0.004) Batch 0.473 (0.479) Remain 31:44:27 loss: 1.7358 Lr: 0.00026
[2025-04-08 14:02:33,964 INFO misc.py line 113 3298914] Train: [1/100][1413/2402] Data 0.003 (0.004) Batch 0.391 (0.478) Remain 31:44:12 loss: 1.4168 Lr: 0.00026
[2025-04-08 14:02:34,492 INFO misc.py line 113 3298914] Train: [1/100][1414/2402] Data 0.004 (0.004) Batch 0.528 (0.479) Remain 31:44:20 loss: 1.7272 Lr: 0.00026
[2025-04-08 14:02:35,036 INFO misc.py line 113 3298914] Train: [1/100][1415/2402] Data 0.003 (0.004) Batch 0.544 (0.479) Remain 31:44:31 loss: 1.7007 Lr: 0.00026
[2025-04-08 14:02:35,465 INFO misc.py line 113 3298914] Train: [1/100][1416/2402] Data 0.004 (0.004) Batch 0.428 (0.479) Remain 31:44:22 loss: 1.8018 Lr: 0.00026
[2025-04-08 14:02:35,970 INFO misc.py line 113 3298914] Train: [1/100][1417/2402] Data 0.004 (0.004) Batch 0.506 (0.479) Remain 31:44:26 loss: 1.2131 Lr: 0.00026
[2025-04-08 14:02:36,449 INFO misc.py line 113 3298914] Train: [1/100][1418/2402] Data 0.004 (0.004) Batch 0.479 (0.479) Remain 31:44:25 loss: 1.9876 Lr: 0.00026
[2025-04-08 14:02:36,982 INFO misc.py line 113 3298914] Train: [1/100][1419/2402] Data 0.003 (0.004) Batch 0.532 (0.479) Remain 31:44:34 loss: 1.6580 Lr: 0.00026
[2025-04-08 14:02:37,341 INFO misc.py line 113 3298914] Train: [1/100][1420/2402] Data 0.003 (0.004) Batch 0.359 (0.478) Remain 31:44:13 loss: 1.6707 Lr: 0.00026
[2025-04-08 14:02:37,818 INFO misc.py line 113 3298914] Train: [1/100][1421/2402] Data 0.003 (0.004) Batch 0.477 (0.478) Remain 31:44:13 loss: 1.7913 Lr: 0.00026
[2025-04-08 14:02:38,207 INFO misc.py line 113 3298914] Train: [1/100][1422/2402] Data 0.003 (0.004) Batch 0.390 (0.478) Remain 31:43:57 loss: 1.7625 Lr: 0.00026
[2025-04-08 14:02:38,671 INFO misc.py line 113 3298914] Train: [1/100][1423/2402] Data 0.004 (0.004) Batch 0.464 (0.478) Remain 31:43:54 loss: 1.8372 Lr: 0.00026
[2025-04-08 14:02:38,989 INFO misc.py line 113 3298914] Train: [1/100][1424/2402] Data 0.003 (0.004) Batch 0.317 (0.478) Remain 31:43:27 loss: 1.5470 Lr: 0.00026
[2025-04-08 14:02:39,502 INFO misc.py line 113 3298914] Train: [1/100][1425/2402] Data 0.003 (0.004) Batch 0.514 (0.478) Remain 31:43:32 loss: 1.0880 Lr: 0.00026
[2025-04-08 14:02:40,087 INFO misc.py line 113 3298914] Train: [1/100][1426/2402] Data 0.004 (0.004) Batch 0.585 (0.478) Remain 31:43:50 loss: 1.6459 Lr: 0.00026
[2025-04-08 14:02:40,516 INFO misc.py line 113 3298914] Train: [1/100][1427/2402] Data 0.003 (0.004) Batch 0.429 (0.478) Remain 31:43:41 loss: 1.5811 Lr: 0.00026
[2025-04-08 14:02:41,012 INFO misc.py line 113 3298914] Train: [1/100][1428/2402] Data 0.003 (0.004) Batch 0.496 (0.478) Remain 31:43:43 loss: 1.9120 Lr: 0.00026
[2025-04-08 14:02:41,514 INFO misc.py line 113 3298914] Train: [1/100][1429/2402] Data 0.003 (0.004) Batch 0.502 (0.478) Remain 31:43:47 loss: 1.7770 Lr: 0.00026
[2025-04-08 14:02:41,975 INFO misc.py line 113 3298914] Train: [1/100][1430/2402] Data 0.003 (0.004) Batch 0.461 (0.478) Remain 31:43:43 loss: 1.9748 Lr: 0.00026
[2025-04-08 14:02:42,518 INFO misc.py line 113 3298914] Train: [1/100][1431/2402] Data 0.003 (0.004) Batch 0.543 (0.478) Remain 31:43:54 loss: 1.4103 Lr: 0.00026
[2025-04-08 14:02:42,992 INFO misc.py line 113 3298914] Train: [1/100][1432/2402] Data 0.004 (0.004) Batch 0.474 (0.478) Remain 31:43:52 loss: 1.8200 Lr: 0.00026
[2025-04-08 14:02:43,514 INFO misc.py line 113 3298914] Train: [1/100][1433/2402] Data 0.004 (0.004) Batch 0.523 (0.478) Remain 31:43:59 loss: 0.9858 Lr: 0.00026
[2025-04-08 14:02:43,997 INFO misc.py line 113 3298914] Train: [1/100][1434/2402] Data 0.003 (0.004) Batch 0.482 (0.478) Remain 31:43:59 loss: 1.7599 Lr: 0.00026
[2025-04-08 14:02:44,471 INFO misc.py line 113 3298914] Train: [1/100][1435/2402] Data 0.004 (0.004) Batch 0.474 (0.478) Remain 31:43:58 loss: 2.1611 Lr: 0.00026
[2025-04-08 14:02:44,954 INFO misc.py line 113 3298914] Train: [1/100][1436/2402] Data 0.004 (0.004) Batch 0.483 (0.478) Remain 31:43:59 loss: 1.2727 Lr: 0.00026
[2025-04-08 14:02:45,421 INFO misc.py line 113 3298914] Train: [1/100][1437/2402] Data 0.003 (0.004) Batch 0.466 (0.478) Remain 31:43:56 loss: 1.6983 Lr: 0.00026
[2025-04-08 14:02:45,862 INFO misc.py line 113 3298914] Train: [1/100][1438/2402] Data 0.004 (0.004) Batch 0.441 (0.478) Remain 31:43:49 loss: 1.6294 Lr: 0.00026
[2025-04-08 14:02:46,326 INFO misc.py line 113 3298914] Train: [1/100][1439/2402] Data 0.003 (0.004) Batch 0.464 (0.478) Remain 31:43:47 loss: 1.5067 Lr: 0.00026
[2025-04-08 14:02:46,731 INFO misc.py line 113 3298914] Train: [1/100][1440/2402] Data 0.003 (0.004) Batch 0.405 (0.478) Remain 31:43:34 loss: 1.6172 Lr: 0.00026
[2025-04-08 14:02:47,172 INFO misc.py line 113 3298914] Train: [1/100][1441/2402] Data 0.004 (0.004) Batch 0.442 (0.478) Remain 31:43:27 loss: 1.6577 Lr: 0.00026
[2025-04-08 14:02:47,689 INFO misc.py line 113 3298914] Train: [1/100][1442/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:43:33 loss: 1.4475 Lr: 0.00026
[2025-04-08 14:02:48,228 INFO misc.py line 113 3298914] Train: [1/100][1443/2402] Data 0.003 (0.004) Batch 0.540 (0.478) Remain 31:43:43 loss: 1.4473 Lr: 0.00026
[2025-04-08 14:02:48,640 INFO misc.py line 113 3298914] Train: [1/100][1444/2402] Data 0.004 (0.004) Batch 0.411 (0.478) Remain 31:43:31 loss: 1.7338 Lr: 0.00026
[2025-04-08 14:02:49,191 INFO misc.py line 113 3298914] Train: [1/100][1445/2402] Data 0.003 (0.004) Batch 0.552 (0.478) Remain 31:43:43 loss: 1.6852 Lr: 0.00026
[2025-04-08 14:02:49,580 INFO misc.py line 113 3298914] Train: [1/100][1446/2402] Data 0.004 (0.004) Batch 0.388 (0.478) Remain 31:43:28 loss: 1.7016 Lr: 0.00026
[2025-04-08 14:02:50,072 INFO misc.py line 113 3298914] Train: [1/100][1447/2402] Data 0.004 (0.004) Batch 0.492 (0.478) Remain 31:43:29 loss: 1.3675 Lr: 0.00026
[2025-04-08 14:02:50,518 INFO misc.py line 113 3298914] Train: [1/100][1448/2402] Data 0.003 (0.004) Batch 0.446 (0.478) Remain 31:43:23 loss: 1.8056 Lr: 0.00026
[2025-04-08 14:02:51,080 INFO misc.py line 113 3298914] Train: [1/100][1449/2402] Data 0.004 (0.004) Batch 0.562 (0.478) Remain 31:43:37 loss: 1.3573 Lr: 0.00026
[2025-04-08 14:02:51,537 INFO misc.py line 113 3298914] Train: [1/100][1450/2402] Data 0.004 (0.004) Batch 0.458 (0.478) Remain 31:43:33 loss: 1.7046 Lr: 0.00026
[2025-04-08 14:02:52,040 INFO misc.py line 113 3298914] Train: [1/100][1451/2402] Data 0.003 (0.004) Batch 0.502 (0.478) Remain 31:43:36 loss: 1.6525 Lr: 0.00026
[2025-04-08 14:02:52,585 INFO misc.py line 113 3298914] Train: [1/100][1452/2402] Data 0.004 (0.004) Batch 0.546 (0.478) Remain 31:43:47 loss: 1.5361 Lr: 0.00026
[2025-04-08 14:02:53,045 INFO misc.py line 113 3298914] Train: [1/100][1453/2402] Data 0.004 (0.004) Batch 0.460 (0.478) Remain 31:43:43 loss: 1.9256 Lr: 0.00026
[2025-04-08 14:02:53,535 INFO misc.py line 113 3298914] Train: [1/100][1454/2402] Data 0.003 (0.004) Batch 0.489 (0.478) Remain 31:43:45 loss: 1.6000 Lr: 0.00026
[2025-04-08 14:02:54,018 INFO misc.py line 113 3298914] Train: [1/100][1455/2402] Data 0.004 (0.004) Batch 0.484 (0.478) Remain 31:43:45 loss: 1.1991 Lr: 0.00026
[2025-04-08 14:02:54,487 INFO misc.py line 113 3298914] Train: [1/100][1456/2402] Data 0.004 (0.004) Batch 0.469 (0.478) Remain 31:43:43 loss: 1.7551 Lr: 0.00026
[2025-04-08 14:02:55,044 INFO misc.py line 113 3298914] Train: [1/100][1457/2402] Data 0.003 (0.004) Batch 0.557 (0.478) Remain 31:43:56 loss: 1.8349 Lr: 0.00026
[2025-04-08 14:02:55,551 INFO misc.py line 113 3298914] Train: [1/100][1458/2402] Data 0.004 (0.004) Batch 0.507 (0.479) Remain 31:44:00 loss: 1.2174 Lr: 0.00026
[2025-04-08 14:02:56,112 INFO misc.py line 113 3298914] Train: [1/100][1459/2402] Data 0.003 (0.004) Batch 0.561 (0.479) Remain 31:44:13 loss: 1.7305 Lr: 0.00026
[2025-04-08 14:02:56,642 INFO misc.py line 113 3298914] Train: [1/100][1460/2402] Data 0.003 (0.004) Batch 0.530 (0.479) Remain 31:44:21 loss: 1.1728 Lr: 0.00026
[2025-04-08 14:02:57,156 INFO misc.py line 113 3298914] Train: [1/100][1461/2402] Data 0.003 (0.004) Batch 0.514 (0.479) Remain 31:44:26 loss: 1.7061 Lr: 0.00026
[2025-04-08 14:02:57,623 INFO misc.py line 113 3298914] Train: [1/100][1462/2402] Data 0.003 (0.004) Batch 0.467 (0.479) Remain 31:44:24 loss: 1.8777 Lr: 0.00026
[2025-04-08 14:02:58,154 INFO misc.py line 113 3298914] Train: [1/100][1463/2402] Data 0.003 (0.004) Batch 0.531 (0.479) Remain 31:44:32 loss: 1.4867 Lr: 0.00026
[2025-04-08 14:02:58,715 INFO misc.py line 113 3298914] Train: [1/100][1464/2402] Data 0.004 (0.004) Batch 0.561 (0.479) Remain 31:44:45 loss: 1.2800 Lr: 0.00026
[2025-04-08 14:02:59,174 INFO misc.py line 113 3298914] Train: [1/100][1465/2402] Data 0.004 (0.004) Batch 0.459 (0.479) Remain 31:44:41 loss: 1.8161 Lr: 0.00027
[2025-04-08 14:02:59,738 INFO misc.py line 113 3298914] Train: [1/100][1466/2402] Data 0.003 (0.004) Batch 0.564 (0.479) Remain 31:44:54 loss: 1.8190 Lr: 0.00027
[2025-04-08 14:03:00,270 INFO misc.py line 113 3298914] Train: [1/100][1467/2402] Data 0.004 (0.004) Batch 0.532 (0.479) Remain 31:45:03 loss: 1.5487 Lr: 0.00027
[2025-04-08 14:03:00,717 INFO misc.py line 113 3298914] Train: [1/100][1468/2402] Data 0.003 (0.004) Batch 0.447 (0.479) Remain 31:44:57 loss: 1.6886 Lr: 0.00027
[2025-04-08 14:03:01,266 INFO misc.py line 113 3298914] Train: [1/100][1469/2402] Data 0.004 (0.004) Batch 0.549 (0.479) Remain 31:45:08 loss: 1.7041 Lr: 0.00027
[2025-04-08 14:03:01,714 INFO misc.py line 113 3298914] Train: [1/100][1470/2402] Data 0.004 (0.004) Batch 0.447 (0.479) Remain 31:45:02 loss: 1.4420 Lr: 0.00027
[2025-04-08 14:03:02,190 INFO misc.py line 113 3298914] Train: [1/100][1471/2402] Data 0.004 (0.004) Batch 0.477 (0.479) Remain 31:45:02 loss: 1.8676 Lr: 0.00027
[2025-04-08 14:03:02,617 INFO misc.py line 113 3298914] Train: [1/100][1472/2402] Data 0.003 (0.004) Batch 0.427 (0.479) Remain 31:44:53 loss: 1.4964 Lr: 0.00027
[2025-04-08 14:03:03,061 INFO misc.py line 113 3298914] Train: [1/100][1473/2402] Data 0.003 (0.004) Batch 0.443 (0.479) Remain 31:44:46 loss: 1.1883 Lr: 0.00027
[2025-04-08 14:03:03,535 INFO misc.py line 113 3298914] Train: [1/100][1474/2402] Data 0.004 (0.004) Batch 0.474 (0.479) Remain 31:44:45 loss: 1.9007 Lr: 0.00027
[2025-04-08 14:03:04,117 INFO misc.py line 113 3298914] Train: [1/100][1475/2402] Data 0.019 (0.004) Batch 0.582 (0.479) Remain 31:45:01 loss: 1.5039 Lr: 0.00027
[2025-04-08 14:03:04,547 INFO misc.py line 113 3298914] Train: [1/100][1476/2402] Data 0.004 (0.004) Batch 0.430 (0.479) Remain 31:44:53 loss: 1.7947 Lr: 0.00027
[2025-04-08 14:03:05,077 INFO misc.py line 113 3298914] Train: [1/100][1477/2402] Data 0.003 (0.004) Batch 0.530 (0.479) Remain 31:45:01 loss: 1.3690 Lr: 0.00027
[2025-04-08 14:03:05,524 INFO misc.py line 113 3298914] Train: [1/100][1478/2402] Data 0.004 (0.004) Batch 0.446 (0.479) Remain 31:44:55 loss: 1.3505 Lr: 0.00027
[2025-04-08 14:03:05,912 INFO misc.py line 113 3298914] Train: [1/100][1479/2402] Data 0.004 (0.004) Batch 0.388 (0.479) Remain 31:44:40 loss: 1.3012 Lr: 0.00027
[2025-04-08 14:03:06,402 INFO misc.py line 113 3298914] Train: [1/100][1480/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:44:42 loss: 1.4446 Lr: 0.00027
[2025-04-08 14:03:06,874 INFO misc.py line 113 3298914] Train: [1/100][1481/2402] Data 0.003 (0.004) Batch 0.472 (0.479) Remain 31:44:40 loss: 1.8617 Lr: 0.00027
[2025-04-08 14:03:07,317 INFO misc.py line 113 3298914] Train: [1/100][1482/2402] Data 0.003 (0.004) Batch 0.443 (0.479) Remain 31:44:34 loss: 1.6370 Lr: 0.00027
[2025-04-08 14:03:07,671 INFO misc.py line 113 3298914] Train: [1/100][1483/2402] Data 0.003 (0.004) Batch 0.353 (0.479) Remain 31:44:13 loss: 1.8066 Lr: 0.00027
[2025-04-08 14:03:08,241 INFO misc.py line 113 3298914] Train: [1/100][1484/2402] Data 0.004 (0.004) Batch 0.570 (0.479) Remain 31:44:27 loss: 1.4792 Lr: 0.00027
[2025-04-08 14:03:08,794 INFO misc.py line 113 3298914] Train: [1/100][1485/2402] Data 0.004 (0.004) Batch 0.553 (0.479) Remain 31:44:39 loss: 1.3229 Lr: 0.00027
[2025-04-08 14:03:09,231 INFO misc.py line 113 3298914] Train: [1/100][1486/2402] Data 0.004 (0.004) Batch 0.437 (0.479) Remain 31:44:32 loss: 1.6407 Lr: 0.00027
[2025-04-08 14:03:09,775 INFO misc.py line 113 3298914] Train: [1/100][1487/2402] Data 0.004 (0.004) Batch 0.544 (0.479) Remain 31:44:42 loss: 1.5681 Lr: 0.00027
[2025-04-08 14:03:10,284 INFO misc.py line 113 3298914] Train: [1/100][1488/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:44:46 loss: 1.7947 Lr: 0.00027
[2025-04-08 14:03:10,752 INFO misc.py line 113 3298914] Train: [1/100][1489/2402] Data 0.004 (0.004) Batch 0.468 (0.479) Remain 31:44:44 loss: 1.9463 Lr: 0.00027
[2025-04-08 14:03:11,189 INFO misc.py line 113 3298914] Train: [1/100][1490/2402] Data 0.004 (0.004) Batch 0.437 (0.479) Remain 31:44:37 loss: 1.6244 Lr: 0.00027
[2025-04-08 14:03:11,710 INFO misc.py line 113 3298914] Train: [1/100][1491/2402] Data 0.003 (0.004) Batch 0.521 (0.479) Remain 31:44:43 loss: 1.6601 Lr: 0.00027
[2025-04-08 14:03:12,269 INFO misc.py line 113 3298914] Train: [1/100][1492/2402] Data 0.003 (0.004) Batch 0.559 (0.479) Remain 31:44:55 loss: 1.8276 Lr: 0.00027
[2025-04-08 14:03:12,711 INFO misc.py line 113 3298914] Train: [1/100][1493/2402] Data 0.003 (0.004) Batch 0.442 (0.479) Remain 31:44:49 loss: 1.2979 Lr: 0.00027
[2025-04-08 14:03:13,224 INFO misc.py line 113 3298914] Train: [1/100][1494/2402] Data 0.003 (0.004) Batch 0.512 (0.479) Remain 31:44:54 loss: 1.4900 Lr: 0.00027
[2025-04-08 14:03:13,714 INFO misc.py line 113 3298914] Train: [1/100][1495/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:44:55 loss: 1.7219 Lr: 0.00027
[2025-04-08 14:03:14,123 INFO misc.py line 113 3298914] Train: [1/100][1496/2402] Data 0.004 (0.004) Batch 0.409 (0.479) Remain 31:44:44 loss: 1.4987 Lr: 0.00027
[2025-04-08 14:03:14,444 INFO misc.py line 113 3298914] Train: [1/100][1497/2402] Data 0.003 (0.004) Batch 0.321 (0.479) Remain 31:44:18 loss: 1.5405 Lr: 0.00027
[2025-04-08 14:03:15,013 INFO misc.py line 113 3298914] Train: [1/100][1498/2402] Data 0.004 (0.004) Batch 0.569 (0.479) Remain 31:44:32 loss: 1.7851 Lr: 0.00027
[2025-04-08 14:03:15,467 INFO misc.py line 113 3298914] Train: [1/100][1499/2402] Data 0.003 (0.004) Batch 0.453 (0.479) Remain 31:44:27 loss: 1.4379 Lr: 0.00027
[2025-04-08 14:03:16,027 INFO misc.py line 113 3298914] Train: [1/100][1500/2402] Data 0.003 (0.004) Batch 0.560 (0.479) Remain 31:44:40 loss: 1.1382 Lr: 0.00027
[2025-04-08 14:03:16,522 INFO misc.py line 113 3298914] Train: [1/100][1501/2402] Data 0.004 (0.004) Batch 0.494 (0.479) Remain 31:44:42 loss: 1.2322 Lr: 0.00027
[2025-04-08 14:03:17,053 INFO misc.py line 113 3298914] Train: [1/100][1502/2402] Data 0.004 (0.004) Batch 0.533 (0.479) Remain 31:44:50 loss: 1.7636 Lr: 0.00027
[2025-04-08 14:03:17,521 INFO misc.py line 113 3298914] Train: [1/100][1503/2402] Data 0.003 (0.004) Batch 0.468 (0.479) Remain 31:44:48 loss: 1.1405 Lr: 0.00027
[2025-04-08 14:03:17,982 INFO misc.py line 113 3298914] Train: [1/100][1504/2402] Data 0.003 (0.004) Batch 0.461 (0.479) Remain 31:44:44 loss: 1.8318 Lr: 0.00027
[2025-04-08 14:03:18,394 INFO misc.py line 113 3298914] Train: [1/100][1505/2402] Data 0.003 (0.004) Batch 0.412 (0.479) Remain 31:44:33 loss: 1.4066 Lr: 0.00027
[2025-04-08 14:03:18,844 INFO misc.py line 113 3298914] Train: [1/100][1506/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:44:28 loss: 1.5263 Lr: 0.00027
[2025-04-08 14:03:19,286 INFO misc.py line 113 3298914] Train: [1/100][1507/2402] Data 0.003 (0.004) Batch 0.442 (0.479) Remain 31:44:22 loss: 1.2243 Lr: 0.00027
[2025-04-08 14:03:19,727 INFO misc.py line 113 3298914] Train: [1/100][1508/2402] Data 0.004 (0.004) Batch 0.441 (0.479) Remain 31:44:16 loss: 1.3936 Lr: 0.00027
[2025-04-08 14:03:20,266 INFO misc.py line 113 3298914] Train: [1/100][1509/2402] Data 0.003 (0.004) Batch 0.539 (0.479) Remain 31:44:25 loss: 1.9376 Lr: 0.00027
[2025-04-08 14:03:20,750 INFO misc.py line 113 3298914] Train: [1/100][1510/2402] Data 0.003 (0.004) Batch 0.483 (0.479) Remain 31:44:25 loss: 1.7304 Lr: 0.00027
[2025-04-08 14:03:21,136 INFO misc.py line 113 3298914] Train: [1/100][1511/2402] Data 0.006 (0.004) Batch 0.387 (0.479) Remain 31:44:10 loss: 1.4560 Lr: 0.00027
[2025-04-08 14:03:21,572 INFO misc.py line 113 3298914] Train: [1/100][1512/2402] Data 0.003 (0.004) Batch 0.436 (0.479) Remain 31:44:03 loss: 1.6881 Lr: 0.00027
[2025-04-08 14:03:21,944 INFO misc.py line 113 3298914] Train: [1/100][1513/2402] Data 0.003 (0.004) Batch 0.371 (0.479) Remain 31:43:45 loss: 1.7897 Lr: 0.00027
[2025-04-08 14:03:22,481 INFO misc.py line 113 3298914] Train: [1/100][1514/2402] Data 0.003 (0.004) Batch 0.537 (0.479) Remain 31:43:54 loss: 1.6204 Lr: 0.00027
[2025-04-08 14:03:22,935 INFO misc.py line 113 3298914] Train: [1/100][1515/2402] Data 0.003 (0.004) Batch 0.454 (0.479) Remain 31:43:49 loss: 1.7251 Lr: 0.00027
[2025-04-08 14:03:23,477 INFO misc.py line 113 3298914] Train: [1/100][1516/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:43:59 loss: 1.6266 Lr: 0.00027
[2025-04-08 14:03:23,980 INFO misc.py line 113 3298914] Train: [1/100][1517/2402] Data 0.003 (0.004) Batch 0.503 (0.479) Remain 31:44:02 loss: 1.3169 Lr: 0.00027
[2025-04-08 14:03:24,366 INFO misc.py line 113 3298914] Train: [1/100][1518/2402] Data 0.004 (0.004) Batch 0.387 (0.479) Remain 31:43:47 loss: 1.6546 Lr: 0.00027
[2025-04-08 14:03:24,847 INFO misc.py line 113 3298914] Train: [1/100][1519/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:43:47 loss: 1.9294 Lr: 0.00027
[2025-04-08 14:03:25,417 INFO misc.py line 113 3298914] Train: [1/100][1520/2402] Data 0.003 (0.004) Batch 0.570 (0.479) Remain 31:44:01 loss: 1.5471 Lr: 0.00027
[2025-04-08 14:03:25,898 INFO misc.py line 113 3298914] Train: [1/100][1521/2402] Data 0.004 (0.004) Batch 0.481 (0.479) Remain 31:44:01 loss: 2.0291 Lr: 0.00027
[2025-04-08 14:03:26,347 INFO misc.py line 113 3298914] Train: [1/100][1522/2402] Data 0.004 (0.004) Batch 0.449 (0.479) Remain 31:43:56 loss: 1.0379 Lr: 0.00027
[2025-04-08 14:03:26,856 INFO misc.py line 113 3298914] Train: [1/100][1523/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:44:00 loss: 1.2352 Lr: 0.00027
[2025-04-08 14:03:27,399 INFO misc.py line 113 3298914] Train: [1/100][1524/2402] Data 0.004 (0.004) Batch 0.544 (0.479) Remain 31:44:10 loss: 1.6437 Lr: 0.00027
[2025-04-08 14:03:27,975 INFO misc.py line 113 3298914] Train: [1/100][1525/2402] Data 0.004 (0.004) Batch 0.576 (0.479) Remain 31:44:25 loss: 1.6514 Lr: 0.00027
[2025-04-08 14:03:28,377 INFO misc.py line 113 3298914] Train: [1/100][1526/2402] Data 0.003 (0.004) Batch 0.402 (0.479) Remain 31:44:12 loss: 1.4729 Lr: 0.00027
[2025-04-08 14:03:28,828 INFO misc.py line 113 3298914] Train: [1/100][1527/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:44:07 loss: 1.6014 Lr: 0.00027
[2025-04-08 14:03:29,332 INFO misc.py line 113 3298914] Train: [1/100][1528/2402] Data 0.003 (0.004) Batch 0.504 (0.479) Remain 31:44:11 loss: 1.5170 Lr: 0.00027
[2025-04-08 14:03:29,893 INFO misc.py line 113 3298914] Train: [1/100][1529/2402] Data 0.004 (0.004) Batch 0.561 (0.479) Remain 31:44:23 loss: 1.5944 Lr: 0.00027
[2025-04-08 14:03:30,367 INFO misc.py line 113 3298914] Train: [1/100][1530/2402] Data 0.003 (0.004) Batch 0.474 (0.479) Remain 31:44:22 loss: 1.7548 Lr: 0.00027
[2025-04-08 14:03:30,849 INFO misc.py line 113 3298914] Train: [1/100][1531/2402] Data 0.004 (0.004) Batch 0.482 (0.479) Remain 31:44:22 loss: 1.3172 Lr: 0.00027
[2025-04-08 14:03:31,221 INFO misc.py line 113 3298914] Train: [1/100][1532/2402] Data 0.004 (0.004) Batch 0.372 (0.479) Remain 31:44:05 loss: 1.6171 Lr: 0.00027
[2025-04-08 14:03:31,714 INFO misc.py line 113 3298914] Train: [1/100][1533/2402] Data 0.003 (0.004) Batch 0.493 (0.479) Remain 31:44:07 loss: 1.6876 Lr: 0.00027
[2025-04-08 14:03:32,422 INFO misc.py line 113 3298914] Train: [1/100][1534/2402] Data 0.004 (0.004) Batch 0.708 (0.479) Remain 31:44:42 loss: 1.5960 Lr: 0.00027
[2025-04-08 14:03:32,884 INFO misc.py line 113 3298914] Train: [1/100][1535/2402] Data 0.003 (0.004) Batch 0.462 (0.479) Remain 31:44:39 loss: 1.6893 Lr: 0.00027
[2025-04-08 14:03:33,447 INFO misc.py line 113 3298914] Train: [1/100][1536/2402] Data 0.003 (0.004) Batch 0.564 (0.479) Remain 31:44:51 loss: 1.8831 Lr: 0.00027
[2025-04-08 14:03:33,991 INFO misc.py line 113 3298914] Train: [1/100][1537/2402] Data 0.004 (0.004) Batch 0.544 (0.479) Remain 31:45:01 loss: 1.5279 Lr: 0.00027
[2025-04-08 14:03:34,533 INFO misc.py line 113 3298914] Train: [1/100][1538/2402] Data 0.004 (0.004) Batch 0.542 (0.479) Remain 31:45:10 loss: 1.4215 Lr: 0.00027
[2025-04-08 14:03:34,970 INFO misc.py line 113 3298914] Train: [1/100][1539/2402] Data 0.004 (0.004) Batch 0.437 (0.479) Remain 31:45:03 loss: 1.6471 Lr: 0.00027
[2025-04-08 14:03:35,372 INFO misc.py line 113 3298914] Train: [1/100][1540/2402] Data 0.003 (0.004) Batch 0.402 (0.479) Remain 31:44:51 loss: 1.4648 Lr: 0.00027
[2025-04-08 14:03:35,823 INFO misc.py line 113 3298914] Train: [1/100][1541/2402] Data 0.004 (0.004) Batch 0.450 (0.479) Remain 31:44:46 loss: 2.0464 Lr: 0.00027
[2025-04-08 14:03:36,392 INFO misc.py line 113 3298914] Train: [1/100][1542/2402] Data 0.004 (0.004) Batch 0.569 (0.479) Remain 31:45:00 loss: 1.6284 Lr: 0.00027
[2025-04-08 14:03:36,862 INFO misc.py line 113 3298914] Train: [1/100][1543/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:44:58 loss: 1.7322 Lr: 0.00027
[2025-04-08 14:03:37,232 INFO misc.py line 113 3298914] Train: [1/100][1544/2402] Data 0.004 (0.004) Batch 0.370 (0.479) Remain 31:44:40 loss: 1.6556 Lr: 0.00027
[2025-04-08 14:03:37,673 INFO misc.py line 113 3298914] Train: [1/100][1545/2402] Data 0.003 (0.004) Batch 0.441 (0.479) Remain 31:44:34 loss: 1.2195 Lr: 0.00027
[2025-04-08 14:03:38,156 INFO misc.py line 113 3298914] Train: [1/100][1546/2402] Data 0.003 (0.004) Batch 0.483 (0.479) Remain 31:44:34 loss: 1.5112 Lr: 0.00027
[2025-04-08 14:03:38,710 INFO misc.py line 113 3298914] Train: [1/100][1547/2402] Data 0.003 (0.004) Batch 0.554 (0.479) Remain 31:44:45 loss: 1.4821 Lr: 0.00027
[2025-04-08 14:03:39,282 INFO misc.py line 113 3298914] Train: [1/100][1548/2402] Data 0.004 (0.004) Batch 0.571 (0.479) Remain 31:44:59 loss: 1.7930 Lr: 0.00027
[2025-04-08 14:03:39,722 INFO misc.py line 113 3298914] Train: [1/100][1549/2402] Data 0.003 (0.004) Batch 0.440 (0.479) Remain 31:44:53 loss: 1.1983 Lr: 0.00027
[2025-04-08 14:03:40,125 INFO misc.py line 113 3298914] Train: [1/100][1550/2402] Data 0.004 (0.004) Batch 0.404 (0.479) Remain 31:44:41 loss: 1.7306 Lr: 0.00027
[2025-04-08 14:03:40,609 INFO misc.py line 113 3298914] Train: [1/100][1551/2402] Data 0.003 (0.004) Batch 0.483 (0.479) Remain 31:44:41 loss: 1.5957 Lr: 0.00027
[2025-04-08 14:03:40,922 INFO misc.py line 113 3298914] Train: [1/100][1552/2402] Data 0.003 (0.004) Batch 0.313 (0.479) Remain 31:44:15 loss: 1.6539 Lr: 0.00027
[2025-04-08 14:03:41,356 INFO misc.py line 113 3298914] Train: [1/100][1553/2402] Data 0.003 (0.004) Batch 0.434 (0.479) Remain 31:44:07 loss: 1.7640 Lr: 0.00027
[2025-04-08 14:03:41,881 INFO misc.py line 113 3298914] Train: [1/100][1554/2402] Data 0.004 (0.004) Batch 0.525 (0.479) Remain 31:44:14 loss: 1.2756 Lr: 0.00027
[2025-04-08 14:03:42,404 INFO misc.py line 113 3298914] Train: [1/100][1555/2402] Data 0.005 (0.004) Batch 0.524 (0.479) Remain 31:44:20 loss: 1.6196 Lr: 0.00027
[2025-04-08 14:03:42,847 INFO misc.py line 113 3298914] Train: [1/100][1556/2402] Data 0.004 (0.004) Batch 0.443 (0.479) Remain 31:44:15 loss: 1.3268 Lr: 0.00027
[2025-04-08 14:03:43,282 INFO misc.py line 113 3298914] Train: [1/100][1557/2402] Data 0.003 (0.004) Batch 0.435 (0.479) Remain 31:44:07 loss: 1.8549 Lr: 0.00027
[2025-04-08 14:03:43,771 INFO misc.py line 113 3298914] Train: [1/100][1558/2402] Data 0.004 (0.004) Batch 0.489 (0.479) Remain 31:44:08 loss: 1.5216 Lr: 0.00027
[2025-04-08 14:03:44,396 INFO misc.py line 113 3298914] Train: [1/100][1559/2402] Data 0.004 (0.004) Batch 0.626 (0.479) Remain 31:44:30 loss: 1.6194 Lr: 0.00027
[2025-04-08 14:03:44,891 INFO misc.py line 113 3298914] Train: [1/100][1560/2402] Data 0.003 (0.004) Batch 0.494 (0.479) Remain 31:44:32 loss: 1.6927 Lr: 0.00027
[2025-04-08 14:03:45,252 INFO misc.py line 113 3298914] Train: [1/100][1561/2402] Data 0.003 (0.004) Batch 0.361 (0.479) Remain 31:44:14 loss: 1.3944 Lr: 0.00027
[2025-04-08 14:03:45,721 INFO misc.py line 113 3298914] Train: [1/100][1562/2402] Data 0.004 (0.004) Batch 0.469 (0.479) Remain 31:44:12 loss: 1.8523 Lr: 0.00027
[2025-04-08 14:03:46,245 INFO misc.py line 113 3298914] Train: [1/100][1563/2402] Data 0.003 (0.004) Batch 0.525 (0.479) Remain 31:44:18 loss: 2.0856 Lr: 0.00027
[2025-04-08 14:03:46,618 INFO misc.py line 113 3298914] Train: [1/100][1564/2402] Data 0.004 (0.004) Batch 0.372 (0.479) Remain 31:44:02 loss: 2.3476 Lr: 0.00027
[2025-04-08 14:03:47,163 INFO misc.py line 113 3298914] Train: [1/100][1565/2402] Data 0.004 (0.004) Batch 0.545 (0.479) Remain 31:44:11 loss: 1.2798 Lr: 0.00027
[2025-04-08 14:03:47,661 INFO misc.py line 113 3298914] Train: [1/100][1566/2402] Data 0.003 (0.004) Batch 0.499 (0.479) Remain 31:44:14 loss: 1.5615 Lr: 0.00027
[2025-04-08 14:03:48,149 INFO misc.py line 113 3298914] Train: [1/100][1567/2402] Data 0.003 (0.004) Batch 0.488 (0.479) Remain 31:44:15 loss: 1.7002 Lr: 0.00027
[2025-04-08 14:03:48,668 INFO misc.py line 113 3298914] Train: [1/100][1568/2402] Data 0.003 (0.004) Batch 0.519 (0.479) Remain 31:44:20 loss: 1.5618 Lr: 0.00027
[2025-04-08 14:03:49,193 INFO misc.py line 113 3298914] Train: [1/100][1569/2402] Data 0.004 (0.004) Batch 0.525 (0.479) Remain 31:44:27 loss: 1.5882 Lr: 0.00027
[2025-04-08 14:03:49,708 INFO misc.py line 113 3298914] Train: [1/100][1570/2402] Data 0.004 (0.004) Batch 0.515 (0.479) Remain 31:44:32 loss: 1.5561 Lr: 0.00027
[2025-04-08 14:03:50,227 INFO misc.py line 113 3298914] Train: [1/100][1571/2402] Data 0.004 (0.004) Batch 0.518 (0.479) Remain 31:44:37 loss: 1.4219 Lr: 0.00027
[2025-04-08 14:03:50,753 INFO misc.py line 113 3298914] Train: [1/100][1572/2402] Data 0.004 (0.004) Batch 0.526 (0.479) Remain 31:44:44 loss: 1.6611 Lr: 0.00027
[2025-04-08 14:03:51,253 INFO misc.py line 113 3298914] Train: [1/100][1573/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:44:47 loss: 1.7373 Lr: 0.00027
[2025-04-08 14:03:51,712 INFO misc.py line 113 3298914] Train: [1/100][1574/2402] Data 0.003 (0.004) Batch 0.459 (0.479) Remain 31:44:43 loss: 1.5237 Lr: 0.00027
[2025-04-08 14:03:52,209 INFO misc.py line 113 3298914] Train: [1/100][1575/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:44:46 loss: 1.8791 Lr: 0.00028
[2025-04-08 14:03:52,713 INFO misc.py line 113 3298914] Train: [1/100][1576/2402] Data 0.004 (0.004) Batch 0.505 (0.479) Remain 31:44:49 loss: 1.5598 Lr: 0.00028
[2025-04-08 14:03:53,104 INFO misc.py line 113 3298914] Train: [1/100][1577/2402] Data 0.004 (0.004) Batch 0.389 (0.479) Remain 31:44:35 loss: 1.8107 Lr: 0.00028
[2025-04-08 14:03:53,593 INFO misc.py line 113 3298914] Train: [1/100][1578/2402] Data 0.005 (0.004) Batch 0.490 (0.479) Remain 31:44:36 loss: 1.7576 Lr: 0.00028
[2025-04-08 14:03:53,977 INFO misc.py line 113 3298914] Train: [1/100][1579/2402] Data 0.003 (0.004) Batch 0.384 (0.479) Remain 31:44:21 loss: 1.3000 Lr: 0.00028
[2025-04-08 14:03:54,471 INFO misc.py line 113 3298914] Train: [1/100][1580/2402] Data 0.004 (0.004) Batch 0.494 (0.479) Remain 31:44:23 loss: 1.5178 Lr: 0.00028
[2025-04-08 14:03:54,945 INFO misc.py line 113 3298914] Train: [1/100][1581/2402] Data 0.003 (0.004) Batch 0.474 (0.479) Remain 31:44:22 loss: 1.4944 Lr: 0.00028
[2025-04-08 14:03:55,473 INFO misc.py line 113 3298914] Train: [1/100][1582/2402] Data 0.003 (0.004) Batch 0.527 (0.479) Remain 31:44:29 loss: 1.7208 Lr: 0.00028
[2025-04-08 14:03:55,958 INFO misc.py line 113 3298914] Train: [1/100][1583/2402] Data 0.003 (0.004) Batch 0.485 (0.479) Remain 31:44:29 loss: 1.5600 Lr: 0.00028
[2025-04-08 14:03:56,352 INFO misc.py line 113 3298914] Train: [1/100][1584/2402] Data 0.003 (0.004) Batch 0.394 (0.479) Remain 31:44:16 loss: 1.7874 Lr: 0.00028
[2025-04-08 14:03:56,848 INFO misc.py line 113 3298914] Train: [1/100][1585/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:44:18 loss: 1.9013 Lr: 0.00028
[2025-04-08 14:03:57,364 INFO misc.py line 113 3298914] Train: [1/100][1586/2402] Data 0.004 (0.004) Batch 0.516 (0.479) Remain 31:44:23 loss: 1.8567 Lr: 0.00028
[2025-04-08 14:03:57,781 INFO misc.py line 113 3298914] Train: [1/100][1587/2402] Data 0.003 (0.004) Batch 0.417 (0.479) Remain 31:44:14 loss: 1.4062 Lr: 0.00028
[2025-04-08 14:03:58,291 INFO misc.py line 113 3298914] Train: [1/100][1588/2402] Data 0.003 (0.004) Batch 0.510 (0.479) Remain 31:44:18 loss: 1.5585 Lr: 0.00028
[2025-04-08 14:03:58,741 INFO misc.py line 113 3298914] Train: [1/100][1589/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:44:13 loss: 1.1426 Lr: 0.00028
[2025-04-08 14:03:59,216 INFO misc.py line 113 3298914] Train: [1/100][1590/2402] Data 0.003 (0.004) Batch 0.476 (0.479) Remain 31:44:12 loss: 1.7497 Lr: 0.00028
[2025-04-08 14:03:59,765 INFO misc.py line 113 3298914] Train: [1/100][1591/2402] Data 0.004 (0.004) Batch 0.548 (0.479) Remain 31:44:22 loss: 1.6899 Lr: 0.00028
[2025-04-08 14:04:00,276 INFO misc.py line 113 3298914] Train: [1/100][1592/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:44:26 loss: 1.8022 Lr: 0.00028
[2025-04-08 14:04:00,777 INFO misc.py line 113 3298914] Train: [1/100][1593/2402] Data 0.003 (0.004) Batch 0.500 (0.479) Remain 31:44:29 loss: 1.7586 Lr: 0.00028
[2025-04-08 14:04:01,243 INFO misc.py line 113 3298914] Train: [1/100][1594/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:44:27 loss: 1.5727 Lr: 0.00028
[2025-04-08 14:04:01,804 INFO misc.py line 113 3298914] Train: [1/100][1595/2402] Data 0.003 (0.004) Batch 0.561 (0.479) Remain 31:44:39 loss: 1.7331 Lr: 0.00028
[2025-04-08 14:04:02,114 INFO misc.py line 113 3298914] Train: [1/100][1596/2402] Data 0.004 (0.004) Batch 0.310 (0.479) Remain 31:44:13 loss: 1.5290 Lr: 0.00028
[2025-04-08 14:04:02,542 INFO misc.py line 113 3298914] Train: [1/100][1597/2402] Data 0.003 (0.004) Batch 0.428 (0.479) Remain 31:44:05 loss: 1.3575 Lr: 0.00028
[2025-04-08 14:04:02,954 INFO misc.py line 113 3298914] Train: [1/100][1598/2402] Data 0.003 (0.004) Batch 0.412 (0.479) Remain 31:43:54 loss: 1.5688 Lr: 0.00028
[2025-04-08 14:04:03,515 INFO misc.py line 113 3298914] Train: [1/100][1599/2402] Data 0.003 (0.004) Batch 0.561 (0.479) Remain 31:44:06 loss: 1.7455 Lr: 0.00028
[2025-04-08 14:04:03,956 INFO misc.py line 113 3298914] Train: [1/100][1600/2402] Data 0.003 (0.004) Batch 0.441 (0.479) Remain 31:44:00 loss: 2.0066 Lr: 0.00028
[2025-04-08 14:04:04,416 INFO misc.py line 113 3298914] Train: [1/100][1601/2402] Data 0.004 (0.004) Batch 0.459 (0.479) Remain 31:43:57 loss: 1.2663 Lr: 0.00028
[2025-04-08 14:04:04,916 INFO misc.py line 113 3298914] Train: [1/100][1602/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:43:59 loss: 1.6692 Lr: 0.00028
[2025-04-08 14:04:05,417 INFO misc.py line 113 3298914] Train: [1/100][1603/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:44:02 loss: 1.6957 Lr: 0.00028
[2025-04-08 14:04:06,002 INFO misc.py line 113 3298914] Train: [1/100][1604/2402] Data 0.004 (0.004) Batch 0.585 (0.479) Remain 31:44:17 loss: 1.2651 Lr: 0.00028
[2025-04-08 14:04:06,418 INFO misc.py line 113 3298914] Train: [1/100][1605/2402] Data 0.003 (0.004) Batch 0.416 (0.479) Remain 31:44:08 loss: 1.7207 Lr: 0.00028
[2025-04-08 14:04:06,892 INFO misc.py line 113 3298914] Train: [1/100][1606/2402] Data 0.004 (0.004) Batch 0.475 (0.479) Remain 31:44:06 loss: 1.6808 Lr: 0.00028
[2025-04-08 14:04:07,408 INFO misc.py line 113 3298914] Train: [1/100][1607/2402] Data 0.003 (0.004) Batch 0.516 (0.479) Remain 31:44:12 loss: 1.7699 Lr: 0.00028
[2025-04-08 14:04:07,835 INFO misc.py line 113 3298914] Train: [1/100][1608/2402] Data 0.003 (0.004) Batch 0.426 (0.479) Remain 31:44:03 loss: 1.9152 Lr: 0.00028
[2025-04-08 14:04:08,351 INFO misc.py line 113 3298914] Train: [1/100][1609/2402] Data 0.004 (0.004) Batch 0.516 (0.479) Remain 31:44:08 loss: 1.2508 Lr: 0.00028
[2025-04-08 14:04:08,811 INFO misc.py line 113 3298914] Train: [1/100][1610/2402] Data 0.003 (0.004) Batch 0.461 (0.479) Remain 31:44:05 loss: 1.7974 Lr: 0.00028
[2025-04-08 14:04:09,254 INFO misc.py line 113 3298914] Train: [1/100][1611/2402] Data 0.003 (0.004) Batch 0.442 (0.479) Remain 31:43:59 loss: 1.5108 Lr: 0.00028
[2025-04-08 14:04:09,757 INFO misc.py line 113 3298914] Train: [1/100][1612/2402] Data 0.004 (0.004) Batch 0.503 (0.479) Remain 31:44:02 loss: 1.3441 Lr: 0.00028
[2025-04-08 14:04:10,239 INFO misc.py line 113 3298914] Train: [1/100][1613/2402] Data 0.004 (0.004) Batch 0.483 (0.479) Remain 31:44:02 loss: 1.6259 Lr: 0.00028
[2025-04-08 14:04:10,772 INFO misc.py line 113 3298914] Train: [1/100][1614/2402] Data 0.003 (0.004) Batch 0.533 (0.479) Remain 31:44:10 loss: 1.6993 Lr: 0.00028
[2025-04-08 14:04:11,248 INFO misc.py line 113 3298914] Train: [1/100][1615/2402] Data 0.004 (0.004) Batch 0.477 (0.479) Remain 31:44:09 loss: 1.6408 Lr: 0.00028
[2025-04-08 14:04:11,748 INFO misc.py line 113 3298914] Train: [1/100][1616/2402] Data 0.004 (0.004) Batch 0.499 (0.479) Remain 31:44:12 loss: 1.8349 Lr: 0.00028
[2025-04-08 14:04:12,211 INFO misc.py line 113 3298914] Train: [1/100][1617/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:44:09 loss: 1.5246 Lr: 0.00028
[2025-04-08 14:04:12,702 INFO misc.py line 113 3298914] Train: [1/100][1618/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:44:10 loss: 1.4143 Lr: 0.00028
[2025-04-08 14:04:13,200 INFO misc.py line 113 3298914] Train: [1/100][1619/2402] Data 0.003 (0.004) Batch 0.498 (0.479) Remain 31:44:12 loss: 2.2353 Lr: 0.00028
[2025-04-08 14:04:13,571 INFO misc.py line 113 3298914] Train: [1/100][1620/2402] Data 0.003 (0.004) Batch 0.371 (0.479) Remain 31:43:56 loss: 1.9071 Lr: 0.00028
[2025-04-08 14:04:14,157 INFO misc.py line 113 3298914] Train: [1/100][1621/2402] Data 0.003 (0.004) Batch 0.586 (0.479) Remain 31:44:11 loss: 1.4604 Lr: 0.00028
[2025-04-08 14:04:14,666 INFO misc.py line 113 3298914] Train: [1/100][1622/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:44:15 loss: 1.6315 Lr: 0.00028
[2025-04-08 14:04:15,091 INFO misc.py line 113 3298914] Train: [1/100][1623/2402] Data 0.003 (0.004) Batch 0.424 (0.479) Remain 31:44:07 loss: 1.4524 Lr: 0.00028
[2025-04-08 14:04:15,437 INFO misc.py line 113 3298914] Train: [1/100][1624/2402] Data 0.003 (0.004) Batch 0.346 (0.479) Remain 31:43:47 loss: 1.6877 Lr: 0.00028
[2025-04-08 14:04:15,939 INFO misc.py line 113 3298914] Train: [1/100][1625/2402] Data 0.004 (0.004) Batch 0.502 (0.479) Remain 31:43:50 loss: 2.2400 Lr: 0.00028
[2025-04-08 14:04:16,441 INFO misc.py line 113 3298914] Train: [1/100][1626/2402] Data 0.004 (0.004) Batch 0.502 (0.479) Remain 31:43:53 loss: 1.5462 Lr: 0.00028
[2025-04-08 14:04:16,863 INFO misc.py line 113 3298914] Train: [1/100][1627/2402] Data 0.004 (0.004) Batch 0.423 (0.479) Remain 31:43:44 loss: 1.3593 Lr: 0.00028
[2025-04-08 14:04:17,260 INFO misc.py line 113 3298914] Train: [1/100][1628/2402] Data 0.004 (0.004) Batch 0.397 (0.479) Remain 31:43:32 loss: 1.5778 Lr: 0.00028
[2025-04-08 14:04:17,655 INFO misc.py line 113 3298914] Train: [1/100][1629/2402] Data 0.003 (0.004) Batch 0.394 (0.479) Remain 31:43:19 loss: 1.0662 Lr: 0.00028
[2025-04-08 14:04:18,126 INFO misc.py line 113 3298914] Train: [1/100][1630/2402] Data 0.004 (0.004) Batch 0.472 (0.479) Remain 31:43:17 loss: 1.6477 Lr: 0.00028
[2025-04-08 14:04:18,614 INFO misc.py line 113 3298914] Train: [1/100][1631/2402] Data 0.003 (0.004) Batch 0.488 (0.479) Remain 31:43:18 loss: 1.8241 Lr: 0.00028
[2025-04-08 14:04:19,031 INFO misc.py line 113 3298914] Train: [1/100][1632/2402] Data 0.003 (0.004) Batch 0.417 (0.479) Remain 31:43:08 loss: 1.6875 Lr: 0.00028
[2025-04-08 14:04:19,579 INFO misc.py line 113 3298914] Train: [1/100][1633/2402] Data 0.003 (0.004) Batch 0.548 (0.479) Remain 31:43:18 loss: 1.7974 Lr: 0.00028
[2025-04-08 14:04:19,992 INFO misc.py line 113 3298914] Train: [1/100][1634/2402] Data 0.004 (0.004) Batch 0.413 (0.479) Remain 31:43:08 loss: 1.7920 Lr: 0.00028
[2025-04-08 14:04:20,418 INFO misc.py line 113 3298914] Train: [1/100][1635/2402] Data 0.003 (0.004) Batch 0.426 (0.479) Remain 31:43:00 loss: 1.6899 Lr: 0.00028
[2025-04-08 14:04:20,934 INFO misc.py line 113 3298914] Train: [1/100][1636/2402] Data 0.003 (0.004) Batch 0.516 (0.479) Remain 31:43:05 loss: 1.7204 Lr: 0.00028
[2025-04-08 14:04:21,443 INFO misc.py line 113 3298914] Train: [1/100][1637/2402] Data 0.004 (0.004) Batch 0.509 (0.479) Remain 31:43:09 loss: 1.5810 Lr: 0.00028
[2025-04-08 14:04:21,976 INFO misc.py line 113 3298914] Train: [1/100][1638/2402] Data 0.004 (0.004) Batch 0.533 (0.479) Remain 31:43:16 loss: 1.3044 Lr: 0.00028
[2025-04-08 14:04:22,536 INFO misc.py line 113 3298914] Train: [1/100][1639/2402] Data 0.003 (0.004) Batch 0.560 (0.479) Remain 31:43:28 loss: 1.5672 Lr: 0.00028
[2025-04-08 14:04:23,118 INFO misc.py line 113 3298914] Train: [1/100][1640/2402] Data 0.003 (0.004) Batch 0.582 (0.479) Remain 31:43:42 loss: 1.7100 Lr: 0.00028
[2025-04-08 14:04:23,660 INFO misc.py line 113 3298914] Train: [1/100][1641/2402] Data 0.004 (0.004) Batch 0.542 (0.479) Remain 31:43:51 loss: 1.2261 Lr: 0.00028
[2025-04-08 14:04:24,141 INFO misc.py line 113 3298914] Train: [1/100][1642/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:43:51 loss: 1.6376 Lr: 0.00028
[2025-04-08 14:04:24,579 INFO misc.py line 113 3298914] Train: [1/100][1643/2402] Data 0.004 (0.004) Batch 0.438 (0.479) Remain 31:43:44 loss: 1.7659 Lr: 0.00028
[2025-04-08 14:04:24,955 INFO misc.py line 113 3298914] Train: [1/100][1644/2402] Data 0.004 (0.004) Batch 0.376 (0.479) Remain 31:43:29 loss: 1.6939 Lr: 0.00028
[2025-04-08 14:04:25,466 INFO misc.py line 113 3298914] Train: [1/100][1645/2402] Data 0.003 (0.004) Batch 0.511 (0.479) Remain 31:43:33 loss: 1.7955 Lr: 0.00028
[2025-04-08 14:04:26,044 INFO misc.py line 113 3298914] Train: [1/100][1646/2402] Data 0.004 (0.004) Batch 0.578 (0.479) Remain 31:43:47 loss: 1.4601 Lr: 0.00028
[2025-04-08 14:04:26,549 INFO misc.py line 113 3298914] Train: [1/100][1647/2402] Data 0.004 (0.004) Batch 0.505 (0.479) Remain 31:43:50 loss: 1.8906 Lr: 0.00028
[2025-04-08 14:04:26,978 INFO misc.py line 113 3298914] Train: [1/100][1648/2402] Data 0.003 (0.004) Batch 0.430 (0.479) Remain 31:43:43 loss: 2.1472 Lr: 0.00028
[2025-04-08 14:04:27,470 INFO misc.py line 113 3298914] Train: [1/100][1649/2402] Data 0.003 (0.004) Batch 0.492 (0.479) Remain 31:43:44 loss: 1.4476 Lr: 0.00028
[2025-04-08 14:04:28,051 INFO misc.py line 113 3298914] Train: [1/100][1650/2402] Data 0.003 (0.004) Batch 0.581 (0.479) Remain 31:43:58 loss: 2.1224 Lr: 0.00028
[2025-04-08 14:04:28,600 INFO misc.py line 113 3298914] Train: [1/100][1651/2402] Data 0.004 (0.004) Batch 0.549 (0.479) Remain 31:44:08 loss: 1.4911 Lr: 0.00028
[2025-04-08 14:04:29,055 INFO misc.py line 113 3298914] Train: [1/100][1652/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:44:04 loss: 1.6259 Lr: 0.00028
[2025-04-08 14:04:29,462 INFO misc.py line 113 3298914] Train: [1/100][1653/2402] Data 0.003 (0.004) Batch 0.406 (0.479) Remain 31:43:53 loss: 1.4559 Lr: 0.00028
[2025-04-08 14:04:29,977 INFO misc.py line 113 3298914] Train: [1/100][1654/2402] Data 0.003 (0.004) Batch 0.515 (0.479) Remain 31:43:58 loss: 1.8202 Lr: 0.00028
[2025-04-08 14:04:30,467 INFO misc.py line 113 3298914] Train: [1/100][1655/2402] Data 0.004 (0.004) Batch 0.491 (0.479) Remain 31:43:59 loss: 1.8471 Lr: 0.00028
[2025-04-08 14:04:30,968 INFO misc.py line 113 3298914] Train: [1/100][1656/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:44:02 loss: 1.8157 Lr: 0.00028
[2025-04-08 14:04:31,438 INFO misc.py line 113 3298914] Train: [1/100][1657/2402] Data 0.003 (0.004) Batch 0.470 (0.479) Remain 31:44:00 loss: 1.6388 Lr: 0.00028
[2025-04-08 14:04:31,949 INFO misc.py line 113 3298914] Train: [1/100][1658/2402] Data 0.004 (0.004) Batch 0.511 (0.479) Remain 31:44:04 loss: 1.4533 Lr: 0.00028
[2025-04-08 14:04:32,497 INFO misc.py line 113 3298914] Train: [1/100][1659/2402] Data 0.003 (0.004) Batch 0.548 (0.479) Remain 31:44:14 loss: 1.2505 Lr: 0.00028
[2025-04-08 14:04:32,952 INFO misc.py line 113 3298914] Train: [1/100][1660/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:44:10 loss: 1.5907 Lr: 0.00028
[2025-04-08 14:04:33,534 INFO misc.py line 113 3298914] Train: [1/100][1661/2402] Data 0.003 (0.004) Batch 0.582 (0.479) Remain 31:44:24 loss: 1.5109 Lr: 0.00028
[2025-04-08 14:04:33,912 INFO misc.py line 113 3298914] Train: [1/100][1662/2402] Data 0.004 (0.004) Batch 0.378 (0.479) Remain 31:44:09 loss: 1.5000 Lr: 0.00028
[2025-04-08 14:04:34,332 INFO misc.py line 113 3298914] Train: [1/100][1663/2402] Data 0.003 (0.004) Batch 0.420 (0.479) Remain 31:44:00 loss: 1.1344 Lr: 0.00028
[2025-04-08 14:04:34,864 INFO misc.py line 113 3298914] Train: [1/100][1664/2402] Data 0.003 (0.004) Batch 0.532 (0.479) Remain 31:44:07 loss: 1.7028 Lr: 0.00028
[2025-04-08 14:04:35,256 INFO misc.py line 113 3298914] Train: [1/100][1665/2402] Data 0.004 (0.004) Batch 0.392 (0.479) Remain 31:43:54 loss: 1.2531 Lr: 0.00028
[2025-04-08 14:04:35,836 INFO misc.py line 113 3298914] Train: [1/100][1666/2402] Data 0.004 (0.004) Batch 0.580 (0.479) Remain 31:44:08 loss: 1.9220 Lr: 0.00028
[2025-04-08 14:04:36,372 INFO misc.py line 113 3298914] Train: [1/100][1667/2402] Data 0.003 (0.004) Batch 0.535 (0.479) Remain 31:44:16 loss: 1.4706 Lr: 0.00028
[2025-04-08 14:04:36,827 INFO misc.py line 113 3298914] Train: [1/100][1668/2402] Data 0.004 (0.004) Batch 0.456 (0.479) Remain 31:44:12 loss: 1.6871 Lr: 0.00028
[2025-04-08 14:04:37,289 INFO misc.py line 113 3298914] Train: [1/100][1669/2402] Data 0.003 (0.004) Batch 0.461 (0.479) Remain 31:44:09 loss: 1.4572 Lr: 0.00028
[2025-04-08 14:04:37,710 INFO misc.py line 113 3298914] Train: [1/100][1670/2402] Data 0.004 (0.004) Batch 0.422 (0.479) Remain 31:44:00 loss: 1.9999 Lr: 0.00028
[2025-04-08 14:04:38,168 INFO misc.py line 113 3298914] Train: [1/100][1671/2402] Data 0.004 (0.004) Batch 0.458 (0.479) Remain 31:43:57 loss: 1.4308 Lr: 0.00028
[2025-04-08 14:04:38,669 INFO misc.py line 113 3298914] Train: [1/100][1672/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:44:00 loss: 1.8037 Lr: 0.00028
[2025-04-08 14:04:39,096 INFO misc.py line 113 3298914] Train: [1/100][1673/2402] Data 0.003 (0.004) Batch 0.427 (0.479) Remain 31:43:52 loss: 1.7214 Lr: 0.00028
[2025-04-08 14:04:39,683 INFO misc.py line 113 3298914] Train: [1/100][1674/2402] Data 0.003 (0.004) Batch 0.587 (0.479) Remain 31:44:07 loss: 1.6754 Lr: 0.00028
[2025-04-08 14:04:40,219 INFO misc.py line 113 3298914] Train: [1/100][1675/2402] Data 0.004 (0.004) Batch 0.537 (0.479) Remain 31:44:14 loss: 1.4049 Lr: 0.00028
[2025-04-08 14:04:40,683 INFO misc.py line 113 3298914] Train: [1/100][1676/2402] Data 0.003 (0.004) Batch 0.463 (0.479) Remain 31:44:12 loss: 1.4746 Lr: 0.00028
[2025-04-08 14:04:41,224 INFO misc.py line 113 3298914] Train: [1/100][1677/2402] Data 0.003 (0.004) Batch 0.541 (0.479) Remain 31:44:20 loss: 1.9995 Lr: 0.00028
[2025-04-08 14:04:41,639 INFO misc.py line 113 3298914] Train: [1/100][1678/2402] Data 0.003 (0.004) Batch 0.416 (0.479) Remain 31:44:11 loss: 1.5235 Lr: 0.00029
[2025-04-08 14:04:42,183 INFO misc.py line 113 3298914] Train: [1/100][1679/2402] Data 0.003 (0.004) Batch 0.543 (0.479) Remain 31:44:19 loss: 1.5125 Lr: 0.00029
[2025-04-08 14:04:42,688 INFO misc.py line 113 3298914] Train: [1/100][1680/2402] Data 0.004 (0.004) Batch 0.505 (0.479) Remain 31:44:22 loss: 1.6087 Lr: 0.00029
[2025-04-08 14:04:43,158 INFO misc.py line 113 3298914] Train: [1/100][1681/2402] Data 0.004 (0.004) Batch 0.470 (0.479) Remain 31:44:21 loss: 2.1522 Lr: 0.00029
[2025-04-08 14:04:43,537 INFO misc.py line 113 3298914] Train: [1/100][1682/2402] Data 0.004 (0.004) Batch 0.379 (0.479) Remain 31:44:06 loss: 1.3665 Lr: 0.00029
[2025-04-08 14:04:43,955 INFO misc.py line 113 3298914] Train: [1/100][1683/2402] Data 0.003 (0.004) Batch 0.418 (0.479) Remain 31:43:57 loss: 1.1559 Lr: 0.00029
[2025-04-08 14:04:44,419 INFO misc.py line 113 3298914] Train: [1/100][1684/2402] Data 0.004 (0.004) Batch 0.464 (0.479) Remain 31:43:54 loss: 1.4906 Lr: 0.00029
[2025-04-08 14:04:44,925 INFO misc.py line 113 3298914] Train: [1/100][1685/2402] Data 0.004 (0.004) Batch 0.506 (0.479) Remain 31:43:58 loss: 2.0923 Lr: 0.00029
[2025-04-08 14:04:45,392 INFO misc.py line 113 3298914] Train: [1/100][1686/2402] Data 0.004 (0.004) Batch 0.467 (0.479) Remain 31:43:56 loss: 1.6947 Lr: 0.00029
[2025-04-08 14:04:45,860 INFO misc.py line 113 3298914] Train: [1/100][1687/2402] Data 0.003 (0.004) Batch 0.468 (0.479) Remain 31:43:54 loss: 1.2949 Lr: 0.00029
[2025-04-08 14:04:46,328 INFO misc.py line 113 3298914] Train: [1/100][1688/2402] Data 0.003 (0.004) Batch 0.467 (0.479) Remain 31:43:51 loss: 1.3661 Lr: 0.00029
[2025-04-08 14:04:46,697 INFO misc.py line 113 3298914] Train: [1/100][1689/2402] Data 0.004 (0.004) Batch 0.369 (0.479) Remain 31:43:35 loss: 1.6329 Lr: 0.00029
[2025-04-08 14:04:47,118 INFO misc.py line 113 3298914] Train: [1/100][1690/2402] Data 0.003 (0.004) Batch 0.422 (0.479) Remain 31:43:27 loss: 1.2388 Lr: 0.00029
[2025-04-08 14:04:47,608 INFO misc.py line 113 3298914] Train: [1/100][1691/2402] Data 0.004 (0.004) Batch 0.490 (0.479) Remain 31:43:28 loss: 1.5427 Lr: 0.00029
[2025-04-08 14:04:48,150 INFO misc.py line 113 3298914] Train: [1/100][1692/2402] Data 0.003 (0.004) Batch 0.541 (0.479) Remain 31:43:36 loss: 1.7659 Lr: 0.00029
[2025-04-08 14:04:48,524 INFO misc.py line 113 3298914] Train: [1/100][1693/2402] Data 0.003 (0.004) Batch 0.374 (0.479) Remain 31:43:21 loss: 1.4737 Lr: 0.00029
[2025-04-08 14:04:48,974 INFO misc.py line 113 3298914] Train: [1/100][1694/2402] Data 0.004 (0.004) Batch 0.450 (0.479) Remain 31:43:16 loss: 1.9569 Lr: 0.00029
[2025-04-08 14:04:49,439 INFO misc.py line 113 3298914] Train: [1/100][1695/2402] Data 0.004 (0.004) Batch 0.466 (0.479) Remain 31:43:14 loss: 1.2116 Lr: 0.00029
[2025-04-08 14:04:50,014 INFO misc.py line 113 3298914] Train: [1/100][1696/2402] Data 0.004 (0.004) Batch 0.575 (0.479) Remain 31:43:27 loss: 1.2509 Lr: 0.00029
[2025-04-08 14:04:50,452 INFO misc.py line 113 3298914] Train: [1/100][1697/2402] Data 0.004 (0.004) Batch 0.438 (0.479) Remain 31:43:21 loss: 1.8455 Lr: 0.00029
[2025-04-08 14:04:50,964 INFO misc.py line 113 3298914] Train: [1/100][1698/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:43:25 loss: 1.9923 Lr: 0.00029
[2025-04-08 14:04:51,413 INFO misc.py line 113 3298914] Train: [1/100][1699/2402] Data 0.003 (0.004) Batch 0.449 (0.479) Remain 31:43:20 loss: 1.6139 Lr: 0.00029
[2025-04-08 14:04:51,869 INFO misc.py line 113 3298914] Train: [1/100][1700/2402] Data 0.004 (0.004) Batch 0.456 (0.479) Remain 31:43:17 loss: 1.7706 Lr: 0.00029
[2025-04-08 14:04:52,383 INFO misc.py line 113 3298914] Train: [1/100][1701/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:43:21 loss: 1.6945 Lr: 0.00029
[2025-04-08 14:04:52,772 INFO misc.py line 113 3298914] Train: [1/100][1702/2402] Data 0.004 (0.004) Batch 0.389 (0.479) Remain 31:43:08 loss: 1.7685 Lr: 0.00029
[2025-04-08 14:04:53,175 INFO misc.py line 113 3298914] Train: [1/100][1703/2402] Data 0.004 (0.004) Batch 0.403 (0.479) Remain 31:42:57 loss: 1.6849 Lr: 0.00029
[2025-04-08 14:04:53,645 INFO misc.py line 113 3298914] Train: [1/100][1704/2402] Data 0.004 (0.004) Batch 0.470 (0.479) Remain 31:42:55 loss: 1.8220 Lr: 0.00029
[2025-04-08 14:04:54,104 INFO misc.py line 113 3298914] Train: [1/100][1705/2402] Data 0.004 (0.004) Batch 0.458 (0.479) Remain 31:42:52 loss: 1.1122 Lr: 0.00029
[2025-04-08 14:04:54,572 INFO misc.py line 113 3298914] Train: [1/100][1706/2402] Data 0.004 (0.004) Batch 0.468 (0.479) Remain 31:42:50 loss: 1.6060 Lr: 0.00029
[2025-04-08 14:04:55,041 INFO misc.py line 113 3298914] Train: [1/100][1707/2402] Data 0.003 (0.004) Batch 0.469 (0.479) Remain 31:42:48 loss: 1.7378 Lr: 0.00029
[2025-04-08 14:04:55,579 INFO misc.py line 113 3298914] Train: [1/100][1708/2402] Data 0.003 (0.004) Batch 0.538 (0.479) Remain 31:42:56 loss: 1.7674 Lr: 0.00029
[2025-04-08 14:04:55,994 INFO misc.py line 113 3298914] Train: [1/100][1709/2402] Data 0.004 (0.004) Batch 0.415 (0.479) Remain 31:42:47 loss: 1.4740 Lr: 0.00029
[2025-04-08 14:04:56,448 INFO misc.py line 113 3298914] Train: [1/100][1710/2402] Data 0.003 (0.004) Batch 0.454 (0.479) Remain 31:42:43 loss: 1.8063 Lr: 0.00029
[2025-04-08 14:04:56,941 INFO misc.py line 113 3298914] Train: [1/100][1711/2402] Data 0.003 (0.004) Batch 0.492 (0.479) Remain 31:42:44 loss: 1.6648 Lr: 0.00029
[2025-04-08 14:04:57,340 INFO misc.py line 113 3298914] Train: [1/100][1712/2402] Data 0.004 (0.004) Batch 0.399 (0.479) Remain 31:42:33 loss: 2.0187 Lr: 0.00029
[2025-04-08 14:04:57,821 INFO misc.py line 113 3298914] Train: [1/100][1713/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:42:32 loss: 1.6178 Lr: 0.00029
[2025-04-08 14:04:58,312 INFO misc.py line 113 3298914] Train: [1/100][1714/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:42:34 loss: 1.3838 Lr: 0.00029
[2025-04-08 14:04:58,893 INFO misc.py line 113 3298914] Train: [1/100][1715/2402] Data 0.004 (0.004) Batch 0.582 (0.479) Remain 31:42:47 loss: 2.0720 Lr: 0.00029
[2025-04-08 14:04:59,430 INFO misc.py line 113 3298914] Train: [1/100][1716/2402] Data 0.003 (0.004) Batch 0.537 (0.479) Remain 31:42:55 loss: 1.6528 Lr: 0.00029
[2025-04-08 14:05:00,033 INFO misc.py line 113 3298914] Train: [1/100][1717/2402] Data 0.003 (0.004) Batch 0.602 (0.479) Remain 31:43:12 loss: 1.2290 Lr: 0.00029
[2025-04-08 14:05:00,612 INFO misc.py line 113 3298914] Train: [1/100][1718/2402] Data 0.003 (0.004) Batch 0.580 (0.479) Remain 31:43:25 loss: 1.8653 Lr: 0.00029
[2025-04-08 14:05:01,003 INFO misc.py line 113 3298914] Train: [1/100][1719/2402] Data 0.003 (0.004) Batch 0.390 (0.479) Remain 31:43:13 loss: 1.5468 Lr: 0.00029
[2025-04-08 14:05:01,435 INFO misc.py line 113 3298914] Train: [1/100][1720/2402] Data 0.003 (0.004) Batch 0.432 (0.479) Remain 31:43:06 loss: 1.5058 Lr: 0.00029
[2025-04-08 14:05:01,871 INFO misc.py line 113 3298914] Train: [1/100][1721/2402] Data 0.004 (0.004) Batch 0.436 (0.479) Remain 31:42:59 loss: 1.5925 Lr: 0.00029
[2025-04-08 14:05:02,331 INFO misc.py line 113 3298914] Train: [1/100][1722/2402] Data 0.004 (0.004) Batch 0.460 (0.479) Remain 31:42:56 loss: 1.4614 Lr: 0.00029
[2025-04-08 14:05:02,852 INFO misc.py line 113 3298914] Train: [1/100][1723/2402] Data 0.003 (0.004) Batch 0.522 (0.479) Remain 31:43:02 loss: 1.4683 Lr: 0.00029
[2025-04-08 14:05:03,256 INFO misc.py line 113 3298914] Train: [1/100][1724/2402] Data 0.003 (0.004) Batch 0.403 (0.479) Remain 31:42:51 loss: 1.3722 Lr: 0.00029
[2025-04-08 14:05:03,751 INFO misc.py line 113 3298914] Train: [1/100][1725/2402] Data 0.004 (0.004) Batch 0.496 (0.479) Remain 31:42:53 loss: 1.5007 Lr: 0.00029
[2025-04-08 14:05:04,240 INFO misc.py line 113 3298914] Train: [1/100][1726/2402] Data 0.003 (0.004) Batch 0.489 (0.479) Remain 31:42:53 loss: 1.5747 Lr: 0.00029
[2025-04-08 14:05:04,626 INFO misc.py line 113 3298914] Train: [1/100][1727/2402] Data 0.003 (0.004) Batch 0.386 (0.479) Remain 31:42:40 loss: 1.2671 Lr: 0.00029
[2025-04-08 14:05:05,113 INFO misc.py line 113 3298914] Train: [1/100][1728/2402] Data 0.004 (0.004) Batch 0.487 (0.479) Remain 31:42:41 loss: 1.8519 Lr: 0.00029
[2025-04-08 14:05:05,585 INFO misc.py line 113 3298914] Train: [1/100][1729/2402] Data 0.004 (0.004) Batch 0.472 (0.479) Remain 31:42:39 loss: 1.3651 Lr: 0.00029
[2025-04-08 14:05:06,053 INFO misc.py line 113 3298914] Train: [1/100][1730/2402] Data 0.004 (0.004) Batch 0.468 (0.479) Remain 31:42:37 loss: 1.6115 Lr: 0.00029
[2025-04-08 14:05:06,569 INFO misc.py line 113 3298914] Train: [1/100][1731/2402] Data 0.003 (0.004) Batch 0.516 (0.479) Remain 31:42:42 loss: 1.2646 Lr: 0.00029
[2025-04-08 14:05:07,142 INFO misc.py line 113 3298914] Train: [1/100][1732/2402] Data 0.003 (0.004) Batch 0.573 (0.479) Remain 31:42:55 loss: 1.5289 Lr: 0.00029
[2025-04-08 14:05:07,619 INFO misc.py line 113 3298914] Train: [1/100][1733/2402] Data 0.004 (0.004) Batch 0.477 (0.479) Remain 31:42:54 loss: 1.4163 Lr: 0.00029
[2025-04-08 14:05:08,109 INFO misc.py line 113 3298914] Train: [1/100][1734/2402] Data 0.004 (0.004) Batch 0.489 (0.479) Remain 31:42:55 loss: 1.5115 Lr: 0.00029
[2025-04-08 14:05:08,553 INFO misc.py line 113 3298914] Train: [1/100][1735/2402] Data 0.003 (0.004) Batch 0.444 (0.479) Remain 31:42:50 loss: 1.3303 Lr: 0.00029
[2025-04-08 14:05:09,033 INFO misc.py line 113 3298914] Train: [1/100][1736/2402] Data 0.004 (0.004) Batch 0.480 (0.479) Remain 31:42:49 loss: 1.9460 Lr: 0.00029
[2025-04-08 14:05:09,458 INFO misc.py line 113 3298914] Train: [1/100][1737/2402] Data 0.003 (0.004) Batch 0.425 (0.479) Remain 31:42:41 loss: 1.4598 Lr: 0.00029
[2025-04-08 14:05:09,926 INFO misc.py line 113 3298914] Train: [1/100][1738/2402] Data 0.003 (0.004) Batch 0.468 (0.479) Remain 31:42:39 loss: 1.3741 Lr: 0.00029
[2025-04-08 14:05:10,368 INFO misc.py line 113 3298914] Train: [1/100][1739/2402] Data 0.004 (0.004) Batch 0.442 (0.479) Remain 31:42:34 loss: 1.5121 Lr: 0.00029
[2025-04-08 14:05:10,747 INFO misc.py line 113 3298914] Train: [1/100][1740/2402] Data 0.003 (0.004) Batch 0.379 (0.479) Remain 31:42:20 loss: 1.5509 Lr: 0.00029
[2025-04-08 14:05:11,067 INFO misc.py line 113 3298914] Train: [1/100][1741/2402] Data 0.004 (0.004) Batch 0.320 (0.479) Remain 31:41:58 loss: 1.3824 Lr: 0.00029
[2025-04-08 14:05:11,525 INFO misc.py line 113 3298914] Train: [1/100][1742/2402] Data 0.004 (0.004) Batch 0.459 (0.479) Remain 31:41:54 loss: 1.6865 Lr: 0.00029
[2025-04-08 14:05:12,068 INFO misc.py line 113 3298914] Train: [1/100][1743/2402] Data 0.003 (0.004) Batch 0.543 (0.479) Remain 31:42:03 loss: 1.9655 Lr: 0.00029
[2025-04-08 14:05:12,507 INFO misc.py line 113 3298914] Train: [1/100][1744/2402] Data 0.003 (0.004) Batch 0.439 (0.479) Remain 31:41:57 loss: 1.4074 Lr: 0.00029
[2025-04-08 14:05:13,020 INFO misc.py line 113 3298914] Train: [1/100][1745/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:42:01 loss: 1.7023 Lr: 0.00029
[2025-04-08 14:05:13,499 INFO misc.py line 113 3298914] Train: [1/100][1746/2402] Data 0.003 (0.004) Batch 0.478 (0.479) Remain 31:42:00 loss: 1.5489 Lr: 0.00029
[2025-04-08 14:05:13,987 INFO misc.py line 113 3298914] Train: [1/100][1747/2402] Data 0.004 (0.004) Batch 0.488 (0.479) Remain 31:42:01 loss: 1.8722 Lr: 0.00029
[2025-04-08 14:05:14,455 INFO misc.py line 113 3298914] Train: [1/100][1748/2402] Data 0.004 (0.004) Batch 0.468 (0.479) Remain 31:41:59 loss: 1.3205 Lr: 0.00029
[2025-04-08 14:05:15,014 INFO misc.py line 113 3298914] Train: [1/100][1749/2402] Data 0.003 (0.004) Batch 0.560 (0.479) Remain 31:42:10 loss: 1.5117 Lr: 0.00029
[2025-04-08 14:05:15,511 INFO misc.py line 113 3298914] Train: [1/100][1750/2402] Data 0.003 (0.004) Batch 0.497 (0.479) Remain 31:42:12 loss: 1.8107 Lr: 0.00029
[2025-04-08 14:05:15,907 INFO misc.py line 113 3298914] Train: [1/100][1751/2402] Data 0.004 (0.004) Batch 0.395 (0.479) Remain 31:42:00 loss: 1.4018 Lr: 0.00029
[2025-04-08 14:05:16,393 INFO misc.py line 113 3298914] Train: [1/100][1752/2402] Data 0.004 (0.004) Batch 0.486 (0.479) Remain 31:42:01 loss: 1.4239 Lr: 0.00029
[2025-04-08 14:05:16,893 INFO misc.py line 113 3298914] Train: [1/100][1753/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:42:03 loss: 1.9055 Lr: 0.00029
[2025-04-08 14:05:17,439 INFO misc.py line 113 3298914] Train: [1/100][1754/2402] Data 0.003 (0.004) Batch 0.546 (0.479) Remain 31:42:12 loss: 1.4315 Lr: 0.00029
[2025-04-08 14:05:17,903 INFO misc.py line 113 3298914] Train: [1/100][1755/2402] Data 0.004 (0.004) Batch 0.463 (0.479) Remain 31:42:09 loss: 1.3684 Lr: 0.00029
[2025-04-08 14:05:18,363 INFO misc.py line 113 3298914] Train: [1/100][1756/2402] Data 0.004 (0.004) Batch 0.460 (0.479) Remain 31:42:06 loss: 1.4986 Lr: 0.00029
[2025-04-08 14:05:18,798 INFO misc.py line 113 3298914] Train: [1/100][1757/2402] Data 0.004 (0.004) Batch 0.436 (0.479) Remain 31:42:00 loss: 1.9269 Lr: 0.00029
[2025-04-08 14:05:19,345 INFO misc.py line 113 3298914] Train: [1/100][1758/2402] Data 0.003 (0.004) Batch 0.547 (0.479) Remain 31:42:09 loss: 1.3944 Lr: 0.00029
[2025-04-08 14:05:19,774 INFO misc.py line 113 3298914] Train: [1/100][1759/2402] Data 0.004 (0.004) Batch 0.429 (0.479) Remain 31:42:02 loss: 1.6679 Lr: 0.00029
[2025-04-08 14:05:20,322 INFO misc.py line 113 3298914] Train: [1/100][1760/2402] Data 0.003 (0.004) Batch 0.548 (0.479) Remain 31:42:10 loss: 1.7131 Lr: 0.00029
[2025-04-08 14:05:20,858 INFO misc.py line 113 3298914] Train: [1/100][1761/2402] Data 0.003 (0.004) Batch 0.536 (0.479) Remain 31:42:18 loss: 1.5304 Lr: 0.00029
[2025-04-08 14:05:21,262 INFO misc.py line 113 3298914] Train: [1/100][1762/2402] Data 0.004 (0.004) Batch 0.404 (0.479) Remain 31:42:07 loss: 1.5764 Lr: 0.00029
[2025-04-08 14:05:21,713 INFO misc.py line 113 3298914] Train: [1/100][1763/2402] Data 0.003 (0.004) Batch 0.451 (0.479) Remain 31:42:03 loss: 1.4121 Lr: 0.00029
[2025-04-08 14:05:22,178 INFO misc.py line 113 3298914] Train: [1/100][1764/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:42:01 loss: 1.4594 Lr: 0.00029
[2025-04-08 14:05:22,610 INFO misc.py line 113 3298914] Train: [1/100][1765/2402] Data 0.004 (0.004) Batch 0.432 (0.479) Remain 31:41:54 loss: 1.8455 Lr: 0.00029
[2025-04-08 14:05:23,109 INFO misc.py line 113 3298914] Train: [1/100][1766/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:41:56 loss: 1.8761 Lr: 0.00029
[2025-04-08 14:05:23,652 INFO misc.py line 113 3298914] Train: [1/100][1767/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:42:04 loss: 1.4207 Lr: 0.00029
[2025-04-08 14:05:24,074 INFO misc.py line 113 3298914] Train: [1/100][1768/2402] Data 0.004 (0.004) Batch 0.422 (0.479) Remain 31:41:56 loss: 1.3562 Lr: 0.00029
[2025-04-08 14:05:24,548 INFO misc.py line 113 3298914] Train: [1/100][1769/2402] Data 0.003 (0.004) Batch 0.474 (0.479) Remain 31:41:55 loss: 1.3087 Lr: 0.00029
[2025-04-08 14:05:25,065 INFO misc.py line 113 3298914] Train: [1/100][1770/2402] Data 0.003 (0.004) Batch 0.516 (0.479) Remain 31:42:00 loss: 1.4716 Lr: 0.00029
[2025-04-08 14:05:25,629 INFO misc.py line 113 3298914] Train: [1/100][1771/2402] Data 0.003 (0.004) Batch 0.565 (0.479) Remain 31:42:11 loss: 1.6434 Lr: 0.00029
[2025-04-08 14:05:26,041 INFO misc.py line 113 3298914] Train: [1/100][1772/2402] Data 0.003 (0.004) Batch 0.411 (0.479) Remain 31:42:01 loss: 1.5210 Lr: 0.00029
[2025-04-08 14:05:26,639 INFO misc.py line 113 3298914] Train: [1/100][1773/2402] Data 0.004 (0.004) Batch 0.598 (0.479) Remain 31:42:17 loss: 1.5330 Lr: 0.00029
[2025-04-08 14:05:27,200 INFO misc.py line 113 3298914] Train: [1/100][1774/2402] Data 0.003 (0.004) Batch 0.561 (0.479) Remain 31:42:28 loss: 1.4918 Lr: 0.00029
[2025-04-08 14:05:27,664 INFO misc.py line 113 3298914] Train: [1/100][1775/2402] Data 0.004 (0.004) Batch 0.464 (0.479) Remain 31:42:25 loss: 1.8000 Lr: 0.00029
[2025-04-08 14:05:28,056 INFO misc.py line 113 3298914] Train: [1/100][1776/2402] Data 0.003 (0.004) Batch 0.392 (0.479) Remain 31:42:13 loss: 1.4283 Lr: 0.00030
[2025-04-08 14:05:28,433 INFO misc.py line 113 3298914] Train: [1/100][1777/2402] Data 0.003 (0.004) Batch 0.377 (0.479) Remain 31:41:59 loss: 1.4713 Lr: 0.00030
[2025-04-08 14:05:28,925 INFO misc.py line 113 3298914] Train: [1/100][1778/2402] Data 0.004 (0.004) Batch 0.492 (0.479) Remain 31:42:00 loss: 1.9337 Lr: 0.00030
[2025-04-08 14:05:29,343 INFO misc.py line 113 3298914] Train: [1/100][1779/2402] Data 0.003 (0.004) Batch 0.418 (0.479) Remain 31:41:51 loss: 1.3807 Lr: 0.00030
[2025-04-08 14:05:29,649 INFO misc.py line 113 3298914] Train: [1/100][1780/2402] Data 0.003 (0.004) Batch 0.307 (0.479) Remain 31:41:28 loss: 1.4620 Lr: 0.00030
[2025-04-08 14:05:30,086 INFO misc.py line 113 3298914] Train: [1/100][1781/2402] Data 0.003 (0.004) Batch 0.437 (0.478) Remain 31:41:22 loss: 1.1856 Lr: 0.00030
[2025-04-08 14:05:30,547 INFO misc.py line 113 3298914] Train: [1/100][1782/2402] Data 0.003 (0.004) Batch 0.461 (0.478) Remain 31:41:19 loss: 1.1449 Lr: 0.00030
[2025-04-08 14:05:31,098 INFO misc.py line 113 3298914] Train: [1/100][1783/2402] Data 0.003 (0.004) Batch 0.550 (0.479) Remain 31:41:28 loss: 1.4121 Lr: 0.00030
[2025-04-08 14:05:31,546 INFO misc.py line 113 3298914] Train: [1/100][1784/2402] Data 0.004 (0.004) Batch 0.448 (0.479) Remain 31:41:24 loss: 1.4765 Lr: 0.00030
[2025-04-08 14:05:32,071 INFO misc.py line 113 3298914] Train: [1/100][1785/2402] Data 0.004 (0.004) Batch 0.526 (0.479) Remain 31:41:29 loss: 1.5479 Lr: 0.00030
[2025-04-08 14:05:32,494 INFO misc.py line 113 3298914] Train: [1/100][1786/2402] Data 0.004 (0.004) Batch 0.423 (0.479) Remain 31:41:22 loss: 1.4302 Lr: 0.00030
[2025-04-08 14:05:33,005 INFO misc.py line 113 3298914] Train: [1/100][1787/2402] Data 0.004 (0.004) Batch 0.511 (0.479) Remain 31:41:25 loss: 1.4722 Lr: 0.00030
[2025-04-08 14:05:33,561 INFO misc.py line 113 3298914] Train: [1/100][1788/2402] Data 0.004 (0.004) Batch 0.556 (0.479) Remain 31:41:35 loss: 1.3936 Lr: 0.00030
[2025-04-08 14:05:34,040 INFO misc.py line 113 3298914] Train: [1/100][1789/2402] Data 0.003 (0.004) Batch 0.479 (0.479) Remain 31:41:35 loss: 1.3724 Lr: 0.00030
[2025-04-08 14:05:34,600 INFO misc.py line 113 3298914] Train: [1/100][1790/2402] Data 0.004 (0.004) Batch 0.560 (0.479) Remain 31:41:45 loss: 1.6058 Lr: 0.00030
[2025-04-08 14:05:34,980 INFO misc.py line 113 3298914] Train: [1/100][1791/2402] Data 0.003 (0.004) Batch 0.380 (0.479) Remain 31:41:32 loss: 1.7234 Lr: 0.00030
[2025-04-08 14:05:35,449 INFO misc.py line 113 3298914] Train: [1/100][1792/2402] Data 0.003 (0.004) Batch 0.469 (0.479) Remain 31:41:30 loss: 1.7785 Lr: 0.00030
[2025-04-08 14:05:35,881 INFO misc.py line 113 3298914] Train: [1/100][1793/2402] Data 0.004 (0.004) Batch 0.432 (0.479) Remain 31:41:23 loss: 1.2787 Lr: 0.00030
[2025-04-08 14:05:36,369 INFO misc.py line 113 3298914] Train: [1/100][1794/2402] Data 0.003 (0.004) Batch 0.488 (0.479) Remain 31:41:24 loss: 1.6218 Lr: 0.00030
[2025-04-08 14:05:36,815 INFO misc.py line 113 3298914] Train: [1/100][1795/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:41:19 loss: 1.7423 Lr: 0.00030
[2025-04-08 14:05:37,276 INFO misc.py line 113 3298914] Train: [1/100][1796/2402] Data 0.004 (0.004) Batch 0.462 (0.479) Remain 31:41:16 loss: 1.4484 Lr: 0.00030
[2025-04-08 14:05:37,685 INFO misc.py line 113 3298914] Train: [1/100][1797/2402] Data 0.004 (0.004) Batch 0.408 (0.478) Remain 31:41:07 loss: 1.4743 Lr: 0.00030
[2025-04-08 14:05:38,287 INFO misc.py line 113 3298914] Train: [1/100][1798/2402] Data 0.004 (0.004) Batch 0.603 (0.479) Remain 31:41:23 loss: 2.0769 Lr: 0.00030
[2025-04-08 14:05:38,784 INFO misc.py line 113 3298914] Train: [1/100][1799/2402] Data 0.003 (0.004) Batch 0.497 (0.479) Remain 31:41:25 loss: 1.4637 Lr: 0.00030
[2025-04-08 14:05:39,141 INFO misc.py line 113 3298914] Train: [1/100][1800/2402] Data 0.004 (0.004) Batch 0.358 (0.478) Remain 31:41:08 loss: 1.5016 Lr: 0.00030
[2025-04-08 14:05:39,505 INFO misc.py line 113 3298914] Train: [1/100][1801/2402] Data 0.003 (0.004) Batch 0.363 (0.478) Remain 31:40:52 loss: 1.4427 Lr: 0.00030
[2025-04-08 14:05:39,866 INFO misc.py line 113 3298914] Train: [1/100][1802/2402] Data 0.003 (0.004) Batch 0.362 (0.478) Remain 31:40:36 loss: 1.5375 Lr: 0.00030
[2025-04-08 14:05:40,407 INFO misc.py line 113 3298914] Train: [1/100][1803/2402] Data 0.004 (0.004) Batch 0.541 (0.478) Remain 31:40:44 loss: 1.9063 Lr: 0.00030
[2025-04-08 14:05:40,886 INFO misc.py line 113 3298914] Train: [1/100][1804/2402] Data 0.003 (0.004) Batch 0.480 (0.478) Remain 31:40:44 loss: 1.5283 Lr: 0.00030
[2025-04-08 14:05:41,414 INFO misc.py line 113 3298914] Train: [1/100][1805/2402] Data 0.003 (0.004) Batch 0.528 (0.478) Remain 31:40:50 loss: 1.9479 Lr: 0.00030
[2025-04-08 14:05:41,938 INFO misc.py line 113 3298914] Train: [1/100][1806/2402] Data 0.004 (0.004) Batch 0.523 (0.478) Remain 31:40:55 loss: 1.6771 Lr: 0.00030
[2025-04-08 14:05:42,459 INFO misc.py line 113 3298914] Train: [1/100][1807/2402] Data 0.004 (0.004) Batch 0.521 (0.478) Remain 31:41:00 loss: 1.4793 Lr: 0.00030
[2025-04-08 14:05:42,884 INFO misc.py line 113 3298914] Train: [1/100][1808/2402] Data 0.004 (0.004) Batch 0.425 (0.478) Remain 31:40:53 loss: 1.3477 Lr: 0.00030
[2025-04-08 14:05:43,393 INFO misc.py line 113 3298914] Train: [1/100][1809/2402] Data 0.004 (0.004) Batch 0.509 (0.478) Remain 31:40:56 loss: 1.2191 Lr: 0.00030
[2025-04-08 14:05:43,941 INFO misc.py line 113 3298914] Train: [1/100][1810/2402] Data 0.003 (0.004) Batch 0.548 (0.478) Remain 31:41:05 loss: 1.6302 Lr: 0.00030
[2025-04-08 14:05:44,344 INFO misc.py line 113 3298914] Train: [1/100][1811/2402] Data 0.004 (0.004) Batch 0.404 (0.478) Remain 31:40:55 loss: 1.1484 Lr: 0.00030
[2025-04-08 14:05:44,696 INFO misc.py line 113 3298914] Train: [1/100][1812/2402] Data 0.003 (0.004) Batch 0.352 (0.478) Remain 31:40:38 loss: 1.4013 Lr: 0.00030
[2025-04-08 14:05:45,247 INFO misc.py line 113 3298914] Train: [1/100][1813/2402] Data 0.003 (0.004) Batch 0.550 (0.478) Remain 31:40:47 loss: 1.7748 Lr: 0.00030
[2025-04-08 14:05:45,653 INFO misc.py line 113 3298914] Train: [1/100][1814/2402] Data 0.004 (0.004) Batch 0.407 (0.478) Remain 31:40:37 loss: 1.2142 Lr: 0.00030
[2025-04-08 14:05:46,115 INFO misc.py line 113 3298914] Train: [1/100][1815/2402] Data 0.003 (0.004) Batch 0.462 (0.478) Remain 31:40:34 loss: 1.3399 Lr: 0.00030
[2025-04-08 14:05:46,492 INFO misc.py line 113 3298914] Train: [1/100][1816/2402] Data 0.003 (0.004) Batch 0.377 (0.478) Remain 31:40:20 loss: 1.6055 Lr: 0.00030
[2025-04-08 14:05:46,969 INFO misc.py line 113 3298914] Train: [1/100][1817/2402] Data 0.004 (0.004) Batch 0.477 (0.478) Remain 31:40:20 loss: 1.5893 Lr: 0.00030
[2025-04-08 14:05:47,394 INFO misc.py line 113 3298914] Train: [1/100][1818/2402] Data 0.004 (0.004) Batch 0.425 (0.478) Remain 31:40:12 loss: 1.5104 Lr: 0.00030
[2025-04-08 14:05:47,926 INFO misc.py line 113 3298914] Train: [1/100][1819/2402] Data 0.003 (0.004) Batch 0.532 (0.478) Remain 31:40:19 loss: 1.4901 Lr: 0.00030
[2025-04-08 14:05:48,461 INFO misc.py line 113 3298914] Train: [1/100][1820/2402] Data 0.003 (0.004) Batch 0.535 (0.478) Remain 31:40:26 loss: 1.5542 Lr: 0.00030
[2025-04-08 14:05:48,981 INFO misc.py line 113 3298914] Train: [1/100][1821/2402] Data 0.003 (0.004) Batch 0.520 (0.478) Remain 31:40:31 loss: 1.5563 Lr: 0.00030
[2025-04-08 14:05:49,483 INFO misc.py line 113 3298914] Train: [1/100][1822/2402] Data 0.004 (0.004) Batch 0.503 (0.478) Remain 31:40:33 loss: 1.2577 Lr: 0.00030
[2025-04-08 14:05:49,988 INFO misc.py line 113 3298914] Train: [1/100][1823/2402] Data 0.003 (0.004) Batch 0.504 (0.478) Remain 31:40:36 loss: 1.6442 Lr: 0.00030
[2025-04-08 14:05:50,497 INFO misc.py line 113 3298914] Train: [1/100][1824/2402] Data 0.003 (0.004) Batch 0.509 (0.478) Remain 31:40:40 loss: 1.3510 Lr: 0.00030
[2025-04-08 14:05:51,006 INFO misc.py line 113 3298914] Train: [1/100][1825/2402] Data 0.003 (0.004) Batch 0.510 (0.478) Remain 31:40:43 loss: 1.7010 Lr: 0.00030
[2025-04-08 14:05:51,513 INFO misc.py line 113 3298914] Train: [1/100][1826/2402] Data 0.003 (0.004) Batch 0.507 (0.478) Remain 31:40:47 loss: 1.1295 Lr: 0.00030
[2025-04-08 14:05:52,019 INFO misc.py line 113 3298914] Train: [1/100][1827/2402] Data 0.004 (0.004) Batch 0.506 (0.478) Remain 31:40:50 loss: 1.4383 Lr: 0.00030
[2025-04-08 14:05:52,420 INFO misc.py line 113 3298914] Train: [1/100][1828/2402] Data 0.004 (0.004) Batch 0.401 (0.478) Remain 31:40:39 loss: 1.6641 Lr: 0.00030
[2025-04-08 14:05:52,954 INFO misc.py line 113 3298914] Train: [1/100][1829/2402] Data 0.003 (0.004) Batch 0.533 (0.478) Remain 31:40:46 loss: 1.7390 Lr: 0.00030
[2025-04-08 14:05:53,528 INFO misc.py line 113 3298914] Train: [1/100][1830/2402] Data 0.005 (0.004) Batch 0.574 (0.478) Remain 31:40:58 loss: 1.3461 Lr: 0.00030
[2025-04-08 14:05:53,941 INFO misc.py line 113 3298914] Train: [1/100][1831/2402] Data 0.003 (0.004) Batch 0.413 (0.478) Remain 31:40:49 loss: 1.8921 Lr: 0.00030
[2025-04-08 14:05:54,442 INFO misc.py line 113 3298914] Train: [1/100][1832/2402] Data 0.003 (0.004) Batch 0.501 (0.478) Remain 31:40:51 loss: 1.4135 Lr: 0.00030
[2025-04-08 14:05:54,775 INFO misc.py line 113 3298914] Train: [1/100][1833/2402] Data 0.003 (0.004) Batch 0.332 (0.478) Remain 31:40:32 loss: 1.5513 Lr: 0.00030
[2025-04-08 14:05:55,260 INFO misc.py line 113 3298914] Train: [1/100][1834/2402] Data 0.004 (0.004) Batch 0.486 (0.478) Remain 31:40:32 loss: 1.4647 Lr: 0.00030
[2025-04-08 14:05:55,658 INFO misc.py line 113 3298914] Train: [1/100][1835/2402] Data 0.003 (0.004) Batch 0.398 (0.478) Remain 31:40:21 loss: 1.4152 Lr: 0.00030
[2025-04-08 14:05:56,064 INFO misc.py line 113 3298914] Train: [1/100][1836/2402] Data 0.004 (0.004) Batch 0.406 (0.478) Remain 31:40:11 loss: 1.1741 Lr: 0.00030
[2025-04-08 14:05:56,495 INFO misc.py line 113 3298914] Train: [1/100][1837/2402] Data 0.004 (0.004) Batch 0.431 (0.478) Remain 31:40:05 loss: 1.6072 Lr: 0.00030
[2025-04-08 14:05:56,949 INFO misc.py line 113 3298914] Train: [1/100][1838/2402] Data 0.003 (0.004) Batch 0.455 (0.478) Remain 31:40:01 loss: 1.9383 Lr: 0.00030
[2025-04-08 14:05:57,496 INFO misc.py line 113 3298914] Train: [1/100][1839/2402] Data 0.004 (0.004) Batch 0.546 (0.478) Remain 31:40:10 loss: 1.3454 Lr: 0.00030
[2025-04-08 14:05:58,085 INFO misc.py line 113 3298914] Train: [1/100][1840/2402] Data 0.004 (0.004) Batch 0.590 (0.478) Remain 31:40:24 loss: 1.2428 Lr: 0.00030
[2025-04-08 14:05:58,616 INFO misc.py line 113 3298914] Train: [1/100][1841/2402] Data 0.004 (0.004) Batch 0.531 (0.478) Remain 31:40:30 loss: 1.6514 Lr: 0.00030
[2025-04-08 14:05:59,258 INFO misc.py line 113 3298914] Train: [1/100][1842/2402] Data 0.004 (0.004) Batch 0.642 (0.478) Remain 31:40:51 loss: 1.4562 Lr: 0.00030
[2025-04-08 14:05:59,787 INFO misc.py line 113 3298914] Train: [1/100][1843/2402] Data 0.004 (0.004) Batch 0.529 (0.479) Remain 31:40:57 loss: 1.7298 Lr: 0.00030
[2025-04-08 14:06:00,224 INFO misc.py line 113 3298914] Train: [1/100][1844/2402] Data 0.004 (0.004) Batch 0.437 (0.478) Remain 31:40:51 loss: 1.3735 Lr: 0.00030
[2025-04-08 14:06:00,664 INFO misc.py line 113 3298914] Train: [1/100][1845/2402] Data 0.004 (0.004) Batch 0.440 (0.478) Remain 31:40:45 loss: 1.2451 Lr: 0.00030
[2025-04-08 14:06:01,287 INFO misc.py line 113 3298914] Train: [1/100][1846/2402] Data 0.004 (0.004) Batch 0.623 (0.479) Remain 31:41:04 loss: 1.5512 Lr: 0.00030
[2025-04-08 14:06:01,866 INFO misc.py line 113 3298914] Train: [1/100][1847/2402] Data 0.003 (0.004) Batch 0.579 (0.479) Remain 31:41:16 loss: 1.7786 Lr: 0.00030
[2025-04-08 14:06:02,261 INFO misc.py line 113 3298914] Train: [1/100][1848/2402] Data 0.004 (0.004) Batch 0.395 (0.479) Remain 31:41:05 loss: 1.4683 Lr: 0.00030
[2025-04-08 14:06:02,818 INFO misc.py line 113 3298914] Train: [1/100][1849/2402] Data 0.003 (0.004) Batch 0.557 (0.479) Remain 31:41:14 loss: 1.9274 Lr: 0.00030
[2025-04-08 14:06:03,333 INFO misc.py line 113 3298914] Train: [1/100][1850/2402] Data 0.003 (0.004) Batch 0.515 (0.479) Remain 31:41:19 loss: 1.8168 Lr: 0.00030
[2025-04-08 14:06:03,833 INFO misc.py line 113 3298914] Train: [1/100][1851/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:41:21 loss: 1.4912 Lr: 0.00030
[2025-04-08 14:06:04,277 INFO misc.py line 113 3298914] Train: [1/100][1852/2402] Data 0.003 (0.004) Batch 0.444 (0.479) Remain 31:41:16 loss: 1.2633 Lr: 0.00030
[2025-04-08 14:06:04,651 INFO misc.py line 113 3298914] Train: [1/100][1853/2402] Data 0.003 (0.004) Batch 0.374 (0.479) Remain 31:41:02 loss: 1.6886 Lr: 0.00030
[2025-04-08 14:06:05,183 INFO misc.py line 113 3298914] Train: [1/100][1854/2402] Data 0.003 (0.004) Batch 0.532 (0.479) Remain 31:41:08 loss: 1.2225 Lr: 0.00030
[2025-04-08 14:06:05,585 INFO misc.py line 113 3298914] Train: [1/100][1855/2402] Data 0.003 (0.004) Batch 0.402 (0.479) Remain 31:40:58 loss: 2.1430 Lr: 0.00030
[2025-04-08 14:06:06,069 INFO misc.py line 113 3298914] Train: [1/100][1856/2402] Data 0.003 (0.004) Batch 0.484 (0.479) Remain 31:40:58 loss: 1.7535 Lr: 0.00030
[2025-04-08 14:06:06,588 INFO misc.py line 113 3298914] Train: [1/100][1857/2402] Data 0.003 (0.004) Batch 0.519 (0.479) Remain 31:41:03 loss: 1.4091 Lr: 0.00030
[2025-04-08 14:06:07,056 INFO misc.py line 113 3298914] Train: [1/100][1858/2402] Data 0.004 (0.004) Batch 0.469 (0.479) Remain 31:41:01 loss: 1.3873 Lr: 0.00030
[2025-04-08 14:06:07,546 INFO misc.py line 113 3298914] Train: [1/100][1859/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:41:02 loss: 1.4317 Lr: 0.00030
[2025-04-08 14:06:08,036 INFO misc.py line 113 3298914] Train: [1/100][1860/2402] Data 0.004 (0.004) Batch 0.490 (0.479) Remain 31:41:03 loss: 1.6380 Lr: 0.00030
[2025-04-08 14:06:08,527 INFO misc.py line 113 3298914] Train: [1/100][1861/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:41:04 loss: 1.6203 Lr: 0.00030
[2025-04-08 14:06:09,043 INFO misc.py line 113 3298914] Train: [1/100][1862/2402] Data 0.004 (0.004) Batch 0.516 (0.479) Remain 31:41:09 loss: 1.6472 Lr: 0.00030
[2025-04-08 14:06:09,528 INFO misc.py line 113 3298914] Train: [1/100][1863/2402] Data 0.003 (0.004) Batch 0.485 (0.479) Remain 31:41:09 loss: 1.6043 Lr: 0.00030
[2025-04-08 14:06:10,065 INFO misc.py line 113 3298914] Train: [1/100][1864/2402] Data 0.004 (0.004) Batch 0.537 (0.479) Remain 31:41:16 loss: 1.9903 Lr: 0.00030
[2025-04-08 14:06:10,496 INFO misc.py line 113 3298914] Train: [1/100][1865/2402] Data 0.003 (0.004) Batch 0.431 (0.479) Remain 31:41:09 loss: 1.3970 Lr: 0.00030
[2025-04-08 14:06:11,031 INFO misc.py line 113 3298914] Train: [1/100][1866/2402] Data 0.003 (0.004) Batch 0.535 (0.479) Remain 31:41:16 loss: 1.4362 Lr: 0.00030
[2025-04-08 14:06:11,488 INFO misc.py line 113 3298914] Train: [1/100][1867/2402] Data 0.004 (0.004) Batch 0.457 (0.479) Remain 31:41:13 loss: 1.4143 Lr: 0.00030
[2025-04-08 14:06:11,906 INFO misc.py line 113 3298914] Train: [1/100][1868/2402] Data 0.004 (0.004) Batch 0.418 (0.479) Remain 31:41:05 loss: 2.0526 Lr: 0.00031
[2025-04-08 14:06:12,455 INFO misc.py line 113 3298914] Train: [1/100][1869/2402] Data 0.004 (0.004) Batch 0.549 (0.479) Remain 31:41:13 loss: 1.5836 Lr: 0.00031
[2025-04-08 14:06:12,833 INFO misc.py line 113 3298914] Train: [1/100][1870/2402] Data 0.003 (0.004) Batch 0.378 (0.479) Remain 31:41:00 loss: 1.8714 Lr: 0.00031
[2025-04-08 14:06:13,300 INFO misc.py line 113 3298914] Train: [1/100][1871/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:40:58 loss: 1.6029 Lr: 0.00031
[2025-04-08 14:06:13,781 INFO misc.py line 113 3298914] Train: [1/100][1872/2402] Data 0.004 (0.004) Batch 0.482 (0.479) Remain 31:40:58 loss: 1.4021 Lr: 0.00031
[2025-04-08 14:06:14,259 INFO misc.py line 113 3298914] Train: [1/100][1873/2402] Data 0.003 (0.004) Batch 0.478 (0.479) Remain 31:40:57 loss: 1.5339 Lr: 0.00031
[2025-04-08 14:06:14,687 INFO misc.py line 113 3298914] Train: [1/100][1874/2402] Data 0.003 (0.004) Batch 0.427 (0.479) Remain 31:40:50 loss: 1.5068 Lr: 0.00031
[2025-04-08 14:06:15,100 INFO misc.py line 113 3298914] Train: [1/100][1875/2402] Data 0.003 (0.004) Batch 0.414 (0.479) Remain 31:40:41 loss: 1.1462 Lr: 0.00031
[2025-04-08 14:06:15,630 INFO misc.py line 113 3298914] Train: [1/100][1876/2402] Data 0.003 (0.004) Batch 0.529 (0.479) Remain 31:40:47 loss: 1.8584 Lr: 0.00031
[2025-04-08 14:06:16,137 INFO misc.py line 113 3298914] Train: [1/100][1877/2402] Data 0.004 (0.004) Batch 0.507 (0.479) Remain 31:40:51 loss: 1.2449 Lr: 0.00031
[2025-04-08 14:06:16,598 INFO misc.py line 113 3298914] Train: [1/100][1878/2402] Data 0.003 (0.004) Batch 0.461 (0.479) Remain 31:40:48 loss: 1.6121 Lr: 0.00031
[2025-04-08 14:06:17,192 INFO misc.py line 113 3298914] Train: [1/100][1879/2402] Data 0.004 (0.004) Batch 0.594 (0.479) Remain 31:41:02 loss: 1.4697 Lr: 0.00031
[2025-04-08 14:06:17,720 INFO misc.py line 113 3298914] Train: [1/100][1880/2402] Data 0.004 (0.004) Batch 0.529 (0.479) Remain 31:41:08 loss: 1.4517 Lr: 0.00031
[2025-04-08 14:06:18,095 INFO misc.py line 113 3298914] Train: [1/100][1881/2402] Data 0.003 (0.004) Batch 0.375 (0.479) Remain 31:40:54 loss: 1.4579 Lr: 0.00031
[2025-04-08 14:06:18,591 INFO misc.py line 113 3298914] Train: [1/100][1882/2402] Data 0.003 (0.004) Batch 0.496 (0.479) Remain 31:40:56 loss: 1.7421 Lr: 0.00031
[2025-04-08 14:06:19,116 INFO misc.py line 113 3298914] Train: [1/100][1883/2402] Data 0.004 (0.004) Batch 0.524 (0.479) Remain 31:41:01 loss: 1.6180 Lr: 0.00031
[2025-04-08 14:06:19,564 INFO misc.py line 113 3298914] Train: [1/100][1884/2402] Data 0.003 (0.004) Batch 0.448 (0.479) Remain 31:40:57 loss: 1.2782 Lr: 0.00031
[2025-04-08 14:06:20,141 INFO misc.py line 113 3298914] Train: [1/100][1885/2402] Data 0.003 (0.004) Batch 0.577 (0.479) Remain 31:41:09 loss: 1.3624 Lr: 0.00031
[2025-04-08 14:06:20,621 INFO misc.py line 113 3298914] Train: [1/100][1886/2402] Data 0.003 (0.004) Batch 0.480 (0.479) Remain 31:41:09 loss: 1.3412 Lr: 0.00031
[2025-04-08 14:06:21,127 INFO misc.py line 113 3298914] Train: [1/100][1887/2402] Data 0.004 (0.004) Batch 0.507 (0.479) Remain 31:41:12 loss: 1.6280 Lr: 0.00031
[2025-04-08 14:06:21,563 INFO misc.py line 113 3298914] Train: [1/100][1888/2402] Data 0.003 (0.004) Batch 0.436 (0.479) Remain 31:41:06 loss: 1.8998 Lr: 0.00031
[2025-04-08 14:06:21,991 INFO misc.py line 113 3298914] Train: [1/100][1889/2402] Data 0.003 (0.004) Batch 0.428 (0.479) Remain 31:40:59 loss: 1.6361 Lr: 0.00031
[2025-04-08 14:06:22,458 INFO misc.py line 113 3298914] Train: [1/100][1890/2402] Data 0.003 (0.004) Batch 0.467 (0.479) Remain 31:40:57 loss: 1.4778 Lr: 0.00031
[2025-04-08 14:06:22,913 INFO misc.py line 113 3298914] Train: [1/100][1891/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:40:54 loss: 1.7891 Lr: 0.00031
[2025-04-08 14:06:23,481 INFO misc.py line 113 3298914] Train: [1/100][1892/2402] Data 0.003 (0.004) Batch 0.567 (0.479) Remain 31:41:04 loss: 1.4374 Lr: 0.00031
[2025-04-08 14:06:24,016 INFO misc.py line 113 3298914] Train: [1/100][1893/2402] Data 0.004 (0.004) Batch 0.535 (0.479) Remain 31:41:11 loss: 1.3522 Lr: 0.00031
[2025-04-08 14:06:24,460 INFO misc.py line 113 3298914] Train: [1/100][1894/2402] Data 0.003 (0.004) Batch 0.444 (0.479) Remain 31:41:06 loss: 1.0866 Lr: 0.00031
[2025-04-08 14:06:24,999 INFO misc.py line 113 3298914] Train: [1/100][1895/2402] Data 0.003 (0.004) Batch 0.539 (0.479) Remain 31:41:13 loss: 1.2697 Lr: 0.00031
[2025-04-08 14:06:25,487 INFO misc.py line 113 3298914] Train: [1/100][1896/2402] Data 0.004 (0.004) Batch 0.488 (0.479) Remain 31:41:14 loss: 1.4663 Lr: 0.00031
[2025-04-08 14:06:26,006 INFO misc.py line 113 3298914] Train: [1/100][1897/2402] Data 0.003 (0.004) Batch 0.519 (0.479) Remain 31:41:18 loss: 1.4327 Lr: 0.00031
[2025-04-08 14:06:26,539 INFO misc.py line 113 3298914] Train: [1/100][1898/2402] Data 0.004 (0.004) Batch 0.533 (0.479) Remain 31:41:25 loss: 1.5123 Lr: 0.00031
[2025-04-08 14:06:26,975 INFO misc.py line 113 3298914] Train: [1/100][1899/2402] Data 0.003 (0.004) Batch 0.436 (0.479) Remain 31:41:19 loss: 1.4406 Lr: 0.00031
[2025-04-08 14:06:27,455 INFO misc.py line 113 3298914] Train: [1/100][1900/2402] Data 0.003 (0.004) Batch 0.480 (0.479) Remain 31:41:19 loss: 1.4852 Lr: 0.00031
[2025-04-08 14:06:27,897 INFO misc.py line 113 3298914] Train: [1/100][1901/2402] Data 0.003 (0.004) Batch 0.442 (0.479) Remain 31:41:14 loss: 1.0583 Lr: 0.00031
[2025-04-08 14:06:28,484 INFO misc.py line 113 3298914] Train: [1/100][1902/2402] Data 0.003 (0.004) Batch 0.587 (0.479) Remain 31:41:27 loss: 1.3913 Lr: 0.00031
[2025-04-08 14:06:29,044 INFO misc.py line 113 3298914] Train: [1/100][1903/2402] Data 0.003 (0.004) Batch 0.560 (0.479) Remain 31:41:36 loss: 1.8098 Lr: 0.00031
[2025-04-08 14:06:29,401 INFO misc.py line 113 3298914] Train: [1/100][1904/2402] Data 0.003 (0.004) Batch 0.357 (0.479) Remain 31:41:21 loss: 1.7082 Lr: 0.00031
[2025-04-08 14:06:29,836 INFO misc.py line 113 3298914] Train: [1/100][1905/2402] Data 0.003 (0.004) Batch 0.435 (0.479) Remain 31:41:15 loss: 1.3326 Lr: 0.00031
[2025-04-08 14:06:30,286 INFO misc.py line 113 3298914] Train: [1/100][1906/2402] Data 0.003 (0.004) Batch 0.450 (0.479) Remain 31:41:11 loss: 1.4752 Lr: 0.00031
[2025-04-08 14:06:30,705 INFO misc.py line 113 3298914] Train: [1/100][1907/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:41:03 loss: 1.4381 Lr: 0.00031
[2025-04-08 14:06:31,258 INFO misc.py line 113 3298914] Train: [1/100][1908/2402] Data 0.004 (0.004) Batch 0.553 (0.479) Remain 31:41:11 loss: 1.2923 Lr: 0.00031
[2025-04-08 14:06:31,835 INFO misc.py line 113 3298914] Train: [1/100][1909/2402] Data 0.004 (0.004) Batch 0.577 (0.479) Remain 31:41:23 loss: 1.4984 Lr: 0.00031
[2025-04-08 14:06:32,204 INFO misc.py line 113 3298914] Train: [1/100][1910/2402] Data 0.003 (0.004) Batch 0.369 (0.479) Remain 31:41:09 loss: 2.0512 Lr: 0.00031
[2025-04-08 14:06:32,625 INFO misc.py line 113 3298914] Train: [1/100][1911/2402] Data 0.003 (0.004) Batch 0.421 (0.479) Remain 31:41:01 loss: 1.2404 Lr: 0.00031
[2025-04-08 14:06:33,091 INFO misc.py line 113 3298914] Train: [1/100][1912/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:40:59 loss: 1.8036 Lr: 0.00031
[2025-04-08 14:06:33,588 INFO misc.py line 113 3298914] Train: [1/100][1913/2402] Data 0.003 (0.004) Batch 0.498 (0.479) Remain 31:41:01 loss: 1.2579 Lr: 0.00031
[2025-04-08 14:06:34,146 INFO misc.py line 113 3298914] Train: [1/100][1914/2402] Data 0.003 (0.004) Batch 0.558 (0.479) Remain 31:41:11 loss: 1.6796 Lr: 0.00031
[2025-04-08 14:06:34,583 INFO misc.py line 113 3298914] Train: [1/100][1915/2402] Data 0.004 (0.004) Batch 0.436 (0.479) Remain 31:41:05 loss: 1.6301 Lr: 0.00031
[2025-04-08 14:06:35,171 INFO misc.py line 113 3298914] Train: [1/100][1916/2402] Data 0.004 (0.004) Batch 0.589 (0.479) Remain 31:41:18 loss: 1.5153 Lr: 0.00031
[2025-04-08 14:06:35,603 INFO misc.py line 113 3298914] Train: [1/100][1917/2402] Data 0.003 (0.004) Batch 0.432 (0.479) Remain 31:41:12 loss: 1.5911 Lr: 0.00031
[2025-04-08 14:06:36,098 INFO misc.py line 113 3298914] Train: [1/100][1918/2402] Data 0.004 (0.004) Batch 0.495 (0.479) Remain 31:41:13 loss: 1.3961 Lr: 0.00031
[2025-04-08 14:06:36,523 INFO misc.py line 113 3298914] Train: [1/100][1919/2402] Data 0.004 (0.004) Batch 0.425 (0.479) Remain 31:41:06 loss: 1.5214 Lr: 0.00031
[2025-04-08 14:06:36,930 INFO misc.py line 113 3298914] Train: [1/100][1920/2402] Data 0.004 (0.004) Batch 0.407 (0.479) Remain 31:40:57 loss: 1.5545 Lr: 0.00031
[2025-04-08 14:06:37,505 INFO misc.py line 113 3298914] Train: [1/100][1921/2402] Data 0.003 (0.004) Batch 0.575 (0.479) Remain 31:41:08 loss: 1.5886 Lr: 0.00031
[2025-04-08 14:06:38,053 INFO misc.py line 113 3298914] Train: [1/100][1922/2402] Data 0.004 (0.004) Batch 0.548 (0.479) Remain 31:41:16 loss: 1.4215 Lr: 0.00031
[2025-04-08 14:06:38,601 INFO misc.py line 113 3298914] Train: [1/100][1923/2402] Data 0.003 (0.004) Batch 0.548 (0.479) Remain 31:41:24 loss: 1.2478 Lr: 0.00031
[2025-04-08 14:06:39,097 INFO misc.py line 113 3298914] Train: [1/100][1924/2402] Data 0.004 (0.004) Batch 0.496 (0.479) Remain 31:41:26 loss: 1.2906 Lr: 0.00031
[2025-04-08 14:06:39,575 INFO misc.py line 113 3298914] Train: [1/100][1925/2402] Data 0.003 (0.004) Batch 0.479 (0.479) Remain 31:41:26 loss: 1.3946 Lr: 0.00031
[2025-04-08 14:06:40,092 INFO misc.py line 113 3298914] Train: [1/100][1926/2402] Data 0.003 (0.004) Batch 0.516 (0.479) Remain 31:41:30 loss: 1.1531 Lr: 0.00031
[2025-04-08 14:06:40,509 INFO misc.py line 113 3298914] Train: [1/100][1927/2402] Data 0.004 (0.004) Batch 0.418 (0.479) Remain 31:41:22 loss: 1.3279 Lr: 0.00031
[2025-04-08 14:06:40,928 INFO misc.py line 113 3298914] Train: [1/100][1928/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:41:14 loss: 1.0721 Lr: 0.00031
[2025-04-08 14:06:41,383 INFO misc.py line 113 3298914] Train: [1/100][1929/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:41:10 loss: 1.7873 Lr: 0.00031
[2025-04-08 14:06:41,759 INFO misc.py line 113 3298914] Train: [1/100][1930/2402] Data 0.003 (0.004) Batch 0.376 (0.479) Remain 31:40:57 loss: 1.1394 Lr: 0.00031
[2025-04-08 14:06:42,223 INFO misc.py line 113 3298914] Train: [1/100][1931/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:40:55 loss: 1.4084 Lr: 0.00031
[2025-04-08 14:06:42,674 INFO misc.py line 113 3298914] Train: [1/100][1932/2402] Data 0.003 (0.004) Batch 0.451 (0.479) Remain 31:40:51 loss: 1.2105 Lr: 0.00031
[2025-04-08 14:06:43,190 INFO misc.py line 113 3298914] Train: [1/100][1933/2402] Data 0.003 (0.004) Batch 0.515 (0.479) Remain 31:40:55 loss: 1.0361 Lr: 0.00031
[2025-04-08 14:06:43,576 INFO misc.py line 113 3298914] Train: [1/100][1934/2402] Data 0.003 (0.004) Batch 0.386 (0.479) Remain 31:40:43 loss: 1.9298 Lr: 0.00031
[2025-04-08 14:06:44,141 INFO misc.py line 113 3298914] Train: [1/100][1935/2402] Data 0.004 (0.004) Batch 0.565 (0.479) Remain 31:40:53 loss: 1.5209 Lr: 0.00031
[2025-04-08 14:06:44,655 INFO misc.py line 113 3298914] Train: [1/100][1936/2402] Data 0.004 (0.004) Batch 0.514 (0.479) Remain 31:40:57 loss: 1.2845 Lr: 0.00031
[2025-04-08 14:06:45,074 INFO misc.py line 113 3298914] Train: [1/100][1937/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:40:49 loss: 1.1947 Lr: 0.00031
[2025-04-08 14:06:45,657 INFO misc.py line 113 3298914] Train: [1/100][1938/2402] Data 0.003 (0.004) Batch 0.583 (0.479) Remain 31:41:02 loss: 1.6133 Lr: 0.00031
[2025-04-08 14:06:46,109 INFO misc.py line 113 3298914] Train: [1/100][1939/2402] Data 0.004 (0.004) Batch 0.453 (0.479) Remain 31:40:58 loss: 1.2625 Lr: 0.00031
[2025-04-08 14:06:46,525 INFO misc.py line 113 3298914] Train: [1/100][1940/2402] Data 0.004 (0.004) Batch 0.416 (0.479) Remain 31:40:50 loss: 1.1278 Lr: 0.00031
[2025-04-08 14:06:46,936 INFO misc.py line 113 3298914] Train: [1/100][1941/2402] Data 0.004 (0.004) Batch 0.411 (0.479) Remain 31:40:41 loss: 1.4684 Lr: 0.00031
[2025-04-08 14:06:47,402 INFO misc.py line 113 3298914] Train: [1/100][1942/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:40:39 loss: 1.3751 Lr: 0.00031
[2025-04-08 14:06:47,883 INFO misc.py line 113 3298914] Train: [1/100][1943/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:40:39 loss: 1.4044 Lr: 0.00031
[2025-04-08 14:06:48,348 INFO misc.py line 113 3298914] Train: [1/100][1944/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:40:37 loss: 1.6894 Lr: 0.00031
[2025-04-08 14:06:48,863 INFO misc.py line 113 3298914] Train: [1/100][1945/2402] Data 0.003 (0.004) Batch 0.514 (0.479) Remain 31:40:41 loss: 1.6627 Lr: 0.00031
[2025-04-08 14:06:49,324 INFO misc.py line 113 3298914] Train: [1/100][1946/2402] Data 0.004 (0.004) Batch 0.461 (0.479) Remain 31:40:38 loss: 1.3374 Lr: 0.00031
[2025-04-08 14:06:49,826 INFO misc.py line 113 3298914] Train: [1/100][1947/2402] Data 0.004 (0.004) Batch 0.502 (0.479) Remain 31:40:40 loss: 1.6941 Lr: 0.00031
[2025-04-08 14:06:50,353 INFO misc.py line 113 3298914] Train: [1/100][1948/2402] Data 0.003 (0.004) Batch 0.527 (0.479) Remain 31:40:46 loss: 1.6251 Lr: 0.00031
[2025-04-08 14:06:50,857 INFO misc.py line 113 3298914] Train: [1/100][1949/2402] Data 0.003 (0.004) Batch 0.504 (0.479) Remain 31:40:48 loss: 1.1063 Lr: 0.00031
[2025-04-08 14:06:51,270 INFO misc.py line 113 3298914] Train: [1/100][1950/2402] Data 0.003 (0.004) Batch 0.413 (0.479) Remain 31:40:40 loss: 1.1702 Lr: 0.00031
[2025-04-08 14:06:51,708 INFO misc.py line 113 3298914] Train: [1/100][1951/2402] Data 0.003 (0.004) Batch 0.438 (0.479) Remain 31:40:34 loss: 1.6185 Lr: 0.00031
[2025-04-08 14:06:52,235 INFO misc.py line 113 3298914] Train: [1/100][1952/2402] Data 0.003 (0.004) Batch 0.528 (0.479) Remain 31:40:40 loss: 1.3319 Lr: 0.00031
[2025-04-08 14:06:52,702 INFO misc.py line 113 3298914] Train: [1/100][1953/2402] Data 0.003 (0.004) Batch 0.466 (0.479) Remain 31:40:38 loss: 1.0357 Lr: 0.00031
[2025-04-08 14:06:53,131 INFO misc.py line 113 3298914] Train: [1/100][1954/2402] Data 0.003 (0.004) Batch 0.429 (0.479) Remain 31:40:31 loss: 1.8026 Lr: 0.00031
[2025-04-08 14:06:53,548 INFO misc.py line 113 3298914] Train: [1/100][1955/2402] Data 0.004 (0.004) Batch 0.417 (0.479) Remain 31:40:23 loss: 1.4245 Lr: 0.00031
[2025-04-08 14:06:53,992 INFO misc.py line 113 3298914] Train: [1/100][1956/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:40:19 loss: 1.6653 Lr: 0.00031
[2025-04-08 14:06:54,482 INFO misc.py line 113 3298914] Train: [1/100][1957/2402] Data 0.003 (0.004) Batch 0.490 (0.479) Remain 31:40:20 loss: 1.3932 Lr: 0.00032
[2025-04-08 14:06:54,955 INFO misc.py line 113 3298914] Train: [1/100][1958/2402] Data 0.003 (0.004) Batch 0.472 (0.479) Remain 31:40:18 loss: 1.5876 Lr: 0.00032
[2025-04-08 14:06:55,393 INFO misc.py line 113 3298914] Train: [1/100][1959/2402] Data 0.004 (0.004) Batch 0.438 (0.479) Remain 31:40:13 loss: 1.5464 Lr: 0.00032
[2025-04-08 14:06:55,805 INFO misc.py line 113 3298914] Train: [1/100][1960/2402] Data 0.003 (0.004) Batch 0.412 (0.479) Remain 31:40:04 loss: 1.3247 Lr: 0.00032
[2025-04-08 14:06:56,279 INFO misc.py line 113 3298914] Train: [1/100][1961/2402] Data 0.003 (0.004) Batch 0.474 (0.479) Remain 31:40:03 loss: 1.6389 Lr: 0.00032
[2025-04-08 14:06:56,765 INFO misc.py line 113 3298914] Train: [1/100][1962/2402] Data 0.003 (0.004) Batch 0.486 (0.479) Remain 31:40:04 loss: 1.1173 Lr: 0.00032
[2025-04-08 14:06:57,286 INFO misc.py line 113 3298914] Train: [1/100][1963/2402] Data 0.003 (0.004) Batch 0.521 (0.479) Remain 31:40:09 loss: 1.7768 Lr: 0.00032
[2025-04-08 14:06:57,745 INFO misc.py line 113 3298914] Train: [1/100][1964/2402] Data 0.003 (0.004) Batch 0.460 (0.479) Remain 31:40:06 loss: 1.8441 Lr: 0.00032
[2025-04-08 14:06:58,228 INFO misc.py line 113 3298914] Train: [1/100][1965/2402] Data 0.004 (0.004) Batch 0.482 (0.479) Remain 31:40:06 loss: 1.3636 Lr: 0.00032
[2025-04-08 14:06:58,768 INFO misc.py line 113 3298914] Train: [1/100][1966/2402] Data 0.004 (0.004) Batch 0.540 (0.479) Remain 31:40:13 loss: 1.6995 Lr: 0.00032
[2025-04-08 14:06:59,187 INFO misc.py line 113 3298914] Train: [1/100][1967/2402] Data 0.003 (0.004) Batch 0.419 (0.479) Remain 31:40:05 loss: 1.0518 Lr: 0.00032
[2025-04-08 14:06:59,625 INFO misc.py line 113 3298914] Train: [1/100][1968/2402] Data 0.003 (0.004) Batch 0.438 (0.479) Remain 31:40:00 loss: 1.2218 Lr: 0.00032
[2025-04-08 14:07:00,159 INFO misc.py line 113 3298914] Train: [1/100][1969/2402] Data 0.004 (0.004) Batch 0.534 (0.479) Remain 31:40:06 loss: 1.4689 Lr: 0.00032
[2025-04-08 14:07:00,525 INFO misc.py line 113 3298914] Train: [1/100][1970/2402] Data 0.004 (0.004) Batch 0.366 (0.478) Remain 31:39:52 loss: 1.5032 Lr: 0.00032
[2025-04-08 14:07:01,024 INFO misc.py line 113 3298914] Train: [1/100][1971/2402] Data 0.003 (0.004) Batch 0.499 (0.479) Remain 31:39:54 loss: 1.2784 Lr: 0.00032
[2025-04-08 14:07:01,600 INFO misc.py line 113 3298914] Train: [1/100][1972/2402] Data 0.004 (0.004) Batch 0.576 (0.479) Remain 31:40:05 loss: 1.7329 Lr: 0.00032
[2025-04-08 14:07:02,088 INFO misc.py line 113 3298914] Train: [1/100][1973/2402] Data 0.003 (0.004) Batch 0.488 (0.479) Remain 31:40:06 loss: 1.4280 Lr: 0.00032
[2025-04-08 14:07:02,550 INFO misc.py line 113 3298914] Train: [1/100][1974/2402] Data 0.004 (0.004) Batch 0.462 (0.479) Remain 31:40:03 loss: 1.1843 Lr: 0.00032
[2025-04-08 14:07:03,050 INFO misc.py line 113 3298914] Train: [1/100][1975/2402] Data 0.003 (0.004) Batch 0.500 (0.479) Remain 31:40:05 loss: 1.4092 Lr: 0.00032
[2025-04-08 14:07:03,506 INFO misc.py line 113 3298914] Train: [1/100][1976/2402] Data 0.003 (0.004) Batch 0.456 (0.479) Remain 31:40:02 loss: 1.3626 Lr: 0.00032
[2025-04-08 14:07:03,951 INFO misc.py line 113 3298914] Train: [1/100][1977/2402] Data 0.004 (0.004) Batch 0.445 (0.479) Remain 31:39:58 loss: 1.1644 Lr: 0.00032
[2025-04-08 14:07:04,418 INFO misc.py line 113 3298914] Train: [1/100][1978/2402] Data 0.003 (0.004) Batch 0.467 (0.479) Remain 31:39:56 loss: 1.5890 Lr: 0.00032
[2025-04-08 14:07:04,846 INFO misc.py line 113 3298914] Train: [1/100][1979/2402] Data 0.003 (0.004) Batch 0.428 (0.479) Remain 31:39:49 loss: 1.1638 Lr: 0.00032
[2025-04-08 14:07:05,196 INFO misc.py line 113 3298914] Train: [1/100][1980/2402] Data 0.003 (0.004) Batch 0.350 (0.478) Remain 31:39:33 loss: 1.6571 Lr: 0.00032
[2025-04-08 14:07:05,606 INFO misc.py line 113 3298914] Train: [1/100][1981/2402] Data 0.003 (0.004) Batch 0.410 (0.478) Remain 31:39:25 loss: 1.5377 Lr: 0.00032
[2025-04-08 14:07:06,130 INFO misc.py line 113 3298914] Train: [1/100][1982/2402] Data 0.003 (0.004) Batch 0.524 (0.478) Remain 31:39:29 loss: 1.0151 Lr: 0.00032
[2025-04-08 14:07:06,707 INFO misc.py line 113 3298914] Train: [1/100][1983/2402] Data 0.004 (0.004) Batch 0.577 (0.478) Remain 31:39:41 loss: 1.2035 Lr: 0.00032
[2025-04-08 14:07:07,126 INFO misc.py line 113 3298914] Train: [1/100][1984/2402] Data 0.003 (0.004) Batch 0.419 (0.478) Remain 31:39:33 loss: 1.6921 Lr: 0.00032
[2025-04-08 14:07:07,724 INFO misc.py line 113 3298914] Train: [1/100][1985/2402] Data 0.003 (0.004) Batch 0.598 (0.479) Remain 31:39:47 loss: 1.5837 Lr: 0.00032
[2025-04-08 14:07:08,165 INFO misc.py line 113 3298914] Train: [1/100][1986/2402] Data 0.003 (0.004) Batch 0.441 (0.478) Remain 31:39:42 loss: 1.9826 Lr: 0.00032
[2025-04-08 14:07:08,564 INFO misc.py line 113 3298914] Train: [1/100][1987/2402] Data 0.003 (0.004) Batch 0.399 (0.478) Remain 31:39:32 loss: 1.2161 Lr: 0.00032
[2025-04-08 14:07:08,990 INFO misc.py line 113 3298914] Train: [1/100][1988/2402] Data 0.003 (0.004) Batch 0.426 (0.478) Remain 31:39:25 loss: 1.7251 Lr: 0.00032
[2025-04-08 14:07:09,560 INFO misc.py line 113 3298914] Train: [1/100][1989/2402] Data 0.003 (0.004) Batch 0.570 (0.478) Remain 31:39:36 loss: 1.5261 Lr: 0.00032
[2025-04-08 14:07:10,038 INFO misc.py line 113 3298914] Train: [1/100][1990/2402] Data 0.003 (0.004) Batch 0.478 (0.478) Remain 31:39:35 loss: 1.7471 Lr: 0.00032
[2025-04-08 14:07:10,537 INFO misc.py line 113 3298914] Train: [1/100][1991/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:39:37 loss: 1.2606 Lr: 0.00032
[2025-04-08 14:07:11,052 INFO misc.py line 113 3298914] Train: [1/100][1992/2402] Data 0.003 (0.004) Batch 0.515 (0.478) Remain 31:39:41 loss: 1.6882 Lr: 0.00032
[2025-04-08 14:07:11,494 INFO misc.py line 113 3298914] Train: [1/100][1993/2402] Data 0.004 (0.004) Batch 0.442 (0.478) Remain 31:39:36 loss: 1.4003 Lr: 0.00032
[2025-04-08 14:07:12,002 INFO misc.py line 113 3298914] Train: [1/100][1994/2402] Data 0.004 (0.004) Batch 0.508 (0.478) Remain 31:39:39 loss: 1.6394 Lr: 0.00032
[2025-04-08 14:07:12,408 INFO misc.py line 113 3298914] Train: [1/100][1995/2402] Data 0.003 (0.004) Batch 0.406 (0.478) Remain 31:39:30 loss: 1.3037 Lr: 0.00032
[2025-04-08 14:07:12,878 INFO misc.py line 113 3298914] Train: [1/100][1996/2402] Data 0.004 (0.004) Batch 0.471 (0.478) Remain 31:39:29 loss: 1.9192 Lr: 0.00032
[2025-04-08 14:07:13,348 INFO misc.py line 113 3298914] Train: [1/100][1997/2402] Data 0.003 (0.004) Batch 0.470 (0.478) Remain 31:39:27 loss: 1.3626 Lr: 0.00032
[2025-04-08 14:07:13,785 INFO misc.py line 113 3298914] Train: [1/100][1998/2402] Data 0.003 (0.004) Batch 0.437 (0.478) Remain 31:39:22 loss: 1.6871 Lr: 0.00032
[2025-04-08 14:07:14,307 INFO misc.py line 113 3298914] Train: [1/100][1999/2402] Data 0.003 (0.004) Batch 0.521 (0.478) Remain 31:39:27 loss: 1.2774 Lr: 0.00032
[2025-04-08 14:07:14,718 INFO misc.py line 113 3298914] Train: [1/100][2000/2402] Data 0.004 (0.004) Batch 0.412 (0.478) Remain 31:39:18 loss: 1.4951 Lr: 0.00032
[2025-04-08 14:07:15,241 INFO misc.py line 113 3298914] Train: [1/100][2001/2402] Data 0.003 (0.004) Batch 0.523 (0.478) Remain 31:39:23 loss: 1.3794 Lr: 0.00032
[2025-04-08 14:07:15,695 INFO misc.py line 113 3298914] Train: [1/100][2002/2402] Data 0.004 (0.004) Batch 0.454 (0.478) Remain 31:39:20 loss: 1.0027 Lr: 0.00032
[2025-04-08 14:07:16,201 INFO misc.py line 113 3298914] Train: [1/100][2003/2402] Data 0.003 (0.004) Batch 0.506 (0.478) Remain 31:39:22 loss: 1.4416 Lr: 0.00032
[2025-04-08 14:07:16,749 INFO misc.py line 113 3298914] Train: [1/100][2004/2402] Data 0.004 (0.004) Batch 0.548 (0.478) Remain 31:39:30 loss: 1.3717 Lr: 0.00032
[2025-04-08 14:07:17,224 INFO misc.py line 113 3298914] Train: [1/100][2005/2402] Data 0.003 (0.004) Batch 0.475 (0.478) Remain 31:39:29 loss: 1.4186 Lr: 0.00032
[2025-04-08 14:07:17,656 INFO misc.py line 113 3298914] Train: [1/100][2006/2402] Data 0.003 (0.004) Batch 0.432 (0.478) Remain 31:39:23 loss: 1.6178 Lr: 0.00032
[2025-04-08 14:07:18,227 INFO misc.py line 113 3298914] Train: [1/100][2007/2402] Data 0.003 (0.004) Batch 0.571 (0.478) Remain 31:39:34 loss: 1.5781 Lr: 0.00032
[2025-04-08 14:07:18,657 INFO misc.py line 113 3298914] Train: [1/100][2008/2402] Data 0.003 (0.004) Batch 0.430 (0.478) Remain 31:39:28 loss: 1.4839 Lr: 0.00032
[2025-04-08 14:07:19,213 INFO misc.py line 113 3298914] Train: [1/100][2009/2402] Data 0.004 (0.004) Batch 0.556 (0.479) Remain 31:39:36 loss: 1.3258 Lr: 0.00032
[2025-04-08 14:07:19,564 INFO misc.py line 113 3298914] Train: [1/100][2010/2402] Data 0.003 (0.004) Batch 0.351 (0.478) Remain 31:39:21 loss: 1.3339 Lr: 0.00032
[2025-04-08 14:07:19,967 INFO misc.py line 113 3298914] Train: [1/100][2011/2402] Data 0.003 (0.004) Batch 0.403 (0.478) Remain 31:39:11 loss: 1.0945 Lr: 0.00032
[2025-04-08 14:07:20,497 INFO misc.py line 113 3298914] Train: [1/100][2012/2402] Data 0.003 (0.004) Batch 0.530 (0.478) Remain 31:39:17 loss: 1.4558 Lr: 0.00032
[2025-04-08 14:07:20,949 INFO misc.py line 113 3298914] Train: [1/100][2013/2402] Data 0.003 (0.004) Batch 0.452 (0.478) Remain 31:39:13 loss: 1.5744 Lr: 0.00032
[2025-04-08 14:07:21,394 INFO misc.py line 113 3298914] Train: [1/100][2014/2402] Data 0.004 (0.004) Batch 0.445 (0.478) Remain 31:39:09 loss: 1.5302 Lr: 0.00032
[2025-04-08 14:07:21,890 INFO misc.py line 113 3298914] Train: [1/100][2015/2402] Data 0.004 (0.004) Batch 0.497 (0.478) Remain 31:39:10 loss: 2.0331 Lr: 0.00032
[2025-04-08 14:07:22,384 INFO misc.py line 113 3298914] Train: [1/100][2016/2402] Data 0.004 (0.004) Batch 0.493 (0.478) Remain 31:39:12 loss: 1.6194 Lr: 0.00032
[2025-04-08 14:07:22,819 INFO misc.py line 113 3298914] Train: [1/100][2017/2402] Data 0.004 (0.004) Batch 0.436 (0.478) Remain 31:39:06 loss: 1.5936 Lr: 0.00032
[2025-04-08 14:07:23,268 INFO misc.py line 113 3298914] Train: [1/100][2018/2402] Data 0.003 (0.004) Batch 0.449 (0.478) Remain 31:39:02 loss: 1.0510 Lr: 0.00032
[2025-04-08 14:07:23,795 INFO misc.py line 113 3298914] Train: [1/100][2019/2402] Data 0.003 (0.004) Batch 0.527 (0.478) Remain 31:39:08 loss: 1.4223 Lr: 0.00032
[2025-04-08 14:07:24,277 INFO misc.py line 113 3298914] Train: [1/100][2020/2402] Data 0.004 (0.004) Batch 0.482 (0.478) Remain 31:39:07 loss: 1.5051 Lr: 0.00032
[2025-04-08 14:07:24,760 INFO misc.py line 113 3298914] Train: [1/100][2021/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:39:07 loss: 1.5496 Lr: 0.00032
[2025-04-08 14:07:25,187 INFO misc.py line 113 3298914] Train: [1/100][2022/2402] Data 0.003 (0.004) Batch 0.427 (0.478) Remain 31:39:01 loss: 1.2425 Lr: 0.00032
[2025-04-08 14:07:25,766 INFO misc.py line 113 3298914] Train: [1/100][2023/2402] Data 0.004 (0.004) Batch 0.579 (0.478) Remain 31:39:12 loss: 1.4317 Lr: 0.00032
[2025-04-08 14:07:26,221 INFO misc.py line 113 3298914] Train: [1/100][2024/2402] Data 0.003 (0.004) Batch 0.455 (0.478) Remain 31:39:09 loss: 1.5171 Lr: 0.00032
[2025-04-08 14:07:26,713 INFO misc.py line 113 3298914] Train: [1/100][2025/2402] Data 0.004 (0.004) Batch 0.492 (0.478) Remain 31:39:10 loss: 1.6075 Lr: 0.00032
[2025-04-08 14:07:27,258 INFO misc.py line 113 3298914] Train: [1/100][2026/2402] Data 0.003 (0.004) Batch 0.544 (0.478) Remain 31:39:17 loss: 1.2241 Lr: 0.00032
[2025-04-08 14:07:27,751 INFO misc.py line 113 3298914] Train: [1/100][2027/2402] Data 0.004 (0.004) Batch 0.494 (0.478) Remain 31:39:19 loss: 1.8261 Lr: 0.00032
[2025-04-08 14:07:28,172 INFO misc.py line 113 3298914] Train: [1/100][2028/2402] Data 0.004 (0.004) Batch 0.421 (0.478) Remain 31:39:12 loss: 1.6366 Lr: 0.00032
[2025-04-08 14:07:28,646 INFO misc.py line 113 3298914] Train: [1/100][2029/2402] Data 0.003 (0.004) Batch 0.474 (0.478) Remain 31:39:11 loss: 1.6022 Lr: 0.00032
[2025-04-08 14:07:29,168 INFO misc.py line 113 3298914] Train: [1/100][2030/2402] Data 0.003 (0.004) Batch 0.522 (0.478) Remain 31:39:15 loss: 1.3086 Lr: 0.00032
[2025-04-08 14:07:29,634 INFO misc.py line 113 3298914] Train: [1/100][2031/2402] Data 0.003 (0.004) Batch 0.466 (0.478) Remain 31:39:13 loss: 1.4641 Lr: 0.00032
[2025-04-08 14:07:30,050 INFO misc.py line 113 3298914] Train: [1/100][2032/2402] Data 0.003 (0.004) Batch 0.415 (0.478) Remain 31:39:05 loss: 1.0235 Lr: 0.00032
[2025-04-08 14:07:30,516 INFO misc.py line 113 3298914] Train: [1/100][2033/2402] Data 0.003 (0.004) Batch 0.467 (0.478) Remain 31:39:04 loss: 1.5447 Lr: 0.00032
[2025-04-08 14:07:31,075 INFO misc.py line 113 3298914] Train: [1/100][2034/2402] Data 0.004 (0.004) Batch 0.559 (0.478) Remain 31:39:12 loss: 1.7761 Lr: 0.00032
[2025-04-08 14:07:31,520 INFO misc.py line 113 3298914] Train: [1/100][2035/2402] Data 0.003 (0.004) Batch 0.444 (0.478) Remain 31:39:08 loss: 1.3495 Lr: 0.00032
[2025-04-08 14:07:32,047 INFO misc.py line 113 3298914] Train: [1/100][2036/2402] Data 0.004 (0.004) Batch 0.527 (0.478) Remain 31:39:13 loss: 1.4289 Lr: 0.00032
[2025-04-08 14:07:32,517 INFO misc.py line 113 3298914] Train: [1/100][2037/2402] Data 0.004 (0.004) Batch 0.471 (0.478) Remain 31:39:12 loss: 1.5327 Lr: 0.00032
[2025-04-08 14:07:32,986 INFO misc.py line 113 3298914] Train: [1/100][2038/2402] Data 0.003 (0.004) Batch 0.468 (0.478) Remain 31:39:10 loss: 1.4701 Lr: 0.00032
[2025-04-08 14:07:33,506 INFO misc.py line 113 3298914] Train: [1/100][2039/2402] Data 0.004 (0.004) Batch 0.520 (0.478) Remain 31:39:15 loss: 1.5290 Lr: 0.00032
[2025-04-08 14:07:34,017 INFO misc.py line 113 3298914] Train: [1/100][2040/2402] Data 0.003 (0.004) Batch 0.511 (0.478) Remain 31:39:18 loss: 1.2234 Lr: 0.00032
[2025-04-08 14:07:34,524 INFO misc.py line 113 3298914] Train: [1/100][2041/2402] Data 0.004 (0.004) Batch 0.507 (0.479) Remain 31:39:21 loss: 1.4595 Lr: 0.00032
[2025-04-08 14:07:34,945 INFO misc.py line 113 3298914] Train: [1/100][2042/2402] Data 0.003 (0.004) Batch 0.421 (0.478) Remain 31:39:14 loss: 1.7148 Lr: 0.00033
[2025-04-08 14:07:35,391 INFO misc.py line 113 3298914] Train: [1/100][2043/2402] Data 0.004 (0.004) Batch 0.446 (0.478) Remain 31:39:09 loss: 1.4964 Lr: 0.00033
[2025-04-08 14:07:35,792 INFO misc.py line 113 3298914] Train: [1/100][2044/2402] Data 0.004 (0.004) Batch 0.401 (0.478) Remain 31:39:00 loss: 1.1494 Lr: 0.00033
[2025-04-08 14:07:36,294 INFO misc.py line 113 3298914] Train: [1/100][2045/2402] Data 0.003 (0.004) Batch 0.501 (0.478) Remain 31:39:02 loss: 1.5034 Lr: 0.00033
[2025-04-08 14:07:36,714 INFO misc.py line 113 3298914] Train: [1/100][2046/2402] Data 0.004 (0.004) Batch 0.420 (0.478) Remain 31:38:55 loss: 1.5759 Lr: 0.00033
[2025-04-08 14:07:37,215 INFO misc.py line 113 3298914] Train: [1/100][2047/2402] Data 0.004 (0.004) Batch 0.502 (0.478) Remain 31:38:57 loss: 1.5453 Lr: 0.00033
[2025-04-08 14:07:37,722 INFO misc.py line 113 3298914] Train: [1/100][2048/2402] Data 0.003 (0.004) Batch 0.507 (0.478) Remain 31:39:00 loss: 1.6856 Lr: 0.00033
[2025-04-08 14:07:38,233 INFO misc.py line 113 3298914] Train: [1/100][2049/2402] Data 0.003 (0.004) Batch 0.511 (0.478) Remain 31:39:03 loss: 1.3896 Lr: 0.00033
[2025-04-08 14:07:38,727 INFO misc.py line 113 3298914] Train: [1/100][2050/2402] Data 0.003 (0.004) Batch 0.494 (0.478) Remain 31:39:04 loss: 1.5812 Lr: 0.00033
[2025-04-08 14:07:39,188 INFO misc.py line 113 3298914] Train: [1/100][2051/2402] Data 0.003 (0.004) Batch 0.461 (0.478) Remain 31:39:02 loss: 1.2931 Lr: 0.00033
[2025-04-08 14:07:39,593 INFO misc.py line 113 3298914] Train: [1/100][2052/2402] Data 0.004 (0.004) Batch 0.404 (0.478) Remain 31:38:53 loss: 1.6355 Lr: 0.00033
[2025-04-08 14:07:40,122 INFO misc.py line 113 3298914] Train: [1/100][2053/2402] Data 0.003 (0.004) Batch 0.529 (0.478) Remain 31:38:58 loss: 1.4343 Lr: 0.00033
[2025-04-08 14:07:40,608 INFO misc.py line 113 3298914] Train: [1/100][2054/2402] Data 0.003 (0.004) Batch 0.486 (0.478) Remain 31:38:59 loss: 1.8623 Lr: 0.00033
[2025-04-08 14:07:41,094 INFO misc.py line 113 3298914] Train: [1/100][2055/2402] Data 0.004 (0.004) Batch 0.487 (0.478) Remain 31:38:59 loss: 1.3785 Lr: 0.00033
[2025-04-08 14:07:41,493 INFO misc.py line 113 3298914] Train: [1/100][2056/2402] Data 0.003 (0.004) Batch 0.398 (0.478) Remain 31:38:49 loss: 1.1219 Lr: 0.00033
[2025-04-08 14:07:42,007 INFO misc.py line 113 3298914] Train: [1/100][2057/2402] Data 0.004 (0.004) Batch 0.515 (0.478) Remain 31:38:53 loss: 1.5466 Lr: 0.00033
[2025-04-08 14:07:42,535 INFO misc.py line 113 3298914] Train: [1/100][2058/2402] Data 0.004 (0.004) Batch 0.528 (0.478) Remain 31:38:58 loss: 1.3795 Lr: 0.00033
[2025-04-08 14:07:43,057 INFO misc.py line 113 3298914] Train: [1/100][2059/2402] Data 0.003 (0.004) Batch 0.521 (0.478) Remain 31:39:03 loss: 1.6642 Lr: 0.00033
[2025-04-08 14:07:43,404 INFO misc.py line 113 3298914] Train: [1/100][2060/2402] Data 0.004 (0.004) Batch 0.347 (0.478) Remain 31:38:47 loss: 1.0962 Lr: 0.00033
[2025-04-08 14:07:43,881 INFO misc.py line 113 3298914] Train: [1/100][2061/2402] Data 0.003 (0.004) Batch 0.477 (0.478) Remain 31:38:46 loss: 1.2312 Lr: 0.00033
[2025-04-08 14:07:44,353 INFO misc.py line 113 3298914] Train: [1/100][2062/2402] Data 0.004 (0.004) Batch 0.472 (0.478) Remain 31:38:45 loss: 1.8813 Lr: 0.00033
[2025-04-08 14:07:44,824 INFO misc.py line 113 3298914] Train: [1/100][2063/2402] Data 0.004 (0.004) Batch 0.471 (0.478) Remain 31:38:44 loss: 1.5138 Lr: 0.00033
[2025-04-08 14:07:45,360 INFO misc.py line 113 3298914] Train: [1/100][2064/2402] Data 0.003 (0.004) Batch 0.536 (0.478) Remain 31:38:50 loss: 1.6949 Lr: 0.00033
[2025-04-08 14:07:45,865 INFO misc.py line 113 3298914] Train: [1/100][2065/2402] Data 0.004 (0.004) Batch 0.506 (0.478) Remain 31:38:53 loss: 1.6058 Lr: 0.00033
[2025-04-08 14:07:46,364 INFO misc.py line 113 3298914] Train: [1/100][2066/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:38:55 loss: 1.2394 Lr: 0.00033
[2025-04-08 14:07:46,829 INFO misc.py line 113 3298914] Train: [1/100][2067/2402] Data 0.003 (0.004) Batch 0.464 (0.478) Remain 31:38:53 loss: 1.5794 Lr: 0.00033
[2025-04-08 14:07:47,218 INFO misc.py line 113 3298914] Train: [1/100][2068/2402] Data 0.003 (0.004) Batch 0.389 (0.478) Remain 31:38:42 loss: 1.8346 Lr: 0.00033
[2025-04-08 14:07:47,742 INFO misc.py line 113 3298914] Train: [1/100][2069/2402] Data 0.003 (0.004) Batch 0.525 (0.478) Remain 31:38:47 loss: 1.2409 Lr: 0.00033
[2025-04-08 14:07:48,084 INFO misc.py line 113 3298914] Train: [1/100][2070/2402] Data 0.004 (0.004) Batch 0.342 (0.478) Remain 31:38:30 loss: 1.4342 Lr: 0.00033
[2025-04-08 14:07:48,552 INFO misc.py line 113 3298914] Train: [1/100][2071/2402] Data 0.003 (0.004) Batch 0.468 (0.478) Remain 31:38:29 loss: 1.4968 Lr: 0.00033
[2025-04-08 14:07:49,060 INFO misc.py line 113 3298914] Train: [1/100][2072/2402] Data 0.003 (0.004) Batch 0.508 (0.478) Remain 31:38:32 loss: 1.2507 Lr: 0.00033
[2025-04-08 14:07:49,575 INFO misc.py line 113 3298914] Train: [1/100][2073/2402] Data 0.003 (0.004) Batch 0.514 (0.478) Remain 31:38:35 loss: 1.6209 Lr: 0.00033
[2025-04-08 14:07:50,042 INFO misc.py line 113 3298914] Train: [1/100][2074/2402] Data 0.004 (0.004) Batch 0.468 (0.478) Remain 31:38:34 loss: 1.4810 Lr: 0.00033
[2025-04-08 14:07:50,589 INFO misc.py line 113 3298914] Train: [1/100][2075/2402] Data 0.003 (0.004) Batch 0.547 (0.478) Remain 31:38:41 loss: 1.6898 Lr: 0.00033
[2025-04-08 14:07:51,175 INFO misc.py line 113 3298914] Train: [1/100][2076/2402] Data 0.004 (0.004) Batch 0.585 (0.478) Remain 31:38:53 loss: 1.2516 Lr: 0.00033
[2025-04-08 14:07:51,669 INFO misc.py line 113 3298914] Train: [1/100][2077/2402] Data 0.003 (0.004) Batch 0.494 (0.478) Remain 31:38:54 loss: 1.5880 Lr: 0.00033
[2025-04-08 14:07:52,209 INFO misc.py line 113 3298914] Train: [1/100][2078/2402] Data 0.004 (0.004) Batch 0.540 (0.478) Remain 31:39:01 loss: 1.5207 Lr: 0.00033
[2025-04-08 14:07:52,721 INFO misc.py line 113 3298914] Train: [1/100][2079/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:39:04 loss: 1.8143 Lr: 0.00033
[2025-04-08 14:07:53,186 INFO misc.py line 113 3298914] Train: [1/100][2080/2402] Data 0.003 (0.004) Batch 0.465 (0.479) Remain 31:39:02 loss: 1.2084 Lr: 0.00033
[2025-04-08 14:07:53,705 INFO misc.py line 113 3298914] Train: [1/100][2081/2402] Data 0.004 (0.004) Batch 0.519 (0.479) Remain 31:39:06 loss: 1.2503 Lr: 0.00033
[2025-04-08 14:07:54,163 INFO misc.py line 113 3298914] Train: [1/100][2082/2402] Data 0.003 (0.004) Batch 0.458 (0.479) Remain 31:39:03 loss: 1.6079 Lr: 0.00033
[2025-04-08 14:07:54,747 INFO misc.py line 113 3298914] Train: [1/100][2083/2402] Data 0.004 (0.004) Batch 0.584 (0.479) Remain 31:39:15 loss: 0.9624 Lr: 0.00033
[2025-04-08 14:07:55,153 INFO misc.py line 113 3298914] Train: [1/100][2084/2402] Data 0.004 (0.004) Batch 0.406 (0.479) Remain 31:39:06 loss: 1.2683 Lr: 0.00033
[2025-04-08 14:07:55,496 INFO misc.py line 113 3298914] Train: [1/100][2085/2402] Data 0.004 (0.004) Batch 0.343 (0.478) Remain 31:38:50 loss: 1.9156 Lr: 0.00033
[2025-04-08 14:07:55,971 INFO misc.py line 113 3298914] Train: [1/100][2086/2402] Data 0.004 (0.004) Batch 0.475 (0.478) Remain 31:38:49 loss: 1.6889 Lr: 0.00033
[2025-04-08 14:07:56,467 INFO misc.py line 113 3298914] Train: [1/100][2087/2402] Data 0.004 (0.004) Batch 0.495 (0.478) Remain 31:38:51 loss: 1.3927 Lr: 0.00033
[2025-04-08 14:07:56,973 INFO misc.py line 113 3298914] Train: [1/100][2088/2402] Data 0.004 (0.004) Batch 0.506 (0.478) Remain 31:38:54 loss: 1.5578 Lr: 0.00033
[2025-04-08 14:07:57,455 INFO misc.py line 113 3298914] Train: [1/100][2089/2402] Data 0.003 (0.004) Batch 0.482 (0.478) Remain 31:38:53 loss: 1.5001 Lr: 0.00033
[2025-04-08 14:07:57,913 INFO misc.py line 113 3298914] Train: [1/100][2090/2402] Data 0.003 (0.004) Batch 0.458 (0.478) Remain 31:38:51 loss: 1.6830 Lr: 0.00033
[2025-04-08 14:07:58,460 INFO misc.py line 113 3298914] Train: [1/100][2091/2402] Data 0.003 (0.004) Batch 0.548 (0.479) Remain 31:38:58 loss: 1.9059 Lr: 0.00033
[2025-04-08 14:07:58,999 INFO misc.py line 113 3298914] Train: [1/100][2092/2402] Data 0.003 (0.004) Batch 0.538 (0.479) Remain 31:39:04 loss: 1.3328 Lr: 0.00033
[2025-04-08 14:07:59,496 INFO misc.py line 113 3298914] Train: [1/100][2093/2402] Data 0.003 (0.004) Batch 0.497 (0.479) Remain 31:39:06 loss: 1.5114 Lr: 0.00033
[2025-04-08 14:08:00,071 INFO misc.py line 113 3298914] Train: [1/100][2094/2402] Data 0.004 (0.004) Batch 0.575 (0.479) Remain 31:39:17 loss: 1.3709 Lr: 0.00033
[2025-04-08 14:08:00,503 INFO misc.py line 113 3298914] Train: [1/100][2095/2402] Data 0.003 (0.004) Batch 0.432 (0.479) Remain 31:39:11 loss: 1.5883 Lr: 0.00033
[2025-04-08 14:08:00,946 INFO misc.py line 113 3298914] Train: [1/100][2096/2402] Data 0.004 (0.004) Batch 0.443 (0.479) Remain 31:39:06 loss: 1.3202 Lr: 0.00033
[2025-04-08 14:08:01,382 INFO misc.py line 113 3298914] Train: [1/100][2097/2402] Data 0.003 (0.004) Batch 0.436 (0.479) Remain 31:39:01 loss: 1.6445 Lr: 0.00033
[2025-04-08 14:08:01,847 INFO misc.py line 113 3298914] Train: [1/100][2098/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:38:59 loss: 1.2071 Lr: 0.00033
[2025-04-08 14:08:02,327 INFO misc.py line 113 3298914] Train: [1/100][2099/2402] Data 0.004 (0.004) Batch 0.480 (0.479) Remain 31:38:59 loss: 1.6029 Lr: 0.00033
[2025-04-08 14:08:02,710 INFO misc.py line 113 3298914] Train: [1/100][2100/2402] Data 0.003 (0.004) Batch 0.384 (0.478) Remain 31:38:47 loss: 1.6360 Lr: 0.00033
[2025-04-08 14:08:03,225 INFO misc.py line 113 3298914] Train: [1/100][2101/2402] Data 0.003 (0.004) Batch 0.514 (0.479) Remain 31:38:51 loss: 1.4605 Lr: 0.00033
[2025-04-08 14:08:03,608 INFO misc.py line 113 3298914] Train: [1/100][2102/2402] Data 0.004 (0.004) Batch 0.382 (0.478) Remain 31:38:40 loss: 1.1686 Lr: 0.00033
[2025-04-08 14:08:04,055 INFO misc.py line 113 3298914] Train: [1/100][2103/2402] Data 0.004 (0.004) Batch 0.447 (0.478) Remain 31:38:36 loss: 1.4926 Lr: 0.00033
[2025-04-08 14:08:04,391 INFO misc.py line 113 3298914] Train: [1/100][2104/2402] Data 0.004 (0.004) Batch 0.337 (0.478) Remain 31:38:19 loss: 1.2420 Lr: 0.00033
[2025-04-08 14:08:04,891 INFO misc.py line 113 3298914] Train: [1/100][2105/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:38:21 loss: 1.4026 Lr: 0.00033
[2025-04-08 14:08:05,629 INFO misc.py line 113 3298914] Train: [1/100][2106/2402] Data 0.004 (0.004) Batch 0.739 (0.479) Remain 31:38:50 loss: 1.2060 Lr: 0.00033
[2025-04-08 14:08:06,021 INFO misc.py line 113 3298914] Train: [1/100][2107/2402] Data 0.003 (0.004) Batch 0.392 (0.478) Remain 31:38:40 loss: 1.4231 Lr: 0.00033
[2025-04-08 14:08:06,548 INFO misc.py line 113 3298914] Train: [1/100][2108/2402] Data 0.004 (0.004) Batch 0.528 (0.478) Remain 31:38:45 loss: 1.4866 Lr: 0.00033
[2025-04-08 14:08:06,954 INFO misc.py line 113 3298914] Train: [1/100][2109/2402] Data 0.003 (0.004) Batch 0.406 (0.478) Remain 31:38:36 loss: 1.4335 Lr: 0.00033
[2025-04-08 14:08:07,412 INFO misc.py line 113 3298914] Train: [1/100][2110/2402] Data 0.003 (0.004) Batch 0.458 (0.478) Remain 31:38:33 loss: 1.8593 Lr: 0.00033
[2025-04-08 14:08:07,825 INFO misc.py line 113 3298914] Train: [1/100][2111/2402] Data 0.004 (0.004) Batch 0.413 (0.478) Remain 31:38:25 loss: 1.2453 Lr: 0.00033
[2025-04-08 14:08:08,286 INFO misc.py line 113 3298914] Train: [1/100][2112/2402] Data 0.004 (0.004) Batch 0.461 (0.478) Remain 31:38:23 loss: 2.0510 Lr: 0.00033
[2025-04-08 14:08:08,751 INFO misc.py line 113 3298914] Train: [1/100][2113/2402] Data 0.003 (0.004) Batch 0.465 (0.478) Remain 31:38:21 loss: 1.7014 Lr: 0.00033
[2025-04-08 14:08:09,305 INFO misc.py line 113 3298914] Train: [1/100][2114/2402] Data 0.004 (0.004) Batch 0.554 (0.478) Remain 31:38:29 loss: 1.4941 Lr: 0.00033
[2025-04-08 14:08:09,857 INFO misc.py line 113 3298914] Train: [1/100][2115/2402] Data 0.003 (0.004) Batch 0.552 (0.478) Remain 31:38:37 loss: 1.9404 Lr: 0.00033
[2025-04-08 14:08:10,391 INFO misc.py line 113 3298914] Train: [1/100][2116/2402] Data 0.004 (0.004) Batch 0.534 (0.478) Remain 31:38:42 loss: 1.3366 Lr: 0.00033
[2025-04-08 14:08:10,976 INFO misc.py line 113 3298914] Train: [1/100][2117/2402] Data 0.003 (0.004) Batch 0.585 (0.479) Remain 31:38:54 loss: 1.4886 Lr: 0.00033
[2025-04-08 14:08:11,397 INFO misc.py line 113 3298914] Train: [1/100][2118/2402] Data 0.003 (0.004) Batch 0.421 (0.479) Remain 31:38:47 loss: 1.5843 Lr: 0.00033
[2025-04-08 14:08:11,943 INFO misc.py line 113 3298914] Train: [1/100][2119/2402] Data 0.003 (0.004) Batch 0.547 (0.479) Remain 31:38:54 loss: 1.4710 Lr: 0.00033
[2025-04-08 14:08:12,484 INFO misc.py line 113 3298914] Train: [1/100][2120/2402] Data 0.003 (0.004) Batch 0.540 (0.479) Remain 31:39:01 loss: 1.3283 Lr: 0.00033
[2025-04-08 14:08:13,020 INFO misc.py line 113 3298914] Train: [1/100][2121/2402] Data 0.004 (0.004) Batch 0.536 (0.479) Remain 31:39:07 loss: 1.3763 Lr: 0.00033
[2025-04-08 14:08:13,420 INFO misc.py line 113 3298914] Train: [1/100][2122/2402] Data 0.004 (0.004) Batch 0.401 (0.479) Remain 31:38:57 loss: 1.4133 Lr: 0.00033
[2025-04-08 14:08:13,873 INFO misc.py line 113 3298914] Train: [1/100][2123/2402] Data 0.003 (0.004) Batch 0.453 (0.479) Remain 31:38:54 loss: 1.4026 Lr: 0.00033
[2025-04-08 14:08:14,370 INFO misc.py line 113 3298914] Train: [1/100][2124/2402] Data 0.003 (0.004) Batch 0.497 (0.479) Remain 31:38:56 loss: 1.2987 Lr: 0.00034
[2025-04-08 14:08:14,822 INFO misc.py line 113 3298914] Train: [1/100][2125/2402] Data 0.004 (0.004) Batch 0.453 (0.479) Remain 31:38:52 loss: 1.6559 Lr: 0.00034
[2025-04-08 14:08:15,348 INFO misc.py line 113 3298914] Train: [1/100][2126/2402] Data 0.004 (0.004) Batch 0.525 (0.479) Remain 31:38:57 loss: 1.5400 Lr: 0.00034
[2025-04-08 14:08:15,708 INFO misc.py line 113 3298914] Train: [1/100][2127/2402] Data 0.003 (0.004) Batch 0.360 (0.479) Remain 31:38:43 loss: 1.4851 Lr: 0.00034
[2025-04-08 14:08:16,191 INFO misc.py line 113 3298914] Train: [1/100][2128/2402] Data 0.004 (0.004) Batch 0.483 (0.479) Remain 31:38:43 loss: 1.2800 Lr: 0.00034
[2025-04-08 14:08:16,682 INFO misc.py line 113 3298914] Train: [1/100][2129/2402] Data 0.004 (0.004) Batch 0.491 (0.479) Remain 31:38:44 loss: 1.6690 Lr: 0.00034
[2025-04-08 14:08:17,145 INFO misc.py line 113 3298914] Train: [1/100][2130/2402] Data 0.003 (0.004) Batch 0.463 (0.479) Remain 31:38:42 loss: 1.6157 Lr: 0.00034
[2025-04-08 14:08:17,612 INFO misc.py line 113 3298914] Train: [1/100][2131/2402] Data 0.003 (0.004) Batch 0.467 (0.479) Remain 31:38:40 loss: 1.7597 Lr: 0.00034
[2025-04-08 14:08:18,155 INFO misc.py line 113 3298914] Train: [1/100][2132/2402] Data 0.004 (0.004) Batch 0.543 (0.479) Remain 31:38:47 loss: 1.5721 Lr: 0.00034
[2025-04-08 14:08:18,750 INFO misc.py line 113 3298914] Train: [1/100][2133/2402] Data 0.003 (0.004) Batch 0.595 (0.479) Remain 31:38:59 loss: 1.4269 Lr: 0.00034
[2025-04-08 14:08:19,233 INFO misc.py line 113 3298914] Train: [1/100][2134/2402] Data 0.003 (0.004) Batch 0.484 (0.479) Remain 31:39:00 loss: 1.5641 Lr: 0.00034
[2025-04-08 14:08:19,753 INFO misc.py line 113 3298914] Train: [1/100][2135/2402] Data 0.003 (0.004) Batch 0.519 (0.479) Remain 31:39:04 loss: 1.5984 Lr: 0.00034
[2025-04-08 14:08:20,233 INFO misc.py line 113 3298914] Train: [1/100][2136/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:39:03 loss: 1.7362 Lr: 0.00034
[2025-04-08 14:08:20,698 INFO misc.py line 113 3298914] Train: [1/100][2137/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:39:01 loss: 1.7977 Lr: 0.00034
[2025-04-08 14:08:21,160 INFO misc.py line 113 3298914] Train: [1/100][2138/2402] Data 0.003 (0.004) Batch 0.462 (0.479) Remain 31:38:59 loss: 1.2898 Lr: 0.00034
[2025-04-08 14:08:21,573 INFO misc.py line 113 3298914] Train: [1/100][2139/2402] Data 0.003 (0.004) Batch 0.413 (0.479) Remain 31:38:51 loss: 1.7776 Lr: 0.00034
[2025-04-08 14:08:21,977 INFO misc.py line 113 3298914] Train: [1/100][2140/2402] Data 0.004 (0.004) Batch 0.403 (0.479) Remain 31:38:42 loss: 1.6276 Lr: 0.00034
[2025-04-08 14:08:22,352 INFO misc.py line 113 3298914] Train: [1/100][2141/2402] Data 0.004 (0.004) Batch 0.376 (0.478) Remain 31:38:30 loss: 1.3777 Lr: 0.00034
[2025-04-08 14:08:22,890 INFO misc.py line 113 3298914] Train: [1/100][2142/2402] Data 0.003 (0.004) Batch 0.538 (0.479) Remain 31:38:36 loss: 1.4054 Lr: 0.00034
[2025-04-08 14:08:23,366 INFO misc.py line 113 3298914] Train: [1/100][2143/2402] Data 0.004 (0.004) Batch 0.476 (0.479) Remain 31:38:36 loss: 1.5550 Lr: 0.00034
[2025-04-08 14:08:23,833 INFO misc.py line 113 3298914] Train: [1/100][2144/2402] Data 0.003 (0.004) Batch 0.468 (0.479) Remain 31:38:34 loss: 1.4364 Lr: 0.00034
[2025-04-08 14:08:24,249 INFO misc.py line 113 3298914] Train: [1/100][2145/2402] Data 0.003 (0.004) Batch 0.415 (0.478) Remain 31:38:27 loss: 1.0367 Lr: 0.00034
[2025-04-08 14:08:24,762 INFO misc.py line 113 3298914] Train: [1/100][2146/2402] Data 0.003 (0.004) Batch 0.513 (0.479) Remain 31:38:30 loss: 1.3075 Lr: 0.00034
[2025-04-08 14:08:25,240 INFO misc.py line 113 3298914] Train: [1/100][2147/2402] Data 0.004 (0.004) Batch 0.478 (0.479) Remain 31:38:29 loss: 1.4690 Lr: 0.00034
[2025-04-08 14:08:25,629 INFO misc.py line 113 3298914] Train: [1/100][2148/2402] Data 0.004 (0.004) Batch 0.389 (0.478) Remain 31:38:19 loss: 1.4825 Lr: 0.00034
[2025-04-08 14:08:26,083 INFO misc.py line 113 3298914] Train: [1/100][2149/2402] Data 0.003 (0.004) Batch 0.453 (0.478) Remain 31:38:16 loss: 1.4182 Lr: 0.00034
[2025-04-08 14:08:26,617 INFO misc.py line 113 3298914] Train: [1/100][2150/2402] Data 0.003 (0.004) Batch 0.534 (0.478) Remain 31:38:21 loss: 1.6406 Lr: 0.00034
[2025-04-08 14:08:27,096 INFO misc.py line 113 3298914] Train: [1/100][2151/2402] Data 0.003 (0.004) Batch 0.479 (0.478) Remain 31:38:21 loss: 1.8034 Lr: 0.00034
[2025-04-08 14:08:27,677 INFO misc.py line 113 3298914] Train: [1/100][2152/2402] Data 0.004 (0.004) Batch 0.581 (0.479) Remain 31:38:32 loss: 1.3239 Lr: 0.00034
[2025-04-08 14:08:28,189 INFO misc.py line 113 3298914] Train: [1/100][2153/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:38:35 loss: 1.5175 Lr: 0.00034
[2025-04-08 14:08:28,770 INFO misc.py line 113 3298914] Train: [1/100][2154/2402] Data 0.004 (0.004) Batch 0.581 (0.479) Remain 31:38:46 loss: 1.2771 Lr: 0.00034
[2025-04-08 14:08:29,189 INFO misc.py line 113 3298914] Train: [1/100][2155/2402] Data 0.004 (0.004) Batch 0.419 (0.479) Remain 31:38:39 loss: 1.2569 Lr: 0.00034
[2025-04-08 14:08:29,630 INFO misc.py line 113 3298914] Train: [1/100][2156/2402] Data 0.003 (0.004) Batch 0.441 (0.479) Remain 31:38:34 loss: 1.5385 Lr: 0.00034
[2025-04-08 14:08:30,104 INFO misc.py line 113 3298914] Train: [1/100][2157/2402] Data 0.003 (0.004) Batch 0.474 (0.479) Remain 31:38:33 loss: 1.4401 Lr: 0.00034
[2025-04-08 14:08:30,560 INFO misc.py line 113 3298914] Train: [1/100][2158/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:38:30 loss: 1.4562 Lr: 0.00034
[2025-04-08 14:08:31,108 INFO misc.py line 113 3298914] Train: [1/100][2159/2402] Data 0.004 (0.004) Batch 0.549 (0.479) Remain 31:38:38 loss: 0.9570 Lr: 0.00034
[2025-04-08 14:08:31,609 INFO misc.py line 113 3298914] Train: [1/100][2160/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:38:40 loss: 1.3267 Lr: 0.00034
[2025-04-08 14:08:32,008 INFO misc.py line 113 3298914] Train: [1/100][2161/2402] Data 0.004 (0.004) Batch 0.399 (0.479) Remain 31:38:30 loss: 1.4910 Lr: 0.00034
[2025-04-08 14:08:32,519 INFO misc.py line 113 3298914] Train: [1/100][2162/2402] Data 0.004 (0.004) Batch 0.511 (0.479) Remain 31:38:33 loss: 1.7086 Lr: 0.00034
[2025-04-08 14:08:33,024 INFO misc.py line 113 3298914] Train: [1/100][2163/2402] Data 0.015 (0.004) Batch 0.505 (0.479) Remain 31:38:36 loss: 1.4540 Lr: 0.00034
[2025-04-08 14:08:33,432 INFO misc.py line 113 3298914] Train: [1/100][2164/2402] Data 0.004 (0.004) Batch 0.409 (0.479) Remain 31:38:28 loss: 1.6544 Lr: 0.00034
[2025-04-08 14:08:33,965 INFO misc.py line 113 3298914] Train: [1/100][2165/2402] Data 0.004 (0.004) Batch 0.532 (0.479) Remain 31:38:33 loss: 1.2623 Lr: 0.00034
[2025-04-08 14:08:34,284 INFO misc.py line 113 3298914] Train: [1/100][2166/2402] Data 0.004 (0.004) Batch 0.319 (0.478) Remain 31:38:15 loss: 1.6398 Lr: 0.00034
[2025-04-08 14:08:34,871 INFO misc.py line 113 3298914] Train: [1/100][2167/2402] Data 0.003 (0.004) Batch 0.587 (0.479) Remain 31:38:27 loss: 1.4360 Lr: 0.00034
[2025-04-08 14:08:35,372 INFO misc.py line 113 3298914] Train: [1/100][2168/2402] Data 0.003 (0.004) Batch 0.501 (0.479) Remain 31:38:28 loss: 1.5772 Lr: 0.00034
[2025-04-08 14:08:35,846 INFO misc.py line 113 3298914] Train: [1/100][2169/2402] Data 0.004 (0.004) Batch 0.474 (0.479) Remain 31:38:28 loss: 1.8224 Lr: 0.00034
[2025-04-08 14:08:36,346 INFO misc.py line 113 3298914] Train: [1/100][2170/2402] Data 0.003 (0.004) Batch 0.500 (0.479) Remain 31:38:29 loss: 1.2756 Lr: 0.00034
[2025-04-08 14:08:36,792 INFO misc.py line 113 3298914] Train: [1/100][2171/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:38:25 loss: 1.5852 Lr: 0.00034
[2025-04-08 14:08:37,328 INFO misc.py line 113 3298914] Train: [1/100][2172/2402] Data 0.004 (0.004) Batch 0.536 (0.479) Remain 31:38:31 loss: 1.3144 Lr: 0.00034
[2025-04-08 14:08:37,861 INFO misc.py line 113 3298914] Train: [1/100][2173/2402] Data 0.003 (0.004) Batch 0.533 (0.479) Remain 31:38:37 loss: 1.4894 Lr: 0.00034
[2025-04-08 14:08:38,372 INFO misc.py line 113 3298914] Train: [1/100][2174/2402] Data 0.003 (0.004) Batch 0.510 (0.479) Remain 31:38:40 loss: 1.5159 Lr: 0.00034
[2025-04-08 14:08:38,889 INFO misc.py line 113 3298914] Train: [1/100][2175/2402] Data 0.003 (0.004) Batch 0.517 (0.479) Remain 31:38:43 loss: 1.4318 Lr: 0.00034
[2025-04-08 14:08:39,475 INFO misc.py line 113 3298914] Train: [1/100][2176/2402] Data 0.004 (0.004) Batch 0.587 (0.479) Remain 31:38:55 loss: 1.5059 Lr: 0.00034
[2025-04-08 14:08:39,992 INFO misc.py line 113 3298914] Train: [1/100][2177/2402] Data 0.003 (0.004) Batch 0.517 (0.479) Remain 31:38:58 loss: 2.1905 Lr: 0.00034
[2025-04-08 14:08:40,456 INFO misc.py line 113 3298914] Train: [1/100][2178/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:38:56 loss: 1.5836 Lr: 0.00034
[2025-04-08 14:08:40,874 INFO misc.py line 113 3298914] Train: [1/100][2179/2402] Data 0.003 (0.004) Batch 0.418 (0.479) Remain 31:38:49 loss: 1.6092 Lr: 0.00034
[2025-04-08 14:08:41,336 INFO misc.py line 113 3298914] Train: [1/100][2180/2402] Data 0.003 (0.004) Batch 0.462 (0.479) Remain 31:38:47 loss: 1.4144 Lr: 0.00034
[2025-04-08 14:08:41,800 INFO misc.py line 113 3298914] Train: [1/100][2181/2402] Data 0.003 (0.004) Batch 0.464 (0.479) Remain 31:38:45 loss: 1.7054 Lr: 0.00034
[2025-04-08 14:08:42,314 INFO misc.py line 113 3298914] Train: [1/100][2182/2402] Data 0.004 (0.004) Batch 0.514 (0.479) Remain 31:38:48 loss: 1.6734 Lr: 0.00034
[2025-04-08 14:08:42,691 INFO misc.py line 113 3298914] Train: [1/100][2183/2402] Data 0.003 (0.004) Batch 0.376 (0.479) Remain 31:38:37 loss: 1.5279 Lr: 0.00034
[2025-04-08 14:08:43,179 INFO misc.py line 113 3298914] Train: [1/100][2184/2402] Data 0.004 (0.004) Batch 0.489 (0.479) Remain 31:38:37 loss: 1.6610 Lr: 0.00034
[2025-04-08 14:08:43,569 INFO misc.py line 113 3298914] Train: [1/100][2185/2402] Data 0.004 (0.004) Batch 0.389 (0.479) Remain 31:38:27 loss: 1.2191 Lr: 0.00034
[2025-04-08 14:08:43,951 INFO misc.py line 113 3298914] Train: [1/100][2186/2402] Data 0.003 (0.004) Batch 0.382 (0.479) Remain 31:38:16 loss: 1.5709 Lr: 0.00034
[2025-04-08 14:08:44,376 INFO misc.py line 113 3298914] Train: [1/100][2187/2402] Data 0.003 (0.004) Batch 0.425 (0.479) Remain 31:38:10 loss: 1.3891 Lr: 0.00034
[2025-04-08 14:08:44,879 INFO misc.py line 113 3298914] Train: [1/100][2188/2402] Data 0.004 (0.004) Batch 0.503 (0.479) Remain 31:38:12 loss: 1.3096 Lr: 0.00034
[2025-04-08 14:08:45,323 INFO misc.py line 113 3298914] Train: [1/100][2189/2402] Data 0.003 (0.004) Batch 0.445 (0.479) Remain 31:38:08 loss: 1.6548 Lr: 0.00034
[2025-04-08 14:08:45,832 INFO misc.py line 113 3298914] Train: [1/100][2190/2402] Data 0.003 (0.004) Batch 0.508 (0.479) Remain 31:38:11 loss: 1.5241 Lr: 0.00034
[2025-04-08 14:08:46,405 INFO misc.py line 113 3298914] Train: [1/100][2191/2402] Data 0.003 (0.004) Batch 0.573 (0.479) Remain 31:38:20 loss: 1.4218 Lr: 0.00034
[2025-04-08 14:08:46,896 INFO misc.py line 113 3298914] Train: [1/100][2192/2402] Data 0.003 (0.004) Batch 0.491 (0.479) Remain 31:38:21 loss: 1.5525 Lr: 0.00034
[2025-04-08 14:08:47,378 INFO misc.py line 113 3298914] Train: [1/100][2193/2402] Data 0.004 (0.004) Batch 0.482 (0.479) Remain 31:38:21 loss: 1.4933 Lr: 0.00034
[2025-04-08 14:08:47,860 INFO misc.py line 113 3298914] Train: [1/100][2194/2402] Data 0.004 (0.004) Batch 0.483 (0.479) Remain 31:38:21 loss: 1.4780 Lr: 0.00034
[2025-04-08 14:08:48,290 INFO misc.py line 113 3298914] Train: [1/100][2195/2402] Data 0.004 (0.004) Batch 0.430 (0.479) Remain 31:38:15 loss: 1.4320 Lr: 0.00034
[2025-04-08 14:08:48,768 INFO misc.py line 113 3298914] Train: [1/100][2196/2402] Data 0.003 (0.004) Batch 0.478 (0.479) Remain 31:38:15 loss: 1.3261 Lr: 0.00034
[2025-04-08 14:08:49,369 INFO misc.py line 113 3298914] Train: [1/100][2197/2402] Data 0.003 (0.004) Batch 0.601 (0.479) Remain 31:38:28 loss: 1.6315 Lr: 0.00034
[2025-04-08 14:08:49,845 INFO misc.py line 113 3298914] Train: [1/100][2198/2402] Data 0.004 (0.004) Batch 0.476 (0.479) Remain 31:38:27 loss: 1.2797 Lr: 0.00034
[2025-04-08 14:08:50,255 INFO misc.py line 113 3298914] Train: [1/100][2199/2402] Data 0.003 (0.004) Batch 0.410 (0.479) Remain 31:38:19 loss: 1.3734 Lr: 0.00034
[2025-04-08 14:08:50,642 INFO misc.py line 113 3298914] Train: [1/100][2200/2402] Data 0.004 (0.004) Batch 0.388 (0.479) Remain 31:38:08 loss: 1.4046 Lr: 0.00034
[2025-04-08 14:08:51,104 INFO misc.py line 113 3298914] Train: [1/100][2201/2402] Data 0.003 (0.004) Batch 0.461 (0.479) Remain 31:38:06 loss: 1.5897 Lr: 0.00034
[2025-04-08 14:08:51,542 INFO misc.py line 113 3298914] Train: [1/100][2202/2402] Data 0.004 (0.004) Batch 0.439 (0.478) Remain 31:38:01 loss: 1.0605 Lr: 0.00034
[2025-04-08 14:08:52,056 INFO misc.py line 113 3298914] Train: [1/100][2203/2402] Data 0.003 (0.004) Batch 0.514 (0.479) Remain 31:38:05 loss: 1.2683 Lr: 0.00034
[2025-04-08 14:08:52,661 INFO misc.py line 113 3298914] Train: [1/100][2204/2402] Data 0.004 (0.004) Batch 0.605 (0.479) Remain 31:38:18 loss: 1.4741 Lr: 0.00035
[2025-04-08 14:08:53,155 INFO misc.py line 113 3298914] Train: [1/100][2205/2402] Data 0.004 (0.004) Batch 0.494 (0.479) Remain 31:38:19 loss: 1.4324 Lr: 0.00035
[2025-04-08 14:08:53,709 INFO misc.py line 113 3298914] Train: [1/100][2206/2402] Data 0.004 (0.004) Batch 0.554 (0.479) Remain 31:38:27 loss: 1.4984 Lr: 0.00035
[2025-04-08 14:08:54,212 INFO misc.py line 113 3298914] Train: [1/100][2207/2402] Data 0.003 (0.004) Batch 0.502 (0.479) Remain 31:38:29 loss: 1.1175 Lr: 0.00035
[2025-04-08 14:08:54,724 INFO misc.py line 113 3298914] Train: [1/100][2208/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:38:32 loss: 1.2933 Lr: 0.00035
[2025-04-08 14:08:55,121 INFO misc.py line 113 3298914] Train: [1/100][2209/2402] Data 0.003 (0.004) Batch 0.397 (0.479) Remain 31:38:23 loss: 1.4903 Lr: 0.00035
[2025-04-08 14:08:55,619 INFO misc.py line 113 3298914] Train: [1/100][2210/2402] Data 0.004 (0.004) Batch 0.498 (0.479) Remain 31:38:24 loss: 1.4927 Lr: 0.00035
[2025-04-08 14:08:56,094 INFO misc.py line 113 3298914] Train: [1/100][2211/2402] Data 0.004 (0.004) Batch 0.475 (0.479) Remain 31:38:23 loss: 1.6397 Lr: 0.00035
[2025-04-08 14:08:56,487 INFO misc.py line 113 3298914] Train: [1/100][2212/2402] Data 0.004 (0.004) Batch 0.393 (0.479) Remain 31:38:14 loss: 1.1962 Lr: 0.00035
[2025-04-08 14:08:56,943 INFO misc.py line 113 3298914] Train: [1/100][2213/2402] Data 0.003 (0.004) Batch 0.456 (0.479) Remain 31:38:11 loss: 1.5010 Lr: 0.00035
[2025-04-08 14:08:57,499 INFO misc.py line 113 3298914] Train: [1/100][2214/2402] Data 0.004 (0.004) Batch 0.556 (0.479) Remain 31:38:19 loss: 1.7772 Lr: 0.00035
[2025-04-08 14:08:57,974 INFO misc.py line 113 3298914] Train: [1/100][2215/2402] Data 0.003 (0.004) Batch 0.475 (0.479) Remain 31:38:18 loss: 1.4728 Lr: 0.00035
[2025-04-08 14:08:58,520 INFO misc.py line 113 3298914] Train: [1/100][2216/2402] Data 0.003 (0.004) Batch 0.546 (0.479) Remain 31:38:25 loss: 1.5804 Lr: 0.00035
[2025-04-08 14:08:58,983 INFO misc.py line 113 3298914] Train: [1/100][2217/2402] Data 0.004 (0.004) Batch 0.463 (0.479) Remain 31:38:22 loss: 1.4822 Lr: 0.00035
[2025-04-08 14:08:59,432 INFO misc.py line 113 3298914] Train: [1/100][2218/2402] Data 0.004 (0.004) Batch 0.448 (0.479) Remain 31:38:19 loss: 1.5625 Lr: 0.00035
[2025-04-08 14:08:59,843 INFO misc.py line 113 3298914] Train: [1/100][2219/2402] Data 0.003 (0.004) Batch 0.411 (0.479) Remain 31:38:11 loss: 1.6076 Lr: 0.00035
[2025-04-08 14:09:00,377 INFO misc.py line 113 3298914] Train: [1/100][2220/2402] Data 0.004 (0.004) Batch 0.534 (0.479) Remain 31:38:17 loss: 1.2504 Lr: 0.00035
[2025-04-08 14:09:00,821 INFO misc.py line 113 3298914] Train: [1/100][2221/2402] Data 0.004 (0.004) Batch 0.444 (0.479) Remain 31:38:12 loss: 1.6535 Lr: 0.00035
[2025-04-08 14:09:01,299 INFO misc.py line 113 3298914] Train: [1/100][2222/2402] Data 0.003 (0.004) Batch 0.478 (0.479) Remain 31:38:12 loss: 1.3079 Lr: 0.00035
[2025-04-08 14:09:01,735 INFO misc.py line 113 3298914] Train: [1/100][2223/2402] Data 0.004 (0.004) Batch 0.437 (0.479) Remain 31:38:07 loss: 1.5354 Lr: 0.00035
[2025-04-08 14:09:02,035 INFO misc.py line 113 3298914] Train: [1/100][2224/2402] Data 0.003 (0.004) Batch 0.300 (0.478) Remain 31:37:47 loss: 1.2401 Lr: 0.00035
[2025-04-08 14:09:02,481 INFO misc.py line 113 3298914] Train: [1/100][2225/2402] Data 0.003 (0.004) Batch 0.446 (0.478) Remain 31:37:43 loss: 1.5341 Lr: 0.00035
[2025-04-08 14:09:02,997 INFO misc.py line 113 3298914] Train: [1/100][2226/2402] Data 0.003 (0.004) Batch 0.516 (0.478) Remain 31:37:47 loss: 1.2958 Lr: 0.00035
[2025-04-08 14:09:03,555 INFO misc.py line 113 3298914] Train: [1/100][2227/2402] Data 0.004 (0.004) Batch 0.558 (0.479) Remain 31:37:55 loss: 1.4782 Lr: 0.00035
[2025-04-08 14:09:04,134 INFO misc.py line 113 3298914] Train: [1/100][2228/2402] Data 0.003 (0.004) Batch 0.579 (0.479) Remain 31:38:05 loss: 1.9647 Lr: 0.00035
[2025-04-08 14:09:04,669 INFO misc.py line 113 3298914] Train: [1/100][2229/2402] Data 0.003 (0.004) Batch 0.536 (0.479) Remain 31:38:11 loss: 1.6455 Lr: 0.00035
[2025-04-08 14:09:05,057 INFO misc.py line 113 3298914] Train: [1/100][2230/2402] Data 0.004 (0.004) Batch 0.387 (0.479) Remain 31:38:00 loss: 1.4469 Lr: 0.00035
[2025-04-08 14:09:05,590 INFO misc.py line 113 3298914] Train: [1/100][2231/2402] Data 0.003 (0.004) Batch 0.533 (0.479) Remain 31:38:06 loss: 1.6759 Lr: 0.00035
[2025-04-08 14:09:06,123 INFO misc.py line 113 3298914] Train: [1/100][2232/2402] Data 0.004 (0.004) Batch 0.533 (0.479) Remain 31:38:11 loss: 1.8536 Lr: 0.00035
[2025-04-08 14:09:06,563 INFO misc.py line 113 3298914] Train: [1/100][2233/2402] Data 0.004 (0.004) Batch 0.440 (0.479) Remain 31:38:06 loss: 1.3050 Lr: 0.00035
[2025-04-08 14:09:07,016 INFO misc.py line 113 3298914] Train: [1/100][2234/2402] Data 0.004 (0.004) Batch 0.453 (0.479) Remain 31:38:03 loss: 1.3801 Lr: 0.00035
[2025-04-08 14:09:07,445 INFO misc.py line 113 3298914] Train: [1/100][2235/2402] Data 0.003 (0.004) Batch 0.430 (0.479) Remain 31:37:58 loss: 1.6588 Lr: 0.00035
[2025-04-08 14:09:07,891 INFO misc.py line 113 3298914] Train: [1/100][2236/2402] Data 0.003 (0.004) Batch 0.446 (0.479) Remain 31:37:54 loss: 1.4900 Lr: 0.00035
[2025-04-08 14:09:08,320 INFO misc.py line 113 3298914] Train: [1/100][2237/2402] Data 0.004 (0.004) Batch 0.429 (0.479) Remain 31:37:48 loss: 1.2840 Lr: 0.00035
[2025-04-08 14:09:08,639 INFO misc.py line 113 3298914] Train: [1/100][2238/2402] Data 0.003 (0.004) Batch 0.319 (0.478) Remain 31:37:30 loss: 1.3715 Lr: 0.00035
[2025-04-08 14:09:09,018 INFO misc.py line 113 3298914] Train: [1/100][2239/2402] Data 0.003 (0.004) Batch 0.379 (0.478) Remain 31:37:19 loss: 1.1433 Lr: 0.00035
[2025-04-08 14:09:09,461 INFO misc.py line 113 3298914] Train: [1/100][2240/2402] Data 0.003 (0.004) Batch 0.443 (0.478) Remain 31:37:15 loss: 1.2341 Lr: 0.00035
[2025-04-08 14:09:09,965 INFO misc.py line 113 3298914] Train: [1/100][2241/2402] Data 0.003 (0.004) Batch 0.504 (0.478) Remain 31:37:17 loss: 1.1843 Lr: 0.00035
[2025-04-08 14:09:10,485 INFO misc.py line 113 3298914] Train: [1/100][2242/2402] Data 0.004 (0.004) Batch 0.520 (0.478) Remain 31:37:21 loss: 1.5299 Lr: 0.00035
[2025-04-08 14:09:11,022 INFO misc.py line 113 3298914] Train: [1/100][2243/2402] Data 0.003 (0.004) Batch 0.538 (0.478) Remain 31:37:27 loss: 1.2856 Lr: 0.00035
[2025-04-08 14:09:11,472 INFO misc.py line 113 3298914] Train: [1/100][2244/2402] Data 0.003 (0.004) Batch 0.450 (0.478) Remain 31:37:23 loss: 1.6346 Lr: 0.00035
[2025-04-08 14:09:11,921 INFO misc.py line 113 3298914] Train: [1/100][2245/2402] Data 0.004 (0.004) Batch 0.449 (0.478) Remain 31:37:20 loss: 0.9061 Lr: 0.00035
[2025-04-08 14:09:12,443 INFO misc.py line 113 3298914] Train: [1/100][2246/2402] Data 0.004 (0.004) Batch 0.522 (0.478) Remain 31:37:24 loss: 1.4351 Lr: 0.00035
[2025-04-08 14:09:12,914 INFO misc.py line 113 3298914] Train: [1/100][2247/2402] Data 0.003 (0.004) Batch 0.471 (0.478) Remain 31:37:23 loss: 1.4082 Lr: 0.00035
[2025-04-08 14:09:13,418 INFO misc.py line 113 3298914] Train: [1/100][2248/2402] Data 0.004 (0.004) Batch 0.504 (0.478) Remain 31:37:25 loss: 1.4807 Lr: 0.00035
[2025-04-08 14:09:13,977 INFO misc.py line 113 3298914] Train: [1/100][2249/2402] Data 0.003 (0.004) Batch 0.559 (0.478) Remain 31:37:33 loss: 1.3512 Lr: 0.00035
[2025-04-08 14:09:14,388 INFO misc.py line 113 3298914] Train: [1/100][2250/2402] Data 0.004 (0.004) Batch 0.410 (0.478) Remain 31:37:25 loss: 1.1190 Lr: 0.00035
[2025-04-08 14:09:14,834 INFO misc.py line 113 3298914] Train: [1/100][2251/2402] Data 0.004 (0.004) Batch 0.446 (0.478) Remain 31:37:21 loss: 1.9982 Lr: 0.00035
[2025-04-08 14:09:15,326 INFO misc.py line 113 3298914] Train: [1/100][2252/2402] Data 0.003 (0.004) Batch 0.492 (0.478) Remain 31:37:22 loss: 1.4706 Lr: 0.00035
[2025-04-08 14:09:15,834 INFO misc.py line 113 3298914] Train: [1/100][2253/2402] Data 0.004 (0.004) Batch 0.508 (0.478) Remain 31:37:25 loss: 1.3687 Lr: 0.00035
[2025-04-08 14:09:16,313 INFO misc.py line 113 3298914] Train: [1/100][2254/2402] Data 0.004 (0.004) Batch 0.479 (0.478) Remain 31:37:25 loss: 1.4427 Lr: 0.00035
[2025-04-08 14:09:16,862 INFO misc.py line 113 3298914] Train: [1/100][2255/2402] Data 0.003 (0.004) Batch 0.549 (0.478) Remain 31:37:32 loss: 1.4280 Lr: 0.00035
[2025-04-08 14:09:17,345 INFO misc.py line 113 3298914] Train: [1/100][2256/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:37:32 loss: 1.3767 Lr: 0.00035
[2025-04-08 14:09:17,861 INFO misc.py line 113 3298914] Train: [1/100][2257/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:37:35 loss: 1.2789 Lr: 0.00035
[2025-04-08 14:09:18,385 INFO misc.py line 113 3298914] Train: [1/100][2258/2402] Data 0.003 (0.004) Batch 0.525 (0.479) Remain 31:37:40 loss: 1.6580 Lr: 0.00035
[2025-04-08 14:09:18,806 INFO misc.py line 113 3298914] Train: [1/100][2259/2402] Data 0.004 (0.004) Batch 0.420 (0.478) Remain 31:37:33 loss: 1.7439 Lr: 0.00035
[2025-04-08 14:09:19,233 INFO misc.py line 113 3298914] Train: [1/100][2260/2402] Data 0.003 (0.004) Batch 0.427 (0.478) Remain 31:37:27 loss: 1.4559 Lr: 0.00035
[2025-04-08 14:09:19,762 INFO misc.py line 113 3298914] Train: [1/100][2261/2402] Data 0.003 (0.004) Batch 0.530 (0.478) Remain 31:37:32 loss: 1.8507 Lr: 0.00035
[2025-04-08 14:09:20,304 INFO misc.py line 113 3298914] Train: [1/100][2262/2402] Data 0.003 (0.004) Batch 0.542 (0.479) Remain 31:37:38 loss: 0.8707 Lr: 0.00035
[2025-04-08 14:09:20,780 INFO misc.py line 113 3298914] Train: [1/100][2263/2402] Data 0.003 (0.004) Batch 0.475 (0.479) Remain 31:37:37 loss: 1.2378 Lr: 0.00035
[2025-04-08 14:09:21,241 INFO misc.py line 113 3298914] Train: [1/100][2264/2402] Data 0.003 (0.004) Batch 0.462 (0.479) Remain 31:37:35 loss: 1.5782 Lr: 0.00035
[2025-04-08 14:09:21,750 INFO misc.py line 113 3298914] Train: [1/100][2265/2402] Data 0.003 (0.004) Batch 0.509 (0.479) Remain 31:37:38 loss: 1.2830 Lr: 0.00035
[2025-04-08 14:09:22,159 INFO misc.py line 113 3298914] Train: [1/100][2266/2402] Data 0.004 (0.004) Batch 0.409 (0.478) Remain 31:37:30 loss: 1.7142 Lr: 0.00035
[2025-04-08 14:09:22,543 INFO misc.py line 113 3298914] Train: [1/100][2267/2402] Data 0.003 (0.004) Batch 0.385 (0.478) Remain 31:37:20 loss: 1.3974 Lr: 0.00035
[2025-04-08 14:09:23,047 INFO misc.py line 113 3298914] Train: [1/100][2268/2402] Data 0.003 (0.004) Batch 0.504 (0.478) Remain 31:37:22 loss: 1.7768 Lr: 0.00035
[2025-04-08 14:09:23,488 INFO misc.py line 113 3298914] Train: [1/100][2269/2402] Data 0.003 (0.004) Batch 0.440 (0.478) Remain 31:37:17 loss: 1.1631 Lr: 0.00035
[2025-04-08 14:09:24,010 INFO misc.py line 113 3298914] Train: [1/100][2270/2402] Data 0.003 (0.004) Batch 0.522 (0.478) Remain 31:37:21 loss: 1.2087 Lr: 0.00035
[2025-04-08 14:09:24,493 INFO misc.py line 113 3298914] Train: [1/100][2271/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:37:21 loss: 1.3207 Lr: 0.00035
[2025-04-08 14:09:24,918 INFO misc.py line 113 3298914] Train: [1/100][2272/2402] Data 0.004 (0.004) Batch 0.425 (0.478) Remain 31:37:15 loss: 1.3694 Lr: 0.00035
[2025-04-08 14:09:25,444 INFO misc.py line 113 3298914] Train: [1/100][2273/2402] Data 0.003 (0.004) Batch 0.526 (0.478) Remain 31:37:20 loss: 1.6728 Lr: 0.00035
[2025-04-08 14:09:25,975 INFO misc.py line 113 3298914] Train: [1/100][2274/2402] Data 0.003 (0.004) Batch 0.531 (0.478) Remain 31:37:25 loss: 1.4398 Lr: 0.00035
[2025-04-08 14:09:26,421 INFO misc.py line 113 3298914] Train: [1/100][2275/2402] Data 0.003 (0.004) Batch 0.447 (0.478) Remain 31:37:21 loss: 1.4842 Lr: 0.00035
[2025-04-08 14:09:26,942 INFO misc.py line 113 3298914] Train: [1/100][2276/2402] Data 0.003 (0.004) Batch 0.520 (0.478) Remain 31:37:25 loss: 1.3908 Lr: 0.00035
[2025-04-08 14:09:27,471 INFO misc.py line 113 3298914] Train: [1/100][2277/2402] Data 0.004 (0.004) Batch 0.529 (0.479) Remain 31:37:30 loss: 1.3777 Lr: 0.00035
[2025-04-08 14:09:27,939 INFO misc.py line 113 3298914] Train: [1/100][2278/2402] Data 0.003 (0.004) Batch 0.468 (0.479) Remain 31:37:28 loss: 1.7361 Lr: 0.00035
[2025-04-08 14:09:28,474 INFO misc.py line 113 3298914] Train: [1/100][2279/2402] Data 0.003 (0.004) Batch 0.534 (0.479) Remain 31:37:34 loss: 1.2935 Lr: 0.00035
[2025-04-08 14:09:28,841 INFO misc.py line 113 3298914] Train: [1/100][2280/2402] Data 0.003 (0.004) Batch 0.368 (0.478) Remain 31:37:22 loss: 1.5130 Lr: 0.00036
[2025-04-08 14:09:29,283 INFO misc.py line 113 3298914] Train: [1/100][2281/2402] Data 0.003 (0.004) Batch 0.442 (0.478) Remain 31:37:17 loss: 1.5683 Lr: 0.00036
[2025-04-08 14:09:29,769 INFO misc.py line 113 3298914] Train: [1/100][2282/2402] Data 0.003 (0.004) Batch 0.485 (0.478) Remain 31:37:17 loss: 1.5488 Lr: 0.00036
[2025-04-08 14:09:30,322 INFO misc.py line 113 3298914] Train: [1/100][2283/2402] Data 0.004 (0.004) Batch 0.554 (0.479) Remain 31:37:25 loss: 1.6164 Lr: 0.00036
[2025-04-08 14:09:30,793 INFO misc.py line 113 3298914] Train: [1/100][2284/2402] Data 0.004 (0.004) Batch 0.471 (0.479) Remain 31:37:24 loss: 1.5284 Lr: 0.00036
[2025-04-08 14:09:31,305 INFO misc.py line 113 3298914] Train: [1/100][2285/2402] Data 0.003 (0.004) Batch 0.512 (0.479) Remain 31:37:27 loss: 1.5209 Lr: 0.00036
[2025-04-08 14:09:31,823 INFO misc.py line 113 3298914] Train: [1/100][2286/2402] Data 0.003 (0.004) Batch 0.518 (0.479) Remain 31:37:30 loss: 1.4162 Lr: 0.00036
[2025-04-08 14:09:32,278 INFO misc.py line 113 3298914] Train: [1/100][2287/2402] Data 0.003 (0.004) Batch 0.455 (0.479) Remain 31:37:27 loss: 1.6098 Lr: 0.00036
[2025-04-08 14:09:32,709 INFO misc.py line 113 3298914] Train: [1/100][2288/2402] Data 0.003 (0.004) Batch 0.431 (0.479) Remain 31:37:22 loss: 1.1681 Lr: 0.00036
[2025-04-08 14:09:33,236 INFO misc.py line 113 3298914] Train: [1/100][2289/2402] Data 0.004 (0.004) Batch 0.528 (0.479) Remain 31:37:26 loss: 1.1534 Lr: 0.00036
[2025-04-08 14:09:33,753 INFO misc.py line 113 3298914] Train: [1/100][2290/2402] Data 0.004 (0.004) Batch 0.516 (0.479) Remain 31:37:30 loss: 1.1378 Lr: 0.00036
[2025-04-08 14:09:34,213 INFO misc.py line 113 3298914] Train: [1/100][2291/2402] Data 0.004 (0.004) Batch 0.460 (0.479) Remain 31:37:27 loss: 1.4142 Lr: 0.00036
[2025-04-08 14:09:34,671 INFO misc.py line 113 3298914] Train: [1/100][2292/2402] Data 0.003 (0.004) Batch 0.458 (0.479) Remain 31:37:25 loss: 1.1746 Lr: 0.00036
[2025-04-08 14:09:35,131 INFO misc.py line 113 3298914] Train: [1/100][2293/2402] Data 0.004 (0.004) Batch 0.460 (0.479) Remain 31:37:23 loss: 1.2133 Lr: 0.00036
[2025-04-08 14:09:35,684 INFO misc.py line 113 3298914] Train: [1/100][2294/2402] Data 0.003 (0.004) Batch 0.553 (0.479) Remain 31:37:30 loss: 1.6171 Lr: 0.00036
[2025-04-08 14:09:36,155 INFO misc.py line 113 3298914] Train: [1/100][2295/2402] Data 0.004 (0.004) Batch 0.471 (0.479) Remain 31:37:28 loss: 1.5562 Lr: 0.00036
[2025-04-08 14:09:36,650 INFO misc.py line 113 3298914] Train: [1/100][2296/2402] Data 0.003 (0.004) Batch 0.495 (0.479) Remain 31:37:30 loss: 1.7477 Lr: 0.00036
[2025-04-08 14:09:37,043 INFO misc.py line 113 3298914] Train: [1/100][2297/2402] Data 0.003 (0.004) Batch 0.393 (0.479) Remain 31:37:20 loss: 1.5342 Lr: 0.00036
[2025-04-08 14:09:37,655 INFO misc.py line 113 3298914] Train: [1/100][2298/2402] Data 0.004 (0.004) Batch 0.612 (0.479) Remain 31:37:34 loss: 1.5435 Lr: 0.00036
[2025-04-08 14:09:38,193 INFO misc.py line 113 3298914] Train: [1/100][2299/2402] Data 0.003 (0.004) Batch 0.538 (0.479) Remain 31:37:39 loss: 1.3226 Lr: 0.00036
[2025-04-08 14:09:38,671 INFO misc.py line 113 3298914] Train: [1/100][2300/2402] Data 0.004 (0.004) Batch 0.478 (0.479) Remain 31:37:39 loss: 1.6250 Lr: 0.00036
[2025-04-08 14:09:39,224 INFO misc.py line 113 3298914] Train: [1/100][2301/2402] Data 0.004 (0.004) Batch 0.553 (0.479) Remain 31:37:46 loss: 1.6176 Lr: 0.00036
[2025-04-08 14:09:39,589 INFO misc.py line 113 3298914] Train: [1/100][2302/2402] Data 0.004 (0.004) Batch 0.365 (0.479) Remain 31:37:34 loss: 1.3591 Lr: 0.00036
[2025-04-08 14:09:39,924 INFO misc.py line 113 3298914] Train: [1/100][2303/2402] Data 0.003 (0.004) Batch 0.335 (0.479) Remain 31:37:19 loss: 1.4614 Lr: 0.00036
[2025-04-08 14:09:40,324 INFO misc.py line 113 3298914] Train: [1/100][2304/2402] Data 0.004 (0.004) Batch 0.400 (0.478) Remain 31:37:10 loss: 1.6272 Lr: 0.00036
[2025-04-08 14:09:40,729 INFO misc.py line 113 3298914] Train: [1/100][2305/2402] Data 0.004 (0.004) Batch 0.405 (0.478) Remain 31:37:02 loss: 1.1730 Lr: 0.00036
[2025-04-08 14:09:41,201 INFO misc.py line 113 3298914] Train: [1/100][2306/2402] Data 0.004 (0.004) Batch 0.472 (0.478) Remain 31:37:01 loss: 1.3502 Lr: 0.00036
[2025-04-08 14:09:41,639 INFO misc.py line 113 3298914] Train: [1/100][2307/2402] Data 0.003 (0.004) Batch 0.437 (0.478) Remain 31:36:56 loss: 1.3999 Lr: 0.00036
[2025-04-08 14:09:42,214 INFO misc.py line 113 3298914] Train: [1/100][2308/2402] Data 0.003 (0.004) Batch 0.575 (0.478) Remain 31:37:05 loss: 1.8081 Lr: 0.00036
[2025-04-08 14:09:42,566 INFO misc.py line 113 3298914] Train: [1/100][2309/2402] Data 0.004 (0.004) Batch 0.353 (0.478) Remain 31:36:52 loss: 1.5258 Lr: 0.00036
[2025-04-08 14:09:42,995 INFO misc.py line 113 3298914] Train: [1/100][2310/2402] Data 0.003 (0.004) Batch 0.429 (0.478) Remain 31:36:46 loss: 1.3832 Lr: 0.00036
[2025-04-08 14:09:43,517 INFO misc.py line 113 3298914] Train: [1/100][2311/2402] Data 0.003 (0.004) Batch 0.521 (0.478) Remain 31:36:50 loss: 1.2773 Lr: 0.00036
[2025-04-08 14:09:43,986 INFO misc.py line 113 3298914] Train: [1/100][2312/2402] Data 0.003 (0.004) Batch 0.470 (0.478) Remain 31:36:49 loss: 1.7210 Lr: 0.00036
[2025-04-08 14:09:44,522 INFO misc.py line 113 3298914] Train: [1/100][2313/2402] Data 0.003 (0.004) Batch 0.535 (0.478) Remain 31:36:54 loss: 1.4194 Lr: 0.00036
[2025-04-08 14:09:45,003 INFO misc.py line 113 3298914] Train: [1/100][2314/2402] Data 0.004 (0.004) Batch 0.481 (0.478) Remain 31:36:54 loss: 1.3162 Lr: 0.00036
[2025-04-08 14:09:45,395 INFO misc.py line 113 3298914] Train: [1/100][2315/2402] Data 0.003 (0.004) Batch 0.391 (0.478) Remain 31:36:45 loss: 1.3253 Lr: 0.00036
[2025-04-08 14:09:45,938 INFO misc.py line 113 3298914] Train: [1/100][2316/2402] Data 0.003 (0.004) Batch 0.543 (0.478) Remain 31:36:51 loss: 1.6423 Lr: 0.00036
[2025-04-08 14:09:46,347 INFO misc.py line 113 3298914] Train: [1/100][2317/2402] Data 0.004 (0.004) Batch 0.409 (0.478) Remain 31:36:43 loss: 1.5543 Lr: 0.00036
[2025-04-08 14:09:46,793 INFO misc.py line 113 3298914] Train: [1/100][2318/2402] Data 0.003 (0.004) Batch 0.446 (0.478) Remain 31:36:40 loss: 1.3501 Lr: 0.00036
[2025-04-08 14:09:47,279 INFO misc.py line 113 3298914] Train: [1/100][2319/2402] Data 0.003 (0.004) Batch 0.486 (0.478) Remain 31:36:40 loss: 1.6183 Lr: 0.00036
[2025-04-08 14:09:47,838 INFO misc.py line 113 3298914] Train: [1/100][2320/2402] Data 0.004 (0.004) Batch 0.559 (0.478) Remain 31:36:48 loss: 1.8489 Lr: 0.00036
[2025-04-08 14:09:48,257 INFO misc.py line 113 3298914] Train: [1/100][2321/2402] Data 0.003 (0.004) Batch 0.419 (0.478) Remain 31:36:41 loss: 1.2514 Lr: 0.00036
[2025-04-08 14:09:48,713 INFO misc.py line 113 3298914] Train: [1/100][2322/2402] Data 0.003 (0.004) Batch 0.456 (0.478) Remain 31:36:38 loss: 1.5583 Lr: 0.00036
[2025-04-08 14:09:49,097 INFO misc.py line 113 3298914] Train: [1/100][2323/2402] Data 0.003 (0.004) Batch 0.384 (0.478) Remain 31:36:28 loss: 1.4563 Lr: 0.00036
[2025-04-08 14:09:49,621 INFO misc.py line 113 3298914] Train: [1/100][2324/2402] Data 0.003 (0.004) Batch 0.524 (0.478) Remain 31:36:32 loss: 1.2239 Lr: 0.00036
[2025-04-08 14:09:50,029 INFO misc.py line 113 3298914] Train: [1/100][2325/2402] Data 0.003 (0.004) Batch 0.408 (0.478) Remain 31:36:25 loss: 1.5310 Lr: 0.00036
[2025-04-08 14:09:50,544 INFO misc.py line 113 3298914] Train: [1/100][2326/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:36:28 loss: 1.5534 Lr: 0.00036
[2025-04-08 14:09:51,108 INFO misc.py line 113 3298914] Train: [1/100][2327/2402] Data 0.003 (0.004) Batch 0.563 (0.478) Remain 31:36:36 loss: 1.2130 Lr: 0.00036
[2025-04-08 14:09:51,496 INFO misc.py line 113 3298914] Train: [1/100][2328/2402] Data 0.003 (0.004) Batch 0.388 (0.478) Remain 31:36:26 loss: 1.2250 Lr: 0.00036
[2025-04-08 14:09:52,099 INFO misc.py line 113 3298914] Train: [1/100][2329/2402] Data 0.004 (0.004) Batch 0.604 (0.478) Remain 31:36:39 loss: 1.2742 Lr: 0.00036
[2025-04-08 14:09:52,508 INFO misc.py line 113 3298914] Train: [1/100][2330/2402] Data 0.004 (0.004) Batch 0.409 (0.478) Remain 31:36:31 loss: 1.2213 Lr: 0.00036
[2025-04-08 14:09:53,027 INFO misc.py line 113 3298914] Train: [1/100][2331/2402] Data 0.003 (0.004) Batch 0.519 (0.478) Remain 31:36:35 loss: 1.2580 Lr: 0.00036
[2025-04-08 14:09:53,560 INFO misc.py line 113 3298914] Train: [1/100][2332/2402] Data 0.003 (0.004) Batch 0.533 (0.478) Remain 31:36:40 loss: 1.4657 Lr: 0.00036
[2025-04-08 14:09:54,004 INFO misc.py line 113 3298914] Train: [1/100][2333/2402] Data 0.004 (0.004) Batch 0.444 (0.478) Remain 31:36:36 loss: 1.3024 Lr: 0.00036
[2025-04-08 14:09:54,364 INFO misc.py line 113 3298914] Train: [1/100][2334/2402] Data 0.004 (0.004) Batch 0.360 (0.478) Remain 31:36:23 loss: 1.4487 Lr: 0.00036
[2025-04-08 14:09:54,775 INFO misc.py line 113 3298914] Train: [1/100][2335/2402] Data 0.003 (0.004) Batch 0.410 (0.478) Remain 31:36:16 loss: 1.1518 Lr: 0.00036
[2025-04-08 14:09:55,327 INFO misc.py line 113 3298914] Train: [1/100][2336/2402] Data 0.004 (0.004) Batch 0.553 (0.478) Remain 31:36:23 loss: 1.4497 Lr: 0.00036
[2025-04-08 14:09:55,882 INFO misc.py line 113 3298914] Train: [1/100][2337/2402] Data 0.003 (0.004) Batch 0.554 (0.478) Remain 31:36:30 loss: 1.5748 Lr: 0.00036
[2025-04-08 14:09:56,246 INFO misc.py line 113 3298914] Train: [1/100][2338/2402] Data 0.004 (0.004) Batch 0.364 (0.478) Remain 31:36:18 loss: 1.5252 Lr: 0.00036
[2025-04-08 14:09:56,790 INFO misc.py line 113 3298914] Train: [1/100][2339/2402] Data 0.003 (0.004) Batch 0.544 (0.478) Remain 31:36:25 loss: 1.3683 Lr: 0.00036
[2025-04-08 14:09:57,168 INFO misc.py line 113 3298914] Train: [1/100][2340/2402] Data 0.003 (0.004) Batch 0.378 (0.478) Remain 31:36:14 loss: 1.6551 Lr: 0.00036
[2025-04-08 14:09:57,704 INFO misc.py line 113 3298914] Train: [1/100][2341/2402] Data 0.004 (0.004) Batch 0.537 (0.478) Remain 31:36:19 loss: 1.8649 Lr: 0.00036
[2025-04-08 14:09:58,152 INFO misc.py line 113 3298914] Train: [1/100][2342/2402] Data 0.003 (0.004) Batch 0.448 (0.478) Remain 31:36:16 loss: 1.3402 Lr: 0.00036
[2025-04-08 14:09:58,655 INFO misc.py line 113 3298914] Train: [1/100][2343/2402] Data 0.003 (0.004) Batch 0.503 (0.478) Remain 31:36:18 loss: 1.0452 Lr: 0.00036
[2025-04-08 14:09:59,096 INFO misc.py line 113 3298914] Train: [1/100][2344/2402] Data 0.004 (0.004) Batch 0.440 (0.478) Remain 31:36:13 loss: 1.4215 Lr: 0.00036
[2025-04-08 14:09:59,564 INFO misc.py line 113 3298914] Train: [1/100][2345/2402] Data 0.004 (0.004) Batch 0.469 (0.478) Remain 31:36:12 loss: 1.3443 Lr: 0.00036
[2025-04-08 14:10:00,102 INFO misc.py line 113 3298914] Train: [1/100][2346/2402] Data 0.003 (0.004) Batch 0.537 (0.478) Remain 31:36:17 loss: 1.6703 Lr: 0.00036
[2025-04-08 14:10:00,548 INFO misc.py line 113 3298914] Train: [1/100][2347/2402] Data 0.004 (0.004) Batch 0.446 (0.478) Remain 31:36:14 loss: 1.5138 Lr: 0.00036
[2025-04-08 14:10:00,978 INFO misc.py line 113 3298914] Train: [1/100][2348/2402] Data 0.003 (0.004) Batch 0.430 (0.478) Remain 31:36:08 loss: 1.6851 Lr: 0.00036
[2025-04-08 14:10:01,493 INFO misc.py line 113 3298914] Train: [1/100][2349/2402] Data 0.003 (0.004) Batch 0.515 (0.478) Remain 31:36:12 loss: 1.0973 Lr: 0.00036
[2025-04-08 14:10:01,944 INFO misc.py line 113 3298914] Train: [1/100][2350/2402] Data 0.003 (0.004) Batch 0.451 (0.478) Remain 31:36:08 loss: 1.5502 Lr: 0.00036
[2025-04-08 14:10:02,288 INFO misc.py line 113 3298914] Train: [1/100][2351/2402] Data 0.003 (0.004) Batch 0.344 (0.478) Remain 31:35:54 loss: 1.0417 Lr: 0.00036
[2025-04-08 14:10:02,719 INFO misc.py line 113 3298914] Train: [1/100][2352/2402] Data 0.003 (0.004) Batch 0.431 (0.478) Remain 31:35:49 loss: 1.3172 Lr: 0.00036
[2025-04-08 14:10:03,225 INFO misc.py line 113 3298914] Train: [1/100][2353/2402] Data 0.004 (0.004) Batch 0.506 (0.478) Remain 31:35:51 loss: 1.5462 Lr: 0.00036
[2025-04-08 14:10:03,553 INFO misc.py line 113 3298914] Train: [1/100][2354/2402] Data 0.003 (0.004) Batch 0.328 (0.478) Remain 31:35:36 loss: 1.4623 Lr: 0.00036
[2025-04-08 14:10:03,909 INFO misc.py line 113 3298914] Train: [1/100][2355/2402] Data 0.003 (0.004) Batch 0.356 (0.478) Remain 31:35:23 loss: 1.2272 Lr: 0.00037
[2025-04-08 14:10:04,449 INFO misc.py line 113 3298914] Train: [1/100][2356/2402] Data 0.004 (0.004) Batch 0.539 (0.478) Remain 31:35:29 loss: 1.8103 Lr: 0.00037
[2025-04-08 14:10:05,005 INFO misc.py line 113 3298914] Train: [1/100][2357/2402] Data 0.004 (0.004) Batch 0.557 (0.478) Remain 31:35:36 loss: 1.7305 Lr: 0.00037
[2025-04-08 14:10:05,566 INFO misc.py line 113 3298914] Train: [1/100][2358/2402] Data 0.003 (0.004) Batch 0.560 (0.478) Remain 31:35:44 loss: 1.2339 Lr: 0.00037
[2025-04-08 14:10:06,100 INFO misc.py line 113 3298914] Train: [1/100][2359/2402] Data 0.003 (0.004) Batch 0.533 (0.478) Remain 31:35:49 loss: 1.2910 Lr: 0.00037
[2025-04-08 14:10:06,552 INFO misc.py line 113 3298914] Train: [1/100][2360/2402] Data 0.004 (0.004) Batch 0.452 (0.478) Remain 31:35:46 loss: 1.3118 Lr: 0.00037
[2025-04-08 14:10:07,068 INFO misc.py line 113 3298914] Train: [1/100][2361/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:35:49 loss: 1.2933 Lr: 0.00037
[2025-04-08 14:10:07,606 INFO misc.py line 113 3298914] Train: [1/100][2362/2402] Data 0.004 (0.004) Batch 0.538 (0.478) Remain 31:35:55 loss: 1.1343 Lr: 0.00037
[2025-04-08 14:10:08,039 INFO misc.py line 113 3298914] Train: [1/100][2363/2402] Data 0.004 (0.004) Batch 0.434 (0.478) Remain 31:35:50 loss: 1.0038 Lr: 0.00037
[2025-04-08 14:10:08,506 INFO misc.py line 113 3298914] Train: [1/100][2364/2402] Data 0.003 (0.004) Batch 0.466 (0.478) Remain 31:35:48 loss: 1.0490 Lr: 0.00037
[2025-04-08 14:10:08,982 INFO misc.py line 113 3298914] Train: [1/100][2365/2402] Data 0.004 (0.004) Batch 0.476 (0.478) Remain 31:35:47 loss: 1.1098 Lr: 0.00037
[2025-04-08 14:10:09,393 INFO misc.py line 113 3298914] Train: [1/100][2366/2402] Data 0.004 (0.004) Batch 0.412 (0.478) Remain 31:35:40 loss: 0.7610 Lr: 0.00037
[2025-04-08 14:10:09,825 INFO misc.py line 113 3298914] Train: [1/100][2367/2402] Data 0.003 (0.004) Batch 0.431 (0.478) Remain 31:35:35 loss: 1.9903 Lr: 0.00037
[2025-04-08 14:10:10,302 INFO misc.py line 113 3298914] Train: [1/100][2368/2402] Data 0.003 (0.004) Batch 0.478 (0.478) Remain 31:35:34 loss: 1.4875 Lr: 0.00037
[2025-04-08 14:10:10,831 INFO misc.py line 113 3298914] Train: [1/100][2369/2402] Data 0.004 (0.004) Batch 0.529 (0.478) Remain 31:35:39 loss: 1.8271 Lr: 0.00037
[2025-04-08 14:10:11,522 INFO misc.py line 113 3298914] Train: [1/100][2370/2402] Data 0.003 (0.004) Batch 0.691 (0.478) Remain 31:36:00 loss: 1.7220 Lr: 0.00037
[2025-04-08 14:10:11,951 INFO misc.py line 113 3298914] Train: [1/100][2371/2402] Data 0.004 (0.004) Batch 0.429 (0.478) Remain 31:35:54 loss: 1.3293 Lr: 0.00037
[2025-04-08 14:10:12,344 INFO misc.py line 113 3298914] Train: [1/100][2372/2402] Data 0.003 (0.004) Batch 0.393 (0.478) Remain 31:35:45 loss: 1.4435 Lr: 0.00037
[2025-04-08 14:10:12,870 INFO misc.py line 113 3298914] Train: [1/100][2373/2402] Data 0.003 (0.004) Batch 0.525 (0.478) Remain 31:35:50 loss: 0.9735 Lr: 0.00037
[2025-04-08 14:10:13,407 INFO misc.py line 113 3298914] Train: [1/100][2374/2402] Data 0.004 (0.004) Batch 0.537 (0.478) Remain 31:35:55 loss: 1.1852 Lr: 0.00037
[2025-04-08 14:10:13,823 INFO misc.py line 113 3298914] Train: [1/100][2375/2402] Data 0.003 (0.004) Batch 0.416 (0.478) Remain 31:35:48 loss: 1.2933 Lr: 0.00037
[2025-04-08 14:10:14,252 INFO misc.py line 113 3298914] Train: [1/100][2376/2402] Data 0.003 (0.004) Batch 0.429 (0.478) Remain 31:35:43 loss: 1.3912 Lr: 0.00037
[2025-04-08 14:10:14,660 INFO misc.py line 113 3298914] Train: [1/100][2377/2402] Data 0.004 (0.004) Batch 0.408 (0.478) Remain 31:35:35 loss: 1.3484 Lr: 0.00037
[2025-04-08 14:10:15,139 INFO misc.py line 113 3298914] Train: [1/100][2378/2402] Data 0.004 (0.004) Batch 0.479 (0.478) Remain 31:35:35 loss: 1.5497 Lr: 0.00037
[2025-04-08 14:10:15,588 INFO misc.py line 113 3298914] Train: [1/100][2379/2402] Data 0.004 (0.004) Batch 0.449 (0.478) Remain 31:35:32 loss: 1.5819 Lr: 0.00037
[2025-04-08 14:10:16,138 INFO misc.py line 113 3298914] Train: [1/100][2380/2402] Data 0.003 (0.004) Batch 0.550 (0.478) Remain 31:35:38 loss: 1.3039 Lr: 0.00037
[2025-04-08 14:10:16,556 INFO misc.py line 113 3298914] Train: [1/100][2381/2402] Data 0.003 (0.004) Batch 0.418 (0.478) Remain 31:35:32 loss: 1.1817 Lr: 0.00037
[2025-04-08 14:10:17,073 INFO misc.py line 113 3298914] Train: [1/100][2382/2402] Data 0.003 (0.004) Batch 0.517 (0.478) Remain 31:35:35 loss: 2.0084 Lr: 0.00037
[2025-04-08 14:10:17,606 INFO misc.py line 113 3298914] Train: [1/100][2383/2402] Data 0.003 (0.004) Batch 0.533 (0.478) Remain 31:35:40 loss: 1.3844 Lr: 0.00037
[2025-04-08 14:10:18,011 INFO misc.py line 113 3298914] Train: [1/100][2384/2402] Data 0.003 (0.004) Batch 0.404 (0.478) Remain 31:35:32 loss: 1.5546 Lr: 0.00037
[2025-04-08 14:10:18,483 INFO misc.py line 113 3298914] Train: [1/100][2385/2402] Data 0.003 (0.004) Batch 0.472 (0.478) Remain 31:35:31 loss: 1.6047 Lr: 0.00037
[2025-04-08 14:10:18,924 INFO misc.py line 113 3298914] Train: [1/100][2386/2402] Data 0.003 (0.004) Batch 0.440 (0.478) Remain 31:35:27 loss: 1.5880 Lr: 0.00037
[2025-04-08 14:10:19,430 INFO misc.py line 113 3298914] Train: [1/100][2387/2402] Data 0.003 (0.004) Batch 0.506 (0.478) Remain 31:35:29 loss: 1.4511 Lr: 0.00037
[2025-04-08 14:10:20,006 INFO misc.py line 113 3298914] Train: [1/100][2388/2402] Data 0.003 (0.004) Batch 0.576 (0.478) Remain 31:35:39 loss: 1.6265 Lr: 0.00037
[2025-04-08 14:10:20,454 INFO misc.py line 113 3298914] Train: [1/100][2389/2402] Data 0.003 (0.004) Batch 0.448 (0.478) Remain 31:35:35 loss: 1.5140 Lr: 0.00037
[2025-04-08 14:10:20,918 INFO misc.py line 113 3298914] Train: [1/100][2390/2402] Data 0.003 (0.004) Batch 0.464 (0.478) Remain 31:35:33 loss: 1.4142 Lr: 0.00037
[2025-04-08 14:10:21,416 INFO misc.py line 113 3298914] Train: [1/100][2391/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:35:35 loss: 1.7804 Lr: 0.00037
[2025-04-08 14:10:21,912 INFO misc.py line 113 3298914] Train: [1/100][2392/2402] Data 0.003 (0.004) Batch 0.496 (0.478) Remain 31:35:36 loss: 1.6088 Lr: 0.00037
[2025-04-08 14:10:22,284 INFO misc.py line 113 3298914] Train: [1/100][2393/2402] Data 0.003 (0.004) Batch 0.372 (0.478) Remain 31:35:25 loss: 1.2486 Lr: 0.00037
[2025-04-08 14:10:22,923 INFO misc.py line 113 3298914] Train: [1/100][2394/2402] Data 0.003 (0.004) Batch 0.639 (0.478) Remain 31:35:41 loss: 1.4365 Lr: 0.00037
[2025-04-08 14:10:23,330 INFO misc.py line 113 3298914] Train: [1/100][2395/2402] Data 0.003 (0.004) Batch 0.407 (0.478) Remain 31:35:33 loss: 1.6267 Lr: 0.00037
[2025-04-08 14:10:23,716 INFO misc.py line 113 3298914] Train: [1/100][2396/2402] Data 0.003 (0.004) Batch 0.386 (0.478) Remain 31:35:23 loss: 1.4584 Lr: 0.00037
[2025-04-08 14:10:24,245 INFO misc.py line 113 3298914] Train: [1/100][2397/2402] Data 0.003 (0.004) Batch 0.529 (0.478) Remain 31:35:28 loss: 1.2032 Lr: 0.00037
[2025-04-08 14:10:24,727 INFO misc.py line 113 3298914] Train: [1/100][2398/2402] Data 0.003 (0.004) Batch 0.482 (0.478) Remain 31:35:28 loss: 1.1689 Lr: 0.00037
[2025-04-08 14:10:25,286 INFO misc.py line 113 3298914] Train: [1/100][2399/2402] Data 0.003 (0.004) Batch 0.559 (0.478) Remain 31:35:35 loss: 1.0240 Lr: 0.00037
[2025-04-08 14:10:25,726 INFO misc.py line 113 3298914] Train: [1/100][2400/2402] Data 0.003 (0.004) Batch 0.440 (0.478) Remain 31:35:31 loss: 1.3133 Lr: 0.00037
[2025-04-08 14:10:26,147 INFO misc.py line 113 3298914] Train: [1/100][2401/2402] Data 0.003 (0.004) Batch 0.421 (0.478) Remain 31:35:25 loss: 1.5044 Lr: 0.00037
[2025-04-08 14:10:26,607 INFO misc.py line 113 3298914] Train: [1/100][2402/2402] Data 0.003 (0.004) Batch 0.460 (0.478) Remain 31:35:23 loss: 1.5198 Lr: 0.00037
[2025-04-08 14:10:26,608 INFO misc.py line 130 3298914] Train result: loss: 1.7792 
[2025-04-08 14:10:26,609 INFO evaluator.py line 115 3298914] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[2025-04-08 14:10:30,040 INFO evaluator.py line 162 3298914] Test: [1/312] Loss 1.2774 
[2025-04-08 14:10:30,204 INFO evaluator.py line 162 3298914] Test: [2/312] Loss 1.8954 
[2025-04-08 14:10:30,390 INFO evaluator.py line 162 3298914] Test: [3/312] Loss 1.5288 
[2025-04-08 14:10:30,499 INFO evaluator.py line 162 3298914] Test: [4/312] Loss 1.3144 
[2025-04-08 14:10:30,638 INFO evaluator.py line 162 3298914] Test: [5/312] Loss 0.3274 
[2025-04-08 14:10:30,824 INFO evaluator.py line 162 3298914] Test: [6/312] Loss 1.2033 
[2025-04-08 14:10:31,111 INFO evaluator.py line 162 3298914] Test: [7/312] Loss 1.4561 
[2025-04-08 14:10:31,267 INFO evaluator.py line 162 3298914] Test: [8/312] Loss 0.8419 
[2025-04-08 14:10:31,389 INFO evaluator.py line 162 3298914] Test: [9/312] Loss 1.4782 
[2025-04-08 14:10:31,573 INFO evaluator.py line 162 3298914] Test: [10/312] Loss 1.0716 
[2025-04-08 14:10:31,778 INFO evaluator.py line 162 3298914] Test: [11/312] Loss 1.8812 
[2025-04-08 14:10:31,888 INFO evaluator.py line 162 3298914] Test: [12/312] Loss 0.7681 
[2025-04-08 14:10:31,999 INFO evaluator.py line 162 3298914] Test: [13/312] Loss 1.3514 
[2025-04-08 14:10:32,169 INFO evaluator.py line 162 3298914] Test: [14/312] Loss 2.2886 
[2025-04-08 14:10:32,399 INFO evaluator.py line 162 3298914] Test: [15/312] Loss 1.6378 
[2025-04-08 14:10:32,529 INFO evaluator.py line 162 3298914] Test: [16/312] Loss 0.8102 
[2025-04-08 14:10:32,697 INFO evaluator.py line 162 3298914] Test: [17/312] Loss 1.4333 
[2025-04-08 14:10:32,799 INFO evaluator.py line 162 3298914] Test: [18/312] Loss 1.4129 
[2025-04-08 14:10:32,933 INFO evaluator.py line 162 3298914] Test: [19/312] Loss 1.1712 
[2025-04-08 14:10:33,055 INFO evaluator.py line 162 3298914] Test: [20/312] Loss 1.2759 
[2025-04-08 14:10:33,170 INFO evaluator.py line 162 3298914] Test: [21/312] Loss 1.5433 
[2025-04-08 14:10:33,346 INFO evaluator.py line 162 3298914] Test: [22/312] Loss 0.5284 
[2025-04-08 14:10:33,470 INFO evaluator.py line 162 3298914] Test: [23/312] Loss 0.8818 
[2025-04-08 14:10:33,679 INFO evaluator.py line 162 3298914] Test: [24/312] Loss 0.9649 
[2025-04-08 14:10:33,937 INFO evaluator.py line 162 3298914] Test: [25/312] Loss 1.7631 
[2025-04-08 14:10:34,174 INFO evaluator.py line 162 3298914] Test: [26/312] Loss 0.7603 
[2025-04-08 14:10:34,321 INFO evaluator.py line 162 3298914] Test: [27/312] Loss 0.4471 
[2025-04-08 14:10:34,431 INFO evaluator.py line 162 3298914] Test: [28/312] Loss 0.8239 
[2025-04-08 14:10:34,605 INFO evaluator.py line 162 3298914] Test: [29/312] Loss 1.5819 
[2025-04-08 14:10:34,743 INFO evaluator.py line 162 3298914] Test: [30/312] Loss 0.7499 
[2025-04-08 14:10:34,867 INFO evaluator.py line 162 3298914] Test: [31/312] Loss 1.1795 
[2025-04-08 14:10:34,972 INFO evaluator.py line 162 3298914] Test: [32/312] Loss 0.3678 
[2025-04-08 14:10:35,120 INFO evaluator.py line 162 3298914] Test: [33/312] Loss 1.6244 
[2025-04-08 14:10:35,230 INFO evaluator.py line 162 3298914] Test: [34/312] Loss 1.3285 
[2025-04-08 14:10:35,403 INFO evaluator.py line 162 3298914] Test: [35/312] Loss 1.5859 
[2025-04-08 14:10:35,609 INFO evaluator.py line 162 3298914] Test: [36/312] Loss 1.2412 
[2025-04-08 14:10:35,757 INFO evaluator.py line 162 3298914] Test: [37/312] Loss 0.9086 
[2025-04-08 14:10:35,948 INFO evaluator.py line 162 3298914] Test: [38/312] Loss 0.9670 
[2025-04-08 14:10:36,231 INFO evaluator.py line 162 3298914] Test: [39/312] Loss 1.2108 
[2025-04-08 14:10:36,362 INFO evaluator.py line 162 3298914] Test: [40/312] Loss 1.7802 
[2025-04-08 14:10:36,490 INFO evaluator.py line 162 3298914] Test: [41/312] Loss 1.1544 
[2025-04-08 14:10:36,729 INFO evaluator.py line 162 3298914] Test: [42/312] Loss 1.4990 
[2025-04-08 14:10:36,871 INFO evaluator.py line 162 3298914] Test: [43/312] Loss 1.9356 
[2025-04-08 14:10:37,070 INFO evaluator.py line 162 3298914] Test: [44/312] Loss 0.8819 
[2025-04-08 14:10:37,218 INFO evaluator.py line 162 3298914] Test: [45/312] Loss 1.2571 
[2025-04-08 14:10:37,374 INFO evaluator.py line 162 3298914] Test: [46/312] Loss 0.9196 
[2025-04-08 14:10:37,479 INFO evaluator.py line 162 3298914] Test: [47/312] Loss 0.7560 
[2025-04-08 14:10:37,668 INFO evaluator.py line 162 3298914] Test: [48/312] Loss 2.0515 
[2025-04-08 14:10:37,847 INFO evaluator.py line 162 3298914] Test: [49/312] Loss 2.0876 
[2025-04-08 14:10:38,005 INFO evaluator.py line 162 3298914] Test: [50/312] Loss 0.9610 
[2025-04-08 14:10:38,112 INFO evaluator.py line 162 3298914] Test: [51/312] Loss 1.1355 
[2025-04-08 14:10:38,290 INFO evaluator.py line 162 3298914] Test: [52/312] Loss 1.0653 
[2025-04-08 14:10:38,417 INFO evaluator.py line 162 3298914] Test: [53/312] Loss 1.3035 
[2025-04-08 14:10:38,575 INFO evaluator.py line 162 3298914] Test: [54/312] Loss 1.7902 
[2025-04-08 14:10:38,879 INFO evaluator.py line 162 3298914] Test: [55/312] Loss 1.0885 
[2025-04-08 14:10:39,103 INFO evaluator.py line 162 3298914] Test: [56/312] Loss 1.6948 
[2025-04-08 14:10:39,270 INFO evaluator.py line 162 3298914] Test: [57/312] Loss 1.4398 
[2025-04-08 14:10:39,440 INFO evaluator.py line 162 3298914] Test: [58/312] Loss 1.3074 
[2025-04-08 14:10:39,575 INFO evaluator.py line 162 3298914] Test: [59/312] Loss 1.1352 
[2025-04-08 14:10:39,700 INFO evaluator.py line 162 3298914] Test: [60/312] Loss 1.0655 
[2025-04-08 14:10:39,874 INFO evaluator.py line 162 3298914] Test: [61/312] Loss 1.0647 
[2025-04-08 14:10:40,059 INFO evaluator.py line 162 3298914] Test: [62/312] Loss 1.4030 
[2025-04-08 14:10:40,287 INFO evaluator.py line 162 3298914] Test: [63/312] Loss 1.4333 
[2025-04-08 14:10:40,460 INFO evaluator.py line 162 3298914] Test: [64/312] Loss 0.7908 
[2025-04-08 14:10:40,604 INFO evaluator.py line 162 3298914] Test: [65/312] Loss 1.1479 
[2025-04-08 14:10:40,770 INFO evaluator.py line 162 3298914] Test: [66/312] Loss 1.7606 
[2025-04-08 14:10:40,895 INFO evaluator.py line 162 3298914] Test: [67/312] Loss 1.2893 
[2025-04-08 14:10:41,023 INFO evaluator.py line 162 3298914] Test: [68/312] Loss 0.8887 
[2025-04-08 14:10:41,164 INFO evaluator.py line 162 3298914] Test: [69/312] Loss 0.8549 
[2025-04-08 14:10:41,275 INFO evaluator.py line 162 3298914] Test: [70/312] Loss 1.1012 
[2025-04-08 14:10:41,396 INFO evaluator.py line 162 3298914] Test: [71/312] Loss 0.8751 
[2025-04-08 14:10:41,676 INFO evaluator.py line 162 3298914] Test: [72/312] Loss 1.4930 
[2025-04-08 14:10:41,964 INFO evaluator.py line 162 3298914] Test: [73/312] Loss 2.5914 
[2025-04-08 14:10:42,150 INFO evaluator.py line 162 3298914] Test: [74/312] Loss 0.5217 
[2025-04-08 14:10:42,363 INFO evaluator.py line 162 3298914] Test: [75/312] Loss 1.3110 
[2025-04-08 14:10:42,526 INFO evaluator.py line 162 3298914] Test: [76/312] Loss 1.3099 
[2025-04-08 14:10:42,630 INFO evaluator.py line 162 3298914] Test: [77/312] Loss 0.8860 
[2025-04-08 14:10:42,758 INFO evaluator.py line 162 3298914] Test: [78/312] Loss 2.0861 
[2025-04-08 14:10:42,960 INFO evaluator.py line 162 3298914] Test: [79/312] Loss 1.6905 
[2025-04-08 14:10:43,111 INFO evaluator.py line 162 3298914] Test: [80/312] Loss 0.9355 
[2025-04-08 14:10:43,323 INFO evaluator.py line 162 3298914] Test: [81/312] Loss 1.3996 
[2025-04-08 14:10:43,505 INFO evaluator.py line 162 3298914] Test: [82/312] Loss 1.0843 
[2025-04-08 14:10:43,724 INFO evaluator.py line 162 3298914] Test: [83/312] Loss 1.6024 
[2025-04-08 14:10:43,898 INFO evaluator.py line 162 3298914] Test: [84/312] Loss 1.3157 
[2025-04-08 14:10:44,201 INFO evaluator.py line 162 3298914] Test: [85/312] Loss 1.6220 
[2025-04-08 14:10:44,330 INFO evaluator.py line 162 3298914] Test: [86/312] Loss 1.0924 
[2025-04-08 14:10:44,484 INFO evaluator.py line 162 3298914] Test: [87/312] Loss 0.6550 
[2025-04-08 14:10:44,630 INFO evaluator.py line 162 3298914] Test: [88/312] Loss 0.5181 
[2025-04-08 14:10:44,764 INFO evaluator.py line 162 3298914] Test: [89/312] Loss 1.4413 
[2025-04-08 14:10:44,911 INFO evaluator.py line 162 3298914] Test: [90/312] Loss 1.1174 
[2025-04-08 14:10:45,094 INFO evaluator.py line 162 3298914] Test: [91/312] Loss 1.1636 
[2025-04-08 14:10:45,231 INFO evaluator.py line 162 3298914] Test: [92/312] Loss 0.8868 
[2025-04-08 14:10:45,420 INFO evaluator.py line 162 3298914] Test: [93/312] Loss 1.7061 
[2025-04-08 14:10:45,575 INFO evaluator.py line 162 3298914] Test: [94/312] Loss 0.7732 
[2025-04-08 14:10:45,679 INFO evaluator.py line 162 3298914] Test: [95/312] Loss 0.9080 
[2025-04-08 14:10:45,801 INFO evaluator.py line 162 3298914] Test: [96/312] Loss 1.1320 
[2025-04-08 14:10:46,067 INFO evaluator.py line 162 3298914] Test: [97/312] Loss 1.0730 
[2025-04-08 14:10:46,239 INFO evaluator.py line 162 3298914] Test: [98/312] Loss 1.6153 
[2025-04-08 14:10:46,446 INFO evaluator.py line 162 3298914] Test: [99/312] Loss 1.4854 
[2025-04-08 14:10:46,606 INFO evaluator.py line 162 3298914] Test: [100/312] Loss 1.3846 
[2025-04-08 14:10:46,764 INFO evaluator.py line 162 3298914] Test: [101/312] Loss 0.5047 
[2025-04-08 14:10:46,967 INFO evaluator.py line 162 3298914] Test: [102/312] Loss 1.0869 
[2025-04-08 14:10:47,149 INFO evaluator.py line 162 3298914] Test: [103/312] Loss 1.4150 
[2025-04-08 14:10:47,278 INFO evaluator.py line 162 3298914] Test: [104/312] Loss 1.2833 
[2025-04-08 14:10:47,454 INFO evaluator.py line 162 3298914] Test: [105/312] Loss 1.1825 
[2025-04-08 14:10:47,615 INFO evaluator.py line 162 3298914] Test: [106/312] Loss 2.3256 
[2025-04-08 14:10:47,743 INFO evaluator.py line 162 3298914] Test: [107/312] Loss 1.3660 
[2025-04-08 14:10:47,945 INFO evaluator.py line 162 3298914] Test: [108/312] Loss 1.6556 
[2025-04-08 14:10:48,086 INFO evaluator.py line 162 3298914] Test: [109/312] Loss 1.3118 
[2025-04-08 14:10:48,198 INFO evaluator.py line 162 3298914] Test: [110/312] Loss 1.4816 
[2025-04-08 14:10:48,310 INFO evaluator.py line 162 3298914] Test: [111/312] Loss 1.3364 
[2025-04-08 14:10:48,459 INFO evaluator.py line 162 3298914] Test: [112/312] Loss 1.5376 
[2025-04-08 14:10:48,643 INFO evaluator.py line 162 3298914] Test: [113/312] Loss 0.8628 
[2025-04-08 14:10:48,747 INFO evaluator.py line 162 3298914] Test: [114/312] Loss 1.5161 
[2025-04-08 14:10:48,952 INFO evaluator.py line 162 3298914] Test: [115/312] Loss 1.5466 
[2025-04-08 14:10:49,141 INFO evaluator.py line 162 3298914] Test: [116/312] Loss 1.3150 
[2025-04-08 14:10:49,274 INFO evaluator.py line 162 3298914] Test: [117/312] Loss 0.9324 
[2025-04-08 14:10:49,401 INFO evaluator.py line 162 3298914] Test: [118/312] Loss 1.7517 
[2025-04-08 14:10:49,573 INFO evaluator.py line 162 3298914] Test: [119/312] Loss 1.1239 
[2025-04-08 14:10:49,752 INFO evaluator.py line 162 3298914] Test: [120/312] Loss 1.5429 
[2025-04-08 14:10:49,990 INFO evaluator.py line 162 3298914] Test: [121/312] Loss 1.0229 
[2025-04-08 14:10:50,165 INFO evaluator.py line 162 3298914] Test: [122/312] Loss 1.1913 
[2025-04-08 14:10:50,274 INFO evaluator.py line 162 3298914] Test: [123/312] Loss 1.4388 
[2025-04-08 14:10:50,425 INFO evaluator.py line 162 3298914] Test: [124/312] Loss 0.3811 
[2025-04-08 14:10:50,525 INFO evaluator.py line 162 3298914] Test: [125/312] Loss 0.9591 
[2025-04-08 14:10:50,697 INFO evaluator.py line 162 3298914] Test: [126/312] Loss 1.4314 
[2025-04-08 14:10:50,849 INFO evaluator.py line 162 3298914] Test: [127/312] Loss 1.3932 
[2025-04-08 14:10:50,997 INFO evaluator.py line 162 3298914] Test: [128/312] Loss 1.2809 
[2025-04-08 14:10:51,118 INFO evaluator.py line 162 3298914] Test: [129/312] Loss 0.5563 
[2025-04-08 14:10:51,223 INFO evaluator.py line 162 3298914] Test: [130/312] Loss 1.1562 
[2025-04-08 14:10:51,384 INFO evaluator.py line 162 3298914] Test: [131/312] Loss 1.8503 
[2025-04-08 14:10:51,582 INFO evaluator.py line 162 3298914] Test: [132/312] Loss 1.3823 
[2025-04-08 14:10:51,752 INFO evaluator.py line 162 3298914] Test: [133/312] Loss 2.2762 
[2025-04-08 14:10:51,933 INFO evaluator.py line 162 3298914] Test: [134/312] Loss 1.0899 
[2025-04-08 14:10:52,076 INFO evaluator.py line 162 3298914] Test: [135/312] Loss 0.9331 
[2025-04-08 14:10:52,269 INFO evaluator.py line 162 3298914] Test: [136/312] Loss 1.4099 
[2025-04-08 14:10:52,419 INFO evaluator.py line 162 3298914] Test: [137/312] Loss 1.3001 
[2025-04-08 14:10:52,544 INFO evaluator.py line 162 3298914] Test: [138/312] Loss 1.1097 
[2025-04-08 14:10:52,701 INFO evaluator.py line 162 3298914] Test: [139/312] Loss 1.8706 
[2025-04-08 14:10:52,872 INFO evaluator.py line 162 3298914] Test: [140/312] Loss 0.6067 
[2025-04-08 14:10:52,998 INFO evaluator.py line 162 3298914] Test: [141/312] Loss 1.1893 
[2025-04-08 14:10:53,164 INFO evaluator.py line 162 3298914] Test: [142/312] Loss 1.4093 
[2025-04-08 14:10:53,307 INFO evaluator.py line 162 3298914] Test: [143/312] Loss 1.6572 
[2025-04-08 14:10:53,429 INFO evaluator.py line 162 3298914] Test: [144/312] Loss 1.0371 
[2025-04-08 14:10:53,569 INFO evaluator.py line 162 3298914] Test: [145/312] Loss 1.9625 
[2025-04-08 14:10:53,709 INFO evaluator.py line 162 3298914] Test: [146/312] Loss 0.9363 
[2025-04-08 14:10:53,819 INFO evaluator.py line 162 3298914] Test: [147/312] Loss 0.6781 
[2025-04-08 14:10:54,086 INFO evaluator.py line 162 3298914] Test: [148/312] Loss 2.5847 
[2025-04-08 14:10:54,259 INFO evaluator.py line 162 3298914] Test: [149/312] Loss 1.5437 
[2025-04-08 14:10:54,575 INFO evaluator.py line 162 3298914] Test: [150/312] Loss 1.2527 
[2025-04-08 14:10:54,728 INFO evaluator.py line 162 3298914] Test: [151/312] Loss 0.2357 
[2025-04-08 14:10:54,882 INFO evaluator.py line 162 3298914] Test: [152/312] Loss 1.8973 
[2025-04-08 14:10:54,992 INFO evaluator.py line 162 3298914] Test: [153/312] Loss 1.3538 
[2025-04-08 14:10:55,231 INFO evaluator.py line 162 3298914] Test: [154/312] Loss 0.7866 
[2025-04-08 14:10:55,365 INFO evaluator.py line 162 3298914] Test: [155/312] Loss 0.8826 
[2025-04-08 14:10:55,561 INFO evaluator.py line 162 3298914] Test: [156/312] Loss 1.1072 
[2025-04-08 14:10:55,721 INFO evaluator.py line 162 3298914] Test: [157/312] Loss 0.6854 
[2025-04-08 14:10:55,968 INFO evaluator.py line 162 3298914] Test: [158/312] Loss 0.9216 
[2025-04-08 14:10:56,124 INFO evaluator.py line 162 3298914] Test: [159/312] Loss 1.7895 
[2025-04-08 14:10:56,315 INFO evaluator.py line 162 3298914] Test: [160/312] Loss 0.7575 
[2025-04-08 14:10:56,436 INFO evaluator.py line 162 3298914] Test: [161/312] Loss 0.9291 
[2025-04-08 14:10:56,582 INFO evaluator.py line 162 3298914] Test: [162/312] Loss 1.2281 
[2025-04-08 14:10:56,858 INFO evaluator.py line 162 3298914] Test: [163/312] Loss 1.3846 
[2025-04-08 14:10:56,973 INFO evaluator.py line 162 3298914] Test: [164/312] Loss 0.3563 
[2025-04-08 14:10:57,167 INFO evaluator.py line 162 3298914] Test: [165/312] Loss 2.2091 
[2025-04-08 14:10:57,340 INFO evaluator.py line 162 3298914] Test: [166/312] Loss 1.5942 
[2025-04-08 14:10:57,506 INFO evaluator.py line 162 3298914] Test: [167/312] Loss 1.4146 
[2025-04-08 14:10:57,707 INFO evaluator.py line 162 3298914] Test: [168/312] Loss 0.6813 
[2025-04-08 14:10:57,851 INFO evaluator.py line 162 3298914] Test: [169/312] Loss 1.3188 
[2025-04-08 14:10:58,008 INFO evaluator.py line 162 3298914] Test: [170/312] Loss 1.9750 
[2025-04-08 14:10:58,133 INFO evaluator.py line 162 3298914] Test: [171/312] Loss 1.0627 
[2025-04-08 14:10:58,304 INFO evaluator.py line 162 3298914] Test: [172/312] Loss 1.3556 
[2025-04-08 14:10:58,433 INFO evaluator.py line 162 3298914] Test: [173/312] Loss 1.0910 
[2025-04-08 14:10:58,541 INFO evaluator.py line 162 3298914] Test: [174/312] Loss 1.0484 
[2025-04-08 14:10:58,669 INFO evaluator.py line 162 3298914] Test: [175/312] Loss 1.3134 
[2025-04-08 14:10:58,822 INFO evaluator.py line 162 3298914] Test: [176/312] Loss 1.8263 
[2025-04-08 14:10:58,963 INFO evaluator.py line 162 3298914] Test: [177/312] Loss 1.9675 
[2025-04-08 14:10:59,104 INFO evaluator.py line 162 3298914] Test: [178/312] Loss 1.3147 
[2025-04-08 14:10:59,291 INFO evaluator.py line 162 3298914] Test: [179/312] Loss 2.0894 
[2025-04-08 14:10:59,416 INFO evaluator.py line 162 3298914] Test: [180/312] Loss 1.3228 
[2025-04-08 14:10:59,542 INFO evaluator.py line 162 3298914] Test: [181/312] Loss 1.2122 
[2025-04-08 14:10:59,651 INFO evaluator.py line 162 3298914] Test: [182/312] Loss 0.3857 
[2025-04-08 14:10:59,783 INFO evaluator.py line 162 3298914] Test: [183/312] Loss 1.1304 
[2025-04-08 14:10:59,943 INFO evaluator.py line 162 3298914] Test: [184/312] Loss 1.0085 
[2025-04-08 14:11:00,155 INFO evaluator.py line 162 3298914] Test: [185/312] Loss 1.7121 
[2025-04-08 14:11:00,346 INFO evaluator.py line 162 3298914] Test: [186/312] Loss 0.8594 
[2025-04-08 14:11:00,531 INFO evaluator.py line 162 3298914] Test: [187/312] Loss 1.2700 
[2025-04-08 14:11:00,829 INFO evaluator.py line 162 3298914] Test: [188/312] Loss 2.6456 
[2025-04-08 14:11:00,979 INFO evaluator.py line 162 3298914] Test: [189/312] Loss 1.0926 
[2025-04-08 14:11:01,139 INFO evaluator.py line 162 3298914] Test: [190/312] Loss 1.1952 
[2025-04-08 14:11:01,287 INFO evaluator.py line 162 3298914] Test: [191/312] Loss 1.3475 
[2025-04-08 14:11:01,477 INFO evaluator.py line 162 3298914] Test: [192/312] Loss 1.5639 
[2025-04-08 14:11:01,625 INFO evaluator.py line 162 3298914] Test: [193/312] Loss 1.3457 
[2025-04-08 14:11:01,826 INFO evaluator.py line 162 3298914] Test: [194/312] Loss 1.0510 
[2025-04-08 14:11:01,932 INFO evaluator.py line 162 3298914] Test: [195/312] Loss 0.4858 
[2025-04-08 14:11:02,079 INFO evaluator.py line 162 3298914] Test: [196/312] Loss 0.8665 
[2025-04-08 14:11:02,202 INFO evaluator.py line 162 3298914] Test: [197/312] Loss 0.8752 
[2025-04-08 14:11:02,373 INFO evaluator.py line 162 3298914] Test: [198/312] Loss 1.1884 
[2025-04-08 14:11:02,498 INFO evaluator.py line 162 3298914] Test: [199/312] Loss 1.0106 
[2025-04-08 14:11:02,784 INFO evaluator.py line 162 3298914] Test: [200/312] Loss 1.1981 
[2025-04-08 14:11:02,893 INFO evaluator.py line 162 3298914] Test: [201/312] Loss 0.8615 
[2025-04-08 14:11:03,066 INFO evaluator.py line 162 3298914] Test: [202/312] Loss 1.1463 
[2025-04-08 14:11:03,230 INFO evaluator.py line 162 3298914] Test: [203/312] Loss 0.2500 
[2025-04-08 14:11:03,394 INFO evaluator.py line 162 3298914] Test: [204/312] Loss 0.9331 
[2025-04-08 14:11:03,661 INFO evaluator.py line 162 3298914] Test: [205/312] Loss 1.4482 
[2025-04-08 14:11:03,821 INFO evaluator.py line 162 3298914] Test: [206/312] Loss 0.9273 
[2025-04-08 14:11:03,991 INFO evaluator.py line 162 3298914] Test: [207/312] Loss 1.2812 
[2025-04-08 14:11:04,129 INFO evaluator.py line 162 3298914] Test: [208/312] Loss 1.5026 
[2025-04-08 14:11:04,312 INFO evaluator.py line 162 3298914] Test: [209/312] Loss 0.8643 
[2025-04-08 14:11:04,589 INFO evaluator.py line 162 3298914] Test: [210/312] Loss 1.5186 
[2025-04-08 14:11:04,719 INFO evaluator.py line 162 3298914] Test: [211/312] Loss 2.3836 
[2025-04-08 14:11:04,858 INFO evaluator.py line 162 3298914] Test: [212/312] Loss 1.2365 
[2025-04-08 14:11:05,030 INFO evaluator.py line 162 3298914] Test: [213/312] Loss 1.2467 
[2025-04-08 14:11:05,190 INFO evaluator.py line 162 3298914] Test: [214/312] Loss 1.0822 
[2025-04-08 14:11:05,363 INFO evaluator.py line 162 3298914] Test: [215/312] Loss 1.6807 
[2025-04-08 14:11:05,498 INFO evaluator.py line 162 3298914] Test: [216/312] Loss 1.3385 
[2025-04-08 14:11:05,608 INFO evaluator.py line 162 3298914] Test: [217/312] Loss 0.7146 
[2025-04-08 14:11:05,808 INFO evaluator.py line 162 3298914] Test: [218/312] Loss 1.5738 
[2025-04-08 14:11:06,114 INFO evaluator.py line 162 3298914] Test: [219/312] Loss 0.7778 
[2025-04-08 14:11:06,350 INFO evaluator.py line 162 3298914] Test: [220/312] Loss 1.7087 
[2025-04-08 14:11:06,461 INFO evaluator.py line 162 3298914] Test: [221/312] Loss 1.6225 
[2025-04-08 14:11:06,604 INFO evaluator.py line 162 3298914] Test: [222/312] Loss 0.9456 
[2025-04-08 14:11:06,788 INFO evaluator.py line 162 3298914] Test: [223/312] Loss 1.9602 
[2025-04-08 14:11:06,897 INFO evaluator.py line 162 3298914] Test: [224/312] Loss 1.2564 
[2025-04-08 14:11:07,005 INFO evaluator.py line 162 3298914] Test: [225/312] Loss 1.3655 
[2025-04-08 14:11:07,291 INFO evaluator.py line 162 3298914] Test: [226/312] Loss 0.7648 
[2025-04-08 14:11:07,469 INFO evaluator.py line 162 3298914] Test: [227/312] Loss 1.5484 
[2025-04-08 14:11:07,651 INFO evaluator.py line 162 3298914] Test: [228/312] Loss 0.6535 
[2025-04-08 14:11:07,757 INFO evaluator.py line 162 3298914] Test: [229/312] Loss 0.6710 
[2025-04-08 14:11:07,882 INFO evaluator.py line 162 3298914] Test: [230/312] Loss 1.2493 
[2025-04-08 14:11:08,003 INFO evaluator.py line 162 3298914] Test: [231/312] Loss 0.7188 
[2025-04-08 14:11:08,185 INFO evaluator.py line 162 3298914] Test: [232/312] Loss 1.0915 
[2025-04-08 14:11:08,386 INFO evaluator.py line 162 3298914] Test: [233/312] Loss 1.2618 
[2025-04-08 14:11:08,580 INFO evaluator.py line 162 3298914] Test: [234/312] Loss 0.5581 
[2025-04-08 14:11:08,789 INFO evaluator.py line 162 3298914] Test: [235/312] Loss 1.3448 
[2025-04-08 14:11:08,973 INFO evaluator.py line 162 3298914] Test: [236/312] Loss 1.4208 
[2025-04-08 14:11:09,169 INFO evaluator.py line 162 3298914] Test: [237/312] Loss 1.8312 
[2025-04-08 14:11:09,357 INFO evaluator.py line 162 3298914] Test: [238/312] Loss 1.1292 
[2025-04-08 14:11:09,596 INFO evaluator.py line 162 3298914] Test: [239/312] Loss 0.9053 
[2025-04-08 14:11:09,717 INFO evaluator.py line 162 3298914] Test: [240/312] Loss 0.8189 
[2025-04-08 14:11:09,824 INFO evaluator.py line 162 3298914] Test: [241/312] Loss 1.0444 
[2025-04-08 14:11:10,109 INFO evaluator.py line 162 3298914] Test: [242/312] Loss 1.6261 
[2025-04-08 14:11:10,245 INFO evaluator.py line 162 3298914] Test: [243/312] Loss 0.7382 
[2025-04-08 14:11:10,435 INFO evaluator.py line 162 3298914] Test: [244/312] Loss 1.1022 
[2025-04-08 14:11:10,565 INFO evaluator.py line 162 3298914] Test: [245/312] Loss 1.0332 
[2025-04-08 14:11:10,836 INFO evaluator.py line 162 3298914] Test: [246/312] Loss 0.6109 
[2025-04-08 14:11:11,014 INFO evaluator.py line 162 3298914] Test: [247/312] Loss 1.2340 
[2025-04-08 14:11:11,235 INFO evaluator.py line 162 3298914] Test: [248/312] Loss 1.1325 
[2025-04-08 14:11:11,382 INFO evaluator.py line 162 3298914] Test: [249/312] Loss 1.5860 
[2025-04-08 14:11:11,510 INFO evaluator.py line 162 3298914] Test: [250/312] Loss 1.3259 
[2025-04-08 14:11:11,697 INFO evaluator.py line 162 3298914] Test: [251/312] Loss 1.0125 
[2025-04-08 14:11:11,817 INFO evaluator.py line 162 3298914] Test: [252/312] Loss 0.8272 
[2025-04-08 14:11:11,925 INFO evaluator.py line 162 3298914] Test: [253/312] Loss 1.4208 
[2025-04-08 14:11:12,037 INFO evaluator.py line 162 3298914] Test: [254/312] Loss 0.8419 
[2025-04-08 14:11:12,184 INFO evaluator.py line 162 3298914] Test: [255/312] Loss 1.2744 
[2025-04-08 14:11:12,329 INFO evaluator.py line 162 3298914] Test: [256/312] Loss 1.0620 
[2025-04-08 14:11:12,454 INFO evaluator.py line 162 3298914] Test: [257/312] Loss 1.4356 
[2025-04-08 14:11:12,650 INFO evaluator.py line 162 3298914] Test: [258/312] Loss 1.1422 
[2025-04-08 14:11:12,827 INFO evaluator.py line 162 3298914] Test: [259/312] Loss 1.0268 
[2025-04-08 14:11:13,012 INFO evaluator.py line 162 3298914] Test: [260/312] Loss 1.1395 
[2025-04-08 14:11:13,145 INFO evaluator.py line 162 3298914] Test: [261/312] Loss 1.2311 
[2025-04-08 14:11:13,350 INFO evaluator.py line 162 3298914] Test: [262/312] Loss 1.4104 
[2025-04-08 14:11:13,488 INFO evaluator.py line 162 3298914] Test: [263/312] Loss 0.9134 
[2025-04-08 14:11:13,668 INFO evaluator.py line 162 3298914] Test: [264/312] Loss 1.4307 
[2025-04-08 14:11:13,839 INFO evaluator.py line 162 3298914] Test: [265/312] Loss 1.6914 
[2025-04-08 14:11:13,965 INFO evaluator.py line 162 3298914] Test: [266/312] Loss 1.6071 
[2025-04-08 14:11:14,165 INFO evaluator.py line 162 3298914] Test: [267/312] Loss 1.8584 
[2025-04-08 14:11:14,339 INFO evaluator.py line 162 3298914] Test: [268/312] Loss 1.4673 
[2025-04-08 14:11:14,552 INFO evaluator.py line 162 3298914] Test: [269/312] Loss 1.4760 
[2025-04-08 14:11:14,764 INFO evaluator.py line 162 3298914] Test: [270/312] Loss 0.6183 
[2025-04-08 14:11:14,903 INFO evaluator.py line 162 3298914] Test: [271/312] Loss 1.2481 
[2025-04-08 14:11:15,090 INFO evaluator.py line 162 3298914] Test: [272/312] Loss 1.1700 
[2025-04-08 14:11:15,198 INFO evaluator.py line 162 3298914] Test: [273/312] Loss 1.3368 
[2025-04-08 14:11:15,417 INFO evaluator.py line 162 3298914] Test: [274/312] Loss 1.4509 
[2025-04-08 14:11:15,579 INFO evaluator.py line 162 3298914] Test: [275/312] Loss 1.2220 
[2025-04-08 14:11:15,701 INFO evaluator.py line 162 3298914] Test: [276/312] Loss 0.9071 
[2025-04-08 14:11:15,919 INFO evaluator.py line 162 3298914] Test: [277/312] Loss 1.2156 
[2025-04-08 14:11:16,072 INFO evaluator.py line 162 3298914] Test: [278/312] Loss 0.2270 
[2025-04-08 14:11:16,266 INFO evaluator.py line 162 3298914] Test: [279/312] Loss 1.2383 
[2025-04-08 14:11:16,414 INFO evaluator.py line 162 3298914] Test: [280/312] Loss 2.1407 
[2025-04-08 14:11:16,588 INFO evaluator.py line 162 3298914] Test: [281/312] Loss 1.1591 
[2025-04-08 14:11:16,695 INFO evaluator.py line 162 3298914] Test: [282/312] Loss 1.1752 
[2025-04-08 14:11:16,845 INFO evaluator.py line 162 3298914] Test: [283/312] Loss 1.9425 
[2025-04-08 14:11:16,963 INFO evaluator.py line 162 3298914] Test: [284/312] Loss 1.9557 
[2025-04-08 14:11:17,106 INFO evaluator.py line 162 3298914] Test: [285/312] Loss 1.6090 
[2025-04-08 14:11:17,358 INFO evaluator.py line 162 3298914] Test: [286/312] Loss 1.4633 
[2025-04-08 14:11:17,526 INFO evaluator.py line 162 3298914] Test: [287/312] Loss 1.5578 
[2025-04-08 14:11:17,652 INFO evaluator.py line 162 3298914] Test: [288/312] Loss 1.1656 
[2025-04-08 14:11:17,811 INFO evaluator.py line 162 3298914] Test: [289/312] Loss 1.1438 
[2025-04-08 14:11:17,972 INFO evaluator.py line 162 3298914] Test: [290/312] Loss 0.4472 
[2025-04-08 14:11:18,130 INFO evaluator.py line 162 3298914] Test: [291/312] Loss 1.0771 
[2025-04-08 14:11:18,313 INFO evaluator.py line 162 3298914] Test: [292/312] Loss 2.1927 
[2025-04-08 14:11:18,620 INFO evaluator.py line 162 3298914] Test: [293/312] Loss 1.6889 
[2025-04-08 14:11:18,727 INFO evaluator.py line 162 3298914] Test: [294/312] Loss 0.8005 
[2025-04-08 14:11:18,832 INFO evaluator.py line 162 3298914] Test: [295/312] Loss 0.9042 
[2025-04-08 14:11:19,062 INFO evaluator.py line 162 3298914] Test: [296/312] Loss 1.3072 
[2025-04-08 14:11:19,193 INFO evaluator.py line 162 3298914] Test: [297/312] Loss 2.0314 
[2025-04-08 14:11:19,409 INFO evaluator.py line 162 3298914] Test: [298/312] Loss 1.0942 
[2025-04-08 14:11:19,573 INFO evaluator.py line 162 3298914] Test: [299/312] Loss 0.8754 
[2025-04-08 14:11:19,747 INFO evaluator.py line 162 3298914] Test: [300/312] Loss 1.7252 
[2025-04-08 14:11:19,917 INFO evaluator.py line 162 3298914] Test: [301/312] Loss 0.4560 
[2025-04-08 14:11:20,115 INFO evaluator.py line 162 3298914] Test: [302/312] Loss 2.1141 
[2025-04-08 14:11:20,234 INFO evaluator.py line 162 3298914] Test: [303/312] Loss 1.1623 
[2025-04-08 14:11:20,441 INFO evaluator.py line 162 3298914] Test: [304/312] Loss 2.1000 
[2025-04-08 14:11:20,583 INFO evaluator.py line 162 3298914] Test: [305/312] Loss 1.2563 
[2025-04-08 14:11:20,684 INFO evaluator.py line 162 3298914] Test: [306/312] Loss 1.1192 
[2025-04-08 14:11:20,836 INFO evaluator.py line 162 3298914] Test: [307/312] Loss 1.1721 
[2025-04-08 14:11:21,064 INFO evaluator.py line 162 3298914] Test: [308/312] Loss 1.8655 
[2025-04-08 14:11:21,231 INFO evaluator.py line 162 3298914] Test: [309/312] Loss 1.0525 
[2025-04-08 14:11:21,341 INFO evaluator.py line 162 3298914] Test: [310/312] Loss 1.8250 
[2025-04-08 14:11:21,463 INFO evaluator.py line 162 3298914] Test: [311/312] Loss 0.8238 
[2025-04-08 14:11:21,650 INFO evaluator.py line 162 3298914] Test: [312/312] Loss 1.3749 
[2025-04-08 14:11:21,709 INFO evaluator.py line 177 3298914] Val result: mIoU/mAcc/allAcc 0.3871/0.5375/0.7610.
[2025-04-08 14:11:21,709 INFO evaluator.py line 183 3298914] Class_0-wall Result: iou/accuracy 0.7051/0.8716
[2025-04-08 14:11:21,709 INFO evaluator.py line 183 3298914] Class_1-floor Result: iou/accuracy 0.9525/0.9806
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_2-cabinet Result: iou/accuracy 0.3559/0.6134
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_3-bed Result: iou/accuracy 0.4468/0.6271
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_4-chair Result: iou/accuracy 0.7260/0.8120
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_5-sofa Result: iou/accuracy 0.3046/0.3429
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_6-table Result: iou/accuracy 0.5168/0.6242
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_7-door Result: iou/accuracy 0.1265/0.1544
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_8-window Result: iou/accuracy 0.3321/0.5050
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_9-bookshelf Result: iou/accuracy 0.6390/0.7610
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_10-picture Result: iou/accuracy 0.0000/0.0000
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_11-counter Result: iou/accuracy 0.3136/0.6710
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_12-desk Result: iou/accuracy 0.3007/0.5618
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_13-curtain Result: iou/accuracy 0.3618/0.5999
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_14-refridgerator Result: iou/accuracy 0.0654/0.0862
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_15-shower curtain Result: iou/accuracy 0.2216/0.2989
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_16-toilet Result: iou/accuracy 0.5248/0.6886
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_17-sink Result: iou/accuracy 0.1814/0.7640
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_18-bathtub Result: iou/accuracy 0.4832/0.5125
[2025-04-08 14:11:21,710 INFO evaluator.py line 183 3298914] Class_19-otherfurniture Result: iou/accuracy 0.1851/0.2755
[2025-04-08 14:11:21,711 INFO evaluator.py line 204 3298914] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2025-04-08 14:11:21,711 INFO misc.py line 154 3298914] Best validation mIoU updated to: 0.3871
[2025-04-08 14:11:21,711 INFO misc.py line 159 3298914] Currently Best mIoU: 0.3871
[2025-04-08 14:11:21,711 INFO misc.py line 168 3298914] Saving checkpoint to: /work3/s204157/data/ego3d/exp/sonata/debug/model/model_last.pth
[2025-04-08 14:11:32,864 INFO misc.py line 113 3298914] Train: [2/100][1/2402] Data 1.867 (1.867) Batch 2.653 (2.653) Remain 175:15:16 loss: 1.3955 Lr: 0.00037
[2025-04-08 14:11:34,601 INFO misc.py line 113 3298914] Train: [2/100][2/2402] Data 0.922 (0.922) Batch 1.751 (1.751) Remain 115:39:00 loss: 1.9534 Lr: 0.00037
[2025-04-08 14:11:35,268 INFO misc.py line 113 3298914] Train: [2/100][3/2402] Data 0.015 (0.015) Batch 0.667 (0.667) Remain 44:02:47 loss: 1.5371 Lr: 0.00037
[2025-04-08 14:11:35,844 INFO misc.py line 113 3298914] Train: [2/100][4/2402] Data 0.004 (0.004) Batch 0.576 (0.576) Remain 38:03:31 loss: 1.6576 Lr: 0.00037
[2025-04-08 14:11:36,319 INFO misc.py line 113 3298914] Train: [2/100][5/2402] Data 0.003 (0.003) Batch 0.475 (0.526) Remain 34:43:04 loss: 1.4239 Lr: 0.00037
[2025-04-08 14:11:36,796 INFO misc.py line 113 3298914] Train: [2/100][6/2402] Data 0.003 (0.003) Batch 0.476 (0.509) Remain 33:38:11 loss: 1.7011 Lr: 0.00037
[2025-04-08 14:11:37,219 INFO misc.py line 113 3298914] Train: [2/100][7/2402] Data 0.004 (0.003) Batch 0.423 (0.488) Remain 32:13:09 loss: 1.6546 Lr: 0.00037
[2025-04-08 14:11:37,705 INFO misc.py line 113 3298914] Train: [2/100][8/2402] Data 0.003 (0.003) Batch 0.486 (0.487) Remain 32:11:55 loss: 0.8029 Lr: 0.00037
[2025-04-08 14:11:38,084 INFO misc.py line 113 3298914] Train: [2/100][9/2402] Data 0.003 (0.003) Batch 0.378 (0.469) Remain 30:59:54 loss: 1.2374 Lr: 0.00037
[2025-04-08 14:11:38,566 INFO misc.py line 113 3298914] Train: [2/100][10/2402] Data 0.003 (0.003) Batch 0.482 (0.471) Remain 31:07:04 loss: 1.0899 Lr: 0.00037
[2025-04-08 14:11:39,034 INFO misc.py line 113 3298914] Train: [2/100][11/2402] Data 0.004 (0.004) Batch 0.469 (0.471) Remain 31:05:46 loss: 1.4921 Lr: 0.00037
[2025-04-08 14:11:39,677 INFO misc.py line 113 3298914] Train: [2/100][12/2402] Data 0.003 (0.004) Batch 0.642 (0.490) Remain 32:21:20 loss: 1.3107 Lr: 0.00037
[2025-04-08 14:11:40,293 INFO misc.py line 113 3298914] Train: [2/100][13/2402] Data 0.026 (0.006) Batch 0.617 (0.503) Remain 33:11:38 loss: 1.4006 Lr: 0.00037
[2025-04-08 14:11:40,797 INFO misc.py line 113 3298914] Train: [2/100][14/2402] Data 0.003 (0.006) Batch 0.503 (0.503) Remain 33:11:53 loss: 1.4812 Lr: 0.00037
[2025-04-08 14:11:41,279 INFO misc.py line 113 3298914] Train: [2/100][15/2402] Data 0.004 (0.005) Batch 0.482 (0.501) Remain 33:05:05 loss: 1.9614 Lr: 0.00037
[2025-04-08 14:11:41,663 INFO misc.py line 113 3298914] Train: [2/100][16/2402] Data 0.004 (0.005) Batch 0.385 (0.492) Remain 32:29:41 loss: 0.9611 Lr: 0.00037
[2025-04-08 14:11:42,118 INFO misc.py line 113 3298914] Train: [2/100][17/2402] Data 0.003 (0.005) Batch 0.454 (0.489) Remain 32:18:57 loss: 1.0063 Lr: 0.00037
[2025-04-08 14:11:42,516 INFO misc.py line 113 3298914] Train: [2/100][18/2402] Data 0.004 (0.005) Batch 0.399 (0.483) Remain 31:54:58 loss: 1.4754 Lr: 0.00037
[2025-04-08 14:11:42,969 INFO misc.py line 113 3298914] Train: [2/100][19/2402] Data 0.004 (0.005) Batch 0.453 (0.481) Remain 31:47:31 loss: 1.2938 Lr: 0.00037
[2025-04-08 14:11:43,425 INFO misc.py line 113 3298914] Train: [2/100][20/2402] Data 0.003 (0.005) Batch 0.456 (0.480) Remain 31:41:37 loss: 1.3743 Lr: 0.00037
[2025-04-08 14:11:43,915 INFO misc.py line 113 3298914] Train: [2/100][21/2402] Data 0.004 (0.005) Batch 0.490 (0.480) Remain 31:43:52 loss: 1.5021 Lr: 0.00037
[2025-04-08 14:11:44,443 INFO misc.py line 113 3298914] Train: [2/100][22/2402] Data 0.004 (0.005) Batch 0.527 (0.483) Remain 31:53:35 loss: 1.5029 Lr: 0.00037
[2025-04-08 14:11:44,847 INFO misc.py line 113 3298914] Train: [2/100][23/2402] Data 0.003 (0.005) Batch 0.404 (0.479) Remain 31:38:01 loss: 1.0819 Lr: 0.00037
[2025-04-08 14:11:45,296 INFO misc.py line 113 3298914] Train: [2/100][24/2402] Data 0.004 (0.005) Batch 0.449 (0.478) Remain 31:32:24 loss: 1.4937 Lr: 0.00037
[2025-04-08 14:11:45,829 INFO misc.py line 113 3298914] Train: [2/100][25/2402] Data 0.003 (0.005) Batch 0.533 (0.480) Remain 31:42:18 loss: 1.3271 Lr: 0.00037
[2025-04-08 14:11:46,358 INFO misc.py line 113 3298914] Train: [2/100][26/2402] Data 0.003 (0.005) Batch 0.530 (0.482) Remain 31:50:52 loss: 1.3595 Lr: 0.00038
[2025-04-08 14:11:46,840 INFO misc.py line 113 3298914] Train: [2/100][27/2402] Data 0.003 (0.004) Batch 0.481 (0.482) Remain 31:50:44 loss: 1.0439 Lr: 0.00038
[2025-04-08 14:11:47,295 INFO misc.py line 113 3298914] Train: [2/100][28/2402] Data 0.003 (0.004) Batch 0.455 (0.481) Remain 31:46:28 loss: 1.7939 Lr: 0.00038
[2025-04-08 14:11:47,697 INFO misc.py line 113 3298914] Train: [2/100][29/2402] Data 0.003 (0.004) Batch 0.402 (0.478) Remain 31:34:24 loss: 1.3181 Lr: 0.00038
[2025-04-08 14:11:48,162 INFO misc.py line 113 3298914] Train: [2/100][30/2402] Data 0.004 (0.004) Batch 0.464 (0.478) Remain 31:32:23 loss: 1.5114 Lr: 0.00038
[2025-04-08 14:11:48,765 INFO misc.py line 113 3298914] Train: [2/100][31/2402] Data 0.004 (0.004) Batch 0.603 (0.482) Remain 31:50:07 loss: 1.4819 Lr: 0.00038
[2025-04-08 14:11:49,293 INFO misc.py line 113 3298914] Train: [2/100][32/2402] Data 0.004 (0.004) Batch 0.529 (0.484) Remain 31:56:30 loss: 1.5787 Lr: 0.00038
[2025-04-08 14:11:49,794 INFO misc.py line 113 3298914] Train: [2/100][33/2402] Data 0.004 (0.004) Batch 0.501 (0.484) Remain 31:58:49 loss: 1.3929 Lr: 0.00038
[2025-04-08 14:11:50,339 INFO misc.py line 113 3298914] Train: [2/100][34/2402] Data 0.004 (0.004) Batch 0.544 (0.486) Remain 32:06:29 loss: 2.0347 Lr: 0.00038
[2025-04-08 14:11:50,776 INFO misc.py line 113 3298914] Train: [2/100][35/2402] Data 0.004 (0.004) Batch 0.437 (0.485) Remain 32:00:25 loss: 1.4934 Lr: 0.00038
[2025-04-08 14:11:51,291 INFO misc.py line 113 3298914] Train: [2/100][36/2402] Data 0.003 (0.004) Batch 0.515 (0.486) Remain 32:04:05 loss: 1.1845 Lr: 0.00038
[2025-04-08 14:11:51,694 INFO misc.py line 113 3298914] Train: [2/100][37/2402] Data 0.003 (0.004) Batch 0.403 (0.483) Remain 31:54:29 loss: 1.5956 Lr: 0.00038
[2025-04-08 14:11:52,242 INFO misc.py line 113 3298914] Train: [2/100][38/2402] Data 0.004 (0.004) Batch 0.548 (0.485) Remain 32:01:47 loss: 1.8208 Lr: 0.00038
[2025-04-08 14:11:52,747 INFO misc.py line 113 3298914] Train: [2/100][39/2402] Data 0.003 (0.004) Batch 0.505 (0.486) Remain 32:03:56 loss: 1.3817 Lr: 0.00038
[2025-04-08 14:11:53,163 INFO misc.py line 113 3298914] Train: [2/100][40/2402] Data 0.003 (0.004) Batch 0.416 (0.484) Remain 31:56:30 loss: 1.8187 Lr: 0.00038
[2025-04-08 14:11:53,592 INFO misc.py line 113 3298914] Train: [2/100][41/2402] Data 0.004 (0.004) Batch 0.429 (0.482) Remain 31:50:48 loss: 0.9791 Lr: 0.00038
[2025-04-08 14:11:54,047 INFO misc.py line 113 3298914] Train: [2/100][42/2402] Data 0.003 (0.004) Batch 0.456 (0.482) Remain 31:48:05 loss: 1.2715 Lr: 0.00038
[2025-04-08 14:11:54,445 INFO misc.py line 113 3298914] Train: [2/100][43/2402] Data 0.004 (0.004) Batch 0.398 (0.479) Remain 31:39:46 loss: 1.1883 Lr: 0.00038
[2025-04-08 14:11:54,926 INFO misc.py line 113 3298914] Train: [2/100][44/2402] Data 0.003 (0.004) Batch 0.481 (0.479) Remain 31:39:54 loss: 1.4509 Lr: 0.00038
[2025-04-08 14:11:55,436 INFO misc.py line 113 3298914] Train: [2/100][45/2402] Data 0.003 (0.004) Batch 0.509 (0.480) Remain 31:42:42 loss: 1.3015 Lr: 0.00038
[2025-04-08 14:11:55,902 INFO misc.py line 113 3298914] Train: [2/100][46/2402] Data 0.004 (0.004) Batch 0.467 (0.480) Remain 31:41:28 loss: 1.2656 Lr: 0.00038
[2025-04-08 14:11:56,493 INFO misc.py line 113 3298914] Train: [2/100][47/2402] Data 0.003 (0.004) Batch 0.591 (0.482) Remain 31:51:27 loss: 1.4833 Lr: 0.00038
[2025-04-08 14:11:56,952 INFO misc.py line 113 3298914] Train: [2/100][48/2402] Data 0.004 (0.004) Batch 0.459 (0.482) Remain 31:49:21 loss: 1.2141 Lr: 0.00038
[2025-04-08 14:11:57,464 INFO misc.py line 113 3298914] Train: [2/100][49/2402] Data 0.003 (0.004) Batch 0.512 (0.483) Remain 31:51:59 loss: 1.6682 Lr: 0.00038
[2025-04-08 14:11:58,018 INFO misc.py line 113 3298914] Train: [2/100][50/2402] Data 0.004 (0.004) Batch 0.553 (0.484) Remain 31:57:57 loss: 1.4117 Lr: 0.00038
[2025-04-08 14:11:58,525 INFO misc.py line 113 3298914] Train: [2/100][51/2402] Data 0.004 (0.004) Batch 0.508 (0.485) Remain 31:59:54 loss: 1.2135 Lr: 0.00038
[2025-04-08 14:11:59,061 INFO misc.py line 113 3298914] Train: [2/100][52/2402] Data 0.003 (0.004) Batch 0.536 (0.486) Remain 32:04:02 loss: 1.4520 Lr: 0.00038
[2025-04-08 14:11:59,562 INFO misc.py line 113 3298914] Train: [2/100][53/2402] Data 0.003 (0.004) Batch 0.501 (0.486) Remain 32:05:16 loss: 1.2646 Lr: 0.00038
[2025-04-08 14:12:00,147 INFO misc.py line 113 3298914] Train: [2/100][54/2402] Data 0.003 (0.004) Batch 0.585 (0.488) Remain 32:12:58 loss: 1.8269 Lr: 0.00038
[2025-04-08 14:12:00,668 INFO misc.py line 113 3298914] Train: [2/100][55/2402] Data 0.003 (0.004) Batch 0.521 (0.488) Remain 32:15:29 loss: 1.4404 Lr: 0.00038
[2025-04-08 14:12:00,967 INFO misc.py line 113 3298914] Train: [2/100][56/2402] Data 0.003 (0.004) Batch 0.299 (0.485) Remain 32:01:19 loss: 1.3849 Lr: 0.00038
[2025-04-08 14:12:01,477 INFO misc.py line 113 3298914] Train: [2/100][57/2402] Data 0.003 (0.004) Batch 0.510 (0.485) Remain 32:03:08 loss: 1.4639 Lr: 0.00038
[2025-04-08 14:12:02,035 INFO misc.py line 113 3298914] Train: [2/100][58/2402] Data 0.004 (0.004) Batch 0.558 (0.487) Remain 32:08:21 loss: 1.3564 Lr: 0.00038
[2025-04-08 14:12:02,462 INFO misc.py line 113 3298914] Train: [2/100][59/2402] Data 0.003 (0.004) Batch 0.427 (0.486) Remain 32:04:08 loss: 1.3858 Lr: 0.00038
[2025-04-08 14:12:02,943 INFO misc.py line 113 3298914] Train: [2/100][60/2402] Data 0.004 (0.004) Batch 0.481 (0.486) Remain 32:03:49 loss: 1.2847 Lr: 0.00038
[2025-04-08 14:12:03,399 INFO misc.py line 113 3298914] Train: [2/100][61/2402] Data 0.003 (0.004) Batch 0.456 (0.485) Remain 32:01:48 loss: 1.5048 Lr: 0.00038
[2025-04-08 14:12:03,764 INFO misc.py line 113 3298914] Train: [2/100][62/2402] Data 0.003 (0.004) Batch 0.365 (0.483) Remain 31:53:43 loss: 0.9654 Lr: 0.00038
[2025-04-08 14:12:04,229 INFO misc.py line 113 3298914] Train: [2/100][63/2402] Data 0.004 (0.004) Batch 0.465 (0.483) Remain 31:52:31 loss: 1.7206 Lr: 0.00038
[2025-04-08 14:12:04,695 INFO misc.py line 113 3298914] Train: [2/100][64/2402] Data 0.021 (0.004) Batch 0.466 (0.482) Remain 31:51:25 loss: 1.3174 Lr: 0.00038
[2025-04-08 14:12:05,186 INFO misc.py line 113 3298914] Train: [2/100][65/2402] Data 0.003 (0.004) Batch 0.491 (0.483) Remain 31:51:57 loss: 1.3383 Lr: 0.00038
[2025-04-08 14:12:05,619 INFO misc.py line 113 3298914] Train: [2/100][66/2402] Data 0.003 (0.004) Batch 0.433 (0.482) Remain 31:48:51 loss: 1.0699 Lr: 0.00038
[2025-04-08 14:12:06,275 INFO misc.py line 113 3298914] Train: [2/100][67/2402] Data 0.003 (0.004) Batch 0.655 (0.484) Remain 31:59:34 loss: 1.5193 Lr: 0.00038
[2025-04-08 14:12:06,769 INFO misc.py line 113 3298914] Train: [2/100][68/2402] Data 0.004 (0.004) Batch 0.495 (0.485) Remain 32:00:11 loss: 1.1213 Lr: 0.00038
[2025-04-08 14:12:07,262 INFO misc.py line 113 3298914] Train: [2/100][69/2402] Data 0.003 (0.004) Batch 0.493 (0.485) Remain 32:00:42 loss: 1.2978 Lr: 0.00038
[2025-04-08 14:12:07,793 INFO misc.py line 113 3298914] Train: [2/100][70/2402] Data 0.004 (0.004) Batch 0.531 (0.485) Remain 32:03:24 loss: 1.4351 Lr: 0.00038
[2025-04-08 14:12:08,113 INFO misc.py line 113 3298914] Train: [2/100][71/2402] Data 0.004 (0.004) Batch 0.320 (0.483) Remain 31:53:46 loss: 1.6322 Lr: 0.00038
[2025-04-08 14:12:08,540 INFO misc.py line 113 3298914] Train: [2/100][72/2402] Data 0.004 (0.004) Batch 0.426 (0.482) Remain 31:50:30 loss: 1.2828 Lr: 0.00038
[2025-04-08 14:12:09,008 INFO misc.py line 113 3298914] Train: [2/100][73/2402] Data 0.003 (0.004) Batch 0.468 (0.482) Remain 31:49:41 loss: 1.7291 Lr: 0.00038
[2025-04-08 14:12:09,474 INFO misc.py line 113 3298914] Train: [2/100][74/2402] Data 0.004 (0.004) Batch 0.466 (0.482) Remain 31:48:48 loss: 2.1858 Lr: 0.00038
[2025-04-08 14:12:09,913 INFO misc.py line 113 3298914] Train: [2/100][75/2402] Data 0.003 (0.004) Batch 0.439 (0.481) Remain 31:46:27 loss: 1.1309 Lr: 0.00038
[2025-04-08 14:12:10,384 INFO misc.py line 113 3298914] Train: [2/100][76/2402] Data 0.003 (0.004) Batch 0.471 (0.481) Remain 31:45:53 loss: 1.3155 Lr: 0.00038
[2025-04-08 14:12:10,914 INFO misc.py line 113 3298914] Train: [2/100][77/2402] Data 0.004 (0.004) Batch 0.530 (0.482) Remain 31:48:31 loss: 1.3484 Lr: 0.00038
[2025-04-08 14:12:11,375 INFO misc.py line 113 3298914] Train: [2/100][78/2402] Data 0.003 (0.004) Batch 0.460 (0.481) Remain 31:47:21 loss: 1.2880 Lr: 0.00038
[2025-04-08 14:12:11,849 INFO misc.py line 113 3298914] Train: [2/100][79/2402] Data 0.004 (0.004) Batch 0.474 (0.481) Remain 31:46:59 loss: 1.3066 Lr: 0.00038
[2025-04-08 14:12:12,442 INFO misc.py line 113 3298914] Train: [2/100][80/2402] Data 0.004 (0.004) Batch 0.593 (0.483) Remain 31:52:44 loss: 1.7371 Lr: 0.00038
[2025-04-08 14:12:12,886 INFO misc.py line 113 3298914] Train: [2/100][81/2402] Data 0.004 (0.004) Batch 0.445 (0.482) Remain 31:50:47 loss: 1.8641 Lr: 0.00038
[2025-04-08 14:12:13,278 INFO misc.py line 113 3298914] Train: [2/100][82/2402] Data 0.004 (0.004) Batch 0.392 (0.481) Remain 31:46:15 loss: 1.2706 Lr: 0.00038
[2025-04-08 14:12:13,726 INFO misc.py line 113 3298914] Train: [2/100][83/2402] Data 0.004 (0.004) Batch 0.448 (0.481) Remain 31:44:35 loss: 1.2626 Lr: 0.00038
[2025-04-08 14:12:14,161 INFO misc.py line 113 3298914] Train: [2/100][84/2402] Data 0.003 (0.004) Batch 0.435 (0.480) Remain 31:42:21 loss: 1.3413 Lr: 0.00038
[2025-04-08 14:12:14,763 INFO misc.py line 113 3298914] Train: [2/100][85/2402] Data 0.004 (0.004) Batch 0.601 (0.482) Remain 31:48:11 loss: 1.2331 Lr: 0.00038
[2025-04-08 14:12:15,230 INFO misc.py line 113 3298914] Train: [2/100][86/2402] Data 0.003 (0.004) Batch 0.468 (0.481) Remain 31:47:32 loss: 1.7658 Lr: 0.00038
[2025-04-08 14:12:15,745 INFO misc.py line 113 3298914] Train: [2/100][87/2402] Data 0.003 (0.004) Batch 0.514 (0.482) Remain 31:49:04 loss: 1.4337 Lr: 0.00038
[2025-04-08 14:12:16,274 INFO misc.py line 113 3298914] Train: [2/100][88/2402] Data 0.004 (0.004) Batch 0.529 (0.482) Remain 31:51:17 loss: 1.4779 Lr: 0.00038
[2025-04-08 14:12:16,828 INFO misc.py line 113 3298914] Train: [2/100][89/2402] Data 0.003 (0.004) Batch 0.554 (0.483) Remain 31:54:35 loss: 1.4511 Lr: 0.00038
[2025-04-08 14:12:17,359 INFO misc.py line 113 3298914] Train: [2/100][90/2402] Data 0.003 (0.004) Batch 0.531 (0.484) Remain 31:56:44 loss: 1.3317 Lr: 0.00038
[2025-04-08 14:12:17,704 INFO misc.py line 113 3298914] Train: [2/100][91/2402] Data 0.003 (0.004) Batch 0.345 (0.482) Remain 31:50:29 loss: 1.2342 Lr: 0.00038
[2025-04-08 14:12:18,303 INFO misc.py line 113 3298914] Train: [2/100][92/2402] Data 0.003 (0.004) Batch 0.599 (0.484) Remain 31:55:41 loss: 1.2355 Lr: 0.00038
[2025-04-08 14:12:18,758 INFO misc.py line 113 3298914] Train: [2/100][93/2402] Data 0.003 (0.004) Batch 0.455 (0.483) Remain 31:54:26 loss: 1.3975 Lr: 0.00038
[2025-04-08 14:12:19,273 INFO misc.py line 113 3298914] Train: [2/100][94/2402] Data 0.003 (0.004) Batch 0.515 (0.484) Remain 31:55:48 loss: 1.5076 Lr: 0.00038
[2025-04-08 14:12:19,782 INFO misc.py line 113 3298914] Train: [2/100][95/2402] Data 0.003 (0.004) Batch 0.508 (0.484) Remain 31:56:50 loss: 1.9117 Lr: 0.00038
[2025-04-08 14:12:20,306 INFO misc.py line 113 3298914] Train: [2/100][96/2402] Data 0.003 (0.004) Batch 0.524 (0.484) Remain 31:58:33 loss: 1.4265 Lr: 0.00038
[2025-04-08 14:12:20,810 INFO misc.py line 113 3298914] Train: [2/100][97/2402] Data 0.004 (0.004) Batch 0.505 (0.484) Remain 31:59:24 loss: 1.6977 Lr: 0.00039
[2025-04-08 14:12:21,211 INFO misc.py line 113 3298914] Train: [2/100][98/2402] Data 0.004 (0.004) Batch 0.401 (0.484) Remain 31:55:54 loss: 0.9907 Lr: 0.00039
[2025-04-08 14:12:21,628 INFO misc.py line 113 3298914] Train: [2/100][99/2402] Data 0.003 (0.004) Batch 0.417 (0.483) Remain 31:53:08 loss: 1.0515 Lr: 0.00039
[2025-04-08 14:12:22,208 INFO misc.py line 113 3298914] Train: [2/100][100/2402] Data 0.003 (0.004) Batch 0.579 (0.484) Remain 31:57:04 loss: 1.7175 Lr: 0.00039
[2025-04-08 14:12:22,639 INFO misc.py line 113 3298914] Train: [2/100][101/2402] Data 0.004 (0.004) Batch 0.431 (0.483) Remain 31:54:56 loss: 1.2761 Lr: 0.00039
[2025-04-08 14:12:23,196 INFO misc.py line 113 3298914] Train: [2/100][102/2402] Data 0.003 (0.004) Batch 0.558 (0.484) Remain 31:57:54 loss: 1.5932 Lr: 0.00039
[2025-04-08 14:12:23,714 INFO misc.py line 113 3298914] Train: [2/100][103/2402] Data 0.004 (0.004) Batch 0.518 (0.484) Remain 31:59:13 loss: 1.2779 Lr: 0.00039
[2025-04-08 14:12:24,182 INFO misc.py line 113 3298914] Train: [2/100][104/2402] Data 0.004 (0.004) Batch 0.468 (0.484) Remain 31:58:34 loss: 1.7390 Lr: 0.00039
[2025-04-08 14:12:24,715 INFO misc.py line 113 3298914] Train: [2/100][105/2402] Data 0.003 (0.004) Batch 0.532 (0.485) Remain 32:00:26 loss: 1.1926 Lr: 0.00039
[2025-04-08 14:12:25,250 INFO misc.py line 113 3298914] Train: [2/100][106/2402] Data 0.003 (0.004) Batch 0.536 (0.485) Remain 32:02:23 loss: 1.2722 Lr: 0.00039
[2025-04-08 14:12:25,713 INFO misc.py line 113 3298914] Train: [2/100][107/2402] Data 0.003 (0.004) Batch 0.462 (0.485) Remain 32:01:30 loss: 1.6103 Lr: 0.00039
[2025-04-08 14:12:26,201 INFO misc.py line 113 3298914] Train: [2/100][108/2402] Data 0.004 (0.004) Batch 0.489 (0.485) Remain 32:01:38 loss: 1.6555 Lr: 0.00039
[2025-04-08 14:12:26,759 INFO misc.py line 113 3298914] Train: [2/100][109/2402] Data 0.003 (0.004) Batch 0.557 (0.486) Remain 32:04:20 loss: 1.4101 Lr: 0.00039
[2025-04-08 14:12:27,301 INFO misc.py line 113 3298914] Train: [2/100][110/2402] Data 0.004 (0.004) Batch 0.542 (0.486) Remain 32:06:25 loss: 1.6203 Lr: 0.00039
[2025-04-08 14:12:27,799 INFO misc.py line 113 3298914] Train: [2/100][111/2402] Data 0.004 (0.004) Batch 0.498 (0.486) Remain 32:06:50 loss: 1.5166 Lr: 0.00039
[2025-04-08 14:12:28,290 INFO misc.py line 113 3298914] Train: [2/100][112/2402] Data 0.004 (0.004) Batch 0.491 (0.486) Remain 32:06:59 loss: 1.2979 Lr: 0.00039
[2025-04-08 14:12:28,691 INFO misc.py line 113 3298914] Train: [2/100][113/2402] Data 0.003 (0.004) Batch 0.401 (0.486) Remain 32:03:53 loss: 1.4947 Lr: 0.00039
[2025-04-08 14:12:29,232 INFO misc.py line 113 3298914] Train: [2/100][114/2402] Data 0.004 (0.004) Batch 0.541 (0.486) Remain 32:05:51 loss: 1.5195 Lr: 0.00039
[2025-04-08 14:12:29,793 INFO misc.py line 113 3298914] Train: [2/100][115/2402] Data 0.004 (0.004) Batch 0.562 (0.487) Remain 32:08:30 loss: 1.1065 Lr: 0.00039
[2025-04-08 14:12:30,328 INFO misc.py line 113 3298914] Train: [2/100][116/2402] Data 0.003 (0.004) Batch 0.535 (0.487) Remain 32:10:12 loss: 1.3451 Lr: 0.00039
[2025-04-08 14:12:30,716 INFO misc.py line 113 3298914] Train: [2/100][117/2402] Data 0.003 (0.004) Batch 0.388 (0.486) Remain 32:06:44 loss: 1.5636 Lr: 0.00039
[2025-04-08 14:12:31,216 INFO misc.py line 113 3298914] Train: [2/100][118/2402] Data 0.003 (0.004) Batch 0.500 (0.487) Remain 32:07:12 loss: 1.7403 Lr: 0.00039
[2025-04-08 14:12:31,711 INFO misc.py line 113 3298914] Train: [2/100][119/2402] Data 0.004 (0.004) Batch 0.495 (0.487) Remain 32:07:28 loss: 1.8065 Lr: 0.00039
[2025-04-08 14:12:32,203 INFO misc.py line 113 3298914] Train: [2/100][120/2402] Data 0.004 (0.004) Batch 0.492 (0.487) Remain 32:07:39 loss: 1.0101 Lr: 0.00039
[2025-04-08 14:12:32,672 INFO misc.py line 113 3298914] Train: [2/100][121/2402] Data 0.004 (0.004) Batch 0.470 (0.486) Remain 32:07:04 loss: 1.4635 Lr: 0.00039
[2025-04-08 14:12:33,191 INFO misc.py line 113 3298914] Train: [2/100][122/2402] Data 0.004 (0.004) Batch 0.518 (0.487) Remain 32:08:07 loss: 1.5405 Lr: 0.00039
[2025-04-08 14:12:33,782 INFO misc.py line 113 3298914] Train: [2/100][123/2402] Data 0.003 (0.004) Batch 0.592 (0.488) Remain 32:11:34 loss: 1.3537 Lr: 0.00039
[2025-04-08 14:12:34,200 INFO misc.py line 113 3298914] Train: [2/100][124/2402] Data 0.004 (0.004) Batch 0.418 (0.487) Remain 32:09:16 loss: 1.4001 Lr: 0.00039
[2025-04-08 14:12:34,735 INFO misc.py line 113 3298914] Train: [2/100][125/2402] Data 0.003 (0.004) Batch 0.535 (0.487) Remain 32:10:49 loss: 1.3164 Lr: 0.00039
[2025-04-08 14:12:35,166 INFO misc.py line 113 3298914] Train: [2/100][126/2402] Data 0.003 (0.004) Batch 0.431 (0.487) Remain 32:08:59 loss: 1.2867 Lr: 0.00039
[2025-04-08 14:12:35,655 INFO misc.py line 113 3298914] Train: [2/100][127/2402] Data 0.003 (0.004) Batch 0.489 (0.487) Remain 32:09:02 loss: 1.3311 Lr: 0.00039
[2025-04-08 14:12:36,124 INFO misc.py line 113 3298914] Train: [2/100][128/2402] Data 0.003 (0.004) Batch 0.469 (0.487) Remain 32:08:28 loss: 1.3682 Lr: 0.00039
[2025-04-08 14:12:36,652 INFO misc.py line 113 3298914] Train: [2/100][129/2402] Data 0.004 (0.004) Batch 0.529 (0.487) Remain 32:09:46 loss: 1.4771 Lr: 0.00039
[2025-04-08 14:12:37,272 INFO misc.py line 113 3298914] Train: [2/100][130/2402] Data 0.003 (0.004) Batch 0.619 (0.488) Remain 32:13:53 loss: 1.5600 Lr: 0.00039
[2025-04-08 14:12:37,723 INFO misc.py line 113 3298914] Train: [2/100][131/2402] Data 0.004 (0.004) Batch 0.451 (0.488) Remain 32:12:44 loss: 1.4225 Lr: 0.00039
[2025-04-08 14:12:38,172 INFO misc.py line 113 3298914] Train: [2/100][132/2402] Data 0.003 (0.004) Batch 0.449 (0.488) Remain 32:11:32 loss: 1.0012 Lr: 0.00039
[2025-04-08 14:12:38,634 INFO misc.py line 113 3298914] Train: [2/100][133/2402] Data 0.003 (0.004) Batch 0.462 (0.487) Remain 32:10:45 loss: 1.3730 Lr: 0.00039
[2025-04-08 14:12:39,108 INFO misc.py line 113 3298914] Train: [2/100][134/2402] Data 0.003 (0.004) Batch 0.473 (0.487) Remain 32:10:19 loss: 1.4700 Lr: 0.00039
[2025-04-08 14:12:39,533 INFO misc.py line 113 3298914] Train: [2/100][135/2402] Data 0.003 (0.004) Batch 0.425 (0.487) Remain 32:08:27 loss: 1.4023 Lr: 0.00039
[2025-04-08 14:12:39,989 INFO misc.py line 113 3298914] Train: [2/100][136/2402] Data 0.003 (0.004) Batch 0.456 (0.487) Remain 32:07:32 loss: 1.4013 Lr: 0.00039
[2025-04-08 14:12:40,392 INFO misc.py line 113 3298914] Train: [2/100][137/2402] Data 0.004 (0.004) Batch 0.402 (0.486) Remain 32:05:02 loss: 1.4546 Lr: 0.00039
[2025-04-08 14:12:40,787 INFO misc.py line 113 3298914] Train: [2/100][138/2402] Data 0.003 (0.004) Batch 0.395 (0.485) Remain 32:02:21 loss: 1.4762 Lr: 0.00039
[2025-04-08 14:12:41,342 INFO misc.py line 113 3298914] Train: [2/100][139/2402] Data 0.004 (0.004) Batch 0.555 (0.486) Remain 32:04:23 loss: 1.6147 Lr: 0.00039
[2025-04-08 14:12:41,930 INFO misc.py line 113 3298914] Train: [2/100][140/2402] Data 0.004 (0.004) Batch 0.588 (0.487) Remain 32:07:19 loss: 1.0973 Lr: 0.00039
[2025-04-08 14:12:42,268 INFO misc.py line 113 3298914] Train: [2/100][141/2402] Data 0.004 (0.004) Batch 0.338 (0.486) Remain 32:03:04 loss: 1.1055 Lr: 0.00039
[2025-04-08 14:12:42,795 INFO misc.py line 113 3298914] Train: [2/100][142/2402] Data 0.004 (0.004) Batch 0.527 (0.486) Remain 32:04:13 loss: 1.3132 Lr: 0.00039
[2025-04-08 14:12:43,165 INFO misc.py line 113 3298914] Train: [2/100][143/2402] Data 0.003 (0.004) Batch 0.370 (0.485) Remain 32:00:56 loss: 1.3084 Lr: 0.00039
[2025-04-08 14:12:43,726 INFO misc.py line 113 3298914] Train: [2/100][144/2402] Data 0.004 (0.004) Batch 0.561 (0.486) Remain 32:03:03 loss: 1.8476 Lr: 0.00039
[2025-04-08 14:12:44,195 INFO misc.py line 113 3298914] Train: [2/100][145/2402] Data 0.004 (0.004) Batch 0.470 (0.485) Remain 32:02:37 loss: 1.4230 Lr: 0.00039
[2025-04-08 14:12:44,695 INFO misc.py line 113 3298914] Train: [2/100][146/2402] Data 0.004 (0.004) Batch 0.500 (0.486) Remain 32:03:00 loss: 1.6707 Lr: 0.00039
[2025-04-08 14:12:45,200 INFO misc.py line 113 3298914] Train: [2/100][147/2402] Data 0.003 (0.004) Batch 0.505 (0.486) Remain 32:03:32 loss: 1.2002 Lr: 0.00039
[2025-04-08 14:12:45,547 INFO misc.py line 113 3298914] Train: [2/100][148/2402] Data 0.003 (0.004) Batch 0.347 (0.485) Remain 31:59:44 loss: 1.6399 Lr: 0.00039
[2025-04-08 14:12:46,088 INFO misc.py line 113 3298914] Train: [2/100][149/2402] Data 0.004 (0.004) Batch 0.541 (0.485) Remain 32:01:15 loss: 1.5365 Lr: 0.00039
[2025-04-08 14:12:46,508 INFO misc.py line 113 3298914] Train: [2/100][150/2402] Data 0.003 (0.004) Batch 0.420 (0.485) Remain 31:59:30 loss: 1.4730 Lr: 0.00039
[2025-04-08 14:12:46,966 INFO misc.py line 113 3298914] Train: [2/100][151/2402] Data 0.004 (0.004) Batch 0.457 (0.484) Remain 31:58:46 loss: 1.2410 Lr: 0.00039
[2025-04-08 14:12:47,426 INFO misc.py line 113 3298914] Train: [2/100][152/2402] Data 0.004 (0.004) Batch 0.460 (0.484) Remain 31:58:07 loss: 1.5996 Lr: 0.00039
[2025-04-08 14:12:47,961 INFO misc.py line 113 3298914] Train: [2/100][153/2402] Data 0.003 (0.004) Batch 0.535 (0.485) Remain 31:59:26 loss: 1.3665 Lr: 0.00039
[2025-04-08 14:12:48,443 INFO misc.py line 113 3298914] Train: [2/100][154/2402] Data 0.004 (0.004) Batch 0.482 (0.485) Remain 31:59:22 loss: 1.3307 Lr: 0.00039
[2025-04-08 14:12:48,887 INFO misc.py line 113 3298914] Train: [2/100][155/2402] Data 0.004 (0.004) Batch 0.444 (0.484) Remain 31:58:18 loss: 1.2744 Lr: 0.00039
[2025-04-08 14:12:49,303 INFO misc.py line 113 3298914] Train: [2/100][156/2402] Data 0.003 (0.004) Batch 0.416 (0.484) Remain 31:56:31 loss: 1.4242 Lr: 0.00039
[2025-04-08 14:12:49,758 INFO misc.py line 113 3298914] Train: [2/100][157/2402] Data 0.004 (0.004) Batch 0.455 (0.484) Remain 31:55:46 loss: 1.3341 Lr: 0.00039
[2025-04-08 14:12:50,242 INFO misc.py line 113 3298914] Train: [2/100][158/2402] Data 0.003 (0.004) Batch 0.484 (0.484) Remain 31:55:47 loss: 1.5916 Lr: 0.00039
[2025-04-08 14:12:50,709 INFO misc.py line 113 3298914] Train: [2/100][159/2402] Data 0.003 (0.004) Batch 0.467 (0.484) Remain 31:55:21 loss: 1.5946 Lr: 0.00039
[2025-04-08 14:12:51,235 INFO misc.py line 113 3298914] Train: [2/100][160/2402] Data 0.003 (0.004) Batch 0.526 (0.484) Remain 31:56:24 loss: 1.4575 Lr: 0.00039
[2025-04-08 14:12:51,764 INFO misc.py line 113 3298914] Train: [2/100][161/2402] Data 0.003 (0.004) Batch 0.529 (0.484) Remain 31:57:31 loss: 1.3193 Lr: 0.00039
[2025-04-08 14:12:52,300 INFO misc.py line 113 3298914] Train: [2/100][162/2402] Data 0.004 (0.004) Batch 0.536 (0.484) Remain 31:58:48 loss: 1.2959 Lr: 0.00039
[2025-04-08 14:12:52,824 INFO misc.py line 113 3298914] Train: [2/100][163/2402] Data 0.004 (0.004) Batch 0.525 (0.485) Remain 31:59:47 loss: 1.5436 Lr: 0.00039
[2025-04-08 14:12:53,357 INFO misc.py line 113 3298914] Train: [2/100][164/2402] Data 0.004 (0.004) Batch 0.532 (0.485) Remain 32:00:57 loss: 1.5391 Lr: 0.00039
[2025-04-08 14:12:53,918 INFO misc.py line 113 3298914] Train: [2/100][165/2402] Data 0.004 (0.004) Batch 0.561 (0.485) Remain 32:02:48 loss: 1.4799 Lr: 0.00039
[2025-04-08 14:12:54,364 INFO misc.py line 113 3298914] Train: [2/100][166/2402] Data 0.004 (0.004) Batch 0.446 (0.485) Remain 32:01:50 loss: 1.3357 Lr: 0.00040
[2025-04-08 14:12:54,900 INFO misc.py line 113 3298914] Train: [2/100][167/2402] Data 0.003 (0.004) Batch 0.536 (0.486) Remain 32:03:03 loss: 0.9446 Lr: 0.00040
[2025-04-08 14:12:55,436 INFO misc.py line 113 3298914] Train: [2/100][168/2402] Data 0.003 (0.004) Batch 0.536 (0.486) Remain 32:04:16 loss: 1.6721 Lr: 0.00040
[2025-04-08 14:12:55,961 INFO misc.py line 113 3298914] Train: [2/100][169/2402] Data 0.004 (0.004) Batch 0.525 (0.486) Remain 32:05:11 loss: 1.4987 Lr: 0.00040
[2025-04-08 14:12:56,539 INFO misc.py line 113 3298914] Train: [2/100][170/2402] Data 0.003 (0.004) Batch 0.579 (0.487) Remain 32:07:22 loss: 1.4282 Lr: 0.00040
[2025-04-08 14:12:56,986 INFO misc.py line 113 3298914] Train: [2/100][171/2402] Data 0.003 (0.004) Batch 0.447 (0.486) Remain 32:06:25 loss: 1.3348 Lr: 0.00040
[2025-04-08 14:12:57,397 INFO misc.py line 113 3298914] Train: [2/100][172/2402] Data 0.003 (0.004) Batch 0.411 (0.486) Remain 32:04:38 loss: 1.3765 Lr: 0.00040
[2025-04-08 14:12:57,827 INFO misc.py line 113 3298914] Train: [2/100][173/2402] Data 0.003 (0.004) Batch 0.430 (0.486) Remain 32:03:20 loss: 1.3457 Lr: 0.00040
[2025-04-08 14:12:58,409 INFO misc.py line 113 3298914] Train: [2/100][174/2402] Data 0.004 (0.004) Batch 0.581 (0.486) Remain 32:05:32 loss: 1.4734 Lr: 0.00040
[2025-04-08 14:12:58,911 INFO misc.py line 113 3298914] Train: [2/100][175/2402] Data 0.003 (0.004) Batch 0.502 (0.486) Remain 32:05:54 loss: 1.2132 Lr: 0.00040
[2025-04-08 14:12:59,451 INFO misc.py line 113 3298914] Train: [2/100][176/2402] Data 0.004 (0.004) Batch 0.541 (0.487) Remain 32:07:08 loss: 1.5353 Lr: 0.00040
[2025-04-08 14:12:59,935 INFO misc.py line 113 3298914] Train: [2/100][177/2402] Data 0.003 (0.004) Batch 0.484 (0.487) Remain 32:07:04 loss: 1.6984 Lr: 0.00040
[2025-04-08 14:13:00,369 INFO misc.py line 113 3298914] Train: [2/100][178/2402] Data 0.003 (0.004) Batch 0.434 (0.486) Remain 32:05:51 loss: 1.3061 Lr: 0.00040
[2025-04-08 14:13:00,844 INFO misc.py line 113 3298914] Train: [2/100][179/2402] Data 0.003 (0.004) Batch 0.475 (0.486) Remain 32:05:35 loss: 1.3353 Lr: 0.00040
[2025-04-08 14:13:01,319 INFO misc.py line 113 3298914] Train: [2/100][180/2402] Data 0.004 (0.004) Batch 0.475 (0.486) Remain 32:05:20 loss: 1.5847 Lr: 0.00040
[2025-04-08 14:13:01,846 INFO misc.py line 113 3298914] Train: [2/100][181/2402] Data 0.003 (0.004) Batch 0.527 (0.486) Remain 32:06:15 loss: 1.6274 Lr: 0.00040
[2025-04-08 14:13:02,272 INFO misc.py line 113 3298914] Train: [2/100][182/2402] Data 0.004 (0.004) Batch 0.426 (0.486) Remain 32:04:54 loss: 1.4297 Lr: 0.00040
[2025-04-08 14:13:02,706 INFO misc.py line 113 3298914] Train: [2/100][183/2402] Data 0.003 (0.004) Batch 0.433 (0.486) Remain 32:03:44 loss: 1.4882 Lr: 0.00040
[2025-04-08 14:13:03,248 INFO misc.py line 113 3298914] Train: [2/100][184/2402] Data 0.003 (0.004) Batch 0.542 (0.486) Remain 32:04:58 loss: 1.3300 Lr: 0.00040
[2025-04-08 14:13:03,692 INFO misc.py line 113 3298914] Train: [2/100][185/2402] Data 0.004 (0.004) Batch 0.443 (0.486) Remain 32:04:02 loss: 1.3516 Lr: 0.00040
[2025-04-08 14:13:04,256 INFO misc.py line 113 3298914] Train: [2/100][186/2402] Data 0.004 (0.004) Batch 0.564 (0.486) Remain 32:05:44 loss: 1.4800 Lr: 0.00040
[2025-04-08 14:13:04,736 INFO misc.py line 113 3298914] Train: [2/100][187/2402] Data 0.004 (0.004) Batch 0.480 (0.486) Remain 32:05:34 loss: 1.2717 Lr: 0.00040
[2025-04-08 14:13:05,304 INFO misc.py line 113 3298914] Train: [2/100][188/2402] Data 0.003 (0.004) Batch 0.568 (0.487) Remain 32:07:19 loss: 1.3927 Lr: 0.00040
[2025-04-08 14:13:05,775 INFO misc.py line 113 3298914] Train: [2/100][189/2402] Data 0.004 (0.004) Batch 0.471 (0.487) Remain 32:06:58 loss: 1.4319 Lr: 0.00040
[2025-04-08 14:13:06,340 INFO misc.py line 113 3298914] Train: [2/100][190/2402] Data 0.004 (0.004) Batch 0.565 (0.487) Remain 32:08:37 loss: 1.5938 Lr: 0.00040
[2025-04-08 14:13:06,725 INFO misc.py line 113 3298914] Train: [2/100][191/2402] Data 0.004 (0.004) Batch 0.385 (0.486) Remain 32:06:28 loss: 1.4713 Lr: 0.00040
[2025-04-08 14:13:07,248 INFO misc.py line 113 3298914] Train: [2/100][192/2402] Data 0.004 (0.004) Batch 0.523 (0.487) Remain 32:07:14 loss: 1.5610 Lr: 0.00040
[2025-04-08 14:13:07,753 INFO misc.py line 113 3298914] Train: [2/100][193/2402] Data 0.003 (0.004) Batch 0.505 (0.487) Remain 32:07:37 loss: 1.6125 Lr: 0.00040
[2025-04-08 14:13:08,170 INFO misc.py line 113 3298914] Train: [2/100][194/2402] Data 0.004 (0.004) Batch 0.417 (0.486) Remain 32:06:10 loss: 1.4291 Lr: 0.00040
[2025-04-08 14:13:08,575 INFO misc.py line 113 3298914] Train: [2/100][195/2402] Data 0.003 (0.004) Batch 0.405 (0.486) Remain 32:04:28 loss: 1.5035 Lr: 0.00040
[2025-04-08 14:13:09,042 INFO misc.py line 113 3298914] Train: [2/100][196/2402] Data 0.003 (0.004) Batch 0.467 (0.486) Remain 32:04:04 loss: 1.4440 Lr: 0.00040
[2025-04-08 14:13:09,514 INFO misc.py line 113 3298914] Train: [2/100][197/2402] Data 0.004 (0.004) Batch 0.472 (0.486) Remain 32:03:47 loss: 1.4805 Lr: 0.00040
[2025-04-08 14:13:10,032 INFO misc.py line 113 3298914] Train: [2/100][198/2402] Data 0.003 (0.004) Batch 0.518 (0.486) Remain 32:04:26 loss: 1.3321 Lr: 0.00040
[2025-04-08 14:13:10,546 INFO misc.py line 113 3298914] Train: [2/100][199/2402] Data 0.003 (0.004) Batch 0.514 (0.486) Remain 32:04:59 loss: 1.3980 Lr: 0.00040
[2025-04-08 14:13:11,140 INFO misc.py line 113 3298914] Train: [2/100][200/2402] Data 0.004 (0.004) Batch 0.594 (0.487) Remain 32:07:08 loss: 1.5698 Lr: 0.00040
[2025-04-08 14:13:11,644 INFO misc.py line 113 3298914] Train: [2/100][201/2402] Data 0.003 (0.004) Batch 0.504 (0.487) Remain 32:07:29 loss: 1.3705 Lr: 0.00040
[2025-04-08 14:13:12,103 INFO misc.py line 113 3298914] Train: [2/100][202/2402] Data 0.003 (0.004) Batch 0.459 (0.487) Remain 32:06:55 loss: 1.5391 Lr: 0.00040
[2025-04-08 14:13:12,673 INFO misc.py line 113 3298914] Train: [2/100][203/2402] Data 0.004 (0.004) Batch 0.570 (0.487) Remain 32:08:34 loss: 1.4843 Lr: 0.00040
[2025-04-08 14:13:13,187 INFO misc.py line 113 3298914] Train: [2/100][204/2402] Data 0.003 (0.004) Batch 0.514 (0.487) Remain 32:09:05 loss: 1.5467 Lr: 0.00040
[2025-04-08 14:13:13,631 INFO misc.py line 113 3298914] Train: [2/100][205/2402] Data 0.005 (0.004) Batch 0.444 (0.487) Remain 32:08:14 loss: 1.4040 Lr: 0.00040
[2025-04-08 14:13:14,056 INFO misc.py line 113 3298914] Train: [2/100][206/2402] Data 0.004 (0.004) Batch 0.424 (0.487) Remain 32:07:00 loss: 1.5639 Lr: 0.00040
[2025-04-08 14:13:14,596 INFO misc.py line 113 3298914] Train: [2/100][207/2402] Data 0.004 (0.004) Batch 0.541 (0.487) Remain 32:08:02 loss: 1.5413 Lr: 0.00040
[2025-04-08 14:13:15,029 INFO misc.py line 113 3298914] Train: [2/100][208/2402] Data 0.004 (0.004) Batch 0.433 (0.487) Remain 32:06:59 loss: 1.4032 Lr: 0.00040
[2025-04-08 14:13:15,591 INFO misc.py line 113 3298914] Train: [2/100][209/2402] Data 0.003 (0.004) Batch 0.562 (0.487) Remain 32:08:26 loss: 1.3687 Lr: 0.00040
[2025-04-08 14:13:16,094 INFO misc.py line 113 3298914] Train: [2/100][210/2402] Data 0.003 (0.004) Batch 0.504 (0.487) Remain 32:08:44 loss: 1.8562 Lr: 0.00040
[2025-04-08 14:13:16,508 INFO misc.py line 113 3298914] Train: [2/100][211/2402] Data 0.003 (0.004) Batch 0.413 (0.487) Remain 32:07:19 loss: 1.3076 Lr: 0.00040
[2025-04-08 14:13:16,892 INFO misc.py line 113 3298914] Train: [2/100][212/2402] Data 0.004 (0.004) Batch 0.385 (0.486) Remain 32:05:23 loss: 1.3118 Lr: 0.00040
[2025-04-08 14:13:17,373 INFO misc.py line 113 3298914] Train: [2/100][213/2402] Data 0.004 (0.004) Batch 0.481 (0.486) Remain 32:05:16 loss: 1.5235 Lr: 0.00040
[2025-04-08 14:13:17,987 INFO misc.py line 113 3298914] Train: [2/100][214/2402] Data 0.003 (0.004) Batch 0.614 (0.487) Remain 32:07:40 loss: 1.1036 Lr: 0.00040
[2025-04-08 14:13:18,490 INFO misc.py line 113 3298914] Train: [2/100][215/2402] Data 0.004 (0.004) Batch 0.503 (0.487) Remain 32:07:57 loss: 1.3510 Lr: 0.00040
[2025-04-08 14:13:18,991 INFO misc.py line 113 3298914] Train: [2/100][216/2402] Data 0.003 (0.004) Batch 0.502 (0.487) Remain 32:08:13 loss: 1.5820 Lr: 0.00040
[2025-04-08 14:13:19,513 INFO misc.py line 113 3298914] Train: [2/100][217/2402] Data 0.004 (0.004) Batch 0.521 (0.487) Remain 32:08:51 loss: 1.7211 Lr: 0.00040
[2025-04-08 14:13:19,994 INFO misc.py line 113 3298914] Train: [2/100][218/2402] Data 0.003 (0.004) Batch 0.481 (0.487) Remain 32:08:44 loss: 1.2385 Lr: 0.00040
[2025-04-08 14:13:20,501 INFO misc.py line 113 3298914] Train: [2/100][219/2402] Data 0.004 (0.004) Batch 0.506 (0.487) Remain 32:09:05 loss: 1.7072 Lr: 0.00040
[2025-04-08 14:13:21,032 INFO misc.py line 113 3298914] Train: [2/100][220/2402] Data 0.004 (0.004) Batch 0.531 (0.487) Remain 32:09:52 loss: 1.4430 Lr: 0.00040
[2025-04-08 14:13:21,549 INFO misc.py line 113 3298914] Train: [2/100][221/2402] Data 0.003 (0.004) Batch 0.517 (0.488) Remain 32:10:24 loss: 1.2782 Lr: 0.00040
[2025-04-08 14:13:21,984 INFO misc.py line 113 3298914] Train: [2/100][222/2402] Data 0.003 (0.004) Batch 0.435 (0.487) Remain 32:09:27 loss: 1.4952 Lr: 0.00040
[2025-04-08 14:13:22,543 INFO misc.py line 113 3298914] Train: [2/100][223/2402] Data 0.003 (0.004) Batch 0.559 (0.488) Remain 32:10:44 loss: 1.7724 Lr: 0.00040
[2025-04-08 14:13:23,050 INFO misc.py line 113 3298914] Train: [2/100][224/2402] Data 0.004 (0.004) Batch 0.507 (0.488) Remain 32:11:04 loss: 1.1364 Lr: 0.00040
[2025-04-08 14:13:23,552 INFO misc.py line 113 3298914] Train: [2/100][225/2402] Data 0.004 (0.004) Batch 0.502 (0.488) Remain 32:11:19 loss: 1.5351 Lr: 0.00040
[2025-04-08 14:13:24,160 INFO misc.py line 113 3298914] Train: [2/100][226/2402] Data 0.003 (0.004) Batch 0.608 (0.488) Remain 32:13:27 loss: 1.3848 Lr: 0.00040
[2025-04-08 14:13:24,616 INFO misc.py line 113 3298914] Train: [2/100][227/2402] Data 0.004 (0.004) Batch 0.456 (0.488) Remain 32:12:52 loss: 1.6945 Lr: 0.00040
[2025-04-08 14:13:25,077 INFO misc.py line 113 3298914] Train: [2/100][228/2402] Data 0.003 (0.004) Batch 0.460 (0.488) Remain 32:12:22 loss: 1.3320 Lr: 0.00040
[2025-04-08 14:13:25,542 INFO misc.py line 113 3298914] Train: [2/100][229/2402] Data 0.003 (0.004) Batch 0.465 (0.488) Remain 32:11:57 loss: 1.6796 Lr: 0.00040
[2025-04-08 14:13:26,041 INFO misc.py line 113 3298914] Train: [2/100][230/2402] Data 0.004 (0.004) Batch 0.500 (0.488) Remain 32:12:09 loss: 1.5558 Lr: 0.00040
[2025-04-08 14:13:26,463 INFO misc.py line 113 3298914] Train: [2/100][231/2402] Data 0.003 (0.004) Batch 0.421 (0.488) Remain 32:10:59 loss: 1.2117 Lr: 0.00040
[2025-04-08 14:13:27,040 INFO misc.py line 113 3298914] Train: [2/100][232/2402] Data 0.003 (0.004) Batch 0.578 (0.488) Remain 32:12:32 loss: 1.5064 Lr: 0.00040
[2025-04-08 14:13:27,546 INFO misc.py line 113 3298914] Train: [2/100][233/2402] Data 0.003 (0.004) Batch 0.506 (0.488) Remain 32:12:50 loss: 1.4446 Lr: 0.00041
[2025-04-08 14:13:28,009 INFO misc.py line 113 3298914] Train: [2/100][234/2402] Data 0.003 (0.004) Batch 0.462 (0.488) Remain 32:12:23 loss: 1.6610 Lr: 0.00041
[2025-04-08 14:13:28,525 INFO misc.py line 113 3298914] Train: [2/100][235/2402] Data 0.004 (0.004) Batch 0.516 (0.488) Remain 32:12:52 loss: 1.2994 Lr: 0.00041
[2025-04-08 14:13:29,121 INFO misc.py line 113 3298914] Train: [2/100][236/2402] Data 0.003 (0.004) Batch 0.597 (0.489) Remain 32:14:42 loss: 1.4820 Lr: 0.00041
[2025-04-08 14:13:29,571 INFO misc.py line 113 3298914] Train: [2/100][237/2402] Data 0.004 (0.004) Batch 0.449 (0.488) Remain 32:14:01 loss: 1.4046 Lr: 0.00041
[2025-04-08 14:13:30,000 INFO misc.py line 113 3298914] Train: [2/100][238/2402] Data 0.003 (0.004) Batch 0.429 (0.488) Remain 32:13:01 loss: 1.4889 Lr: 0.00041
[2025-04-08 14:13:30,488 INFO misc.py line 113 3298914] Train: [2/100][239/2402] Data 0.003 (0.004) Batch 0.488 (0.488) Remain 32:13:00 loss: 1.1535 Lr: 0.00041
[2025-04-08 14:13:30,977 INFO misc.py line 113 3298914] Train: [2/100][240/2402] Data 0.004 (0.004) Batch 0.489 (0.488) Remain 32:13:01 loss: 1.7514 Lr: 0.00041
[2025-04-08 14:13:31,334 INFO misc.py line 113 3298914] Train: [2/100][241/2402] Data 0.003 (0.004) Batch 0.357 (0.488) Remain 32:10:49 loss: 1.7933 Lr: 0.00041
[2025-04-08 14:13:31,861 INFO misc.py line 113 3298914] Train: [2/100][242/2402] Data 0.004 (0.004) Batch 0.527 (0.488) Remain 32:11:28 loss: 1.3256 Lr: 0.00041
[2025-04-08 14:13:32,326 INFO misc.py line 113 3298914] Train: [2/100][243/2402] Data 0.003 (0.004) Batch 0.465 (0.488) Remain 32:11:04 loss: 1.2878 Lr: 0.00041
[2025-04-08 14:13:32,760 INFO misc.py line 113 3298914] Train: [2/100][244/2402] Data 0.004 (0.004) Batch 0.434 (0.488) Remain 32:10:11 loss: 1.7422 Lr: 0.00041
[2025-04-08 14:13:33,296 INFO misc.py line 113 3298914] Train: [2/100][245/2402] Data 0.003 (0.004) Batch 0.536 (0.488) Remain 32:10:58 loss: 1.4345 Lr: 0.00041
[2025-04-08 14:13:33,678 INFO misc.py line 113 3298914] Train: [2/100][246/2402] Data 0.003 (0.004) Batch 0.382 (0.487) Remain 32:09:14 loss: 1.5821 Lr: 0.00041
[2025-04-08 14:13:34,201 INFO misc.py line 113 3298914] Train: [2/100][247/2402] Data 0.004 (0.004) Batch 0.523 (0.487) Remain 32:09:49 loss: 1.7695 Lr: 0.00041
[2025-04-08 14:13:34,566 INFO misc.py line 113 3298914] Train: [2/100][248/2402] Data 0.003 (0.004) Batch 0.365 (0.487) Remain 32:07:49 loss: 1.2203 Lr: 0.00041
[2025-04-08 14:13:35,049 INFO misc.py line 113 3298914] Train: [2/100][249/2402] Data 0.003 (0.004) Batch 0.483 (0.487) Remain 32:07:45 loss: 1.5811 Lr: 0.00041
[2025-04-08 14:13:35,628 INFO misc.py line 113 3298914] Train: [2/100][250/2402] Data 0.004 (0.004) Batch 0.579 (0.487) Remain 32:09:13 loss: 1.6894 Lr: 0.00041
[2025-04-08 14:13:36,147 INFO misc.py line 113 3298914] Train: [2/100][251/2402] Data 0.004 (0.004) Batch 0.519 (0.487) Remain 32:09:43 loss: 1.0885 Lr: 0.00041
[2025-04-08 14:13:36,702 INFO misc.py line 113 3298914] Train: [2/100][252/2402] Data 0.003 (0.004) Batch 0.556 (0.488) Remain 32:10:47 loss: 1.5197 Lr: 0.00041
[2025-04-08 14:13:37,136 INFO misc.py line 113 3298914] Train: [2/100][253/2402] Data 0.004 (0.004) Batch 0.434 (0.487) Remain 32:09:56 loss: 1.5476 Lr: 0.00041
[2025-04-08 14:13:37,629 INFO misc.py line 113 3298914] Train: [2/100][254/2402] Data 0.003 (0.004) Batch 0.492 (0.487) Remain 32:10:00 loss: 1.3685 Lr: 0.00041
[2025-04-08 14:13:38,145 INFO misc.py line 113 3298914] Train: [2/100][255/2402] Data 0.004 (0.004) Batch 0.516 (0.488) Remain 32:10:27 loss: 1.2974 Lr: 0.00041
[2025-04-08 14:13:38,600 INFO misc.py line 113 3298914] Train: [2/100][256/2402] Data 0.003 (0.004) Batch 0.455 (0.487) Remain 32:09:55 loss: 1.6671 Lr: 0.00041
[2025-04-08 14:13:39,177 INFO misc.py line 113 3298914] Train: [2/100][257/2402] Data 0.003 (0.004) Batch 0.577 (0.488) Remain 32:11:19 loss: 1.2815 Lr: 0.00041
[2025-04-08 14:13:39,616 INFO misc.py line 113 3298914] Train: [2/100][258/2402] Data 0.004 (0.004) Batch 0.439 (0.488) Remain 32:10:33 loss: 1.4946 Lr: 0.00041
[2025-04-08 14:13:40,152 INFO misc.py line 113 3298914] Train: [2/100][259/2402] Data 0.003 (0.004) Batch 0.537 (0.488) Remain 32:11:17 loss: 1.1763 Lr: 0.00041
[2025-04-08 14:13:40,529 INFO misc.py line 113 3298914] Train: [2/100][260/2402] Data 0.004 (0.004) Batch 0.377 (0.487) Remain 32:09:34 loss: 1.5189 Lr: 0.00041
[2025-04-08 14:13:40,999 INFO misc.py line 113 3298914] Train: [2/100][261/2402] Data 0.004 (0.004) Batch 0.471 (0.487) Remain 32:09:18 loss: 1.6604 Lr: 0.00041
[2025-04-08 14:13:41,444 INFO misc.py line 113 3298914] Train: [2/100][262/2402] Data 0.003 (0.004) Batch 0.444 (0.487) Remain 32:08:38 loss: 1.8846 Lr: 0.00041
[2025-04-08 14:13:41,871 INFO misc.py line 113 3298914] Train: [2/100][263/2402] Data 0.004 (0.004) Batch 0.428 (0.487) Remain 32:07:43 loss: 1.7967 Lr: 0.00041
[2025-04-08 14:13:42,302 INFO misc.py line 113 3298914] Train: [2/100][264/2402] Data 0.003 (0.004) Batch 0.431 (0.487) Remain 32:06:52 loss: 1.5130 Lr: 0.00041
[2025-04-08 14:13:42,726 INFO misc.py line 113 3298914] Train: [2/100][265/2402] Data 0.003 (0.004) Batch 0.423 (0.486) Remain 32:05:54 loss: 1.0886 Lr: 0.00041
[2025-04-08 14:13:43,224 INFO misc.py line 113 3298914] Train: [2/100][266/2402] Data 0.004 (0.004) Batch 0.498 (0.487) Remain 32:06:04 loss: 1.4083 Lr: 0.00041
[2025-04-08 14:13:43,670 INFO misc.py line 113 3298914] Train: [2/100][267/2402] Data 0.004 (0.004) Batch 0.446 (0.486) Remain 32:05:27 loss: 0.9157 Lr: 0.00041
[2025-04-08 14:13:44,177 INFO misc.py line 113 3298914] Train: [2/100][268/2402] Data 0.003 (0.004) Batch 0.508 (0.486) Remain 32:05:46 loss: 1.2034 Lr: 0.00041
[2025-04-08 14:13:44,537 INFO misc.py line 113 3298914] Train: [2/100][269/2402] Data 0.004 (0.004) Batch 0.360 (0.486) Remain 32:03:52 loss: 1.4869 Lr: 0.00041
[2025-04-08 14:13:44,941 INFO misc.py line 113 3298914] Train: [2/100][270/2402] Data 0.003 (0.004) Batch 0.404 (0.486) Remain 32:02:38 loss: 1.3176 Lr: 0.00041
[2025-04-08 14:13:45,455 INFO misc.py line 113 3298914] Train: [2/100][271/2402] Data 0.003 (0.004) Batch 0.513 (0.486) Remain 32:03:02 loss: 1.2475 Lr: 0.00041
[2025-04-08 14:13:45,929 INFO misc.py line 113 3298914] Train: [2/100][272/2402] Data 0.004 (0.004) Batch 0.475 (0.486) Remain 32:02:52 loss: 1.2363 Lr: 0.00041
[2025-04-08 14:13:46,514 INFO misc.py line 113 3298914] Train: [2/100][273/2402] Data 0.004 (0.004) Batch 0.585 (0.486) Remain 32:04:20 loss: 1.2835 Lr: 0.00041
[2025-04-08 14:13:47,049 INFO misc.py line 113 3298914] Train: [2/100][274/2402] Data 0.004 (0.004) Batch 0.535 (0.486) Remain 32:05:02 loss: 1.2676 Lr: 0.00041
[2025-04-08 14:13:47,437 INFO misc.py line 113 3298914] Train: [2/100][275/2402] Data 0.003 (0.004) Batch 0.388 (0.486) Remain 32:03:36 loss: 1.0413 Lr: 0.00041
[2025-04-08 14:13:47,961 INFO misc.py line 113 3298914] Train: [2/100][276/2402] Data 0.004 (0.004) Batch 0.523 (0.486) Remain 32:04:08 loss: 1.5151 Lr: 0.00041
[2025-04-08 14:13:48,422 INFO misc.py line 113 3298914] Train: [2/100][277/2402] Data 0.004 (0.004) Batch 0.461 (0.486) Remain 32:03:45 loss: 1.5456 Lr: 0.00041
[2025-04-08 14:13:48,934 INFO misc.py line 113 3298914] Train: [2/100][278/2402] Data 0.004 (0.004) Batch 0.512 (0.486) Remain 32:04:07 loss: 1.3639 Lr: 0.00041
[2025-04-08 14:13:49,496 INFO misc.py line 113 3298914] Train: [2/100][279/2402] Data 0.003 (0.004) Batch 0.562 (0.486) Remain 32:05:12 loss: 1.4728 Lr: 0.00041
[2025-04-08 14:13:49,868 INFO misc.py line 113 3298914] Train: [2/100][280/2402] Data 0.004 (0.004) Batch 0.372 (0.486) Remain 32:03:34 loss: 1.3227 Lr: 0.00041
[2025-04-08 14:13:50,343 INFO misc.py line 113 3298914] Train: [2/100][281/2402] Data 0.004 (0.004) Batch 0.474 (0.486) Remain 32:03:24 loss: 1.0977 Lr: 0.00041
[2025-04-08 14:13:50,702 INFO misc.py line 113 3298914] Train: [2/100][282/2402] Data 0.003 (0.004) Batch 0.359 (0.485) Remain 32:01:36 loss: 1.3589 Lr: 0.00041
[2025-04-08 14:13:51,172 INFO misc.py line 113 3298914] Train: [2/100][283/2402] Data 0.003 (0.004) Batch 0.470 (0.485) Remain 32:01:22 loss: 1.8705 Lr: 0.00041
[2025-04-08 14:13:51,765 INFO misc.py line 113 3298914] Train: [2/100][284/2402] Data 0.004 (0.004) Batch 0.593 (0.486) Remain 32:02:53 loss: 1.5021 Lr: 0.00041
[2025-04-08 14:13:52,258 INFO misc.py line 113 3298914] Train: [2/100][285/2402] Data 0.003 (0.004) Batch 0.493 (0.486) Remain 32:02:58 loss: 1.1124 Lr: 0.00041
[2025-04-08 14:13:52,782 INFO misc.py line 113 3298914] Train: [2/100][286/2402] Data 0.003 (0.004) Batch 0.524 (0.486) Remain 32:03:30 loss: 1.0728 Lr: 0.00041
[2025-04-08 14:13:53,291 INFO misc.py line 113 3298914] Train: [2/100][287/2402] Data 0.003 (0.004) Batch 0.508 (0.486) Remain 32:03:48 loss: 1.2692 Lr: 0.00041
[2025-04-08 14:13:53,770 INFO misc.py line 113 3298914] Train: [2/100][288/2402] Data 0.004 (0.004) Batch 0.480 (0.486) Remain 32:03:43 loss: 1.2661 Lr: 0.00041
[2025-04-08 14:13:54,339 INFO misc.py line 113 3298914] Train: [2/100][289/2402] Data 0.003 (0.004) Batch 0.568 (0.486) Remain 32:04:50 loss: 1.9163 Lr: 0.00041
[2025-04-08 14:13:54,841 INFO misc.py line 113 3298914] Train: [2/100][290/2402] Data 0.004 (0.004) Batch 0.502 (0.486) Remain 32:05:03 loss: 1.8516 Lr: 0.00041
[2025-04-08 14:13:55,228 INFO misc.py line 113 3298914] Train: [2/100][291/2402] Data 0.003 (0.004) Batch 0.387 (0.486) Remain 32:03:40 loss: 1.2477 Lr: 0.00041
[2025-04-08 14:13:55,670 INFO misc.py line 113 3298914] Train: [2/100][292/2402] Data 0.003 (0.004) Batch 0.442 (0.486) Remain 32:03:04 loss: 1.2588 Lr: 0.00041
[2025-04-08 14:13:56,111 INFO misc.py line 113 3298914] Train: [2/100][293/2402] Data 0.004 (0.004) Batch 0.441 (0.486) Remain 32:02:27 loss: 1.1613 Lr: 0.00041
[2025-04-08 14:13:56,683 INFO misc.py line 113 3298914] Train: [2/100][294/2402] Data 0.003 (0.004) Batch 0.571 (0.486) Remain 32:03:37 loss: 1.3871 Lr: 0.00041
[2025-04-08 14:13:57,157 INFO misc.py line 113 3298914] Train: [2/100][295/2402] Data 0.004 (0.004) Batch 0.474 (0.486) Remain 32:03:26 loss: 1.0894 Lr: 0.00041
[2025-04-08 14:13:57,516 INFO misc.py line 113 3298914] Train: [2/100][296/2402] Data 0.004 (0.004) Batch 0.359 (0.485) Remain 32:01:43 loss: 1.1702 Lr: 0.00041
[2025-04-08 14:13:58,007 INFO misc.py line 113 3298914] Train: [2/100][297/2402] Data 0.004 (0.004) Batch 0.491 (0.486) Remain 32:01:47 loss: 1.2997 Lr: 0.00041
[2025-04-08 14:13:58,491 INFO misc.py line 113 3298914] Train: [2/100][298/2402] Data 0.004 (0.004) Batch 0.485 (0.486) Remain 32:01:46 loss: 1.5758 Lr: 0.00041
[2025-04-08 14:13:58,992 INFO misc.py line 113 3298914] Train: [2/100][299/2402] Data 0.003 (0.004) Batch 0.501 (0.486) Remain 32:01:57 loss: 1.2494 Lr: 0.00042
[2025-04-08 14:13:59,471 INFO misc.py line 113 3298914] Train: [2/100][300/2402] Data 0.004 (0.004) Batch 0.480 (0.486) Remain 32:01:52 loss: 1.5976 Lr: 0.00042
[2025-04-08 14:14:00,067 INFO misc.py line 113 3298914] Train: [2/100][301/2402] Data 0.004 (0.004) Batch 0.596 (0.486) Remain 32:03:20 loss: 1.6278 Lr: 0.00042
[2025-04-08 14:14:00,560 INFO misc.py line 113 3298914] Train: [2/100][302/2402] Data 0.003 (0.004) Batch 0.493 (0.486) Remain 32:03:25 loss: 1.5622 Lr: 0.00042
[2025-04-08 14:14:01,046 INFO misc.py line 113 3298914] Train: [2/100][303/2402] Data 0.004 (0.004) Batch 0.486 (0.486) Remain 32:03:24 loss: 1.6389 Lr: 0.00042
[2025-04-08 14:14:01,451 INFO misc.py line 113 3298914] Train: [2/100][304/2402] Data 0.003 (0.004) Batch 0.405 (0.486) Remain 32:02:20 loss: 1.4630 Lr: 0.00042
[2025-04-08 14:14:01,975 INFO misc.py line 113 3298914] Train: [2/100][305/2402] Data 0.004 (0.004) Batch 0.524 (0.486) Remain 32:02:50 loss: 1.2801 Lr: 0.00042
[2025-04-08 14:14:02,424 INFO misc.py line 113 3298914] Train: [2/100][306/2402] Data 0.003 (0.004) Batch 0.448 (0.486) Remain 32:02:20 loss: 1.4436 Lr: 0.00042
[2025-04-08 14:14:02,920 INFO misc.py line 113 3298914] Train: [2/100][307/2402] Data 0.004 (0.004) Batch 0.496 (0.486) Remain 32:02:28 loss: 1.3944 Lr: 0.00042
[2025-04-08 14:14:03,359 INFO misc.py line 113 3298914] Train: [2/100][308/2402] Data 0.004 (0.004) Batch 0.439 (0.486) Remain 32:01:51 loss: 1.4112 Lr: 0.00042
[2025-04-08 14:14:03,722 INFO misc.py line 113 3298914] Train: [2/100][309/2402] Data 0.004 (0.004) Batch 0.363 (0.485) Remain 32:00:15 loss: 1.4425 Lr: 0.00042
[2025-04-08 14:14:04,130 INFO misc.py line 113 3298914] Train: [2/100][310/2402] Data 0.003 (0.004) Batch 0.407 (0.485) Remain 31:59:15 loss: 1.6077 Lr: 0.00042
[2025-04-08 14:14:04,540 INFO misc.py line 113 3298914] Train: [2/100][311/2402] Data 0.004 (0.004) Batch 0.410 (0.485) Remain 31:58:17 loss: 1.0263 Lr: 0.00042
[2025-04-08 14:14:05,133 INFO misc.py line 113 3298914] Train: [2/100][312/2402] Data 0.004 (0.004) Batch 0.593 (0.485) Remain 31:59:39 loss: 1.4206 Lr: 0.00042
[2025-04-08 14:14:05,507 INFO misc.py line 113 3298914] Train: [2/100][313/2402] Data 0.003 (0.004) Batch 0.374 (0.485) Remain 31:58:14 loss: 1.4661 Lr: 0.00042
[2025-04-08 14:14:05,944 INFO misc.py line 113 3298914] Train: [2/100][314/2402] Data 0.004 (0.004) Batch 0.437 (0.484) Remain 31:57:37 loss: 1.4482 Lr: 0.00042
[2025-04-08 14:14:06,406 INFO misc.py line 113 3298914] Train: [2/100][315/2402] Data 0.003 (0.004) Batch 0.462 (0.484) Remain 31:57:19 loss: 1.6892 Lr: 0.00042
[2025-04-08 14:14:06,953 INFO misc.py line 113 3298914] Train: [2/100][316/2402] Data 0.003 (0.004) Batch 0.547 (0.485) Remain 31:58:07 loss: 1.4863 Lr: 0.00042
[2025-04-08 14:14:07,354 INFO misc.py line 113 3298914] Train: [2/100][317/2402] Data 0.004 (0.004) Batch 0.401 (0.484) Remain 31:57:03 loss: 1.9206 Lr: 0.00042
[2025-04-08 14:14:07,887 INFO misc.py line 113 3298914] Train: [2/100][318/2402] Data 0.003 (0.004) Batch 0.533 (0.485) Remain 31:57:39 loss: 1.0983 Lr: 0.00042
[2025-04-08 14:14:08,314 INFO misc.py line 113 3298914] Train: [2/100][319/2402] Data 0.003 (0.004) Batch 0.426 (0.484) Remain 31:56:55 loss: 1.5970 Lr: 0.00042
[2025-04-08 14:14:08,827 INFO misc.py line 113 3298914] Train: [2/100][320/2402] Data 0.004 (0.004) Batch 0.513 (0.484) Remain 31:57:16 loss: 1.5801 Lr: 0.00042
[2025-04-08 14:14:09,379 INFO misc.py line 113 3298914] Train: [2/100][321/2402] Data 0.003 (0.004) Batch 0.553 (0.485) Remain 31:58:07 loss: 1.0740 Lr: 0.00042
[2025-04-08 14:14:09,950 INFO misc.py line 113 3298914] Train: [2/100][322/2402] Data 0.003 (0.004) Batch 0.571 (0.485) Remain 31:59:10 loss: 1.4593 Lr: 0.00042
[2025-04-08 14:14:10,416 INFO misc.py line 113 3298914] Train: [2/100][323/2402] Data 0.004 (0.004) Batch 0.467 (0.485) Remain 31:58:56 loss: 1.2080 Lr: 0.00042
[2025-04-08 14:14:10,907 INFO misc.py line 113 3298914] Train: [2/100][324/2402] Data 0.003 (0.004) Batch 0.490 (0.485) Remain 31:59:00 loss: 1.3869 Lr: 0.00042
[2025-04-08 14:14:11,410 INFO misc.py line 113 3298914] Train: [2/100][325/2402] Data 0.004 (0.004) Batch 0.503 (0.485) Remain 31:59:13 loss: 1.3063 Lr: 0.00042
[2025-04-08 14:14:12,033 INFO misc.py line 113 3298914] Train: [2/100][326/2402] Data 0.004 (0.004) Batch 0.623 (0.485) Remain 32:00:54 loss: 1.3699 Lr: 0.00042
[2025-04-08 14:14:12,538 INFO misc.py line 113 3298914] Train: [2/100][327/2402] Data 0.004 (0.004) Batch 0.505 (0.485) Remain 32:01:08 loss: 0.8765 Lr: 0.00042
[2025-04-08 14:14:13,065 INFO misc.py line 113 3298914] Train: [2/100][328/2402] Data 0.003 (0.004) Batch 0.527 (0.486) Remain 32:01:38 loss: 1.2073 Lr: 0.00042
[2025-04-08 14:14:13,579 INFO misc.py line 113 3298914] Train: [2/100][329/2402] Data 0.003 (0.004) Batch 0.514 (0.486) Remain 32:01:58 loss: 1.5112 Lr: 0.00042
[2025-04-08 14:14:14,003 INFO misc.py line 113 3298914] Train: [2/100][330/2402] Data 0.004 (0.004) Batch 0.423 (0.485) Remain 32:01:12 loss: 1.2309 Lr: 0.00042
[2025-04-08 14:14:14,566 INFO misc.py line 113 3298914] Train: [2/100][331/2402] Data 0.003 (0.004) Batch 0.563 (0.486) Remain 32:02:08 loss: 1.3087 Lr: 0.00042
[2025-04-08 14:14:15,052 INFO misc.py line 113 3298914] Train: [2/100][332/2402] Data 0.003 (0.004) Batch 0.487 (0.486) Remain 32:02:08 loss: 1.1348 Lr: 0.00042
[2025-04-08 14:14:15,624 INFO misc.py line 113 3298914] Train: [2/100][333/2402] Data 0.004 (0.004) Batch 0.572 (0.486) Remain 32:03:10 loss: 1.5677 Lr: 0.00042
[2025-04-08 14:14:16,180 INFO misc.py line 113 3298914] Train: [2/100][334/2402] Data 0.003 (0.004) Batch 0.556 (0.486) Remain 32:03:59 loss: 1.3205 Lr: 0.00042
[2025-04-08 14:14:16,664 INFO misc.py line 113 3298914] Train: [2/100][335/2402] Data 0.004 (0.004) Batch 0.484 (0.486) Remain 32:03:57 loss: 1.7510 Lr: 0.00042
[2025-04-08 14:14:17,175 INFO misc.py line 113 3298914] Train: [2/100][336/2402] Data 0.004 (0.004) Batch 0.511 (0.486) Remain 32:04:15 loss: 1.2768 Lr: 0.00042
[2025-04-08 14:14:17,543 INFO misc.py line 113 3298914] Train: [2/100][337/2402] Data 0.004 (0.004) Batch 0.368 (0.486) Remain 32:02:50 loss: 1.1555 Lr: 0.00042
[2025-04-08 14:14:18,106 INFO misc.py line 113 3298914] Train: [2/100][338/2402] Data 0.003 (0.004) Batch 0.563 (0.486) Remain 32:03:44 loss: 1.1995 Lr: 0.00042
[2025-04-08 14:14:18,583 INFO misc.py line 113 3298914] Train: [2/100][339/2402] Data 0.003 (0.004) Batch 0.477 (0.486) Remain 32:03:38 loss: 1.0669 Lr: 0.00042
[2025-04-08 14:14:19,084 INFO misc.py line 113 3298914] Train: [2/100][340/2402] Data 0.003 (0.004) Batch 0.501 (0.486) Remain 32:03:48 loss: 1.8565 Lr: 0.00042
[2025-04-08 14:14:19,567 INFO misc.py line 113 3298914] Train: [2/100][341/2402] Data 0.003 (0.004) Batch 0.482 (0.486) Remain 32:03:45 loss: 1.1885 Lr: 0.00042
[2025-04-08 14:14:20,049 INFO misc.py line 113 3298914] Train: [2/100][342/2402] Data 0.003 (0.004) Batch 0.483 (0.486) Remain 32:03:42 loss: 1.1670 Lr: 0.00042
[2025-04-08 14:14:20,566 INFO misc.py line 113 3298914] Train: [2/100][343/2402] Data 0.003 (0.004) Batch 0.517 (0.486) Remain 32:04:02 loss: 1.2453 Lr: 0.00042
[2025-04-08 14:14:20,914 INFO misc.py line 113 3298914] Train: [2/100][344/2402] Data 0.003 (0.004) Batch 0.348 (0.486) Remain 32:02:26 loss: 1.2863 Lr: 0.00042
[2025-04-08 14:14:21,426 INFO misc.py line 113 3298914] Train: [2/100][345/2402] Data 0.003 (0.004) Batch 0.512 (0.486) Remain 32:02:43 loss: 1.5858 Lr: 0.00042
[2025-04-08 14:14:22,000 INFO misc.py line 113 3298914] Train: [2/100][346/2402] Data 0.004 (0.004) Batch 0.575 (0.486) Remain 32:03:44 loss: 1.2107 Lr: 0.00042
[2025-04-08 14:14:22,557 INFO misc.py line 113 3298914] Train: [2/100][347/2402] Data 0.004 (0.004) Batch 0.557 (0.486) Remain 32:04:33 loss: 1.5729 Lr: 0.00042
[2025-04-08 14:14:22,956 INFO misc.py line 113 3298914] Train: [2/100][348/2402] Data 0.003 (0.004) Batch 0.399 (0.486) Remain 32:03:32 loss: 1.0049 Lr: 0.00042
[2025-04-08 14:14:23,426 INFO misc.py line 113 3298914] Train: [2/100][349/2402] Data 0.003 (0.004) Batch 0.470 (0.486) Remain 32:03:21 loss: 1.1570 Lr: 0.00042
[2025-04-08 14:14:23,874 INFO misc.py line 113 3298914] Train: [2/100][350/2402] Data 0.004 (0.004) Batch 0.447 (0.486) Remain 32:02:54 loss: 1.4283 Lr: 0.00042
[2025-04-08 14:14:24,371 INFO misc.py line 113 3298914] Train: [2/100][351/2402] Data 0.003 (0.004) Batch 0.497 (0.486) Remain 32:03:01 loss: 1.6307 Lr: 0.00042
[2025-04-08 14:14:24,872 INFO misc.py line 113 3298914] Train: [2/100][352/2402] Data 0.004 (0.004) Batch 0.501 (0.486) Remain 32:03:11 loss: 1.4147 Lr: 0.00042
[2025-04-08 14:14:25,370 INFO misc.py line 113 3298914] Train: [2/100][353/2402] Data 0.004 (0.004) Batch 0.498 (0.486) Remain 32:03:18 loss: 1.4131 Lr: 0.00042
[2025-04-08 14:14:25,921 INFO misc.py line 113 3298914] Train: [2/100][354/2402] Data 0.004 (0.004) Batch 0.552 (0.486) Remain 32:04:02 loss: 1.4127 Lr: 0.00042
[2025-04-08 14:14:26,396 INFO misc.py line 113 3298914] Train: [2/100][355/2402] Data 0.004 (0.004) Batch 0.474 (0.486) Remain 32:03:54 loss: 1.3175 Lr: 0.00042
[2025-04-08 14:14:26,943 INFO misc.py line 113 3298914] Train: [2/100][356/2402] Data 0.004 (0.004) Batch 0.548 (0.486) Remain 32:04:35 loss: 1.1942 Lr: 0.00042
[2025-04-08 14:14:27,324 INFO misc.py line 113 3298914] Train: [2/100][357/2402] Data 0.004 (0.004) Batch 0.380 (0.486) Remain 32:03:23 loss: 1.1088 Lr: 0.00042
[2025-04-08 14:14:27,826 INFO misc.py line 113 3298914] Train: [2/100][358/2402] Data 0.004 (0.004) Batch 0.502 (0.486) Remain 32:03:33 loss: 1.2632 Lr: 0.00042
[2025-04-08 14:14:28,438 INFO misc.py line 113 3298914] Train: [2/100][359/2402] Data 0.003 (0.004) Batch 0.613 (0.486) Remain 32:04:57 loss: 1.4919 Lr: 0.00042
[2025-04-08 14:14:28,867 INFO misc.py line 113 3298914] Train: [2/100][360/2402] Data 0.003 (0.004) Batch 0.429 (0.486) Remain 32:04:19 loss: 1.2256 Lr: 0.00042
[2025-04-08 14:14:29,333 INFO misc.py line 113 3298914] Train: [2/100][361/2402] Data 0.003 (0.004) Batch 0.466 (0.486) Remain 32:04:05 loss: 1.2668 Lr: 0.00042
[2025-04-08 14:14:29,738 INFO misc.py line 113 3298914] Train: [2/100][362/2402] Data 0.003 (0.004) Batch 0.405 (0.486) Remain 32:03:10 loss: 1.5318 Lr: 0.00042
[2025-04-08 14:14:30,254 INFO misc.py line 113 3298914] Train: [2/100][363/2402] Data 0.003 (0.004) Batch 0.516 (0.486) Remain 32:03:30 loss: 1.6809 Lr: 0.00042
[2025-04-08 14:14:30,638 INFO misc.py line 113 3298914] Train: [2/100][364/2402] Data 0.003 (0.004) Batch 0.384 (0.486) Remain 32:02:22 loss: 1.2314 Lr: 0.00043
[2025-04-08 14:14:31,081 INFO misc.py line 113 3298914] Train: [2/100][365/2402] Data 0.004 (0.004) Batch 0.442 (0.486) Remain 32:01:53 loss: 1.0651 Lr: 0.00043
[2025-04-08 14:14:31,485 INFO misc.py line 113 3298914] Train: [2/100][366/2402] Data 0.003 (0.004) Batch 0.405 (0.485) Remain 32:01:00 loss: 1.2502 Lr: 0.00043
[2025-04-08 14:14:32,004 INFO misc.py line 113 3298914] Train: [2/100][367/2402] Data 0.004 (0.004) Batch 0.518 (0.486) Remain 32:01:21 loss: 1.0133 Lr: 0.00043
[2025-04-08 14:14:32,490 INFO misc.py line 113 3298914] Train: [2/100][368/2402] Data 0.003 (0.004) Batch 0.486 (0.486) Remain 32:01:20 loss: 1.8046 Lr: 0.00043
[2025-04-08 14:14:32,937 INFO misc.py line 113 3298914] Train: [2/100][369/2402] Data 0.004 (0.004) Batch 0.447 (0.485) Remain 32:00:55 loss: 1.6786 Lr: 0.00043
[2025-04-08 14:14:33,408 INFO misc.py line 113 3298914] Train: [2/100][370/2402] Data 0.003 (0.004) Batch 0.471 (0.485) Remain 32:00:45 loss: 1.9414 Lr: 0.00043
[2025-04-08 14:14:33,927 INFO misc.py line 113 3298914] Train: [2/100][371/2402] Data 0.003 (0.004) Batch 0.519 (0.485) Remain 32:01:06 loss: 1.5787 Lr: 0.00043
[2025-04-08 14:14:34,465 INFO misc.py line 113 3298914] Train: [2/100][372/2402] Data 0.003 (0.004) Batch 0.538 (0.486) Remain 32:01:40 loss: 1.3576 Lr: 0.00043
[2025-04-08 14:14:34,990 INFO misc.py line 113 3298914] Train: [2/100][373/2402] Data 0.003 (0.004) Batch 0.525 (0.486) Remain 32:02:05 loss: 1.5681 Lr: 0.00043
[2025-04-08 14:14:35,483 INFO misc.py line 113 3298914] Train: [2/100][374/2402] Data 0.004 (0.004) Batch 0.493 (0.486) Remain 32:02:09 loss: 1.3243 Lr: 0.00043
[2025-04-08 14:14:35,911 INFO misc.py line 113 3298914] Train: [2/100][375/2402] Data 0.004 (0.004) Batch 0.428 (0.486) Remain 32:01:32 loss: 1.3096 Lr: 0.00043
[2025-04-08 14:14:36,448 INFO misc.py line 113 3298914] Train: [2/100][376/2402] Data 0.003 (0.004) Batch 0.537 (0.486) Remain 32:02:04 loss: 1.6793 Lr: 0.00043
[2025-04-08 14:14:36,834 INFO misc.py line 113 3298914] Train: [2/100][377/2402] Data 0.004 (0.004) Batch 0.386 (0.485) Remain 32:01:00 loss: 1.4078 Lr: 0.00043
[2025-04-08 14:14:37,367 INFO misc.py line 113 3298914] Train: [2/100][378/2402] Data 0.003 (0.004) Batch 0.533 (0.486) Remain 32:01:30 loss: 1.4108 Lr: 0.00043
[2025-04-08 14:14:37,878 INFO misc.py line 113 3298914] Train: [2/100][379/2402] Data 0.003 (0.004) Batch 0.511 (0.486) Remain 32:01:45 loss: 1.2767 Lr: 0.00043
[2025-04-08 14:14:38,421 INFO misc.py line 113 3298914] Train: [2/100][380/2402] Data 0.003 (0.004) Batch 0.543 (0.486) Remain 32:02:21 loss: 1.2635 Lr: 0.00043
[2025-04-08 14:14:38,931 INFO misc.py line 113 3298914] Train: [2/100][381/2402] Data 0.003 (0.004) Batch 0.510 (0.486) Remain 32:02:35 loss: 1.4269 Lr: 0.00043
[2025-04-08 14:14:39,455 INFO misc.py line 113 3298914] Train: [2/100][382/2402] Data 0.004 (0.004) Batch 0.524 (0.486) Remain 32:02:59 loss: 1.4755 Lr: 0.00043
[2025-04-08 14:14:39,939 INFO misc.py line 113 3298914] Train: [2/100][383/2402] Data 0.003 (0.004) Batch 0.484 (0.486) Remain 32:02:57 loss: 1.3331 Lr: 0.00043
[2025-04-08 14:14:40,484 INFO misc.py line 113 3298914] Train: [2/100][384/2402] Data 0.004 (0.004) Batch 0.546 (0.486) Remain 32:03:34 loss: 1.1008 Lr: 0.00043
[2025-04-08 14:14:41,033 INFO misc.py line 113 3298914] Train: [2/100][385/2402] Data 0.003 (0.004) Batch 0.548 (0.486) Remain 32:04:12 loss: 1.0595 Lr: 0.00043
[2025-04-08 14:14:41,534 INFO misc.py line 113 3298914] Train: [2/100][386/2402] Data 0.003 (0.004) Batch 0.501 (0.486) Remain 32:04:20 loss: 1.7096 Lr: 0.00043
[2025-04-08 14:14:42,033 INFO misc.py line 113 3298914] Train: [2/100][387/2402] Data 0.004 (0.004) Batch 0.499 (0.486) Remain 32:04:28 loss: 1.5404 Lr: 0.00043
[2025-04-08 14:14:42,498 INFO misc.py line 113 3298914] Train: [2/100][388/2402] Data 0.004 (0.004) Batch 0.465 (0.486) Remain 32:04:14 loss: 1.9110 Lr: 0.00043
[2025-04-08 14:14:43,001 INFO misc.py line 113 3298914] Train: [2/100][389/2402] Data 0.004 (0.004) Batch 0.504 (0.486) Remain 32:04:24 loss: 1.9319 Lr: 0.00043
[2025-04-08 14:14:43,573 INFO misc.py line 113 3298914] Train: [2/100][390/2402] Data 0.004 (0.004) Batch 0.572 (0.487) Remain 32:05:16 loss: 1.4837 Lr: 0.00043
[2025-04-08 14:14:43,949 INFO misc.py line 113 3298914] Train: [2/100][391/2402] Data 0.004 (0.004) Batch 0.376 (0.486) Remain 32:04:08 loss: 1.2580 Lr: 0.00043
[2025-04-08 14:14:44,325 INFO misc.py line 113 3298914] Train: [2/100][392/2402] Data 0.003 (0.004) Batch 0.375 (0.486) Remain 32:03:00 loss: 1.7371 Lr: 0.00043
[2025-04-08 14:14:44,835 INFO misc.py line 113 3298914] Train: [2/100][393/2402] Data 0.004 (0.004) Batch 0.511 (0.486) Remain 32:03:14 loss: 2.2053 Lr: 0.00043
[2025-04-08 14:14:45,323 INFO misc.py line 113 3298914] Train: [2/100][394/2402] Data 0.003 (0.004) Batch 0.488 (0.486) Remain 32:03:15 loss: 1.1372 Lr: 0.00043
[2025-04-08 14:14:45,803 INFO misc.py line 113 3298914] Train: [2/100][395/2402] Data 0.004 (0.004) Batch 0.481 (0.486) Remain 32:03:11 loss: 1.5308 Lr: 0.00043
[2025-04-08 14:14:46,285 INFO misc.py line 113 3298914] Train: [2/100][396/2402] Data 0.003 (0.004) Batch 0.482 (0.486) Remain 32:03:08 loss: 1.3951 Lr: 0.00043
[2025-04-08 14:14:46,779 INFO misc.py line 113 3298914] Train: [2/100][397/2402] Data 0.004 (0.004) Batch 0.494 (0.486) Remain 32:03:12 loss: 1.6601 Lr: 0.00043
[2025-04-08 14:14:47,355 INFO misc.py line 113 3298914] Train: [2/100][398/2402] Data 0.004 (0.004) Batch 0.576 (0.486) Remain 32:04:06 loss: 1.9663 Lr: 0.00043
[2025-04-08 14:14:47,920 INFO misc.py line 113 3298914] Train: [2/100][399/2402] Data 0.003 (0.004) Batch 0.565 (0.486) Remain 32:04:52 loss: 1.2594 Lr: 0.00043
[2025-04-08 14:14:48,387 INFO misc.py line 113 3298914] Train: [2/100][400/2402] Data 0.004 (0.004) Batch 0.467 (0.486) Remain 32:04:40 loss: 1.4834 Lr: 0.00043
[2025-04-08 14:14:48,897 INFO misc.py line 113 3298914] Train: [2/100][401/2402] Data 0.003 (0.004) Batch 0.509 (0.487) Remain 32:04:54 loss: 1.4208 Lr: 0.00043
[2025-04-08 14:14:49,483 INFO misc.py line 113 3298914] Train: [2/100][402/2402] Data 0.003 (0.004) Batch 0.587 (0.487) Remain 32:05:53 loss: 1.7547 Lr: 0.00043
[2025-04-08 14:14:49,921 INFO misc.py line 113 3298914] Train: [2/100][403/2402] Data 0.004 (0.004) Batch 0.438 (0.487) Remain 32:05:23 loss: 1.6988 Lr: 0.00043
[2025-04-08 14:14:50,455 INFO misc.py line 113 3298914] Train: [2/100][404/2402] Data 0.003 (0.004) Batch 0.534 (0.487) Remain 32:05:51 loss: 1.4469 Lr: 0.00043
[2025-04-08 14:14:50,944 INFO misc.py line 113 3298914] Train: [2/100][405/2402] Data 0.003 (0.004) Batch 0.489 (0.487) Remain 32:05:52 loss: 1.4611 Lr: 0.00043
[2025-04-08 14:14:51,454 INFO misc.py line 113 3298914] Train: [2/100][406/2402] Data 0.004 (0.004) Batch 0.510 (0.487) Remain 32:06:05 loss: 1.0958 Lr: 0.00043
[2025-04-08 14:14:51,926 INFO misc.py line 113 3298914] Train: [2/100][407/2402] Data 0.003 (0.004) Batch 0.472 (0.487) Remain 32:05:56 loss: 1.7798 Lr: 0.00043
[2025-04-08 14:14:52,399 INFO misc.py line 113 3298914] Train: [2/100][408/2402] Data 0.004 (0.004) Batch 0.473 (0.487) Remain 32:05:47 loss: 1.3198 Lr: 0.00043
[2025-04-08 14:14:52,705 INFO misc.py line 113 3298914] Train: [2/100][409/2402] Data 0.004 (0.004) Batch 0.307 (0.486) Remain 32:04:01 loss: 1.3802 Lr: 0.00043
[2025-04-08 14:14:53,301 INFO misc.py line 113 3298914] Train: [2/100][410/2402] Data 0.003 (0.004) Batch 0.595 (0.487) Remain 32:05:04 loss: 1.6241 Lr: 0.00043
[2025-04-08 14:14:53,759 INFO misc.py line 113 3298914] Train: [2/100][411/2402] Data 0.003 (0.004) Batch 0.458 (0.486) Remain 32:04:47 loss: 1.5385 Lr: 0.00043
[2025-04-08 14:14:54,209 INFO misc.py line 113 3298914] Train: [2/100][412/2402] Data 0.004 (0.004) Batch 0.450 (0.486) Remain 32:04:25 loss: 1.5053 Lr: 0.00043
[2025-04-08 14:14:54,665 INFO misc.py line 113 3298914] Train: [2/100][413/2402] Data 0.004 (0.004) Batch 0.455 (0.486) Remain 32:04:07 loss: 1.3769 Lr: 0.00043
[2025-04-08 14:14:55,076 INFO misc.py line 113 3298914] Train: [2/100][414/2402] Data 0.003 (0.004) Batch 0.411 (0.486) Remain 32:03:23 loss: 1.4956 Lr: 0.00043
[2025-04-08 14:14:55,462 INFO misc.py line 113 3298914] Train: [2/100][415/2402] Data 0.003 (0.004) Batch 0.386 (0.486) Remain 32:02:25 loss: 1.3579 Lr: 0.00043
[2025-04-08 14:14:55,962 INFO misc.py line 113 3298914] Train: [2/100][416/2402] Data 0.003 (0.004) Batch 0.500 (0.486) Remain 32:02:33 loss: 1.7356 Lr: 0.00043
[2025-04-08 14:14:56,516 INFO misc.py line 113 3298914] Train: [2/100][417/2402] Data 0.004 (0.004) Batch 0.554 (0.486) Remain 32:03:11 loss: 1.6231 Lr: 0.00043
[2025-04-08 14:14:56,998 INFO misc.py line 113 3298914] Train: [2/100][418/2402] Data 0.004 (0.004) Batch 0.482 (0.486) Remain 32:03:08 loss: 1.3029 Lr: 0.00043
[2025-04-08 14:14:57,504 INFO misc.py line 113 3298914] Train: [2/100][419/2402] Data 0.003 (0.004) Batch 0.505 (0.486) Remain 32:03:19 loss: 1.3801 Lr: 0.00043
[2025-04-08 14:14:57,991 INFO misc.py line 113 3298914] Train: [2/100][420/2402] Data 0.004 (0.004) Batch 0.488 (0.486) Remain 32:03:19 loss: 1.8858 Lr: 0.00043
[2025-04-08 14:14:58,409 INFO misc.py line 113 3298914] Train: [2/100][421/2402] Data 0.003 (0.004) Batch 0.418 (0.486) Remain 32:02:40 loss: 1.5044 Lr: 0.00043
[2025-04-08 14:14:58,797 INFO misc.py line 113 3298914] Train: [2/100][422/2402] Data 0.004 (0.004) Batch 0.388 (0.486) Remain 32:01:44 loss: 1.6377 Lr: 0.00043
[2025-04-08 14:14:59,342 INFO misc.py line 113 3298914] Train: [2/100][423/2402] Data 0.003 (0.004) Batch 0.545 (0.486) Remain 32:02:17 loss: 1.5797 Lr: 0.00043
[2025-04-08 14:14:59,703 INFO misc.py line 113 3298914] Train: [2/100][424/2402] Data 0.004 (0.004) Batch 0.361 (0.486) Remain 32:01:06 loss: 0.9521 Lr: 0.00043
[2025-04-08 14:15:00,151 INFO misc.py line 113 3298914] Train: [2/100][425/2402] Data 0.003 (0.004) Batch 0.447 (0.486) Remain 32:00:44 loss: 1.4447 Lr: 0.00043
[2025-04-08 14:15:00,627 INFO misc.py line 113 3298914] Train: [2/100][426/2402] Data 0.003 (0.004) Batch 0.476 (0.485) Remain 32:00:39 loss: 1.5975 Lr: 0.00043
[2025-04-08 14:15:01,156 INFO misc.py line 113 3298914] Train: [2/100][427/2402] Data 0.003 (0.004) Batch 0.529 (0.486) Remain 32:01:02 loss: 1.4798 Lr: 0.00043
[2025-04-08 14:15:01,586 INFO misc.py line 113 3298914] Train: [2/100][428/2402] Data 0.004 (0.004) Batch 0.430 (0.485) Remain 32:00:31 loss: 1.7505 Lr: 0.00044
[2025-04-08 14:15:02,127 INFO misc.py line 113 3298914] Train: [2/100][429/2402] Data 0.004 (0.004) Batch 0.542 (0.486) Remain 32:01:02 loss: 1.7211 Lr: 0.00044
[2025-04-08 14:15:02,593 INFO misc.py line 113 3298914] Train: [2/100][430/2402] Data 0.004 (0.004) Batch 0.465 (0.486) Remain 32:00:50 loss: 1.8720 Lr: 0.00044
[2025-04-08 14:15:03,137 INFO misc.py line 113 3298914] Train: [2/100][431/2402] Data 0.003 (0.004) Batch 0.545 (0.486) Remain 32:01:22 loss: 1.1536 Lr: 0.00044
[2025-04-08 14:15:03,533 INFO misc.py line 113 3298914] Train: [2/100][432/2402] Data 0.004 (0.004) Batch 0.396 (0.485) Remain 32:00:32 loss: 1.4823 Lr: 0.00044
[2025-04-08 14:15:04,058 INFO misc.py line 113 3298914] Train: [2/100][433/2402] Data 0.003 (0.004) Batch 0.524 (0.486) Remain 32:00:53 loss: 1.3920 Lr: 0.00044
[2025-04-08 14:15:04,561 INFO misc.py line 113 3298914] Train: [2/100][434/2402] Data 0.004 (0.004) Batch 0.503 (0.486) Remain 32:01:02 loss: 1.4218 Lr: 0.00044
[2025-04-08 14:15:05,067 INFO misc.py line 113 3298914] Train: [2/100][435/2402] Data 0.003 (0.004) Batch 0.506 (0.486) Remain 32:01:13 loss: 1.4466 Lr: 0.00044
[2025-04-08 14:15:05,582 INFO misc.py line 113 3298914] Train: [2/100][436/2402] Data 0.004 (0.004) Batch 0.516 (0.486) Remain 32:01:29 loss: 1.8908 Lr: 0.00044
[2025-04-08 14:15:06,102 INFO misc.py line 113 3298914] Train: [2/100][437/2402] Data 0.004 (0.004) Batch 0.520 (0.486) Remain 32:01:47 loss: 1.4796 Lr: 0.00044
[2025-04-08 14:15:06,478 INFO misc.py line 113 3298914] Train: [2/100][438/2402] Data 0.003 (0.004) Batch 0.376 (0.486) Remain 32:00:47 loss: 1.2486 Lr: 0.00044
[2025-04-08 14:15:07,027 INFO misc.py line 113 3298914] Train: [2/100][439/2402] Data 0.003 (0.004) Batch 0.548 (0.486) Remain 32:01:21 loss: 1.5412 Lr: 0.00044
[2025-04-08 14:15:07,611 INFO misc.py line 113 3298914] Train: [2/100][440/2402] Data 0.003 (0.004) Batch 0.584 (0.486) Remain 32:02:14 loss: 1.5154 Lr: 0.00044
[2025-04-08 14:15:08,059 INFO misc.py line 113 3298914] Train: [2/100][441/2402] Data 0.003 (0.004) Batch 0.448 (0.486) Remain 32:01:53 loss: 1.2007 Lr: 0.00044
[2025-04-08 14:15:08,687 INFO misc.py line 113 3298914] Train: [2/100][442/2402] Data 0.004 (0.004) Batch 0.629 (0.486) Remain 32:03:09 loss: 1.6791 Lr: 0.00044
[2025-04-08 14:15:09,090 INFO misc.py line 113 3298914] Train: [2/100][443/2402] Data 0.003 (0.004) Batch 0.402 (0.486) Remain 32:02:24 loss: 1.1710 Lr: 0.00044
[2025-04-08 14:15:09,626 INFO misc.py line 113 3298914] Train: [2/100][444/2402] Data 0.003 (0.004) Batch 0.537 (0.486) Remain 32:02:50 loss: 1.3616 Lr: 0.00044
[2025-04-08 14:15:10,135 INFO misc.py line 113 3298914] Train: [2/100][445/2402] Data 0.003 (0.004) Batch 0.508 (0.486) Remain 32:03:02 loss: 1.4346 Lr: 0.00044
[2025-04-08 14:15:10,502 INFO misc.py line 113 3298914] Train: [2/100][446/2402] Data 0.004 (0.004) Batch 0.367 (0.486) Remain 32:01:58 loss: 1.0981 Lr: 0.00044
[2025-04-08 14:15:10,991 INFO misc.py line 113 3298914] Train: [2/100][447/2402] Data 0.003 (0.004) Batch 0.489 (0.486) Remain 32:01:59 loss: 1.5128 Lr: 0.00044
[2025-04-08 14:15:11,472 INFO misc.py line 113 3298914] Train: [2/100][448/2402] Data 0.004 (0.004) Batch 0.480 (0.486) Remain 32:01:55 loss: 1.4775 Lr: 0.00044
[2025-04-08 14:15:12,010 INFO misc.py line 113 3298914] Train: [2/100][449/2402] Data 0.003 (0.004) Batch 0.539 (0.486) Remain 32:02:23 loss: 1.2491 Lr: 0.00044
[2025-04-08 14:15:12,543 INFO misc.py line 113 3298914] Train: [2/100][450/2402] Data 0.004 (0.004) Batch 0.533 (0.486) Remain 32:02:48 loss: 1.6968 Lr: 0.00044
[2025-04-08 14:15:13,002 INFO misc.py line 113 3298914] Train: [2/100][451/2402] Data 0.004 (0.004) Batch 0.459 (0.486) Remain 32:02:33 loss: 1.8155 Lr: 0.00044
[2025-04-08 14:15:13,503 INFO misc.py line 113 3298914] Train: [2/100][452/2402] Data 0.003 (0.004) Batch 0.502 (0.486) Remain 32:02:40 loss: 1.4006 Lr: 0.00044
[2025-04-08 14:15:13,885 INFO misc.py line 113 3298914] Train: [2/100][453/2402] Data 0.004 (0.004) Batch 0.382 (0.486) Remain 32:01:45 loss: 0.9634 Lr: 0.00044
[2025-04-08 14:15:14,427 INFO misc.py line 113 3298914] Train: [2/100][454/2402] Data 0.003 (0.004) Batch 0.541 (0.486) Remain 32:02:14 loss: 1.9977 Lr: 0.00044
[2025-04-08 14:15:14,967 INFO misc.py line 113 3298914] Train: [2/100][455/2402] Data 0.004 (0.004) Batch 0.541 (0.486) Remain 32:02:42 loss: 1.6777 Lr: 0.00044
[2025-04-08 14:15:15,413 INFO misc.py line 113 3298914] Train: [2/100][456/2402] Data 0.004 (0.004) Batch 0.446 (0.486) Remain 32:02:21 loss: 1.4812 Lr: 0.00044
[2025-04-08 14:15:15,819 INFO misc.py line 113 3298914] Train: [2/100][457/2402] Data 0.003 (0.004) Batch 0.405 (0.486) Remain 32:01:38 loss: 1.5996 Lr: 0.00044
[2025-04-08 14:15:16,274 INFO misc.py line 113 3298914] Train: [2/100][458/2402] Data 0.003 (0.004) Batch 0.456 (0.486) Remain 32:01:22 loss: 1.2391 Lr: 0.00044
[2025-04-08 14:15:16,778 INFO misc.py line 113 3298914] Train: [2/100][459/2402] Data 0.003 (0.004) Batch 0.504 (0.486) Remain 32:01:31 loss: 1.4931 Lr: 0.00044
[2025-04-08 14:15:17,273 INFO misc.py line 113 3298914] Train: [2/100][460/2402] Data 0.003 (0.004) Batch 0.495 (0.486) Remain 32:01:35 loss: 1.4907 Lr: 0.00044
[2025-04-08 14:15:17,664 INFO misc.py line 113 3298914] Train: [2/100][461/2402] Data 0.003 (0.004) Batch 0.390 (0.486) Remain 32:00:45 loss: 1.5058 Lr: 0.00044
[2025-04-08 14:15:18,126 INFO misc.py line 113 3298914] Train: [2/100][462/2402] Data 0.004 (0.004) Batch 0.462 (0.486) Remain 32:00:33 loss: 1.5774 Lr: 0.00044
[2025-04-08 14:15:18,602 INFO misc.py line 113 3298914] Train: [2/100][463/2402] Data 0.003 (0.004) Batch 0.476 (0.486) Remain 32:00:27 loss: 1.3512 Lr: 0.00044
[2025-04-08 14:15:19,127 INFO misc.py line 113 3298914] Train: [2/100][464/2402] Data 0.003 (0.004) Batch 0.525 (0.486) Remain 32:00:47 loss: 1.6091 Lr: 0.00044
[2025-04-08 14:15:19,624 INFO misc.py line 113 3298914] Train: [2/100][465/2402] Data 0.004 (0.004) Batch 0.498 (0.486) Remain 32:00:52 loss: 1.2497 Lr: 0.00044
[2025-04-08 14:15:20,066 INFO misc.py line 113 3298914] Train: [2/100][466/2402] Data 0.003 (0.004) Batch 0.442 (0.486) Remain 32:00:29 loss: 1.5921 Lr: 0.00044
[2025-04-08 14:15:20,437 INFO misc.py line 113 3298914] Train: [2/100][467/2402] Data 0.004 (0.004) Batch 0.371 (0.485) Remain 31:59:30 loss: 1.3939 Lr: 0.00044
[2025-04-08 14:15:20,944 INFO misc.py line 113 3298914] Train: [2/100][468/2402] Data 0.004 (0.004) Batch 0.507 (0.485) Remain 31:59:41 loss: 1.6090 Lr: 0.00044
[2025-04-08 14:15:21,358 INFO misc.py line 113 3298914] Train: [2/100][469/2402] Data 0.003 (0.004) Batch 0.414 (0.485) Remain 31:59:04 loss: 1.7258 Lr: 0.00044
[2025-04-08 14:15:21,927 INFO misc.py line 113 3298914] Train: [2/100][470/2402] Data 0.004 (0.004) Batch 0.569 (0.485) Remain 31:59:46 loss: 1.4961 Lr: 0.00044
[2025-04-08 14:15:22,411 INFO misc.py line 113 3298914] Train: [2/100][471/2402] Data 0.003 (0.004) Batch 0.484 (0.485) Remain 31:59:45 loss: 1.5533 Lr: 0.00044
[2025-04-08 14:15:22,782 INFO misc.py line 113 3298914] Train: [2/100][472/2402] Data 0.004 (0.004) Batch 0.371 (0.485) Remain 31:58:47 loss: 1.7015 Lr: 0.00044
[2025-04-08 14:15:23,266 INFO misc.py line 113 3298914] Train: [2/100][473/2402] Data 0.003 (0.004) Batch 0.483 (0.485) Remain 31:58:46 loss: 1.4618 Lr: 0.00044
[2025-04-08 14:15:23,715 INFO misc.py line 113 3298914] Train: [2/100][474/2402] Data 0.004 (0.004) Batch 0.450 (0.485) Remain 31:58:27 loss: 1.4457 Lr: 0.00044
[2025-04-08 14:15:24,206 INFO misc.py line 113 3298914] Train: [2/100][475/2402] Data 0.003 (0.004) Batch 0.491 (0.485) Remain 31:58:30 loss: 1.4295 Lr: 0.00044
[2025-04-08 14:15:24,607 INFO misc.py line 113 3298914] Train: [2/100][476/2402] Data 0.003 (0.004) Batch 0.401 (0.485) Remain 31:57:47 loss: 1.4175 Lr: 0.00044
[2025-04-08 14:15:25,152 INFO misc.py line 113 3298914] Train: [2/100][477/2402] Data 0.004 (0.004) Batch 0.545 (0.485) Remain 31:58:17 loss: 1.3814 Lr: 0.00044
[2025-04-08 14:15:25,466 INFO misc.py line 113 3298914] Train: [2/100][478/2402] Data 0.003 (0.004) Batch 0.314 (0.485) Remain 31:56:51 loss: 1.3080 Lr: 0.00044
[2025-04-08 14:15:25,975 INFO misc.py line 113 3298914] Train: [2/100][479/2402] Data 0.003 (0.004) Batch 0.509 (0.485) Remain 31:57:03 loss: 1.4096 Lr: 0.00044
[2025-04-08 14:15:26,401 INFO misc.py line 113 3298914] Train: [2/100][480/2402] Data 0.003 (0.004) Batch 0.426 (0.485) Remain 31:56:33 loss: 1.2751 Lr: 0.00044
[2025-04-08 14:15:26,818 INFO misc.py line 113 3298914] Train: [2/100][481/2402] Data 0.004 (0.004) Batch 0.417 (0.484) Remain 31:55:59 loss: 1.5241 Lr: 0.00044
[2025-04-08 14:15:27,274 INFO misc.py line 113 3298914] Train: [2/100][482/2402] Data 0.003 (0.004) Batch 0.455 (0.484) Remain 31:55:44 loss: 1.8428 Lr: 0.00044
[2025-04-08 14:15:27,750 INFO misc.py line 113 3298914] Train: [2/100][483/2402] Data 0.003 (0.004) Batch 0.477 (0.484) Remain 31:55:40 loss: 1.5392 Lr: 0.00044
[2025-04-08 14:15:28,236 INFO misc.py line 113 3298914] Train: [2/100][484/2402] Data 0.004 (0.004) Batch 0.486 (0.484) Remain 31:55:40 loss: 1.1493 Lr: 0.00044
[2025-04-08 14:15:28,734 INFO misc.py line 113 3298914] Train: [2/100][485/2402] Data 0.003 (0.004) Batch 0.498 (0.484) Remain 31:55:46 loss: 1.2303 Lr: 0.00044
[2025-04-08 14:15:29,245 INFO misc.py line 113 3298914] Train: [2/100][486/2402] Data 0.003 (0.004) Batch 0.511 (0.484) Remain 31:55:58 loss: 1.3336 Lr: 0.00044
[2025-04-08 14:15:29,676 INFO misc.py line 113 3298914] Train: [2/100][487/2402] Data 0.003 (0.004) Batch 0.431 (0.484) Remain 31:55:32 loss: 1.3089 Lr: 0.00044
[2025-04-08 14:15:30,157 INFO misc.py line 113 3298914] Train: [2/100][488/2402] Data 0.004 (0.004) Batch 0.481 (0.484) Remain 31:55:30 loss: 1.4418 Lr: 0.00044
[2025-04-08 14:15:30,719 INFO misc.py line 113 3298914] Train: [2/100][489/2402] Data 0.004 (0.004) Batch 0.563 (0.484) Remain 31:56:08 loss: 1.0634 Lr: 0.00044
[2025-04-08 14:15:31,238 INFO misc.py line 113 3298914] Train: [2/100][490/2402] Data 0.003 (0.004) Batch 0.519 (0.485) Remain 31:56:24 loss: 1.4915 Lr: 0.00045
[2025-04-08 14:15:31,719 INFO misc.py line 113 3298914] Train: [2/100][491/2402] Data 0.003 (0.004) Batch 0.481 (0.485) Remain 31:56:21 loss: 1.3004 Lr: 0.00045
[2025-04-08 14:15:32,145 INFO misc.py line 113 3298914] Train: [2/100][492/2402] Data 0.004 (0.004) Batch 0.427 (0.484) Remain 31:55:53 loss: 1.1568 Lr: 0.00045
[2025-04-08 14:15:32,578 INFO misc.py line 113 3298914] Train: [2/100][493/2402] Data 0.003 (0.004) Batch 0.433 (0.484) Remain 31:55:27 loss: 1.0677 Lr: 0.00045
[2025-04-08 14:15:32,975 INFO misc.py line 113 3298914] Train: [2/100][494/2402] Data 0.004 (0.004) Batch 0.397 (0.484) Remain 31:54:45 loss: 1.3869 Lr: 0.00045
[2025-04-08 14:15:33,414 INFO misc.py line 113 3298914] Train: [2/100][495/2402] Data 0.004 (0.004) Batch 0.438 (0.484) Remain 31:54:22 loss: 1.4633 Lr: 0.00045
[2025-04-08 14:15:33,810 INFO misc.py line 113 3298914] Train: [2/100][496/2402] Data 0.004 (0.004) Batch 0.397 (0.484) Remain 31:53:39 loss: 1.3280 Lr: 0.00045
[2025-04-08 14:15:34,381 INFO misc.py line 113 3298914] Train: [2/100][497/2402] Data 0.004 (0.004) Batch 0.570 (0.484) Remain 31:54:21 loss: 1.0353 Lr: 0.00045
[2025-04-08 14:15:35,018 INFO misc.py line 113 3298914] Train: [2/100][498/2402] Data 0.004 (0.004) Batch 0.638 (0.484) Remain 31:55:34 loss: 1.2473 Lr: 0.00045
[2025-04-08 14:15:35,442 INFO misc.py line 113 3298914] Train: [2/100][499/2402] Data 0.004 (0.004) Batch 0.423 (0.484) Remain 31:55:04 loss: 1.4467 Lr: 0.00045
[2025-04-08 14:15:35,833 INFO misc.py line 113 3298914] Train: [2/100][500/2402] Data 0.004 (0.004) Batch 0.392 (0.484) Remain 31:54:19 loss: 1.3288 Lr: 0.00045
[2025-04-08 14:15:36,305 INFO misc.py line 113 3298914] Train: [2/100][501/2402] Data 0.003 (0.004) Batch 0.472 (0.484) Remain 31:54:13 loss: 1.2303 Lr: 0.00045
[2025-04-08 14:15:36,756 INFO misc.py line 113 3298914] Train: [2/100][502/2402] Data 0.004 (0.004) Batch 0.451 (0.484) Remain 31:53:57 loss: 1.5382 Lr: 0.00045
[2025-04-08 14:15:37,251 INFO misc.py line 113 3298914] Train: [2/100][503/2402] Data 0.004 (0.004) Batch 0.495 (0.484) Remain 31:54:01 loss: 1.3313 Lr: 0.00045
[2025-04-08 14:15:37,722 INFO misc.py line 113 3298914] Train: [2/100][504/2402] Data 0.003 (0.004) Batch 0.472 (0.484) Remain 31:53:55 loss: 1.5599 Lr: 0.00045
[2025-04-08 14:15:38,181 INFO misc.py line 113 3298914] Train: [2/100][505/2402] Data 0.003 (0.004) Batch 0.459 (0.484) Remain 31:53:43 loss: 1.2837 Lr: 0.00045
[2025-04-08 14:15:38,719 INFO misc.py line 113 3298914] Train: [2/100][506/2402] Data 0.004 (0.004) Batch 0.538 (0.484) Remain 31:54:08 loss: 1.3916 Lr: 0.00045
[2025-04-08 14:15:39,196 INFO misc.py line 113 3298914] Train: [2/100][507/2402] Data 0.004 (0.004) Batch 0.477 (0.484) Remain 31:54:04 loss: 1.5499 Lr: 0.00045
[2025-04-08 14:15:39,756 INFO misc.py line 113 3298914] Train: [2/100][508/2402] Data 0.004 (0.004) Batch 0.560 (0.484) Remain 31:54:39 loss: 1.6389 Lr: 0.00045
[2025-04-08 14:15:40,204 INFO misc.py line 113 3298914] Train: [2/100][509/2402] Data 0.003 (0.004) Batch 0.447 (0.484) Remain 31:54:21 loss: 1.3894 Lr: 0.00045
[2025-04-08 14:15:40,766 INFO misc.py line 113 3298914] Train: [2/100][510/2402] Data 0.004 (0.004) Batch 0.562 (0.484) Remain 31:54:58 loss: 1.4003 Lr: 0.00045
[2025-04-08 14:15:41,169 INFO misc.py line 113 3298914] Train: [2/100][511/2402] Data 0.004 (0.004) Batch 0.403 (0.484) Remain 31:54:19 loss: 1.4343 Lr: 0.00045
[2025-04-08 14:15:41,732 INFO misc.py line 113 3298914] Train: [2/100][512/2402] Data 0.004 (0.004) Batch 0.562 (0.484) Remain 31:54:55 loss: 1.3697 Lr: 0.00045
[2025-04-08 14:15:42,263 INFO misc.py line 113 3298914] Train: [2/100][513/2402] Data 0.004 (0.004) Batch 0.531 (0.484) Remain 31:55:17 loss: 1.5511 Lr: 0.00045
[2025-04-08 14:15:42,794 INFO misc.py line 113 3298914] Train: [2/100][514/2402] Data 0.004 (0.004) Batch 0.532 (0.484) Remain 31:55:38 loss: 1.3964 Lr: 0.00045
[2025-04-08 14:15:43,338 INFO misc.py line 113 3298914] Train: [2/100][515/2402] Data 0.004 (0.004) Batch 0.544 (0.485) Remain 31:56:05 loss: 1.2519 Lr: 0.00045
[2025-04-08 14:15:43,836 INFO misc.py line 113 3298914] Train: [2/100][516/2402] Data 0.004 (0.004) Batch 0.498 (0.485) Remain 31:56:11 loss: 1.4170 Lr: 0.00045
[2025-04-08 14:15:44,284 INFO misc.py line 113 3298914] Train: [2/100][517/2402] Data 0.003 (0.004) Batch 0.447 (0.484) Remain 31:55:54 loss: 1.4913 Lr: 0.00045
[2025-04-08 14:15:44,768 INFO misc.py line 113 3298914] Train: [2/100][518/2402] Data 0.003 (0.004) Batch 0.484 (0.484) Remain 31:55:53 loss: 1.3126 Lr: 0.00045
[2025-04-08 14:15:45,219 INFO misc.py line 113 3298914] Train: [2/100][519/2402] Data 0.004 (0.004) Batch 0.451 (0.484) Remain 31:55:37 loss: 1.3763 Lr: 0.00045
[2025-04-08 14:15:45,695 INFO misc.py line 113 3298914] Train: [2/100][520/2402] Data 0.003 (0.004) Batch 0.476 (0.484) Remain 31:55:33 loss: 1.3016 Lr: 0.00045
[2025-04-08 14:15:46,056 INFO misc.py line 113 3298914] Train: [2/100][521/2402] Data 0.004 (0.004) Batch 0.360 (0.484) Remain 31:54:35 loss: 1.2184 Lr: 0.00045
[2025-04-08 14:15:46,539 INFO misc.py line 113 3298914] Train: [2/100][522/2402] Data 0.004 (0.004) Batch 0.483 (0.484) Remain 31:54:35 loss: 1.0660 Lr: 0.00045
[2025-04-08 14:15:47,014 INFO misc.py line 113 3298914] Train: [2/100][523/2402] Data 0.004 (0.004) Batch 0.475 (0.484) Remain 31:54:30 loss: 1.1659 Lr: 0.00045
[2025-04-08 14:15:47,539 INFO misc.py line 113 3298914] Train: [2/100][524/2402] Data 0.004 (0.004) Batch 0.525 (0.484) Remain 31:54:48 loss: 1.2383 Lr: 0.00045
[2025-04-08 14:15:48,091 INFO misc.py line 113 3298914] Train: [2/100][525/2402] Data 0.004 (0.004) Batch 0.552 (0.484) Remain 31:55:18 loss: 1.3482 Lr: 0.00045
[2025-04-08 14:15:48,465 INFO misc.py line 113 3298914] Train: [2/100][526/2402] Data 0.004 (0.004) Batch 0.374 (0.484) Remain 31:54:28 loss: 1.3313 Lr: 0.00045
[2025-04-08 14:15:48,946 INFO misc.py line 113 3298914] Train: [2/100][527/2402] Data 0.003 (0.004) Batch 0.480 (0.484) Remain 31:54:26 loss: 1.5056 Lr: 0.00045
[2025-04-08 14:15:49,434 INFO misc.py line 113 3298914] Train: [2/100][528/2402] Data 0.003 (0.004) Batch 0.488 (0.484) Remain 31:54:27 loss: 1.5914 Lr: 0.00045
[2025-04-08 14:15:49,810 INFO misc.py line 113 3298914] Train: [2/100][529/2402] Data 0.004 (0.004) Batch 0.376 (0.484) Remain 31:53:38 loss: 1.3235 Lr: 0.00045
[2025-04-08 14:15:50,221 INFO misc.py line 113 3298914] Train: [2/100][530/2402] Data 0.003 (0.004) Batch 0.412 (0.484) Remain 31:53:05 loss: 1.4881 Lr: 0.00045
[2025-04-08 14:15:50,680 INFO misc.py line 113 3298914] Train: [2/100][531/2402] Data 0.004 (0.004) Batch 0.457 (0.484) Remain 31:52:53 loss: 1.2262 Lr: 0.00045
[2025-04-08 14:15:51,234 INFO misc.py line 113 3298914] Train: [2/100][532/2402] Data 0.005 (0.004) Batch 0.556 (0.484) Remain 31:53:24 loss: 1.3242 Lr: 0.00045
[2025-04-08 14:15:51,671 INFO misc.py line 113 3298914] Train: [2/100][533/2402] Data 0.003 (0.004) Batch 0.436 (0.484) Remain 31:53:03 loss: 0.8117 Lr: 0.00045
[2025-04-08 14:15:52,144 INFO misc.py line 113 3298914] Train: [2/100][534/2402] Data 0.004 (0.004) Batch 0.474 (0.484) Remain 31:52:58 loss: 1.6581 Lr: 0.00045
[2025-04-08 14:15:52,685 INFO misc.py line 113 3298914] Train: [2/100][535/2402] Data 0.004 (0.004) Batch 0.541 (0.484) Remain 31:53:23 loss: 1.2833 Lr: 0.00045
[2025-04-08 14:15:53,196 INFO misc.py line 113 3298914] Train: [2/100][536/2402] Data 0.004 (0.004) Batch 0.511 (0.484) Remain 31:53:34 loss: 1.2323 Lr: 0.00045
[2025-04-08 14:15:53,639 INFO misc.py line 113 3298914] Train: [2/100][537/2402] Data 0.004 (0.004) Batch 0.443 (0.484) Remain 31:53:15 loss: 1.2813 Lr: 0.00045
[2025-04-08 14:15:54,094 INFO misc.py line 113 3298914] Train: [2/100][538/2402] Data 0.004 (0.004) Batch 0.455 (0.484) Remain 31:53:02 loss: 1.0550 Lr: 0.00045
[2025-04-08 14:15:54,635 INFO misc.py line 113 3298914] Train: [2/100][539/2402] Data 0.004 (0.004) Batch 0.541 (0.484) Remain 31:53:27 loss: 1.3496 Lr: 0.00045
[2025-04-08 14:15:55,122 INFO misc.py line 113 3298914] Train: [2/100][540/2402] Data 0.004 (0.004) Batch 0.486 (0.484) Remain 31:53:28 loss: 1.2896 Lr: 0.00045
[2025-04-08 14:15:55,575 INFO misc.py line 113 3298914] Train: [2/100][541/2402] Data 0.004 (0.004) Batch 0.453 (0.484) Remain 31:53:14 loss: 1.6012 Lr: 0.00045
[2025-04-08 14:15:56,159 INFO misc.py line 113 3298914] Train: [2/100][542/2402] Data 0.004 (0.004) Batch 0.584 (0.484) Remain 31:53:57 loss: 1.3588 Lr: 0.00045
[2025-04-08 14:15:56,559 INFO misc.py line 113 3298914] Train: [2/100][543/2402] Data 0.003 (0.004) Batch 0.400 (0.484) Remain 31:53:20 loss: 1.5246 Lr: 0.00045
[2025-04-08 14:15:56,950 INFO misc.py line 113 3298914] Train: [2/100][544/2402] Data 0.004 (0.004) Batch 0.391 (0.484) Remain 31:52:39 loss: 1.5701 Lr: 0.00045
[2025-04-08 14:15:57,303 INFO misc.py line 113 3298914] Train: [2/100][545/2402] Data 0.004 (0.004) Batch 0.353 (0.483) Remain 31:51:41 loss: 1.0539 Lr: 0.00045
[2025-04-08 14:15:57,767 INFO misc.py line 113 3298914] Train: [2/100][546/2402] Data 0.003 (0.004) Batch 0.464 (0.483) Remain 31:51:32 loss: 1.6486 Lr: 0.00045
[2025-04-08 14:15:58,303 INFO misc.py line 113 3298914] Train: [2/100][547/2402] Data 0.004 (0.004) Batch 0.536 (0.484) Remain 31:51:54 loss: 1.4964 Lr: 0.00045
[2025-04-08 14:15:58,776 INFO misc.py line 113 3298914] Train: [2/100][548/2402] Data 0.003 (0.004) Batch 0.473 (0.483) Remain 31:51:49 loss: 1.4604 Lr: 0.00045
[2025-04-08 14:15:59,198 INFO misc.py line 113 3298914] Train: [2/100][549/2402] Data 0.004 (0.004) Batch 0.422 (0.483) Remain 31:51:22 loss: 1.2556 Lr: 0.00045
[2025-04-08 14:15:59,607 INFO misc.py line 113 3298914] Train: [2/100][550/2402] Data 0.003 (0.004) Batch 0.409 (0.483) Remain 31:50:49 loss: 1.4441 Lr: 0.00045
[2025-04-08 14:16:00,174 INFO misc.py line 113 3298914] Train: [2/100][551/2402] Data 0.004 (0.004) Batch 0.568 (0.483) Remain 31:51:25 loss: 0.9463 Lr: 0.00045
[2025-04-08 14:16:00,641 INFO misc.py line 113 3298914] Train: [2/100][552/2402] Data 0.003 (0.004) Batch 0.467 (0.483) Remain 31:51:18 loss: 1.2968 Lr: 0.00046
[2025-04-08 14:16:01,115 INFO misc.py line 113 3298914] Train: [2/100][553/2402] Data 0.004 (0.004) Batch 0.474 (0.483) Remain 31:51:13 loss: 1.2655 Lr: 0.00046
[2025-04-08 14:16:01,604 INFO misc.py line 113 3298914] Train: [2/100][554/2402] Data 0.004 (0.004) Batch 0.488 (0.483) Remain 31:51:15 loss: 1.5054 Lr: 0.00046
[2025-04-08 14:16:02,100 INFO misc.py line 113 3298914] Train: [2/100][555/2402] Data 0.003 (0.004) Batch 0.497 (0.483) Remain 31:51:20 loss: 1.5087 Lr: 0.00046
[2025-04-08 14:16:02,577 INFO misc.py line 113 3298914] Train: [2/100][556/2402] Data 0.003 (0.004) Batch 0.477 (0.483) Remain 31:51:17 loss: 1.3694 Lr: 0.00046
[2025-04-08 14:16:03,092 INFO misc.py line 113 3298914] Train: [2/100][557/2402] Data 0.004 (0.004) Batch 0.515 (0.483) Remain 31:51:30 loss: 1.6098 Lr: 0.00046
[2025-04-08 14:16:03,628 INFO misc.py line 113 3298914] Train: [2/100][558/2402] Data 0.003 (0.004) Batch 0.535 (0.484) Remain 31:51:52 loss: 1.9401 Lr: 0.00046
[2025-04-08 14:16:04,155 INFO misc.py line 113 3298914] Train: [2/100][559/2402] Data 0.004 (0.004) Batch 0.527 (0.484) Remain 31:52:10 loss: 1.5020 Lr: 0.00046
[2025-04-08 14:16:04,558 INFO misc.py line 113 3298914] Train: [2/100][560/2402] Data 0.004 (0.004) Batch 0.403 (0.483) Remain 31:51:35 loss: 1.4186 Lr: 0.00046
[2025-04-08 14:16:05,094 INFO misc.py line 113 3298914] Train: [2/100][561/2402] Data 0.003 (0.004) Batch 0.536 (0.484) Remain 31:51:57 loss: 1.3929 Lr: 0.00046
[2025-04-08 14:16:05,599 INFO misc.py line 113 3298914] Train: [2/100][562/2402] Data 0.003 (0.004) Batch 0.505 (0.484) Remain 31:52:05 loss: 1.4247 Lr: 0.00046
[2025-04-08 14:16:06,044 INFO misc.py line 113 3298914] Train: [2/100][563/2402] Data 0.004 (0.004) Batch 0.446 (0.484) Remain 31:51:49 loss: 1.4351 Lr: 0.00046
[2025-04-08 14:16:06,560 INFO misc.py line 113 3298914] Train: [2/100][564/2402] Data 0.004 (0.004) Batch 0.516 (0.484) Remain 31:52:02 loss: 1.4190 Lr: 0.00046
[2025-04-08 14:16:06,998 INFO misc.py line 113 3298914] Train: [2/100][565/2402] Data 0.004 (0.004) Batch 0.437 (0.484) Remain 31:51:42 loss: 1.1814 Lr: 0.00046
[2025-04-08 14:16:07,371 INFO misc.py line 113 3298914] Train: [2/100][566/2402] Data 0.003 (0.004) Batch 0.373 (0.483) Remain 31:50:55 loss: 1.2322 Lr: 0.00046
[2025-04-08 14:16:07,904 INFO misc.py line 113 3298914] Train: [2/100][567/2402] Data 0.004 (0.004) Batch 0.532 (0.483) Remain 31:51:15 loss: 1.2367 Lr: 0.00046
[2025-04-08 14:16:08,446 INFO misc.py line 113 3298914] Train: [2/100][568/2402] Data 0.004 (0.004) Batch 0.543 (0.483) Remain 31:51:40 loss: 1.1887 Lr: 0.00046
[2025-04-08 14:16:08,924 INFO misc.py line 113 3298914] Train: [2/100][569/2402] Data 0.004 (0.004) Batch 0.477 (0.483) Remain 31:51:37 loss: 1.4119 Lr: 0.00046
[2025-04-08 14:16:09,354 INFO misc.py line 113 3298914] Train: [2/100][570/2402] Data 0.004 (0.004) Batch 0.430 (0.483) Remain 31:51:14 loss: 1.6073 Lr: 0.00046
[2025-04-08 14:16:09,876 INFO misc.py line 113 3298914] Train: [2/100][571/2402] Data 0.004 (0.004) Batch 0.522 (0.483) Remain 31:51:30 loss: 1.1526 Lr: 0.00046
[2025-04-08 14:16:10,287 INFO misc.py line 113 3298914] Train: [2/100][572/2402] Data 0.004 (0.004) Batch 0.412 (0.483) Remain 31:50:59 loss: 1.1662 Lr: 0.00046
[2025-04-08 14:16:10,717 INFO misc.py line 113 3298914] Train: [2/100][573/2402] Data 0.004 (0.004) Batch 0.430 (0.483) Remain 31:50:36 loss: 1.6636 Lr: 0.00046
[2025-04-08 14:16:11,199 INFO misc.py line 113 3298914] Train: [2/100][574/2402] Data 0.003 (0.004) Batch 0.482 (0.483) Remain 31:50:35 loss: 1.4079 Lr: 0.00046
[2025-04-08 14:16:11,627 INFO misc.py line 113 3298914] Train: [2/100][575/2402] Data 0.004 (0.004) Batch 0.427 (0.483) Remain 31:50:12 loss: 1.7790 Lr: 0.00046
[2025-04-08 14:16:12,213 INFO misc.py line 113 3298914] Train: [2/100][576/2402] Data 0.004 (0.004) Batch 0.586 (0.483) Remain 31:50:54 loss: 1.3458 Lr: 0.00046
[2025-04-08 14:16:12,676 INFO misc.py line 113 3298914] Train: [2/100][577/2402] Data 0.004 (0.004) Batch 0.463 (0.483) Remain 31:50:45 loss: 1.7371 Lr: 0.00046
[2025-04-08 14:16:13,153 INFO misc.py line 113 3298914] Train: [2/100][578/2402] Data 0.004 (0.004) Batch 0.477 (0.483) Remain 31:50:42 loss: 1.2461 Lr: 0.00046
[2025-04-08 14:16:13,536 INFO misc.py line 113 3298914] Train: [2/100][579/2402] Data 0.004 (0.004) Batch 0.383 (0.483) Remain 31:50:00 loss: 1.6386 Lr: 0.00046
[2025-04-08 14:16:13,980 INFO misc.py line 113 3298914] Train: [2/100][580/2402] Data 0.004 (0.004) Batch 0.444 (0.483) Remain 31:49:44 loss: 1.2935 Lr: 0.00046
[2025-04-08 14:16:14,519 INFO misc.py line 113 3298914] Train: [2/100][581/2402] Data 0.004 (0.004) Batch 0.539 (0.483) Remain 31:50:06 loss: 1.4815 Lr: 0.00046
[2025-04-08 14:16:15,040 INFO misc.py line 113 3298914] Train: [2/100][582/2402] Data 0.003 (0.004) Batch 0.521 (0.483) Remain 31:50:21 loss: 1.6272 Lr: 0.00046
[2025-04-08 14:16:15,552 INFO misc.py line 113 3298914] Train: [2/100][583/2402] Data 0.004 (0.004) Batch 0.512 (0.483) Remain 31:50:33 loss: 0.6513 Lr: 0.00046
[2025-04-08 14:16:16,162 INFO misc.py line 113 3298914] Train: [2/100][584/2402] Data 0.004 (0.004) Batch 0.610 (0.483) Remain 31:51:24 loss: 1.5817 Lr: 0.00046
[2025-04-08 14:16:16,716 INFO misc.py line 113 3298914] Train: [2/100][585/2402] Data 0.004 (0.004) Batch 0.554 (0.484) Remain 31:51:52 loss: 1.1270 Lr: 0.00046
[2025-04-08 14:16:17,095 INFO misc.py line 113 3298914] Train: [2/100][586/2402] Data 0.004 (0.004) Batch 0.379 (0.483) Remain 31:51:09 loss: 1.2958 Lr: 0.00046
[2025-04-08 14:16:17,432 INFO misc.py line 113 3298914] Train: [2/100][587/2402] Data 0.003 (0.004) Batch 0.336 (0.483) Remain 31:50:09 loss: 1.5694 Lr: 0.00046
[2025-04-08 14:16:18,011 INFO misc.py line 113 3298914] Train: [2/100][588/2402] Data 0.004 (0.004) Batch 0.579 (0.483) Remain 31:50:47 loss: 1.4066 Lr: 0.00046
[2025-04-08 14:16:18,476 INFO misc.py line 113 3298914] Train: [2/100][589/2402] Data 0.004 (0.004) Batch 0.466 (0.483) Remain 31:50:40 loss: 1.2815 Lr: 0.00046
[2025-04-08 14:16:18,979 INFO misc.py line 113 3298914] Train: [2/100][590/2402] Data 0.003 (0.004) Batch 0.502 (0.483) Remain 31:50:47 loss: 1.3446 Lr: 0.00046
[2025-04-08 14:16:19,517 INFO misc.py line 113 3298914] Train: [2/100][591/2402] Data 0.004 (0.004) Batch 0.538 (0.483) Remain 31:51:08 loss: 1.3148 Lr: 0.00046
[2025-04-08 14:16:20,191 INFO misc.py line 113 3298914] Train: [2/100][592/2402] Data 0.004 (0.004) Batch 0.675 (0.484) Remain 31:52:25 loss: 1.1878 Lr: 0.00046
[2025-04-08 14:16:20,560 INFO misc.py line 113 3298914] Train: [2/100][593/2402] Data 0.004 (0.004) Batch 0.368 (0.484) Remain 31:51:38 loss: 1.3936 Lr: 0.00046
[2025-04-08 14:16:20,992 INFO misc.py line 113 3298914] Train: [2/100][594/2402] Data 0.004 (0.004) Batch 0.433 (0.483) Remain 31:51:17 loss: 1.3044 Lr: 0.00046
[2025-04-08 14:16:21,455 INFO misc.py line 113 3298914] Train: [2/100][595/2402] Data 0.003 (0.004) Batch 0.463 (0.483) Remain 31:51:09 loss: 1.2546 Lr: 0.00046
[2025-04-08 14:16:21,936 INFO misc.py line 113 3298914] Train: [2/100][596/2402] Data 0.004 (0.004) Batch 0.481 (0.483) Remain 31:51:07 loss: 1.2681 Lr: 0.00046
[2025-04-08 14:16:22,598 INFO misc.py line 113 3298914] Train: [2/100][597/2402] Data 0.004 (0.004) Batch 0.662 (0.484) Remain 31:52:18 loss: 1.3397 Lr: 0.00046
[2025-04-08 14:16:23,077 INFO misc.py line 113 3298914] Train: [2/100][598/2402] Data 0.004 (0.004) Batch 0.479 (0.484) Remain 31:52:15 loss: 1.3042 Lr: 0.00046
[2025-04-08 14:16:23,663 INFO misc.py line 113 3298914] Train: [2/100][599/2402] Data 0.004 (0.004) Batch 0.586 (0.484) Remain 31:52:56 loss: 1.4067 Lr: 0.00046
[2025-04-08 14:16:24,104 INFO misc.py line 113 3298914] Train: [2/100][600/2402] Data 0.004 (0.004) Batch 0.442 (0.484) Remain 31:52:38 loss: 1.1322 Lr: 0.00046
[2025-04-08 14:16:24,613 INFO misc.py line 113 3298914] Train: [2/100][601/2402] Data 0.003 (0.004) Batch 0.508 (0.484) Remain 31:52:48 loss: 1.2429 Lr: 0.00046
[2025-04-08 14:16:25,146 INFO misc.py line 113 3298914] Train: [2/100][602/2402] Data 0.004 (0.004) Batch 0.533 (0.484) Remain 31:53:07 loss: 1.4339 Lr: 0.00046
[2025-04-08 14:16:25,587 INFO misc.py line 113 3298914] Train: [2/100][603/2402] Data 0.004 (0.004) Batch 0.442 (0.484) Remain 31:52:49 loss: 1.7160 Lr: 0.00046
[2025-04-08 14:16:26,044 INFO misc.py line 113 3298914] Train: [2/100][604/2402] Data 0.003 (0.004) Batch 0.456 (0.484) Remain 31:52:38 loss: 1.5384 Lr: 0.00046
[2025-04-08 14:16:26,588 INFO misc.py line 113 3298914] Train: [2/100][605/2402] Data 0.004 (0.004) Batch 0.544 (0.484) Remain 31:53:01 loss: 1.3825 Lr: 0.00046
[2025-04-08 14:16:27,038 INFO misc.py line 113 3298914] Train: [2/100][606/2402] Data 0.004 (0.004) Batch 0.450 (0.484) Remain 31:52:48 loss: 1.5187 Lr: 0.00046
[2025-04-08 14:16:27,458 INFO misc.py line 113 3298914] Train: [2/100][607/2402] Data 0.004 (0.004) Batch 0.420 (0.484) Remain 31:52:22 loss: 1.1316 Lr: 0.00046
[2025-04-08 14:16:27,885 INFO misc.py line 113 3298914] Train: [2/100][608/2402] Data 0.003 (0.004) Batch 0.427 (0.484) Remain 31:51:59 loss: 1.2314 Lr: 0.00046
[2025-04-08 14:16:28,461 INFO misc.py line 113 3298914] Train: [2/100][609/2402] Data 0.004 (0.004) Batch 0.577 (0.484) Remain 31:52:35 loss: 1.6739 Lr: 0.00046
[2025-04-08 14:16:29,009 INFO misc.py line 113 3298914] Train: [2/100][610/2402] Data 0.004 (0.004) Batch 0.548 (0.484) Remain 31:52:59 loss: 1.5911 Lr: 0.00046
[2025-04-08 14:16:29,572 INFO misc.py line 113 3298914] Train: [2/100][611/2402] Data 0.004 (0.004) Batch 0.563 (0.484) Remain 31:53:30 loss: 1.4326 Lr: 0.00046
[2025-04-08 14:16:30,088 INFO misc.py line 113 3298914] Train: [2/100][612/2402] Data 0.004 (0.004) Batch 0.516 (0.484) Remain 31:53:42 loss: 1.4313 Lr: 0.00047
[2025-04-08 14:16:30,655 INFO misc.py line 113 3298914] Train: [2/100][613/2402] Data 0.003 (0.004) Batch 0.567 (0.484) Remain 31:54:14 loss: 1.1581 Lr: 0.00047
[2025-04-08 14:16:31,091 INFO misc.py line 113 3298914] Train: [2/100][614/2402] Data 0.003 (0.004) Batch 0.436 (0.484) Remain 31:53:54 loss: 1.4865 Lr: 0.00047
[2025-04-08 14:16:31,568 INFO misc.py line 113 3298914] Train: [2/100][615/2402] Data 0.004 (0.004) Batch 0.478 (0.484) Remain 31:53:51 loss: 1.4621 Lr: 0.00047
[2025-04-08 14:16:32,043 INFO misc.py line 113 3298914] Train: [2/100][616/2402] Data 0.004 (0.004) Batch 0.474 (0.484) Remain 31:53:47 loss: 1.1753 Lr: 0.00047
[2025-04-08 14:16:32,572 INFO misc.py line 113 3298914] Train: [2/100][617/2402] Data 0.003 (0.004) Batch 0.529 (0.484) Remain 31:54:04 loss: 1.4580 Lr: 0.00047
[2025-04-08 14:16:32,920 INFO misc.py line 113 3298914] Train: [2/100][618/2402] Data 0.004 (0.004) Batch 0.347 (0.484) Remain 31:53:11 loss: 1.0064 Lr: 0.00047
[2025-04-08 14:16:33,364 INFO misc.py line 113 3298914] Train: [2/100][619/2402] Data 0.004 (0.004) Batch 0.445 (0.484) Remain 31:52:55 loss: 1.0966 Lr: 0.00047
[2025-04-08 14:16:33,840 INFO misc.py line 113 3298914] Train: [2/100][620/2402] Data 0.003 (0.004) Batch 0.476 (0.484) Remain 31:52:52 loss: 1.5192 Lr: 0.00047
[2025-04-08 14:16:34,311 INFO misc.py line 113 3298914] Train: [2/100][621/2402] Data 0.003 (0.004) Batch 0.471 (0.484) Remain 31:52:46 loss: 1.5355 Lr: 0.00047
[2025-04-08 14:16:34,793 INFO misc.py line 113 3298914] Train: [2/100][622/2402] Data 0.004 (0.004) Batch 0.482 (0.484) Remain 31:52:45 loss: 1.1009 Lr: 0.00047
[2025-04-08 14:16:35,281 INFO misc.py line 113 3298914] Train: [2/100][623/2402] Data 0.004 (0.004) Batch 0.489 (0.484) Remain 31:52:46 loss: 1.6240 Lr: 0.00047
[2025-04-08 14:16:35,769 INFO misc.py line 113 3298914] Train: [2/100][624/2402] Data 0.004 (0.004) Batch 0.487 (0.484) Remain 31:52:47 loss: 1.0510 Lr: 0.00047
[2025-04-08 14:16:36,215 INFO misc.py line 113 3298914] Train: [2/100][625/2402] Data 0.004 (0.004) Batch 0.446 (0.484) Remain 31:52:32 loss: 1.5617 Lr: 0.00047
[2025-04-08 14:16:36,619 INFO misc.py line 113 3298914] Train: [2/100][626/2402] Data 0.004 (0.004) Batch 0.404 (0.484) Remain 31:52:01 loss: 1.2241 Lr: 0.00047
[2025-04-08 14:16:37,091 INFO misc.py line 113 3298914] Train: [2/100][627/2402] Data 0.004 (0.004) Batch 0.472 (0.484) Remain 31:51:56 loss: 1.3433 Lr: 0.00047
[2025-04-08 14:16:37,656 INFO misc.py line 113 3298914] Train: [2/100][628/2402] Data 0.004 (0.004) Batch 0.565 (0.484) Remain 31:52:27 loss: 1.3087 Lr: 0.00047
[2025-04-08 14:16:38,100 INFO misc.py line 113 3298914] Train: [2/100][629/2402] Data 0.004 (0.004) Batch 0.444 (0.484) Remain 31:52:11 loss: 1.4830 Lr: 0.00047
[2025-04-08 14:16:38,645 INFO misc.py line 113 3298914] Train: [2/100][630/2402] Data 0.004 (0.004) Batch 0.545 (0.484) Remain 31:52:34 loss: 1.3877 Lr: 0.00047
[2025-04-08 14:16:39,067 INFO misc.py line 113 3298914] Train: [2/100][631/2402] Data 0.004 (0.004) Batch 0.422 (0.484) Remain 31:52:10 loss: 1.4058 Lr: 0.00047
[2025-04-08 14:16:39,549 INFO misc.py line 113 3298914] Train: [2/100][632/2402] Data 0.003 (0.004) Batch 0.481 (0.484) Remain 31:52:09 loss: 0.8404 Lr: 0.00047
[2025-04-08 14:16:39,936 INFO misc.py line 113 3298914] Train: [2/100][633/2402] Data 0.004 (0.004) Batch 0.387 (0.484) Remain 31:51:32 loss: 1.3718 Lr: 0.00047
[2025-04-08 14:16:40,427 INFO misc.py line 113 3298914] Train: [2/100][634/2402] Data 0.004 (0.004) Batch 0.491 (0.484) Remain 31:51:34 loss: 1.3691 Lr: 0.00047
[2025-04-08 14:16:40,863 INFO misc.py line 113 3298914] Train: [2/100][635/2402] Data 0.004 (0.004) Batch 0.436 (0.484) Remain 31:51:16 loss: 1.2416 Lr: 0.00047
[2025-04-08 14:16:41,416 INFO misc.py line 113 3298914] Train: [2/100][636/2402] Data 0.004 (0.004) Batch 0.554 (0.484) Remain 31:51:41 loss: 1.6963 Lr: 0.00047
[2025-04-08 14:16:41,914 INFO misc.py line 113 3298914] Train: [2/100][637/2402] Data 0.003 (0.004) Batch 0.498 (0.484) Remain 31:51:46 loss: 1.2285 Lr: 0.00047
[2025-04-08 14:16:42,244 INFO misc.py line 113 3298914] Train: [2/100][638/2402] Data 0.004 (0.004) Batch 0.330 (0.483) Remain 31:50:48 loss: 1.2232 Lr: 0.00047
[2025-04-08 14:16:42,748 INFO misc.py line 113 3298914] Train: [2/100][639/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:50:56 loss: 1.5129 Lr: 0.00047
[2025-04-08 14:16:43,216 INFO misc.py line 113 3298914] Train: [2/100][640/2402] Data 0.004 (0.004) Batch 0.468 (0.483) Remain 31:50:49 loss: 0.9491 Lr: 0.00047
[2025-04-08 14:16:43,750 INFO misc.py line 113 3298914] Train: [2/100][641/2402] Data 0.004 (0.004) Batch 0.534 (0.484) Remain 31:51:08 loss: 1.6867 Lr: 0.00047
[2025-04-08 14:16:44,213 INFO misc.py line 113 3298914] Train: [2/100][642/2402] Data 0.004 (0.004) Batch 0.462 (0.483) Remain 31:50:59 loss: 1.6348 Lr: 0.00047
[2025-04-08 14:16:44,625 INFO misc.py line 113 3298914] Train: [2/100][643/2402] Data 0.004 (0.004) Batch 0.412 (0.483) Remain 31:50:33 loss: 1.2359 Lr: 0.00047
[2025-04-08 14:16:45,076 INFO misc.py line 113 3298914] Train: [2/100][644/2402] Data 0.004 (0.004) Batch 0.451 (0.483) Remain 31:50:20 loss: 1.0390 Lr: 0.00047
[2025-04-08 14:16:45,434 INFO misc.py line 113 3298914] Train: [2/100][645/2402] Data 0.004 (0.004) Batch 0.358 (0.483) Remain 31:49:33 loss: 1.1699 Lr: 0.00047
[2025-04-08 14:16:45,989 INFO misc.py line 113 3298914] Train: [2/100][646/2402] Data 0.004 (0.004) Batch 0.555 (0.483) Remain 31:49:59 loss: 1.3497 Lr: 0.00047
[2025-04-08 14:16:46,419 INFO misc.py line 113 3298914] Train: [2/100][647/2402] Data 0.004 (0.004) Batch 0.429 (0.483) Remain 31:49:39 loss: 1.0984 Lr: 0.00047
[2025-04-08 14:16:46,881 INFO misc.py line 113 3298914] Train: [2/100][648/2402] Data 0.003 (0.004) Batch 0.463 (0.483) Remain 31:49:31 loss: 1.3844 Lr: 0.00047
[2025-04-08 14:16:47,323 INFO misc.py line 113 3298914] Train: [2/100][649/2402] Data 0.004 (0.004) Batch 0.442 (0.483) Remain 31:49:15 loss: 1.3244 Lr: 0.00047
[2025-04-08 14:16:47,828 INFO misc.py line 113 3298914] Train: [2/100][650/2402] Data 0.003 (0.004) Batch 0.504 (0.483) Remain 31:49:23 loss: 1.6173 Lr: 0.00047
[2025-04-08 14:16:48,537 INFO misc.py line 113 3298914] Train: [2/100][651/2402] Data 0.004 (0.004) Batch 0.709 (0.483) Remain 31:50:45 loss: 1.5656 Lr: 0.00047
[2025-04-08 14:16:49,038 INFO misc.py line 113 3298914] Train: [2/100][652/2402] Data 0.004 (0.004) Batch 0.502 (0.483) Remain 31:50:51 loss: 1.2930 Lr: 0.00047
[2025-04-08 14:16:49,439 INFO misc.py line 113 3298914] Train: [2/100][653/2402] Data 0.003 (0.004) Batch 0.400 (0.483) Remain 31:50:20 loss: 1.0109 Lr: 0.00047
[2025-04-08 14:16:49,897 INFO misc.py line 113 3298914] Train: [2/100][654/2402] Data 0.004 (0.004) Batch 0.459 (0.483) Remain 31:50:11 loss: 1.2807 Lr: 0.00047
[2025-04-08 14:16:50,383 INFO misc.py line 113 3298914] Train: [2/100][655/2402] Data 0.004 (0.004) Batch 0.486 (0.483) Remain 31:50:11 loss: 1.1851 Lr: 0.00047
[2025-04-08 14:16:50,828 INFO misc.py line 113 3298914] Train: [2/100][656/2402] Data 0.004 (0.004) Batch 0.445 (0.483) Remain 31:49:57 loss: 1.1425 Lr: 0.00047
[2025-04-08 14:16:51,309 INFO misc.py line 113 3298914] Train: [2/100][657/2402] Data 0.004 (0.004) Batch 0.481 (0.483) Remain 31:49:55 loss: 1.5309 Lr: 0.00047
[2025-04-08 14:16:51,715 INFO misc.py line 113 3298914] Train: [2/100][658/2402] Data 0.004 (0.004) Batch 0.407 (0.483) Remain 31:49:27 loss: 1.8487 Lr: 0.00047
[2025-04-08 14:16:52,226 INFO misc.py line 113 3298914] Train: [2/100][659/2402] Data 0.003 (0.004) Batch 0.511 (0.483) Remain 31:49:37 loss: 1.5208 Lr: 0.00047
[2025-04-08 14:16:52,687 INFO misc.py line 113 3298914] Train: [2/100][660/2402] Data 0.004 (0.004) Batch 0.461 (0.483) Remain 31:49:28 loss: 1.2644 Lr: 0.00047
[2025-04-08 14:16:53,051 INFO misc.py line 113 3298914] Train: [2/100][661/2402] Data 0.004 (0.004) Batch 0.364 (0.483) Remain 31:48:45 loss: 1.3843 Lr: 0.00047
[2025-04-08 14:16:53,557 INFO misc.py line 113 3298914] Train: [2/100][662/2402] Data 0.004 (0.004) Batch 0.506 (0.483) Remain 31:48:53 loss: 0.9252 Lr: 0.00047
[2025-04-08 14:16:54,003 INFO misc.py line 113 3298914] Train: [2/100][663/2402] Data 0.004 (0.004) Batch 0.446 (0.483) Remain 31:48:39 loss: 1.8742 Lr: 0.00047
[2025-04-08 14:16:54,514 INFO misc.py line 113 3298914] Train: [2/100][664/2402] Data 0.004 (0.004) Batch 0.510 (0.483) Remain 31:48:48 loss: 1.2359 Lr: 0.00047
[2025-04-08 14:16:54,945 INFO misc.py line 113 3298914] Train: [2/100][665/2402] Data 0.003 (0.004) Batch 0.431 (0.483) Remain 31:48:29 loss: 1.3855 Lr: 0.00047
[2025-04-08 14:16:55,393 INFO misc.py line 113 3298914] Train: [2/100][666/2402] Data 0.004 (0.004) Batch 0.448 (0.483) Remain 31:48:16 loss: 1.9991 Lr: 0.00047
[2025-04-08 14:16:55,827 INFO misc.py line 113 3298914] Train: [2/100][667/2402] Data 0.003 (0.004) Batch 0.435 (0.483) Remain 31:47:59 loss: 1.3590 Lr: 0.00047
[2025-04-08 14:16:56,302 INFO misc.py line 113 3298914] Train: [2/100][668/2402] Data 0.003 (0.004) Batch 0.474 (0.483) Remain 31:47:55 loss: 1.1159 Lr: 0.00047
[2025-04-08 14:16:56,726 INFO misc.py line 113 3298914] Train: [2/100][669/2402] Data 0.004 (0.004) Batch 0.425 (0.483) Remain 31:47:34 loss: 1.2597 Lr: 0.00047
[2025-04-08 14:16:57,211 INFO misc.py line 113 3298914] Train: [2/100][670/2402] Data 0.004 (0.004) Batch 0.484 (0.483) Remain 31:47:34 loss: 1.8717 Lr: 0.00047
[2025-04-08 14:16:57,681 INFO misc.py line 113 3298914] Train: [2/100][671/2402] Data 0.004 (0.004) Batch 0.470 (0.483) Remain 31:47:29 loss: 1.5859 Lr: 0.00047
[2025-04-08 14:16:58,178 INFO misc.py line 113 3298914] Train: [2/100][672/2402] Data 0.004 (0.004) Batch 0.497 (0.483) Remain 31:47:34 loss: 1.1976 Lr: 0.00048
[2025-04-08 14:16:58,624 INFO misc.py line 113 3298914] Train: [2/100][673/2402] Data 0.003 (0.004) Batch 0.445 (0.483) Remain 31:47:20 loss: 1.2404 Lr: 0.00048
[2025-04-08 14:16:59,164 INFO misc.py line 113 3298914] Train: [2/100][674/2402] Data 0.004 (0.004) Batch 0.540 (0.483) Remain 31:47:40 loss: 1.4854 Lr: 0.00048
[2025-04-08 14:16:59,657 INFO misc.py line 113 3298914] Train: [2/100][675/2402] Data 0.003 (0.004) Batch 0.493 (0.483) Remain 31:47:43 loss: 1.3550 Lr: 0.00048
[2025-04-08 14:17:00,130 INFO misc.py line 113 3298914] Train: [2/100][676/2402] Data 0.004 (0.004) Batch 0.473 (0.483) Remain 31:47:39 loss: 1.2994 Lr: 0.00048
[2025-04-08 14:17:00,687 INFO misc.py line 113 3298914] Train: [2/100][677/2402] Data 0.004 (0.004) Batch 0.557 (0.483) Remain 31:48:05 loss: 1.4105 Lr: 0.00048
[2025-04-08 14:17:01,251 INFO misc.py line 113 3298914] Train: [2/100][678/2402] Data 0.003 (0.004) Batch 0.563 (0.483) Remain 31:48:33 loss: 1.4165 Lr: 0.00048
[2025-04-08 14:17:01,779 INFO misc.py line 113 3298914] Train: [2/100][679/2402] Data 0.004 (0.004) Batch 0.529 (0.483) Remain 31:48:48 loss: 1.5938 Lr: 0.00048
[2025-04-08 14:17:02,281 INFO misc.py line 113 3298914] Train: [2/100][680/2402] Data 0.003 (0.004) Batch 0.502 (0.483) Remain 31:48:54 loss: 1.3844 Lr: 0.00048
[2025-04-08 14:17:02,857 INFO misc.py line 113 3298914] Train: [2/100][681/2402] Data 0.004 (0.004) Batch 0.576 (0.483) Remain 31:49:26 loss: 1.1288 Lr: 0.00048
[2025-04-08 14:17:03,174 INFO misc.py line 113 3298914] Train: [2/100][682/2402] Data 0.004 (0.004) Batch 0.318 (0.483) Remain 31:48:28 loss: 1.0318 Lr: 0.00048
[2025-04-08 14:17:03,568 INFO misc.py line 113 3298914] Train: [2/100][683/2402] Data 0.003 (0.004) Batch 0.393 (0.483) Remain 31:47:56 loss: 1.4660 Lr: 0.00048
[2025-04-08 14:17:03,976 INFO misc.py line 113 3298914] Train: [2/100][684/2402] Data 0.004 (0.004) Batch 0.409 (0.483) Remain 31:47:30 loss: 1.0587 Lr: 0.00048
[2025-04-08 14:17:04,392 INFO misc.py line 113 3298914] Train: [2/100][685/2402] Data 0.003 (0.004) Batch 0.416 (0.483) Remain 31:47:07 loss: 1.5278 Lr: 0.00048
[2025-04-08 14:17:04,906 INFO misc.py line 113 3298914] Train: [2/100][686/2402] Data 0.003 (0.004) Batch 0.514 (0.483) Remain 31:47:17 loss: 1.4252 Lr: 0.00048
[2025-04-08 14:17:05,313 INFO misc.py line 113 3298914] Train: [2/100][687/2402] Data 0.003 (0.004) Batch 0.407 (0.483) Remain 31:46:50 loss: 1.2348 Lr: 0.00048
[2025-04-08 14:17:05,809 INFO misc.py line 113 3298914] Train: [2/100][688/2402] Data 0.004 (0.004) Batch 0.496 (0.483) Remain 31:46:54 loss: 1.5347 Lr: 0.00048
[2025-04-08 14:17:06,358 INFO misc.py line 113 3298914] Train: [2/100][689/2402] Data 0.004 (0.004) Batch 0.550 (0.483) Remain 31:47:17 loss: 1.3639 Lr: 0.00048
[2025-04-08 14:17:06,835 INFO misc.py line 113 3298914] Train: [2/100][690/2402] Data 0.004 (0.004) Batch 0.477 (0.483) Remain 31:47:14 loss: 1.8391 Lr: 0.00048
[2025-04-08 14:17:07,226 INFO misc.py line 113 3298914] Train: [2/100][691/2402] Data 0.004 (0.004) Batch 0.391 (0.482) Remain 31:46:42 loss: 1.2648 Lr: 0.00048
[2025-04-08 14:17:07,808 INFO misc.py line 113 3298914] Train: [2/100][692/2402] Data 0.004 (0.004) Batch 0.582 (0.483) Remain 31:47:16 loss: 1.2910 Lr: 0.00048
[2025-04-08 14:17:08,277 INFO misc.py line 113 3298914] Train: [2/100][693/2402] Data 0.004 (0.004) Batch 0.468 (0.483) Remain 31:47:11 loss: 1.7169 Lr: 0.00048
[2025-04-08 14:17:08,775 INFO misc.py line 113 3298914] Train: [2/100][694/2402] Data 0.004 (0.004) Batch 0.498 (0.483) Remain 31:47:15 loss: 0.9972 Lr: 0.00048
[2025-04-08 14:17:09,278 INFO misc.py line 113 3298914] Train: [2/100][695/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:47:22 loss: 1.2515 Lr: 0.00048
[2025-04-08 14:17:09,753 INFO misc.py line 113 3298914] Train: [2/100][696/2402] Data 0.011 (0.004) Batch 0.475 (0.483) Remain 31:47:19 loss: 1.4291 Lr: 0.00048
[2025-04-08 14:17:10,189 INFO misc.py line 113 3298914] Train: [2/100][697/2402] Data 0.003 (0.004) Batch 0.436 (0.483) Remain 31:47:03 loss: 1.3283 Lr: 0.00048
[2025-04-08 14:17:10,661 INFO misc.py line 113 3298914] Train: [2/100][698/2402] Data 0.004 (0.004) Batch 0.472 (0.483) Remain 31:46:59 loss: 1.2571 Lr: 0.00048
[2025-04-08 14:17:11,148 INFO misc.py line 113 3298914] Train: [2/100][699/2402] Data 0.004 (0.004) Batch 0.486 (0.483) Remain 31:46:59 loss: 1.2606 Lr: 0.00048
[2025-04-08 14:17:11,820 INFO misc.py line 113 3298914] Train: [2/100][700/2402] Data 0.004 (0.004) Batch 0.672 (0.483) Remain 31:48:03 loss: 1.2635 Lr: 0.00048
[2025-04-08 14:17:12,357 INFO misc.py line 113 3298914] Train: [2/100][701/2402] Data 0.003 (0.004) Batch 0.537 (0.483) Remain 31:48:21 loss: 1.4148 Lr: 0.00048
[2025-04-08 14:17:12,702 INFO misc.py line 113 3298914] Train: [2/100][702/2402] Data 0.004 (0.004) Batch 0.345 (0.483) Remain 31:47:34 loss: 1.4237 Lr: 0.00048
[2025-04-08 14:17:13,063 INFO misc.py line 113 3298914] Train: [2/100][703/2402] Data 0.004 (0.004) Batch 0.361 (0.483) Remain 31:46:52 loss: 1.3871 Lr: 0.00048
[2025-04-08 14:17:13,540 INFO misc.py line 113 3298914] Train: [2/100][704/2402] Data 0.004 (0.004) Batch 0.477 (0.483) Remain 31:46:50 loss: 1.3248 Lr: 0.00048
[2025-04-08 14:17:14,054 INFO misc.py line 113 3298914] Train: [2/100][705/2402] Data 0.004 (0.004) Batch 0.514 (0.483) Remain 31:47:00 loss: 1.6913 Lr: 0.00048
[2025-04-08 14:17:14,501 INFO misc.py line 113 3298914] Train: [2/100][706/2402] Data 0.004 (0.004) Batch 0.447 (0.483) Remain 31:46:48 loss: 1.0329 Lr: 0.00048
[2025-04-08 14:17:14,922 INFO misc.py line 113 3298914] Train: [2/100][707/2402] Data 0.004 (0.004) Batch 0.421 (0.482) Remain 31:46:27 loss: 1.5296 Lr: 0.00048
[2025-04-08 14:17:15,423 INFO misc.py line 113 3298914] Train: [2/100][708/2402] Data 0.003 (0.004) Batch 0.501 (0.482) Remain 31:46:32 loss: 1.6674 Lr: 0.00048
[2025-04-08 14:17:15,939 INFO misc.py line 113 3298914] Train: [2/100][709/2402] Data 0.004 (0.004) Batch 0.516 (0.483) Remain 31:46:43 loss: 1.1706 Lr: 0.00048
[2025-04-08 14:17:16,373 INFO misc.py line 113 3298914] Train: [2/100][710/2402] Data 0.004 (0.004) Batch 0.434 (0.482) Remain 31:46:26 loss: 0.8933 Lr: 0.00048
[2025-04-08 14:17:16,910 INFO misc.py line 113 3298914] Train: [2/100][711/2402] Data 0.004 (0.004) Batch 0.537 (0.483) Remain 31:46:44 loss: 1.4647 Lr: 0.00048
[2025-04-08 14:17:17,358 INFO misc.py line 113 3298914] Train: [2/100][712/2402] Data 0.004 (0.004) Batch 0.448 (0.482) Remain 31:46:32 loss: 1.3457 Lr: 0.00048
[2025-04-08 14:17:17,902 INFO misc.py line 113 3298914] Train: [2/100][713/2402] Data 0.004 (0.004) Batch 0.544 (0.483) Remain 31:46:52 loss: 1.0704 Lr: 0.00048
[2025-04-08 14:17:18,381 INFO misc.py line 113 3298914] Train: [2/100][714/2402] Data 0.004 (0.004) Batch 0.479 (0.483) Remain 31:46:50 loss: 1.1438 Lr: 0.00048
[2025-04-08 14:17:18,866 INFO misc.py line 113 3298914] Train: [2/100][715/2402] Data 0.004 (0.004) Batch 0.485 (0.483) Remain 31:46:51 loss: 1.2708 Lr: 0.00048
[2025-04-08 14:17:19,265 INFO misc.py line 113 3298914] Train: [2/100][716/2402] Data 0.004 (0.004) Batch 0.399 (0.482) Remain 31:46:22 loss: 0.9618 Lr: 0.00048
[2025-04-08 14:17:19,722 INFO misc.py line 113 3298914] Train: [2/100][717/2402] Data 0.004 (0.004) Batch 0.457 (0.482) Remain 31:46:13 loss: 1.4289 Lr: 0.00048
[2025-04-08 14:17:20,216 INFO misc.py line 113 3298914] Train: [2/100][718/2402] Data 0.003 (0.004) Batch 0.495 (0.482) Remain 31:46:17 loss: 1.3813 Lr: 0.00048
[2025-04-08 14:17:20,671 INFO misc.py line 113 3298914] Train: [2/100][719/2402] Data 0.003 (0.004) Batch 0.454 (0.482) Remain 31:46:07 loss: 1.3317 Lr: 0.00048
[2025-04-08 14:17:21,171 INFO misc.py line 113 3298914] Train: [2/100][720/2402] Data 0.004 (0.004) Batch 0.501 (0.482) Remain 31:46:13 loss: 1.2115 Lr: 0.00048
[2025-04-08 14:17:21,648 INFO misc.py line 113 3298914] Train: [2/100][721/2402] Data 0.004 (0.004) Batch 0.476 (0.482) Remain 31:46:10 loss: 1.7402 Lr: 0.00048
[2025-04-08 14:17:22,086 INFO misc.py line 113 3298914] Train: [2/100][722/2402] Data 0.004 (0.004) Batch 0.439 (0.482) Remain 31:45:55 loss: 1.6973 Lr: 0.00048
[2025-04-08 14:17:22,615 INFO misc.py line 113 3298914] Train: [2/100][723/2402] Data 0.003 (0.004) Batch 0.528 (0.482) Remain 31:46:10 loss: 1.1100 Lr: 0.00048
[2025-04-08 14:17:22,989 INFO misc.py line 113 3298914] Train: [2/100][724/2402] Data 0.004 (0.004) Batch 0.374 (0.482) Remain 31:45:34 loss: 1.7578 Lr: 0.00048
[2025-04-08 14:17:23,438 INFO misc.py line 113 3298914] Train: [2/100][725/2402] Data 0.004 (0.004) Batch 0.449 (0.482) Remain 31:45:22 loss: 1.2290 Lr: 0.00048
[2025-04-08 14:17:23,934 INFO misc.py line 113 3298914] Train: [2/100][726/2402] Data 0.004 (0.004) Batch 0.496 (0.482) Remain 31:45:26 loss: 0.9676 Lr: 0.00048
[2025-04-08 14:17:24,316 INFO misc.py line 113 3298914] Train: [2/100][727/2402] Data 0.004 (0.004) Batch 0.382 (0.482) Remain 31:44:53 loss: 1.2946 Lr: 0.00048
[2025-04-08 14:17:24,785 INFO misc.py line 113 3298914] Train: [2/100][728/2402] Data 0.004 (0.004) Batch 0.469 (0.482) Remain 31:44:48 loss: 1.3669 Lr: 0.00048
[2025-04-08 14:17:25,254 INFO misc.py line 113 3298914] Train: [2/100][729/2402] Data 0.004 (0.004) Batch 0.469 (0.482) Remain 31:44:44 loss: 0.8793 Lr: 0.00048
[2025-04-08 14:17:25,754 INFO misc.py line 113 3298914] Train: [2/100][730/2402] Data 0.004 (0.004) Batch 0.500 (0.482) Remain 31:44:49 loss: 1.1427 Lr: 0.00049
[2025-04-08 14:17:26,319 INFO misc.py line 113 3298914] Train: [2/100][731/2402] Data 0.004 (0.004) Batch 0.565 (0.482) Remain 31:45:16 loss: 1.5525 Lr: 0.00049
[2025-04-08 14:17:26,707 INFO misc.py line 113 3298914] Train: [2/100][732/2402] Data 0.004 (0.004) Batch 0.389 (0.482) Remain 31:44:45 loss: 1.3313 Lr: 0.00049
[2025-04-08 14:17:27,217 INFO misc.py line 113 3298914] Train: [2/100][733/2402] Data 0.003 (0.004) Batch 0.509 (0.482) Remain 31:44:53 loss: 1.0717 Lr: 0.00049
[2025-04-08 14:17:27,697 INFO misc.py line 113 3298914] Train: [2/100][734/2402] Data 0.003 (0.004) Batch 0.480 (0.482) Remain 31:44:52 loss: 1.2978 Lr: 0.00049
[2025-04-08 14:17:28,239 INFO misc.py line 113 3298914] Train: [2/100][735/2402] Data 0.004 (0.004) Batch 0.542 (0.482) Remain 31:45:11 loss: 1.4435 Lr: 0.00049
[2025-04-08 14:17:28,659 INFO misc.py line 113 3298914] Train: [2/100][736/2402] Data 0.004 (0.004) Batch 0.420 (0.482) Remain 31:44:50 loss: 1.1835 Lr: 0.00049
[2025-04-08 14:17:29,197 INFO misc.py line 113 3298914] Train: [2/100][737/2402] Data 0.003 (0.004) Batch 0.538 (0.482) Remain 31:45:08 loss: 1.5426 Lr: 0.00049
[2025-04-08 14:17:29,682 INFO misc.py line 113 3298914] Train: [2/100][738/2402] Data 0.004 (0.004) Batch 0.485 (0.482) Remain 31:45:08 loss: 1.0163 Lr: 0.00049
[2025-04-08 14:17:30,229 INFO misc.py line 113 3298914] Train: [2/100][739/2402] Data 0.004 (0.004) Batch 0.547 (0.482) Remain 31:45:29 loss: 1.6696 Lr: 0.00049
[2025-04-08 14:17:30,807 INFO misc.py line 113 3298914] Train: [2/100][740/2402] Data 0.004 (0.004) Batch 0.579 (0.482) Remain 31:45:59 loss: 1.5380 Lr: 0.00049
[2025-04-08 14:17:31,253 INFO misc.py line 113 3298914] Train: [2/100][741/2402] Data 0.004 (0.004) Batch 0.445 (0.482) Remain 31:45:47 loss: 1.2315 Lr: 0.00049
[2025-04-08 14:17:31,757 INFO misc.py line 113 3298914] Train: [2/100][742/2402] Data 0.003 (0.004) Batch 0.504 (0.482) Remain 31:45:53 loss: 1.3797 Lr: 0.00049
[2025-04-08 14:17:32,355 INFO misc.py line 113 3298914] Train: [2/100][743/2402] Data 0.003 (0.004) Batch 0.597 (0.483) Remain 31:46:30 loss: 1.2829 Lr: 0.00049
[2025-04-08 14:17:32,925 INFO misc.py line 113 3298914] Train: [2/100][744/2402] Data 0.003 (0.004) Batch 0.570 (0.483) Remain 31:46:57 loss: 1.2902 Lr: 0.00049
[2025-04-08 14:17:33,318 INFO misc.py line 113 3298914] Train: [2/100][745/2402] Data 0.004 (0.004) Batch 0.393 (0.483) Remain 31:46:28 loss: 1.2643 Lr: 0.00049
[2025-04-08 14:17:33,786 INFO misc.py line 113 3298914] Train: [2/100][746/2402] Data 0.004 (0.004) Batch 0.468 (0.483) Remain 31:46:23 loss: 1.4969 Lr: 0.00049
[2025-04-08 14:17:34,194 INFO misc.py line 113 3298914] Train: [2/100][747/2402] Data 0.004 (0.004) Batch 0.407 (0.482) Remain 31:45:59 loss: 1.4605 Lr: 0.00049
[2025-04-08 14:17:34,734 INFO misc.py line 113 3298914] Train: [2/100][748/2402] Data 0.004 (0.004) Batch 0.541 (0.483) Remain 31:46:17 loss: 1.5844 Lr: 0.00049
[2025-04-08 14:17:35,196 INFO misc.py line 113 3298914] Train: [2/100][749/2402] Data 0.003 (0.004) Batch 0.461 (0.482) Remain 31:46:10 loss: 1.4666 Lr: 0.00049
[2025-04-08 14:17:35,615 INFO misc.py line 113 3298914] Train: [2/100][750/2402] Data 0.004 (0.004) Batch 0.420 (0.482) Remain 31:45:49 loss: 1.4493 Lr: 0.00049
[2025-04-08 14:17:36,062 INFO misc.py line 113 3298914] Train: [2/100][751/2402] Data 0.003 (0.004) Batch 0.446 (0.482) Remain 31:45:37 loss: 1.2418 Lr: 0.00049
[2025-04-08 14:17:36,579 INFO misc.py line 113 3298914] Train: [2/100][752/2402] Data 0.004 (0.004) Batch 0.518 (0.482) Remain 31:45:48 loss: 1.3816 Lr: 0.00049
[2025-04-08 14:17:37,067 INFO misc.py line 113 3298914] Train: [2/100][753/2402] Data 0.004 (0.004) Batch 0.488 (0.482) Remain 31:45:49 loss: 1.5953 Lr: 0.00049
[2025-04-08 14:17:37,581 INFO misc.py line 113 3298914] Train: [2/100][754/2402] Data 0.003 (0.004) Batch 0.513 (0.482) Remain 31:45:58 loss: 1.4415 Lr: 0.00049
[2025-04-08 14:17:38,109 INFO misc.py line 113 3298914] Train: [2/100][755/2402] Data 0.004 (0.004) Batch 0.528 (0.482) Remain 31:46:12 loss: 1.2577 Lr: 0.00049
[2025-04-08 14:17:38,668 INFO misc.py line 113 3298914] Train: [2/100][756/2402] Data 0.004 (0.004) Batch 0.560 (0.483) Remain 31:46:36 loss: 1.8027 Lr: 0.00049
[2025-04-08 14:17:39,042 INFO misc.py line 113 3298914] Train: [2/100][757/2402] Data 0.004 (0.004) Batch 0.374 (0.482) Remain 31:46:02 loss: 1.3944 Lr: 0.00049
[2025-04-08 14:17:39,566 INFO misc.py line 113 3298914] Train: [2/100][758/2402] Data 0.004 (0.004) Batch 0.524 (0.483) Remain 31:46:14 loss: 1.6164 Lr: 0.00049
[2025-04-08 14:17:39,973 INFO misc.py line 113 3298914] Train: [2/100][759/2402] Data 0.004 (0.004) Batch 0.407 (0.482) Remain 31:45:50 loss: 1.1461 Lr: 0.00049
[2025-04-08 14:17:40,398 INFO misc.py line 113 3298914] Train: [2/100][760/2402] Data 0.004 (0.004) Batch 0.425 (0.482) Remain 31:45:31 loss: 1.7353 Lr: 0.00049
[2025-04-08 14:17:40,946 INFO misc.py line 113 3298914] Train: [2/100][761/2402] Data 0.004 (0.004) Batch 0.548 (0.482) Remain 31:45:51 loss: 1.3205 Lr: 0.00049
[2025-04-08 14:17:41,422 INFO misc.py line 113 3298914] Train: [2/100][762/2402] Data 0.004 (0.004) Batch 0.475 (0.482) Remain 31:45:48 loss: 1.5726 Lr: 0.00049
[2025-04-08 14:17:41,750 INFO misc.py line 113 3298914] Train: [2/100][763/2402] Data 0.005 (0.004) Batch 0.330 (0.482) Remain 31:45:00 loss: 1.3337 Lr: 0.00049
[2025-04-08 14:17:42,225 INFO misc.py line 113 3298914] Train: [2/100][764/2402] Data 0.004 (0.004) Batch 0.475 (0.482) Remain 31:44:57 loss: 1.0318 Lr: 0.00049
[2025-04-08 14:17:42,656 INFO misc.py line 113 3298914] Train: [2/100][765/2402] Data 0.004 (0.004) Batch 0.431 (0.482) Remain 31:44:41 loss: 1.4148 Lr: 0.00049
[2025-04-08 14:17:43,179 INFO misc.py line 113 3298914] Train: [2/100][766/2402] Data 0.003 (0.004) Batch 0.522 (0.482) Remain 31:44:53 loss: 1.3123 Lr: 0.00049
[2025-04-08 14:17:43,753 INFO misc.py line 113 3298914] Train: [2/100][767/2402] Data 0.004 (0.004) Batch 0.574 (0.482) Remain 31:45:21 loss: 1.2888 Lr: 0.00049
[2025-04-08 14:17:44,261 INFO misc.py line 113 3298914] Train: [2/100][768/2402] Data 0.004 (0.004) Batch 0.509 (0.482) Remain 31:45:29 loss: 1.3248 Lr: 0.00049
[2025-04-08 14:17:44,784 INFO misc.py line 113 3298914] Train: [2/100][769/2402] Data 0.004 (0.004) Batch 0.522 (0.482) Remain 31:45:41 loss: 1.6854 Lr: 0.00049
[2025-04-08 14:17:45,361 INFO misc.py line 113 3298914] Train: [2/100][770/2402] Data 0.004 (0.004) Batch 0.577 (0.483) Remain 31:46:09 loss: 0.8336 Lr: 0.00049
[2025-04-08 14:17:45,789 INFO misc.py line 113 3298914] Train: [2/100][771/2402] Data 0.004 (0.004) Batch 0.428 (0.482) Remain 31:45:52 loss: 1.8166 Lr: 0.00049
[2025-04-08 14:17:46,170 INFO misc.py line 113 3298914] Train: [2/100][772/2402] Data 0.004 (0.004) Batch 0.382 (0.482) Remain 31:45:21 loss: 1.5495 Lr: 0.00049
[2025-04-08 14:17:46,636 INFO misc.py line 113 3298914] Train: [2/100][773/2402] Data 0.004 (0.004) Batch 0.465 (0.482) Remain 31:45:15 loss: 1.2971 Lr: 0.00049
[2025-04-08 14:17:47,144 INFO misc.py line 113 3298914] Train: [2/100][774/2402] Data 0.004 (0.004) Batch 0.508 (0.482) Remain 31:45:22 loss: 1.5144 Lr: 0.00049
[2025-04-08 14:17:47,741 INFO misc.py line 113 3298914] Train: [2/100][775/2402] Data 0.003 (0.004) Batch 0.597 (0.482) Remain 31:45:57 loss: 1.5761 Lr: 0.00049
[2025-04-08 14:17:48,150 INFO misc.py line 113 3298914] Train: [2/100][776/2402] Data 0.003 (0.004) Batch 0.409 (0.482) Remain 31:45:34 loss: 1.3761 Lr: 0.00049
[2025-04-08 14:17:48,662 INFO misc.py line 113 3298914] Train: [2/100][777/2402] Data 0.004 (0.004) Batch 0.512 (0.482) Remain 31:45:43 loss: 1.7278 Lr: 0.00049
[2025-04-08 14:17:49,173 INFO misc.py line 113 3298914] Train: [2/100][778/2402] Data 0.004 (0.004) Batch 0.511 (0.482) Remain 31:45:51 loss: 0.9422 Lr: 0.00049
[2025-04-08 14:17:49,643 INFO misc.py line 113 3298914] Train: [2/100][779/2402] Data 0.003 (0.004) Batch 0.470 (0.482) Remain 31:45:47 loss: 1.5290 Lr: 0.00049
[2025-04-08 14:17:50,169 INFO misc.py line 113 3298914] Train: [2/100][780/2402] Data 0.003 (0.004) Batch 0.526 (0.482) Remain 31:46:00 loss: 1.5806 Lr: 0.00049
[2025-04-08 14:17:50,718 INFO misc.py line 113 3298914] Train: [2/100][781/2402] Data 0.004 (0.004) Batch 0.549 (0.483) Remain 31:46:19 loss: 1.4485 Lr: 0.00049
[2025-04-08 14:17:51,256 INFO misc.py line 113 3298914] Train: [2/100][782/2402] Data 0.003 (0.004) Batch 0.538 (0.483) Remain 31:46:36 loss: 1.3829 Lr: 0.00049
[2025-04-08 14:17:51,724 INFO misc.py line 113 3298914] Train: [2/100][783/2402] Data 0.004 (0.004) Batch 0.468 (0.483) Remain 31:46:31 loss: 0.9148 Lr: 0.00049
[2025-04-08 14:17:52,165 INFO misc.py line 113 3298914] Train: [2/100][784/2402] Data 0.003 (0.004) Batch 0.441 (0.483) Remain 31:46:18 loss: 1.4083 Lr: 0.00049
[2025-04-08 14:17:52,559 INFO misc.py line 113 3298914] Train: [2/100][785/2402] Data 0.004 (0.004) Batch 0.394 (0.482) Remain 31:45:50 loss: 1.1152 Lr: 0.00049
[2025-04-08 14:17:52,919 INFO misc.py line 113 3298914] Train: [2/100][786/2402] Data 0.004 (0.004) Batch 0.360 (0.482) Remain 31:45:13 loss: 1.0323 Lr: 0.00049
[2025-04-08 14:17:53,378 INFO misc.py line 113 3298914] Train: [2/100][787/2402] Data 0.004 (0.004) Batch 0.459 (0.482) Remain 31:45:05 loss: 1.0818 Lr: 0.00049
[2025-04-08 14:17:53,882 INFO misc.py line 113 3298914] Train: [2/100][788/2402] Data 0.004 (0.004) Batch 0.504 (0.482) Remain 31:45:11 loss: 1.0500 Lr: 0.00050
[2025-04-08 14:17:54,466 INFO misc.py line 113 3298914] Train: [2/100][789/2402] Data 0.004 (0.004) Batch 0.583 (0.482) Remain 31:45:41 loss: 1.3945 Lr: 0.00050
[2025-04-08 14:17:54,991 INFO misc.py line 113 3298914] Train: [2/100][790/2402] Data 0.004 (0.004) Batch 0.526 (0.482) Remain 31:45:54 loss: 1.3573 Lr: 0.00050
[2025-04-08 14:17:55,519 INFO misc.py line 113 3298914] Train: [2/100][791/2402] Data 0.004 (0.004) Batch 0.528 (0.483) Remain 31:46:07 loss: 1.8761 Lr: 0.00050
[2025-04-08 14:17:56,024 INFO misc.py line 113 3298914] Train: [2/100][792/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:46:13 loss: 1.3307 Lr: 0.00050
[2025-04-08 14:17:56,476 INFO misc.py line 113 3298914] Train: [2/100][793/2402] Data 0.004 (0.004) Batch 0.452 (0.483) Remain 31:46:03 loss: 1.6670 Lr: 0.00050
[2025-04-08 14:17:56,898 INFO misc.py line 113 3298914] Train: [2/100][794/2402] Data 0.004 (0.004) Batch 0.423 (0.482) Remain 31:45:45 loss: 1.1010 Lr: 0.00050
[2025-04-08 14:17:57,438 INFO misc.py line 113 3298914] Train: [2/100][795/2402] Data 0.004 (0.004) Batch 0.540 (0.483) Remain 31:46:02 loss: 1.1580 Lr: 0.00050
[2025-04-08 14:17:57,879 INFO misc.py line 113 3298914] Train: [2/100][796/2402] Data 0.003 (0.004) Batch 0.441 (0.482) Remain 31:45:49 loss: 1.0436 Lr: 0.00050
[2025-04-08 14:17:58,386 INFO misc.py line 113 3298914] Train: [2/100][797/2402] Data 0.003 (0.004) Batch 0.506 (0.483) Remain 31:45:56 loss: 1.3816 Lr: 0.00050
[2025-04-08 14:17:58,915 INFO misc.py line 113 3298914] Train: [2/100][798/2402] Data 0.003 (0.004) Batch 0.529 (0.483) Remain 31:46:09 loss: 1.2489 Lr: 0.00050
[2025-04-08 14:17:59,387 INFO misc.py line 113 3298914] Train: [2/100][799/2402] Data 0.004 (0.004) Batch 0.472 (0.483) Remain 31:46:05 loss: 1.3037 Lr: 0.00050
[2025-04-08 14:17:59,823 INFO misc.py line 113 3298914] Train: [2/100][800/2402] Data 0.003 (0.004) Batch 0.437 (0.483) Remain 31:45:51 loss: 1.5296 Lr: 0.00050
[2025-04-08 14:18:00,269 INFO misc.py line 113 3298914] Train: [2/100][801/2402] Data 0.003 (0.004) Batch 0.446 (0.482) Remain 31:45:40 loss: 1.0355 Lr: 0.00050
[2025-04-08 14:18:00,679 INFO misc.py line 113 3298914] Train: [2/100][802/2402] Data 0.004 (0.004) Batch 0.410 (0.482) Remain 31:45:18 loss: 1.2448 Lr: 0.00050
[2025-04-08 14:18:01,174 INFO misc.py line 113 3298914] Train: [2/100][803/2402] Data 0.004 (0.004) Batch 0.495 (0.482) Remain 31:45:21 loss: 1.5953 Lr: 0.00050
[2025-04-08 14:18:01,665 INFO misc.py line 113 3298914] Train: [2/100][804/2402] Data 0.004 (0.004) Batch 0.492 (0.482) Remain 31:45:23 loss: 1.5879 Lr: 0.00050
[2025-04-08 14:18:02,185 INFO misc.py line 113 3298914] Train: [2/100][805/2402] Data 0.004 (0.004) Batch 0.520 (0.482) Remain 31:45:34 loss: 1.2538 Lr: 0.00050
[2025-04-08 14:18:02,656 INFO misc.py line 113 3298914] Train: [2/100][806/2402] Data 0.003 (0.004) Batch 0.470 (0.482) Remain 31:45:30 loss: 1.4826 Lr: 0.00050
[2025-04-08 14:18:03,146 INFO misc.py line 113 3298914] Train: [2/100][807/2402] Data 0.004 (0.004) Batch 0.491 (0.482) Remain 31:45:32 loss: 1.2865 Lr: 0.00050
[2025-04-08 14:18:03,668 INFO misc.py line 113 3298914] Train: [2/100][808/2402] Data 0.004 (0.004) Batch 0.522 (0.482) Remain 31:45:43 loss: 0.9386 Lr: 0.00050
[2025-04-08 14:18:04,194 INFO misc.py line 113 3298914] Train: [2/100][809/2402] Data 0.004 (0.004) Batch 0.526 (0.483) Remain 31:45:55 loss: 1.2867 Lr: 0.00050
[2025-04-08 14:18:04,615 INFO misc.py line 113 3298914] Train: [2/100][810/2402] Data 0.004 (0.004) Batch 0.422 (0.482) Remain 31:45:37 loss: 1.4180 Lr: 0.00050
[2025-04-08 14:18:05,070 INFO misc.py line 113 3298914] Train: [2/100][811/2402] Data 0.003 (0.004) Batch 0.455 (0.482) Remain 31:45:28 loss: 1.2417 Lr: 0.00050
[2025-04-08 14:18:05,503 INFO misc.py line 113 3298914] Train: [2/100][812/2402] Data 0.004 (0.004) Batch 0.432 (0.482) Remain 31:45:13 loss: 1.1078 Lr: 0.00050
[2025-04-08 14:18:05,981 INFO misc.py line 113 3298914] Train: [2/100][813/2402] Data 0.004 (0.004) Batch 0.478 (0.482) Remain 31:45:11 loss: 1.2379 Lr: 0.00050
[2025-04-08 14:18:06,452 INFO misc.py line 113 3298914] Train: [2/100][814/2402] Data 0.003 (0.004) Batch 0.471 (0.482) Remain 31:45:08 loss: 1.5255 Lr: 0.00050
[2025-04-08 14:18:06,863 INFO misc.py line 113 3298914] Train: [2/100][815/2402] Data 0.004 (0.004) Batch 0.411 (0.482) Remain 31:44:46 loss: 1.4005 Lr: 0.00050
[2025-04-08 14:18:07,386 INFO misc.py line 113 3298914] Train: [2/100][816/2402] Data 0.004 (0.004) Batch 0.523 (0.482) Remain 31:44:58 loss: 1.4015 Lr: 0.00050
[2025-04-08 14:18:07,872 INFO misc.py line 113 3298914] Train: [2/100][817/2402] Data 0.004 (0.004) Batch 0.486 (0.482) Remain 31:44:58 loss: 1.5724 Lr: 0.00050
[2025-04-08 14:18:08,317 INFO misc.py line 113 3298914] Train: [2/100][818/2402] Data 0.004 (0.004) Batch 0.445 (0.482) Remain 31:44:47 loss: 1.5287 Lr: 0.00050
[2025-04-08 14:18:08,801 INFO misc.py line 113 3298914] Train: [2/100][819/2402] Data 0.003 (0.004) Batch 0.484 (0.482) Remain 31:44:47 loss: 1.4746 Lr: 0.00050
[2025-04-08 14:18:09,217 INFO misc.py line 113 3298914] Train: [2/100][820/2402] Data 0.004 (0.004) Batch 0.415 (0.482) Remain 31:44:27 loss: 1.3688 Lr: 0.00050
[2025-04-08 14:18:09,811 INFO misc.py line 113 3298914] Train: [2/100][821/2402] Data 0.004 (0.004) Batch 0.595 (0.482) Remain 31:44:59 loss: 1.3720 Lr: 0.00050
[2025-04-08 14:18:10,404 INFO misc.py line 113 3298914] Train: [2/100][822/2402] Data 0.004 (0.004) Batch 0.593 (0.482) Remain 31:45:31 loss: 1.2698 Lr: 0.00050
[2025-04-08 14:18:10,782 INFO misc.py line 113 3298914] Train: [2/100][823/2402] Data 0.003 (0.004) Batch 0.378 (0.482) Remain 31:45:00 loss: 1.0415 Lr: 0.00050
[2025-04-08 14:18:11,239 INFO misc.py line 113 3298914] Train: [2/100][824/2402] Data 0.003 (0.004) Batch 0.457 (0.482) Remain 31:44:52 loss: 1.3609 Lr: 0.00050
[2025-04-08 14:18:11,711 INFO misc.py line 113 3298914] Train: [2/100][825/2402] Data 0.004 (0.004) Batch 0.472 (0.482) Remain 31:44:49 loss: 1.4698 Lr: 0.00050
[2025-04-08 14:18:12,301 INFO misc.py line 113 3298914] Train: [2/100][826/2402] Data 0.004 (0.004) Batch 0.590 (0.482) Remain 31:45:19 loss: 1.4759 Lr: 0.00050
[2025-04-08 14:18:12,747 INFO misc.py line 113 3298914] Train: [2/100][827/2402] Data 0.004 (0.004) Batch 0.446 (0.482) Remain 31:45:08 loss: 1.5555 Lr: 0.00050
[2025-04-08 14:18:13,179 INFO misc.py line 113 3298914] Train: [2/100][828/2402] Data 0.004 (0.004) Batch 0.432 (0.482) Remain 31:44:53 loss: 1.0721 Lr: 0.00050
[2025-04-08 14:18:13,716 INFO misc.py line 113 3298914] Train: [2/100][829/2402] Data 0.003 (0.004) Batch 0.537 (0.482) Remain 31:45:09 loss: 1.4790 Lr: 0.00050
[2025-04-08 14:18:14,198 INFO misc.py line 113 3298914] Train: [2/100][830/2402] Data 0.004 (0.004) Batch 0.482 (0.482) Remain 31:45:08 loss: 1.2594 Lr: 0.00050
[2025-04-08 14:18:14,624 INFO misc.py line 113 3298914] Train: [2/100][831/2402] Data 0.004 (0.004) Batch 0.426 (0.482) Remain 31:44:51 loss: 1.3477 Lr: 0.00050
[2025-04-08 14:18:14,971 INFO misc.py line 113 3298914] Train: [2/100][832/2402] Data 0.004 (0.004) Batch 0.346 (0.482) Remain 31:44:12 loss: 1.2634 Lr: 0.00050
[2025-04-08 14:18:15,364 INFO misc.py line 113 3298914] Train: [2/100][833/2402] Data 0.004 (0.004) Batch 0.393 (0.482) Remain 31:43:46 loss: 1.7136 Lr: 0.00050
[2025-04-08 14:18:15,900 INFO misc.py line 113 3298914] Train: [2/100][834/2402] Data 0.004 (0.004) Batch 0.536 (0.482) Remain 31:44:01 loss: 1.0875 Lr: 0.00050
[2025-04-08 14:18:16,503 INFO misc.py line 113 3298914] Train: [2/100][835/2402] Data 0.004 (0.004) Batch 0.603 (0.482) Remain 31:44:35 loss: 1.1244 Lr: 0.00050
[2025-04-08 14:18:16,904 INFO misc.py line 113 3298914] Train: [2/100][836/2402] Data 0.004 (0.004) Batch 0.402 (0.482) Remain 31:44:12 loss: 1.4290 Lr: 0.00050
[2025-04-08 14:18:17,331 INFO misc.py line 113 3298914] Train: [2/100][837/2402] Data 0.004 (0.004) Batch 0.426 (0.482) Remain 31:43:55 loss: 1.4554 Lr: 0.00050
[2025-04-08 14:18:17,937 INFO misc.py line 113 3298914] Train: [2/100][838/2402] Data 0.004 (0.004) Batch 0.606 (0.482) Remain 31:44:30 loss: 1.4582 Lr: 0.00050
[2025-04-08 14:18:18,533 INFO misc.py line 113 3298914] Train: [2/100][839/2402] Data 0.003 (0.004) Batch 0.596 (0.482) Remain 31:45:02 loss: 1.1244 Lr: 0.00050
[2025-04-08 14:18:18,968 INFO misc.py line 113 3298914] Train: [2/100][840/2402] Data 0.003 (0.004) Batch 0.434 (0.482) Remain 31:44:48 loss: 1.3492 Lr: 0.00050
[2025-04-08 14:18:19,555 INFO misc.py line 113 3298914] Train: [2/100][841/2402] Data 0.004 (0.004) Batch 0.587 (0.482) Remain 31:45:17 loss: 1.6075 Lr: 0.00050
[2025-04-08 14:18:20,057 INFO misc.py line 113 3298914] Train: [2/100][842/2402] Data 0.004 (0.004) Batch 0.503 (0.482) Remain 31:45:22 loss: 1.3301 Lr: 0.00050
[2025-04-08 14:18:20,463 INFO misc.py line 113 3298914] Train: [2/100][843/2402] Data 0.004 (0.004) Batch 0.405 (0.482) Remain 31:45:00 loss: 1.2433 Lr: 0.00050
[2025-04-08 14:18:20,959 INFO misc.py line 113 3298914] Train: [2/100][844/2402] Data 0.004 (0.004) Batch 0.496 (0.482) Remain 31:45:03 loss: 1.4036 Lr: 0.00050
[2025-04-08 14:18:21,517 INFO misc.py line 113 3298914] Train: [2/100][845/2402] Data 0.004 (0.004) Batch 0.559 (0.482) Remain 31:45:24 loss: 1.2470 Lr: 0.00051
[2025-04-08 14:18:22,018 INFO misc.py line 113 3298914] Train: [2/100][846/2402] Data 0.004 (0.004) Batch 0.501 (0.483) Remain 31:45:29 loss: 1.6258 Lr: 0.00051
[2025-04-08 14:18:22,498 INFO misc.py line 113 3298914] Train: [2/100][847/2402] Data 0.003 (0.004) Batch 0.480 (0.482) Remain 31:45:28 loss: 0.9925 Lr: 0.00051
[2025-04-08 14:18:22,987 INFO misc.py line 113 3298914] Train: [2/100][848/2402] Data 0.004 (0.004) Batch 0.488 (0.483) Remain 31:45:29 loss: 1.3883 Lr: 0.00051
[2025-04-08 14:18:23,390 INFO misc.py line 113 3298914] Train: [2/100][849/2402] Data 0.004 (0.004) Batch 0.404 (0.482) Remain 31:45:06 loss: 1.3448 Lr: 0.00051
[2025-04-08 14:18:23,858 INFO misc.py line 113 3298914] Train: [2/100][850/2402] Data 0.004 (0.004) Batch 0.467 (0.482) Remain 31:45:02 loss: 1.5885 Lr: 0.00051
[2025-04-08 14:18:24,272 INFO misc.py line 113 3298914] Train: [2/100][851/2402] Data 0.003 (0.004) Batch 0.414 (0.482) Remain 31:44:42 loss: 1.9073 Lr: 0.00051
[2025-04-08 14:18:24,816 INFO misc.py line 113 3298914] Train: [2/100][852/2402] Data 0.004 (0.004) Batch 0.545 (0.482) Remain 31:44:59 loss: 1.7268 Lr: 0.00051
[2025-04-08 14:18:25,308 INFO misc.py line 113 3298914] Train: [2/100][853/2402] Data 0.003 (0.004) Batch 0.492 (0.482) Remain 31:45:01 loss: 1.3637 Lr: 0.00051
[2025-04-08 14:18:25,785 INFO misc.py line 113 3298914] Train: [2/100][854/2402] Data 0.004 (0.004) Batch 0.476 (0.482) Remain 31:44:59 loss: 2.1980 Lr: 0.00051
[2025-04-08 14:18:26,338 INFO misc.py line 113 3298914] Train: [2/100][855/2402] Data 0.004 (0.004) Batch 0.553 (0.482) Remain 31:45:18 loss: 1.3756 Lr: 0.00051
[2025-04-08 14:18:26,854 INFO misc.py line 113 3298914] Train: [2/100][856/2402] Data 0.004 (0.004) Batch 0.516 (0.483) Remain 31:45:27 loss: 1.1093 Lr: 0.00051
[2025-04-08 14:18:27,277 INFO misc.py line 113 3298914] Train: [2/100][857/2402] Data 0.004 (0.004) Batch 0.422 (0.482) Remain 31:45:10 loss: 1.2573 Lr: 0.00051
[2025-04-08 14:18:27,701 INFO misc.py line 113 3298914] Train: [2/100][858/2402] Data 0.003 (0.004) Batch 0.424 (0.482) Remain 31:44:53 loss: 1.2643 Lr: 0.00051
[2025-04-08 14:18:28,232 INFO misc.py line 113 3298914] Train: [2/100][859/2402] Data 0.004 (0.004) Batch 0.532 (0.482) Remain 31:45:06 loss: 1.5912 Lr: 0.00051
[2025-04-08 14:18:28,759 INFO misc.py line 113 3298914] Train: [2/100][860/2402] Data 0.004 (0.004) Batch 0.527 (0.482) Remain 31:45:18 loss: 1.0856 Lr: 0.00051
[2025-04-08 14:18:29,136 INFO misc.py line 113 3298914] Train: [2/100][861/2402] Data 0.004 (0.004) Batch 0.377 (0.482) Remain 31:44:49 loss: 1.3150 Lr: 0.00051
[2025-04-08 14:18:29,563 INFO misc.py line 113 3298914] Train: [2/100][862/2402] Data 0.003 (0.004) Batch 0.427 (0.482) Remain 31:44:33 loss: 1.1140 Lr: 0.00051
[2025-04-08 14:18:30,106 INFO misc.py line 113 3298914] Train: [2/100][863/2402] Data 0.004 (0.004) Batch 0.544 (0.482) Remain 31:44:49 loss: 1.5307 Lr: 0.00051
[2025-04-08 14:18:30,595 INFO misc.py line 113 3298914] Train: [2/100][864/2402] Data 0.004 (0.004) Batch 0.488 (0.482) Remain 31:44:50 loss: 1.6151 Lr: 0.00051
[2025-04-08 14:18:31,085 INFO misc.py line 113 3298914] Train: [2/100][865/2402] Data 0.004 (0.004) Batch 0.490 (0.482) Remain 31:44:52 loss: 2.0157 Lr: 0.00051
[2025-04-08 14:18:31,517 INFO misc.py line 113 3298914] Train: [2/100][866/2402] Data 0.004 (0.004) Batch 0.431 (0.482) Remain 31:44:38 loss: 1.0854 Lr: 0.00051
[2025-04-08 14:18:32,068 INFO misc.py line 113 3298914] Train: [2/100][867/2402] Data 0.003 (0.004) Batch 0.551 (0.482) Remain 31:44:56 loss: 1.5809 Lr: 0.00051
[2025-04-08 14:18:32,458 INFO misc.py line 113 3298914] Train: [2/100][868/2402] Data 0.004 (0.004) Batch 0.390 (0.482) Remain 31:44:30 loss: 1.9128 Lr: 0.00051
[2025-04-08 14:18:32,896 INFO misc.py line 113 3298914] Train: [2/100][869/2402] Data 0.004 (0.004) Batch 0.439 (0.482) Remain 31:44:18 loss: 1.2147 Lr: 0.00051
[2025-04-08 14:18:33,464 INFO misc.py line 113 3298914] Train: [2/100][870/2402] Data 0.004 (0.004) Batch 0.568 (0.482) Remain 31:44:41 loss: 1.0461 Lr: 0.00051
[2025-04-08 14:18:33,973 INFO misc.py line 113 3298914] Train: [2/100][871/2402] Data 0.003 (0.004) Batch 0.509 (0.482) Remain 31:44:48 loss: 1.3787 Lr: 0.00051
[2025-04-08 14:18:34,687 INFO misc.py line 113 3298914] Train: [2/100][872/2402] Data 0.004 (0.004) Batch 0.713 (0.483) Remain 31:45:50 loss: 1.7148 Lr: 0.00051
[2025-04-08 14:18:35,221 INFO misc.py line 113 3298914] Train: [2/100][873/2402] Data 0.004 (0.004) Batch 0.535 (0.483) Remain 31:46:04 loss: 1.1100 Lr: 0.00051
[2025-04-08 14:18:35,717 INFO misc.py line 113 3298914] Train: [2/100][874/2402] Data 0.004 (0.004) Batch 0.496 (0.483) Remain 31:46:07 loss: 1.5792 Lr: 0.00051
[2025-04-08 14:18:36,151 INFO misc.py line 113 3298914] Train: [2/100][875/2402] Data 0.004 (0.004) Batch 0.433 (0.483) Remain 31:45:53 loss: 1.6456 Lr: 0.00051
[2025-04-08 14:18:36,687 INFO misc.py line 113 3298914] Train: [2/100][876/2402] Data 0.004 (0.004) Batch 0.536 (0.483) Remain 31:46:07 loss: 1.5813 Lr: 0.00051
[2025-04-08 14:18:37,185 INFO misc.py line 113 3298914] Train: [2/100][877/2402] Data 0.004 (0.004) Batch 0.499 (0.483) Remain 31:46:11 loss: 1.3497 Lr: 0.00051
[2025-04-08 14:18:37,663 INFO misc.py line 113 3298914] Train: [2/100][878/2402] Data 0.004 (0.004) Batch 0.478 (0.483) Remain 31:46:09 loss: 1.5063 Lr: 0.00051
[2025-04-08 14:18:38,147 INFO misc.py line 113 3298914] Train: [2/100][879/2402] Data 0.004 (0.004) Batch 0.483 (0.483) Remain 31:46:09 loss: 1.4041 Lr: 0.00051
[2025-04-08 14:18:38,772 INFO misc.py line 113 3298914] Train: [2/100][880/2402] Data 0.004 (0.004) Batch 0.625 (0.483) Remain 31:46:47 loss: 1.1515 Lr: 0.00051
[2025-04-08 14:18:39,251 INFO misc.py line 113 3298914] Train: [2/100][881/2402] Data 0.004 (0.004) Batch 0.479 (0.483) Remain 31:46:45 loss: 1.0363 Lr: 0.00051
[2025-04-08 14:18:39,709 INFO misc.py line 113 3298914] Train: [2/100][882/2402] Data 0.004 (0.004) Batch 0.459 (0.483) Remain 31:46:38 loss: 1.2196 Lr: 0.00051
[2025-04-08 14:18:40,264 INFO misc.py line 113 3298914] Train: [2/100][883/2402] Data 0.004 (0.004) Batch 0.555 (0.483) Remain 31:46:57 loss: 1.2511 Lr: 0.00051
[2025-04-08 14:18:40,767 INFO misc.py line 113 3298914] Train: [2/100][884/2402] Data 0.003 (0.004) Batch 0.503 (0.483) Remain 31:47:02 loss: 1.3324 Lr: 0.00051
[2025-04-08 14:18:41,275 INFO misc.py line 113 3298914] Train: [2/100][885/2402] Data 0.004 (0.004) Batch 0.508 (0.483) Remain 31:47:08 loss: 1.2747 Lr: 0.00051
[2025-04-08 14:18:41,770 INFO misc.py line 113 3298914] Train: [2/100][886/2402] Data 0.004 (0.004) Batch 0.495 (0.483) Remain 31:47:11 loss: 1.3538 Lr: 0.00051
[2025-04-08 14:18:42,249 INFO misc.py line 113 3298914] Train: [2/100][887/2402] Data 0.004 (0.004) Batch 0.479 (0.483) Remain 31:47:09 loss: 1.3371 Lr: 0.00051
[2025-04-08 14:18:42,741 INFO misc.py line 113 3298914] Train: [2/100][888/2402] Data 0.004 (0.004) Batch 0.492 (0.483) Remain 31:47:11 loss: 1.0851 Lr: 0.00051
[2025-04-08 14:18:43,302 INFO misc.py line 113 3298914] Train: [2/100][889/2402] Data 0.004 (0.004) Batch 0.562 (0.483) Remain 31:47:32 loss: 1.1196 Lr: 0.00051
[2025-04-08 14:18:43,759 INFO misc.py line 113 3298914] Train: [2/100][890/2402] Data 0.004 (0.004) Batch 0.456 (0.483) Remain 31:47:24 loss: 1.4003 Lr: 0.00051
[2025-04-08 14:18:44,202 INFO misc.py line 113 3298914] Train: [2/100][891/2402] Data 0.004 (0.004) Batch 0.443 (0.483) Remain 31:47:13 loss: 1.4523 Lr: 0.00051
[2025-04-08 14:18:44,675 INFO misc.py line 113 3298914] Train: [2/100][892/2402] Data 0.004 (0.004) Batch 0.473 (0.483) Remain 31:47:10 loss: 1.8005 Lr: 0.00051
[2025-04-08 14:18:45,239 INFO misc.py line 113 3298914] Train: [2/100][893/2402] Data 0.004 (0.004) Batch 0.565 (0.483) Remain 31:47:31 loss: 1.6865 Lr: 0.00051
[2025-04-08 14:18:45,766 INFO misc.py line 113 3298914] Train: [2/100][894/2402] Data 0.003 (0.004) Batch 0.527 (0.483) Remain 31:47:42 loss: 1.1127 Lr: 0.00051
[2025-04-08 14:18:46,271 INFO misc.py line 113 3298914] Train: [2/100][895/2402] Data 0.004 (0.004) Batch 0.505 (0.483) Remain 31:47:47 loss: 1.3343 Lr: 0.00051
[2025-04-08 14:18:46,658 INFO misc.py line 113 3298914] Train: [2/100][896/2402] Data 0.003 (0.004) Batch 0.388 (0.483) Remain 31:47:21 loss: 1.4848 Lr: 0.00051
[2025-04-08 14:18:47,100 INFO misc.py line 113 3298914] Train: [2/100][897/2402] Data 0.003 (0.004) Batch 0.441 (0.483) Remain 31:47:10 loss: 1.5385 Lr: 0.00051
[2025-04-08 14:18:47,460 INFO misc.py line 113 3298914] Train: [2/100][898/2402] Data 0.004 (0.004) Batch 0.360 (0.483) Remain 31:46:37 loss: 1.4378 Lr: 0.00051
[2025-04-08 14:18:47,910 INFO misc.py line 113 3298914] Train: [2/100][899/2402] Data 0.004 (0.004) Batch 0.450 (0.483) Remain 31:46:28 loss: 1.3448 Lr: 0.00051
[2025-04-08 14:18:48,450 INFO misc.py line 113 3298914] Train: [2/100][900/2402] Data 0.004 (0.004) Batch 0.540 (0.483) Remain 31:46:42 loss: 1.1272 Lr: 0.00051
[2025-04-08 14:18:48,998 INFO misc.py line 113 3298914] Train: [2/100][901/2402] Data 0.004 (0.004) Batch 0.548 (0.483) Remain 31:46:59 loss: 1.5841 Lr: 0.00052
[2025-04-08 14:18:49,388 INFO misc.py line 113 3298914] Train: [2/100][902/2402] Data 0.003 (0.004) Batch 0.390 (0.483) Remain 31:46:34 loss: 1.3651 Lr: 0.00052
[2025-04-08 14:18:49,838 INFO misc.py line 113 3298914] Train: [2/100][903/2402] Data 0.004 (0.004) Batch 0.450 (0.483) Remain 31:46:25 loss: 1.4508 Lr: 0.00052
[2025-04-08 14:18:50,324 INFO misc.py line 113 3298914] Train: [2/100][904/2402] Data 0.004 (0.004) Batch 0.486 (0.483) Remain 31:46:25 loss: 1.3634 Lr: 0.00052
[2025-04-08 14:18:50,829 INFO misc.py line 113 3298914] Train: [2/100][905/2402] Data 0.004 (0.004) Batch 0.505 (0.483) Remain 31:46:31 loss: 1.4265 Lr: 0.00052
[2025-04-08 14:18:51,365 INFO misc.py line 113 3298914] Train: [2/100][906/2402] Data 0.003 (0.004) Batch 0.535 (0.483) Remain 31:46:44 loss: 1.4200 Lr: 0.00052
[2025-04-08 14:18:51,804 INFO misc.py line 113 3298914] Train: [2/100][907/2402] Data 0.004 (0.004) Batch 0.440 (0.483) Remain 31:46:32 loss: 1.2613 Lr: 0.00052
[2025-04-08 14:18:52,205 INFO misc.py line 113 3298914] Train: [2/100][908/2402] Data 0.003 (0.004) Batch 0.400 (0.483) Remain 31:46:10 loss: 1.3601 Lr: 0.00052
[2025-04-08 14:18:52,596 INFO misc.py line 113 3298914] Train: [2/100][909/2402] Data 0.004 (0.004) Batch 0.391 (0.483) Remain 31:45:45 loss: 0.9637 Lr: 0.00052
[2025-04-08 14:18:52,964 INFO misc.py line 113 3298914] Train: [2/100][910/2402] Data 0.004 (0.004) Batch 0.369 (0.483) Remain 31:45:15 loss: 1.1415 Lr: 0.00052
[2025-04-08 14:18:53,436 INFO misc.py line 113 3298914] Train: [2/100][911/2402] Data 0.004 (0.004) Batch 0.472 (0.483) Remain 31:45:12 loss: 1.2972 Lr: 0.00052
[2025-04-08 14:18:53,843 INFO misc.py line 113 3298914] Train: [2/100][912/2402] Data 0.004 (0.004) Batch 0.406 (0.482) Remain 31:44:52 loss: 1.3315 Lr: 0.00052
[2025-04-08 14:18:54,356 INFO misc.py line 113 3298914] Train: [2/100][913/2402] Data 0.004 (0.004) Batch 0.513 (0.483) Remain 31:44:59 loss: 1.5823 Lr: 0.00052
[2025-04-08 14:18:55,046 INFO misc.py line 113 3298914] Train: [2/100][914/2402] Data 0.004 (0.004) Batch 0.689 (0.483) Remain 31:45:53 loss: 1.5779 Lr: 0.00052
[2025-04-08 14:18:55,567 INFO misc.py line 113 3298914] Train: [2/100][915/2402] Data 0.004 (0.004) Batch 0.521 (0.483) Remain 31:46:02 loss: 1.5486 Lr: 0.00052
[2025-04-08 14:18:56,005 INFO misc.py line 113 3298914] Train: [2/100][916/2402] Data 0.004 (0.004) Batch 0.438 (0.483) Remain 31:45:50 loss: 1.3580 Lr: 0.00052
[2025-04-08 14:18:56,433 INFO misc.py line 113 3298914] Train: [2/100][917/2402] Data 0.004 (0.004) Batch 0.428 (0.483) Remain 31:45:35 loss: 1.2247 Lr: 0.00052
[2025-04-08 14:18:56,899 INFO misc.py line 113 3298914] Train: [2/100][918/2402] Data 0.004 (0.004) Batch 0.466 (0.483) Remain 31:45:31 loss: 1.4667 Lr: 0.00052
[2025-04-08 14:18:57,444 INFO misc.py line 113 3298914] Train: [2/100][919/2402] Data 0.003 (0.004) Batch 0.545 (0.483) Remain 31:45:46 loss: 1.0369 Lr: 0.00052
[2025-04-08 14:18:57,905 INFO misc.py line 113 3298914] Train: [2/100][920/2402] Data 0.004 (0.004) Batch 0.462 (0.483) Remain 31:45:40 loss: 0.8698 Lr: 0.00052
[2025-04-08 14:18:58,410 INFO misc.py line 113 3298914] Train: [2/100][921/2402] Data 0.004 (0.004) Batch 0.505 (0.483) Remain 31:45:45 loss: 1.3473 Lr: 0.00052
[2025-04-08 14:18:58,903 INFO misc.py line 113 3298914] Train: [2/100][922/2402] Data 0.004 (0.004) Batch 0.493 (0.483) Remain 31:45:48 loss: 1.3613 Lr: 0.00052
[2025-04-08 14:18:59,459 INFO misc.py line 113 3298914] Train: [2/100][923/2402] Data 0.004 (0.004) Batch 0.556 (0.483) Remain 31:46:06 loss: 1.2441 Lr: 0.00052
[2025-04-08 14:18:59,997 INFO misc.py line 113 3298914] Train: [2/100][924/2402] Data 0.004 (0.004) Batch 0.537 (0.483) Remain 31:46:20 loss: 1.3526 Lr: 0.00052
[2025-04-08 14:19:00,527 INFO misc.py line 113 3298914] Train: [2/100][925/2402] Data 0.004 (0.004) Batch 0.530 (0.483) Remain 31:46:31 loss: 1.4380 Lr: 0.00052
[2025-04-08 14:19:01,085 INFO misc.py line 113 3298914] Train: [2/100][926/2402] Data 0.004 (0.004) Batch 0.557 (0.483) Remain 31:46:50 loss: 1.6156 Lr: 0.00052
[2025-04-08 14:19:01,592 INFO misc.py line 113 3298914] Train: [2/100][927/2402] Data 0.004 (0.004) Batch 0.508 (0.483) Remain 31:46:56 loss: 1.2222 Lr: 0.00052
[2025-04-08 14:19:02,138 INFO misc.py line 113 3298914] Train: [2/100][928/2402] Data 0.004 (0.004) Batch 0.546 (0.483) Remain 31:47:11 loss: 1.2106 Lr: 0.00052
[2025-04-08 14:19:02,657 INFO misc.py line 113 3298914] Train: [2/100][929/2402] Data 0.004 (0.004) Batch 0.519 (0.483) Remain 31:47:20 loss: 1.0635 Lr: 0.00052
[2025-04-08 14:19:03,095 INFO misc.py line 113 3298914] Train: [2/100][930/2402] Data 0.004 (0.004) Batch 0.439 (0.483) Remain 31:47:08 loss: 1.1348 Lr: 0.00052
[2025-04-08 14:19:03,595 INFO misc.py line 113 3298914] Train: [2/100][931/2402] Data 0.004 (0.004) Batch 0.500 (0.483) Remain 31:47:12 loss: 1.4369 Lr: 0.00052
[2025-04-08 14:19:04,067 INFO misc.py line 113 3298914] Train: [2/100][932/2402] Data 0.004 (0.004) Batch 0.472 (0.483) Remain 31:47:09 loss: 1.3337 Lr: 0.00052
[2025-04-08 14:19:04,642 INFO misc.py line 113 3298914] Train: [2/100][933/2402] Data 0.004 (0.004) Batch 0.575 (0.483) Remain 31:47:32 loss: 1.7040 Lr: 0.00052
[2025-04-08 14:19:05,256 INFO misc.py line 113 3298914] Train: [2/100][934/2402] Data 0.003 (0.004) Batch 0.614 (0.483) Remain 31:48:04 loss: 1.7922 Lr: 0.00052
[2025-04-08 14:19:05,815 INFO misc.py line 113 3298914] Train: [2/100][935/2402] Data 0.004 (0.004) Batch 0.559 (0.483) Remain 31:48:23 loss: 1.2094 Lr: 0.00052
[2025-04-08 14:19:06,296 INFO misc.py line 113 3298914] Train: [2/100][936/2402] Data 0.003 (0.004) Batch 0.480 (0.483) Remain 31:48:22 loss: 1.4355 Lr: 0.00052
[2025-04-08 14:19:06,859 INFO misc.py line 113 3298914] Train: [2/100][937/2402] Data 0.004 (0.004) Batch 0.564 (0.483) Remain 31:48:42 loss: 1.4971 Lr: 0.00052
[2025-04-08 14:19:07,359 INFO misc.py line 113 3298914] Train: [2/100][938/2402] Data 0.003 (0.004) Batch 0.500 (0.484) Remain 31:48:45 loss: 1.5186 Lr: 0.00052
[2025-04-08 14:19:07,852 INFO misc.py line 113 3298914] Train: [2/100][939/2402] Data 0.004 (0.004) Batch 0.493 (0.484) Remain 31:48:47 loss: 1.3893 Lr: 0.00052
[2025-04-08 14:19:08,302 INFO misc.py line 113 3298914] Train: [2/100][940/2402] Data 0.004 (0.004) Batch 0.449 (0.483) Remain 31:48:38 loss: 1.2449 Lr: 0.00052
[2025-04-08 14:19:08,791 INFO misc.py line 113 3298914] Train: [2/100][941/2402] Data 0.004 (0.004) Batch 0.490 (0.483) Remain 31:48:39 loss: 1.5397 Lr: 0.00052
[2025-04-08 14:19:09,379 INFO misc.py line 113 3298914] Train: [2/100][942/2402] Data 0.004 (0.004) Batch 0.588 (0.484) Remain 31:49:05 loss: 1.4499 Lr: 0.00052
[2025-04-08 14:19:09,773 INFO misc.py line 113 3298914] Train: [2/100][943/2402] Data 0.004 (0.004) Batch 0.394 (0.484) Remain 31:48:42 loss: 1.3469 Lr: 0.00052
[2025-04-08 14:19:10,258 INFO misc.py line 113 3298914] Train: [2/100][944/2402] Data 0.003 (0.004) Batch 0.485 (0.484) Remain 31:48:42 loss: 1.3194 Lr: 0.00052
[2025-04-08 14:19:10,658 INFO misc.py line 113 3298914] Train: [2/100][945/2402] Data 0.004 (0.004) Batch 0.400 (0.483) Remain 31:48:20 loss: 1.4626 Lr: 0.00052
[2025-04-08 14:19:11,030 INFO misc.py line 113 3298914] Train: [2/100][946/2402] Data 0.003 (0.004) Batch 0.372 (0.483) Remain 31:47:52 loss: 1.4058 Lr: 0.00052
[2025-04-08 14:19:11,460 INFO misc.py line 113 3298914] Train: [2/100][947/2402] Data 0.003 (0.004) Batch 0.431 (0.483) Remain 31:47:38 loss: 1.2222 Lr: 0.00052
[2025-04-08 14:19:11,887 INFO misc.py line 113 3298914] Train: [2/100][948/2402] Data 0.003 (0.004) Batch 0.427 (0.483) Remain 31:47:24 loss: 1.3466 Lr: 0.00052
[2025-04-08 14:19:12,326 INFO misc.py line 113 3298914] Train: [2/100][949/2402] Data 0.004 (0.004) Batch 0.439 (0.483) Remain 31:47:12 loss: 1.0669 Lr: 0.00052
[2025-04-08 14:19:12,908 INFO misc.py line 113 3298914] Train: [2/100][950/2402] Data 0.004 (0.004) Batch 0.582 (0.483) Remain 31:47:36 loss: 1.5781 Lr: 0.00052
[2025-04-08 14:19:13,467 INFO misc.py line 113 3298914] Train: [2/100][951/2402] Data 0.004 (0.004) Batch 0.559 (0.483) Remain 31:47:55 loss: 1.1349 Lr: 0.00052
[2025-04-08 14:19:13,911 INFO misc.py line 113 3298914] Train: [2/100][952/2402] Data 0.003 (0.004) Batch 0.443 (0.483) Remain 31:47:44 loss: 1.2136 Lr: 0.00052
[2025-04-08 14:19:14,446 INFO misc.py line 113 3298914] Train: [2/100][953/2402] Data 0.004 (0.004) Batch 0.536 (0.483) Remain 31:47:57 loss: 1.1218 Lr: 0.00052
[2025-04-08 14:19:14,926 INFO misc.py line 113 3298914] Train: [2/100][954/2402] Data 0.003 (0.004) Batch 0.479 (0.483) Remain 31:47:55 loss: 1.4748 Lr: 0.00052
[2025-04-08 14:19:15,376 INFO misc.py line 113 3298914] Train: [2/100][955/2402] Data 0.004 (0.004) Batch 0.450 (0.483) Remain 31:47:47 loss: 1.2949 Lr: 0.00052
[2025-04-08 14:19:15,888 INFO misc.py line 113 3298914] Train: [2/100][956/2402] Data 0.004 (0.004) Batch 0.512 (0.483) Remain 31:47:53 loss: 1.1801 Lr: 0.00052
[2025-04-08 14:19:16,333 INFO misc.py line 113 3298914] Train: [2/100][957/2402] Data 0.004 (0.004) Batch 0.445 (0.483) Remain 31:47:43 loss: 1.4724 Lr: 0.00052
[2025-04-08 14:19:16,856 INFO misc.py line 113 3298914] Train: [2/100][958/2402] Data 0.003 (0.004) Batch 0.523 (0.483) Remain 31:47:53 loss: 1.2478 Lr: 0.00053
[2025-04-08 14:19:17,358 INFO misc.py line 113 3298914] Train: [2/100][959/2402] Data 0.004 (0.004) Batch 0.502 (0.483) Remain 31:47:57 loss: 1.3519 Lr: 0.00053
[2025-04-08 14:19:17,884 INFO misc.py line 113 3298914] Train: [2/100][960/2402] Data 0.004 (0.004) Batch 0.526 (0.483) Remain 31:48:07 loss: 1.0006 Lr: 0.00053
[2025-04-08 14:19:18,385 INFO misc.py line 113 3298914] Train: [2/100][961/2402] Data 0.004 (0.004) Batch 0.501 (0.483) Remain 31:48:11 loss: 1.3407 Lr: 0.00053
[2025-04-08 14:19:18,906 INFO misc.py line 113 3298914] Train: [2/100][962/2402] Data 0.004 (0.004) Batch 0.521 (0.483) Remain 31:48:20 loss: 1.6474 Lr: 0.00053
[2025-04-08 14:19:19,462 INFO misc.py line 113 3298914] Train: [2/100][963/2402] Data 0.004 (0.004) Batch 0.556 (0.484) Remain 31:48:37 loss: 1.4273 Lr: 0.00053
[2025-04-08 14:19:19,970 INFO misc.py line 113 3298914] Train: [2/100][964/2402] Data 0.003 (0.004) Batch 0.508 (0.484) Remain 31:48:43 loss: 1.1318 Lr: 0.00053
[2025-04-08 14:19:20,464 INFO misc.py line 113 3298914] Train: [2/100][965/2402] Data 0.003 (0.004) Batch 0.494 (0.484) Remain 31:48:45 loss: 1.2921 Lr: 0.00053
[2025-04-08 14:19:20,932 INFO misc.py line 113 3298914] Train: [2/100][966/2402] Data 0.004 (0.004) Batch 0.468 (0.484) Remain 31:48:40 loss: 1.3344 Lr: 0.00053
[2025-04-08 14:19:21,434 INFO misc.py line 113 3298914] Train: [2/100][967/2402] Data 0.004 (0.004) Batch 0.502 (0.484) Remain 31:48:44 loss: 1.3124 Lr: 0.00053
[2025-04-08 14:19:21,841 INFO misc.py line 113 3298914] Train: [2/100][968/2402] Data 0.004 (0.004) Batch 0.407 (0.483) Remain 31:48:25 loss: 1.1447 Lr: 0.00053
[2025-04-08 14:19:22,319 INFO misc.py line 113 3298914] Train: [2/100][969/2402] Data 0.004 (0.004) Batch 0.478 (0.483) Remain 31:48:23 loss: 1.3967 Lr: 0.00053
[2025-04-08 14:19:22,740 INFO misc.py line 113 3298914] Train: [2/100][970/2402] Data 0.003 (0.004) Batch 0.420 (0.483) Remain 31:48:07 loss: 1.0344 Lr: 0.00053
[2025-04-08 14:19:23,217 INFO misc.py line 113 3298914] Train: [2/100][971/2402] Data 0.004 (0.004) Batch 0.477 (0.483) Remain 31:48:05 loss: 1.2610 Lr: 0.00053
[2025-04-08 14:19:23,767 INFO misc.py line 113 3298914] Train: [2/100][972/2402] Data 0.004 (0.004) Batch 0.551 (0.483) Remain 31:48:21 loss: 1.4339 Lr: 0.00053
[2025-04-08 14:19:24,204 INFO misc.py line 113 3298914] Train: [2/100][973/2402] Data 0.003 (0.004) Batch 0.436 (0.483) Remain 31:48:09 loss: 1.0790 Lr: 0.00053
[2025-04-08 14:19:24,607 INFO misc.py line 113 3298914] Train: [2/100][974/2402] Data 0.003 (0.004) Batch 0.404 (0.483) Remain 31:47:49 loss: 1.0264 Lr: 0.00053
[2025-04-08 14:19:25,099 INFO misc.py line 113 3298914] Train: [2/100][975/2402] Data 0.003 (0.004) Batch 0.491 (0.483) Remain 31:47:51 loss: 1.3548 Lr: 0.00053
[2025-04-08 14:19:25,594 INFO misc.py line 113 3298914] Train: [2/100][976/2402] Data 0.004 (0.004) Batch 0.495 (0.483) Remain 31:47:53 loss: 1.4060 Lr: 0.00053
[2025-04-08 14:19:26,126 INFO misc.py line 113 3298914] Train: [2/100][977/2402] Data 0.004 (0.004) Batch 0.533 (0.483) Remain 31:48:05 loss: 1.3272 Lr: 0.00053
[2025-04-08 14:19:26,657 INFO misc.py line 113 3298914] Train: [2/100][978/2402] Data 0.003 (0.004) Batch 0.531 (0.483) Remain 31:48:16 loss: 1.4932 Lr: 0.00053
[2025-04-08 14:19:27,101 INFO misc.py line 113 3298914] Train: [2/100][979/2402] Data 0.004 (0.004) Batch 0.444 (0.483) Remain 31:48:06 loss: 1.6109 Lr: 0.00053
[2025-04-08 14:19:27,499 INFO misc.py line 113 3298914] Train: [2/100][980/2402] Data 0.004 (0.004) Batch 0.398 (0.483) Remain 31:47:44 loss: 1.1385 Lr: 0.00053
[2025-04-08 14:19:27,941 INFO misc.py line 113 3298914] Train: [2/100][981/2402] Data 0.004 (0.004) Batch 0.443 (0.483) Remain 31:47:34 loss: 0.9760 Lr: 0.00053
[2025-04-08 14:19:28,239 INFO misc.py line 113 3298914] Train: [2/100][982/2402] Data 0.004 (0.004) Batch 0.297 (0.483) Remain 31:46:48 loss: 1.0799 Lr: 0.00053
[2025-04-08 14:19:28,712 INFO misc.py line 113 3298914] Train: [2/100][983/2402] Data 0.004 (0.004) Batch 0.473 (0.483) Remain 31:46:45 loss: 1.4057 Lr: 0.00053
[2025-04-08 14:19:29,207 INFO misc.py line 113 3298914] Train: [2/100][984/2402] Data 0.004 (0.004) Batch 0.496 (0.483) Remain 31:46:48 loss: 1.3328 Lr: 0.00053
[2025-04-08 14:19:29,703 INFO misc.py line 113 3298914] Train: [2/100][985/2402] Data 0.004 (0.004) Batch 0.495 (0.483) Remain 31:46:50 loss: 1.4440 Lr: 0.00053
[2025-04-08 14:19:30,160 INFO misc.py line 113 3298914] Train: [2/100][986/2402] Data 0.004 (0.004) Batch 0.457 (0.483) Remain 31:46:44 loss: 1.4095 Lr: 0.00053
[2025-04-08 14:19:30,631 INFO misc.py line 113 3298914] Train: [2/100][987/2402] Data 0.003 (0.004) Batch 0.471 (0.483) Remain 31:46:40 loss: 1.4881 Lr: 0.00053
[2025-04-08 14:19:31,093 INFO misc.py line 113 3298914] Train: [2/100][988/2402] Data 0.004 (0.004) Batch 0.462 (0.483) Remain 31:46:35 loss: 1.4647 Lr: 0.00053
[2025-04-08 14:19:31,608 INFO misc.py line 113 3298914] Train: [2/100][989/2402] Data 0.003 (0.004) Batch 0.515 (0.483) Remain 31:46:42 loss: 1.4665 Lr: 0.00053
[2025-04-08 14:19:32,142 INFO misc.py line 113 3298914] Train: [2/100][990/2402] Data 0.004 (0.004) Batch 0.534 (0.483) Remain 31:46:54 loss: 2.1678 Lr: 0.00053
[2025-04-08 14:19:32,704 INFO misc.py line 113 3298914] Train: [2/100][991/2402] Data 0.004 (0.004) Batch 0.561 (0.483) Remain 31:47:12 loss: 1.5232 Lr: 0.00053
[2025-04-08 14:19:33,096 INFO misc.py line 113 3298914] Train: [2/100][992/2402] Data 0.004 (0.004) Batch 0.392 (0.483) Remain 31:46:50 loss: 1.4972 Lr: 0.00053
[2025-04-08 14:19:33,556 INFO misc.py line 113 3298914] Train: [2/100][993/2402] Data 0.004 (0.004) Batch 0.461 (0.483) Remain 31:46:44 loss: 1.2671 Lr: 0.00053
[2025-04-08 14:19:34,016 INFO misc.py line 113 3298914] Train: [2/100][994/2402] Data 0.003 (0.004) Batch 0.459 (0.483) Remain 31:46:38 loss: 1.6883 Lr: 0.00053
[2025-04-08 14:19:34,424 INFO misc.py line 113 3298914] Train: [2/100][995/2402] Data 0.003 (0.004) Batch 0.409 (0.483) Remain 31:46:20 loss: 1.2349 Lr: 0.00053
[2025-04-08 14:19:34,849 INFO misc.py line 113 3298914] Train: [2/100][996/2402] Data 0.003 (0.004) Batch 0.424 (0.483) Remain 31:46:05 loss: 1.3093 Lr: 0.00053
[2025-04-08 14:19:35,277 INFO misc.py line 113 3298914] Train: [2/100][997/2402] Data 0.003 (0.004) Batch 0.428 (0.483) Remain 31:45:51 loss: 1.0501 Lr: 0.00053
[2025-04-08 14:19:35,825 INFO misc.py line 113 3298914] Train: [2/100][998/2402] Data 0.004 (0.004) Batch 0.549 (0.483) Remain 31:46:07 loss: 1.6124 Lr: 0.00053
[2025-04-08 14:19:36,324 INFO misc.py line 113 3298914] Train: [2/100][999/2402] Data 0.004 (0.004) Batch 0.499 (0.483) Remain 31:46:10 loss: 1.4465 Lr: 0.00053
[2025-04-08 14:19:36,797 INFO misc.py line 113 3298914] Train: [2/100][1000/2402] Data 0.003 (0.004) Batch 0.473 (0.483) Remain 31:46:07 loss: 1.1592 Lr: 0.00053
[2025-04-08 14:19:37,352 INFO misc.py line 113 3298914] Train: [2/100][1001/2402] Data 0.004 (0.004) Batch 0.555 (0.483) Remain 31:46:24 loss: 1.4568 Lr: 0.00053
[2025-04-08 14:19:37,724 INFO misc.py line 113 3298914] Train: [2/100][1002/2402] Data 0.004 (0.004) Batch 0.373 (0.483) Remain 31:45:57 loss: 1.6175 Lr: 0.00053
[2025-04-08 14:19:38,280 INFO misc.py line 113 3298914] Train: [2/100][1003/2402] Data 0.004 (0.004) Batch 0.555 (0.483) Remain 31:46:14 loss: 1.3207 Lr: 0.00053
[2025-04-08 14:19:38,813 INFO misc.py line 113 3298914] Train: [2/100][1004/2402] Data 0.003 (0.004) Batch 0.533 (0.483) Remain 31:46:25 loss: 1.6141 Lr: 0.00053
[2025-04-08 14:19:39,408 INFO misc.py line 113 3298914] Train: [2/100][1005/2402] Data 0.004 (0.004) Batch 0.595 (0.483) Remain 31:46:51 loss: 1.4035 Lr: 0.00053
[2025-04-08 14:19:39,946 INFO misc.py line 113 3298914] Train: [2/100][1006/2402] Data 0.004 (0.004) Batch 0.538 (0.483) Remain 31:47:03 loss: 1.0559 Lr: 0.00053
[2025-04-08 14:19:40,344 INFO misc.py line 113 3298914] Train: [2/100][1007/2402] Data 0.004 (0.004) Batch 0.398 (0.483) Remain 31:46:43 loss: 1.4180 Lr: 0.00053
[2025-04-08 14:19:40,875 INFO misc.py line 113 3298914] Train: [2/100][1008/2402] Data 0.003 (0.004) Batch 0.532 (0.483) Remain 31:46:54 loss: 1.1887 Lr: 0.00053
[2025-04-08 14:19:41,329 INFO misc.py line 113 3298914] Train: [2/100][1009/2402] Data 0.004 (0.004) Batch 0.453 (0.483) Remain 31:46:46 loss: 0.9799 Lr: 0.00053
[2025-04-08 14:19:41,801 INFO misc.py line 113 3298914] Train: [2/100][1010/2402] Data 0.004 (0.004) Batch 0.472 (0.483) Remain 31:46:43 loss: 1.1488 Lr: 0.00053
[2025-04-08 14:19:42,349 INFO misc.py line 113 3298914] Train: [2/100][1011/2402] Data 0.003 (0.004) Batch 0.548 (0.483) Remain 31:46:58 loss: 1.4165 Lr: 0.00053
[2025-04-08 14:19:42,865 INFO misc.py line 113 3298914] Train: [2/100][1012/2402] Data 0.004 (0.004) Batch 0.516 (0.483) Remain 31:47:05 loss: 1.2616 Lr: 0.00053
[2025-04-08 14:19:43,198 INFO misc.py line 113 3298914] Train: [2/100][1013/2402] Data 0.003 (0.004) Batch 0.333 (0.483) Remain 31:46:30 loss: 1.1382 Lr: 0.00054
[2025-04-08 14:19:43,644 INFO misc.py line 113 3298914] Train: [2/100][1014/2402] Data 0.004 (0.004) Batch 0.446 (0.483) Remain 31:46:20 loss: 1.3888 Lr: 0.00054
[2025-04-08 14:19:44,218 INFO misc.py line 113 3298914] Train: [2/100][1015/2402] Data 0.004 (0.004) Batch 0.574 (0.483) Remain 31:46:41 loss: 1.4265 Lr: 0.00054
[2025-04-08 14:19:44,613 INFO misc.py line 113 3298914] Train: [2/100][1016/2402] Data 0.003 (0.004) Batch 0.395 (0.483) Remain 31:46:20 loss: 1.2694 Lr: 0.00054
[2025-04-08 14:19:45,108 INFO misc.py line 113 3298914] Train: [2/100][1017/2402] Data 0.003 (0.004) Batch 0.494 (0.483) Remain 31:46:22 loss: 1.6124 Lr: 0.00054
[2025-04-08 14:19:45,537 INFO misc.py line 113 3298914] Train: [2/100][1018/2402] Data 0.004 (0.004) Batch 0.430 (0.483) Remain 31:46:09 loss: 1.3215 Lr: 0.00054
[2025-04-08 14:19:45,960 INFO misc.py line 113 3298914] Train: [2/100][1019/2402] Data 0.003 (0.004) Batch 0.422 (0.483) Remain 31:45:55 loss: 1.2293 Lr: 0.00054
[2025-04-08 14:19:46,388 INFO misc.py line 113 3298914] Train: [2/100][1020/2402] Data 0.004 (0.004) Batch 0.429 (0.483) Remain 31:45:41 loss: 1.1218 Lr: 0.00054
[2025-04-08 14:19:46,879 INFO misc.py line 113 3298914] Train: [2/100][1021/2402] Data 0.003 (0.004) Batch 0.491 (0.483) Remain 31:45:43 loss: 1.1964 Lr: 0.00054
[2025-04-08 14:19:47,400 INFO misc.py line 113 3298914] Train: [2/100][1022/2402] Data 0.004 (0.004) Batch 0.521 (0.483) Remain 31:45:51 loss: 1.2988 Lr: 0.00054
[2025-04-08 14:19:47,795 INFO misc.py line 113 3298914] Train: [2/100][1023/2402] Data 0.004 (0.004) Batch 0.395 (0.483) Remain 31:45:30 loss: 1.0929 Lr: 0.00054
[2025-04-08 14:19:48,239 INFO misc.py line 113 3298914] Train: [2/100][1024/2402] Data 0.003 (0.004) Batch 0.444 (0.483) Remain 31:45:21 loss: 1.4412 Lr: 0.00054
[2025-04-08 14:19:48,629 INFO misc.py line 113 3298914] Train: [2/100][1025/2402] Data 0.004 (0.004) Batch 0.390 (0.483) Remain 31:44:59 loss: 2.1618 Lr: 0.00054
[2025-04-08 14:19:49,119 INFO misc.py line 113 3298914] Train: [2/100][1026/2402] Data 0.004 (0.004) Batch 0.490 (0.483) Remain 31:45:00 loss: 1.2741 Lr: 0.00054
[2025-04-08 14:19:49,620 INFO misc.py line 113 3298914] Train: [2/100][1027/2402] Data 0.004 (0.004) Batch 0.501 (0.483) Remain 31:45:04 loss: 1.6615 Lr: 0.00054
[2025-04-08 14:19:50,020 INFO misc.py line 113 3298914] Train: [2/100][1028/2402] Data 0.004 (0.004) Batch 0.401 (0.483) Remain 31:44:44 loss: 1.1638 Lr: 0.00054
[2025-04-08 14:19:50,502 INFO misc.py line 113 3298914] Train: [2/100][1029/2402] Data 0.004 (0.004) Batch 0.481 (0.483) Remain 31:44:43 loss: 1.2064 Lr: 0.00054
[2025-04-08 14:19:51,021 INFO misc.py line 113 3298914] Train: [2/100][1030/2402] Data 0.003 (0.004) Batch 0.519 (0.483) Remain 31:44:51 loss: 1.0262 Lr: 0.00054
[2025-04-08 14:19:51,459 INFO misc.py line 113 3298914] Train: [2/100][1031/2402] Data 0.003 (0.004) Batch 0.437 (0.483) Remain 31:44:41 loss: 1.3887 Lr: 0.00054
[2025-04-08 14:19:51,956 INFO misc.py line 113 3298914] Train: [2/100][1032/2402] Data 0.004 (0.004) Batch 0.497 (0.483) Remain 31:44:43 loss: 1.2033 Lr: 0.00054
[2025-04-08 14:19:52,483 INFO misc.py line 113 3298914] Train: [2/100][1033/2402] Data 0.003 (0.004) Batch 0.528 (0.483) Remain 31:44:53 loss: 1.2258 Lr: 0.00054
[2025-04-08 14:19:52,961 INFO misc.py line 113 3298914] Train: [2/100][1034/2402] Data 0.004 (0.004) Batch 0.478 (0.483) Remain 31:44:51 loss: 1.3884 Lr: 0.00054
[2025-04-08 14:19:53,493 INFO misc.py line 113 3298914] Train: [2/100][1035/2402] Data 0.003 (0.004) Batch 0.533 (0.483) Remain 31:45:02 loss: 1.3074 Lr: 0.00054
[2025-04-08 14:19:53,977 INFO misc.py line 113 3298914] Train: [2/100][1036/2402] Data 0.004 (0.004) Batch 0.483 (0.483) Remain 31:45:02 loss: 1.3274 Lr: 0.00054
[2025-04-08 14:19:54,477 INFO misc.py line 113 3298914] Train: [2/100][1037/2402] Data 0.003 (0.004) Batch 0.500 (0.483) Remain 31:45:06 loss: 1.5969 Lr: 0.00054
[2025-04-08 14:19:54,920 INFO misc.py line 113 3298914] Train: [2/100][1038/2402] Data 0.004 (0.004) Batch 0.443 (0.483) Remain 31:44:56 loss: 1.2003 Lr: 0.00054
[2025-04-08 14:19:55,368 INFO misc.py line 113 3298914] Train: [2/100][1039/2402] Data 0.004 (0.004) Batch 0.449 (0.483) Remain 31:44:48 loss: 1.3188 Lr: 0.00054
[2025-04-08 14:19:55,841 INFO misc.py line 113 3298914] Train: [2/100][1040/2402] Data 0.003 (0.004) Batch 0.473 (0.483) Remain 31:44:45 loss: 1.5700 Lr: 0.00054
[2025-04-08 14:19:56,368 INFO misc.py line 113 3298914] Train: [2/100][1041/2402] Data 0.004 (0.004) Batch 0.526 (0.483) Remain 31:44:54 loss: 1.2829 Lr: 0.00054
[2025-04-08 14:19:56,907 INFO misc.py line 113 3298914] Train: [2/100][1042/2402] Data 0.004 (0.004) Batch 0.540 (0.483) Remain 31:45:07 loss: 1.2822 Lr: 0.00054
[2025-04-08 14:19:57,340 INFO misc.py line 113 3298914] Train: [2/100][1043/2402] Data 0.003 (0.004) Batch 0.433 (0.483) Remain 31:44:55 loss: 1.4998 Lr: 0.00054
[2025-04-08 14:19:57,800 INFO misc.py line 113 3298914] Train: [2/100][1044/2402] Data 0.004 (0.004) Batch 0.460 (0.483) Remain 31:44:49 loss: 1.1499 Lr: 0.00054
[2025-04-08 14:19:58,336 INFO misc.py line 113 3298914] Train: [2/100][1045/2402] Data 0.004 (0.004) Batch 0.535 (0.483) Remain 31:45:01 loss: 1.3793 Lr: 0.00054
[2025-04-08 14:19:58,779 INFO misc.py line 113 3298914] Train: [2/100][1046/2402] Data 0.004 (0.004) Batch 0.443 (0.483) Remain 31:44:51 loss: 1.5837 Lr: 0.00054
[2025-04-08 14:19:59,254 INFO misc.py line 113 3298914] Train: [2/100][1047/2402] Data 0.004 (0.004) Batch 0.476 (0.483) Remain 31:44:49 loss: 1.0485 Lr: 0.00054
[2025-04-08 14:19:59,704 INFO misc.py line 113 3298914] Train: [2/100][1048/2402] Data 0.004 (0.004) Batch 0.449 (0.483) Remain 31:44:41 loss: 1.2930 Lr: 0.00054
[2025-04-08 14:20:00,140 INFO misc.py line 113 3298914] Train: [2/100][1049/2402] Data 0.004 (0.004) Batch 0.436 (0.483) Remain 31:44:30 loss: 1.2203 Lr: 0.00054
[2025-04-08 14:20:00,564 INFO misc.py line 113 3298914] Train: [2/100][1050/2402] Data 0.004 (0.004) Batch 0.424 (0.483) Remain 31:44:16 loss: 1.4445 Lr: 0.00054
[2025-04-08 14:20:01,125 INFO misc.py line 113 3298914] Train: [2/100][1051/2402] Data 0.004 (0.004) Batch 0.561 (0.483) Remain 31:44:34 loss: 1.2338 Lr: 0.00054
[2025-04-08 14:20:01,618 INFO misc.py line 113 3298914] Train: [2/100][1052/2402] Data 0.004 (0.004) Batch 0.494 (0.483) Remain 31:44:36 loss: 1.1924 Lr: 0.00054
[2025-04-08 14:20:02,126 INFO misc.py line 113 3298914] Train: [2/100][1053/2402] Data 0.004 (0.004) Batch 0.508 (0.483) Remain 31:44:41 loss: 1.5186 Lr: 0.00054
[2025-04-08 14:20:02,468 INFO misc.py line 113 3298914] Train: [2/100][1054/2402] Data 0.003 (0.004) Batch 0.342 (0.483) Remain 31:44:09 loss: 1.1589 Lr: 0.00054
[2025-04-08 14:20:02,912 INFO misc.py line 113 3298914] Train: [2/100][1055/2402] Data 0.003 (0.004) Batch 0.444 (0.483) Remain 31:44:00 loss: 0.7829 Lr: 0.00054
[2025-04-08 14:20:03,395 INFO misc.py line 113 3298914] Train: [2/100][1056/2402] Data 0.004 (0.004) Batch 0.483 (0.483) Remain 31:43:59 loss: 1.5832 Lr: 0.00054
[2025-04-08 14:20:03,900 INFO misc.py line 113 3298914] Train: [2/100][1057/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:44:04 loss: 1.6882 Lr: 0.00054
[2025-04-08 14:20:04,286 INFO misc.py line 113 3298914] Train: [2/100][1058/2402] Data 0.004 (0.004) Batch 0.387 (0.482) Remain 31:43:42 loss: 1.5529 Lr: 0.00054
[2025-04-08 14:20:04,809 INFO misc.py line 113 3298914] Train: [2/100][1059/2402] Data 0.004 (0.004) Batch 0.523 (0.483) Remain 31:43:50 loss: 1.3039 Lr: 0.00054
[2025-04-08 14:20:05,267 INFO misc.py line 113 3298914] Train: [2/100][1060/2402] Data 0.003 (0.004) Batch 0.458 (0.482) Remain 31:43:44 loss: 1.6949 Lr: 0.00054
[2025-04-08 14:20:05,663 INFO misc.py line 113 3298914] Train: [2/100][1061/2402] Data 0.003 (0.004) Batch 0.396 (0.482) Remain 31:43:24 loss: 1.3178 Lr: 0.00054
[2025-04-08 14:20:06,214 INFO misc.py line 113 3298914] Train: [2/100][1062/2402] Data 0.003 (0.004) Batch 0.552 (0.482) Remain 31:43:39 loss: 1.6233 Lr: 0.00054
[2025-04-08 14:20:06,627 INFO misc.py line 113 3298914] Train: [2/100][1063/2402] Data 0.003 (0.004) Batch 0.412 (0.482) Remain 31:43:23 loss: 1.8333 Lr: 0.00054
[2025-04-08 14:20:07,028 INFO misc.py line 113 3298914] Train: [2/100][1064/2402] Data 0.004 (0.004) Batch 0.401 (0.482) Remain 31:43:04 loss: 1.1929 Lr: 0.00054
[2025-04-08 14:20:07,587 INFO misc.py line 113 3298914] Train: [2/100][1065/2402] Data 0.004 (0.004) Batch 0.560 (0.482) Remain 31:43:21 loss: 1.1391 Lr: 0.00054
[2025-04-08 14:20:08,212 INFO misc.py line 113 3298914] Train: [2/100][1066/2402] Data 0.004 (0.004) Batch 0.625 (0.483) Remain 31:43:52 loss: 1.5981 Lr: 0.00054
[2025-04-08 14:20:08,576 INFO misc.py line 113 3298914] Train: [2/100][1067/2402] Data 0.004 (0.004) Batch 0.364 (0.482) Remain 31:43:26 loss: 1.0995 Lr: 0.00055
[2025-04-08 14:20:09,039 INFO misc.py line 113 3298914] Train: [2/100][1068/2402] Data 0.003 (0.004) Batch 0.463 (0.482) Remain 31:43:21 loss: 1.4319 Lr: 0.00055
[2025-04-08 14:20:09,702 INFO misc.py line 113 3298914] Train: [2/100][1069/2402] Data 0.004 (0.004) Batch 0.664 (0.483) Remain 31:44:00 loss: 1.1420 Lr: 0.00055
[2025-04-08 14:20:10,156 INFO misc.py line 113 3298914] Train: [2/100][1070/2402] Data 0.004 (0.004) Batch 0.454 (0.483) Remain 31:43:54 loss: 1.3548 Lr: 0.00055
[2025-04-08 14:20:10,504 INFO misc.py line 113 3298914] Train: [2/100][1071/2402] Data 0.003 (0.004) Batch 0.348 (0.482) Remain 31:43:23 loss: 1.1039 Lr: 0.00055
[2025-04-08 14:20:11,008 INFO misc.py line 113 3298914] Train: [2/100][1072/2402] Data 0.003 (0.004) Batch 0.504 (0.482) Remain 31:43:28 loss: 1.3176 Lr: 0.00055
[2025-04-08 14:20:11,508 INFO misc.py line 113 3298914] Train: [2/100][1073/2402] Data 0.004 (0.004) Batch 0.500 (0.482) Remain 31:43:31 loss: 1.4070 Lr: 0.00055
[2025-04-08 14:20:11,972 INFO misc.py line 113 3298914] Train: [2/100][1074/2402] Data 0.003 (0.004) Batch 0.464 (0.482) Remain 31:43:26 loss: 1.5232 Lr: 0.00055
[2025-04-08 14:20:12,479 INFO misc.py line 113 3298914] Train: [2/100][1075/2402] Data 0.004 (0.004) Batch 0.507 (0.482) Remain 31:43:31 loss: 1.3104 Lr: 0.00055
[2025-04-08 14:20:12,960 INFO misc.py line 113 3298914] Train: [2/100][1076/2402] Data 0.003 (0.004) Batch 0.480 (0.482) Remain 31:43:30 loss: 1.0963 Lr: 0.00055
[2025-04-08 14:20:13,463 INFO misc.py line 113 3298914] Train: [2/100][1077/2402] Data 0.004 (0.004) Batch 0.504 (0.482) Remain 31:43:35 loss: 1.3799 Lr: 0.00055
[2025-04-08 14:20:13,960 INFO misc.py line 113 3298914] Train: [2/100][1078/2402] Data 0.004 (0.004) Batch 0.496 (0.483) Remain 31:43:37 loss: 1.3922 Lr: 0.00055
[2025-04-08 14:20:14,432 INFO misc.py line 113 3298914] Train: [2/100][1079/2402] Data 0.004 (0.004) Batch 0.473 (0.482) Remain 31:43:35 loss: 1.2425 Lr: 0.00055
[2025-04-08 14:20:14,879 INFO misc.py line 113 3298914] Train: [2/100][1080/2402] Data 0.004 (0.004) Batch 0.446 (0.482) Remain 31:43:26 loss: 1.4041 Lr: 0.00055
[2025-04-08 14:20:15,433 INFO misc.py line 113 3298914] Train: [2/100][1081/2402] Data 0.016 (0.004) Batch 0.554 (0.483) Remain 31:43:41 loss: 1.6620 Lr: 0.00055
[2025-04-08 14:20:15,964 INFO misc.py line 113 3298914] Train: [2/100][1082/2402] Data 0.004 (0.004) Batch 0.531 (0.483) Remain 31:43:52 loss: 1.2809 Lr: 0.00055
[2025-04-08 14:20:16,469 INFO misc.py line 113 3298914] Train: [2/100][1083/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:43:56 loss: 1.4105 Lr: 0.00055
[2025-04-08 14:20:16,956 INFO misc.py line 113 3298914] Train: [2/100][1084/2402] Data 0.004 (0.004) Batch 0.488 (0.483) Remain 31:43:56 loss: 1.6030 Lr: 0.00055
[2025-04-08 14:20:17,427 INFO misc.py line 113 3298914] Train: [2/100][1085/2402] Data 0.004 (0.004) Batch 0.471 (0.483) Remain 31:43:53 loss: 1.5801 Lr: 0.00055
[2025-04-08 14:20:17,869 INFO misc.py line 113 3298914] Train: [2/100][1086/2402] Data 0.003 (0.004) Batch 0.442 (0.483) Remain 31:43:44 loss: 0.9676 Lr: 0.00055
[2025-04-08 14:20:18,263 INFO misc.py line 113 3298914] Train: [2/100][1087/2402] Data 0.004 (0.004) Batch 0.395 (0.482) Remain 31:43:24 loss: 1.2244 Lr: 0.00055
[2025-04-08 14:20:18,772 INFO misc.py line 113 3298914] Train: [2/100][1088/2402] Data 0.004 (0.004) Batch 0.508 (0.482) Remain 31:43:30 loss: 1.2622 Lr: 0.00055
[2025-04-08 14:20:19,275 INFO misc.py line 113 3298914] Train: [2/100][1089/2402] Data 0.004 (0.004) Batch 0.503 (0.483) Remain 31:43:34 loss: 1.3680 Lr: 0.00055
[2025-04-08 14:20:19,788 INFO misc.py line 113 3298914] Train: [2/100][1090/2402] Data 0.004 (0.004) Batch 0.513 (0.483) Remain 31:43:40 loss: 1.6790 Lr: 0.00055
[2025-04-08 14:20:20,279 INFO misc.py line 113 3298914] Train: [2/100][1091/2402] Data 0.003 (0.004) Batch 0.491 (0.483) Remain 31:43:41 loss: 1.1490 Lr: 0.00055
[2025-04-08 14:20:20,792 INFO misc.py line 113 3298914] Train: [2/100][1092/2402] Data 0.004 (0.004) Batch 0.513 (0.483) Remain 31:43:47 loss: 1.4046 Lr: 0.00055
[2025-04-08 14:20:21,371 INFO misc.py line 113 3298914] Train: [2/100][1093/2402] Data 0.004 (0.004) Batch 0.579 (0.483) Remain 31:44:08 loss: 1.5449 Lr: 0.00055
[2025-04-08 14:20:21,879 INFO misc.py line 113 3298914] Train: [2/100][1094/2402] Data 0.004 (0.004) Batch 0.508 (0.483) Remain 31:44:13 loss: 1.3795 Lr: 0.00055
[2025-04-08 14:20:22,371 INFO misc.py line 113 3298914] Train: [2/100][1095/2402] Data 0.003 (0.004) Batch 0.492 (0.483) Remain 31:44:14 loss: 1.5923 Lr: 0.00055
[2025-04-08 14:20:22,868 INFO misc.py line 113 3298914] Train: [2/100][1096/2402] Data 0.003 (0.004) Batch 0.497 (0.483) Remain 31:44:17 loss: 1.6385 Lr: 0.00055
[2025-04-08 14:20:23,289 INFO misc.py line 113 3298914] Train: [2/100][1097/2402] Data 0.004 (0.004) Batch 0.421 (0.483) Remain 31:44:03 loss: 1.3613 Lr: 0.00055
[2025-04-08 14:20:23,787 INFO misc.py line 113 3298914] Train: [2/100][1098/2402] Data 0.004 (0.004) Batch 0.498 (0.483) Remain 31:44:06 loss: 1.4770 Lr: 0.00055
[2025-04-08 14:20:24,144 INFO misc.py line 113 3298914] Train: [2/100][1099/2402] Data 0.003 (0.004) Batch 0.357 (0.483) Remain 31:43:38 loss: 0.9902 Lr: 0.00055
[2025-04-08 14:20:24,605 INFO misc.py line 113 3298914] Train: [2/100][1100/2402] Data 0.004 (0.004) Batch 0.462 (0.483) Remain 31:43:33 loss: 0.9430 Lr: 0.00055
[2025-04-08 14:20:25,076 INFO misc.py line 113 3298914] Train: [2/100][1101/2402] Data 0.004 (0.004) Batch 0.470 (0.483) Remain 31:43:30 loss: 0.9507 Lr: 0.00055
[2025-04-08 14:20:25,626 INFO misc.py line 113 3298914] Train: [2/100][1102/2402] Data 0.003 (0.004) Batch 0.551 (0.483) Remain 31:43:44 loss: 1.3953 Lr: 0.00055
[2025-04-08 14:20:26,134 INFO misc.py line 113 3298914] Train: [2/100][1103/2402] Data 0.004 (0.004) Batch 0.507 (0.483) Remain 31:43:49 loss: 1.4692 Lr: 0.00055
[2025-04-08 14:20:26,633 INFO misc.py line 113 3298914] Train: [2/100][1104/2402] Data 0.003 (0.004) Batch 0.499 (0.483) Remain 31:43:52 loss: 1.0907 Lr: 0.00055
[2025-04-08 14:20:27,130 INFO misc.py line 113 3298914] Train: [2/100][1105/2402] Data 0.003 (0.004) Batch 0.497 (0.483) Remain 31:43:55 loss: 1.3567 Lr: 0.00055
[2025-04-08 14:20:27,683 INFO misc.py line 113 3298914] Train: [2/100][1106/2402] Data 0.004 (0.004) Batch 0.553 (0.483) Remain 31:44:09 loss: 1.8230 Lr: 0.00055
[2025-04-08 14:20:28,189 INFO misc.py line 113 3298914] Train: [2/100][1107/2402] Data 0.003 (0.004) Batch 0.506 (0.483) Remain 31:44:14 loss: 1.2236 Lr: 0.00055
[2025-04-08 14:20:28,658 INFO misc.py line 113 3298914] Train: [2/100][1108/2402] Data 0.004 (0.004) Batch 0.469 (0.483) Remain 31:44:10 loss: 1.5261 Lr: 0.00055
[2025-04-08 14:20:29,174 INFO misc.py line 113 3298914] Train: [2/100][1109/2402] Data 0.003 (0.004) Batch 0.516 (0.483) Remain 31:44:17 loss: 1.1590 Lr: 0.00055
[2025-04-08 14:20:29,616 INFO misc.py line 113 3298914] Train: [2/100][1110/2402] Data 0.003 (0.004) Batch 0.443 (0.483) Remain 31:44:08 loss: 1.3234 Lr: 0.00055
[2025-04-08 14:20:30,077 INFO misc.py line 113 3298914] Train: [2/100][1111/2402] Data 0.004 (0.004) Batch 0.460 (0.483) Remain 31:44:03 loss: 1.1832 Lr: 0.00055
[2025-04-08 14:20:30,539 INFO misc.py line 113 3298914] Train: [2/100][1112/2402] Data 0.004 (0.004) Batch 0.463 (0.483) Remain 31:43:58 loss: 1.1262 Lr: 0.00055
[2025-04-08 14:20:30,892 INFO misc.py line 113 3298914] Train: [2/100][1113/2402] Data 0.004 (0.004) Batch 0.353 (0.483) Remain 31:43:30 loss: 1.0012 Lr: 0.00055
[2025-04-08 14:20:31,454 INFO misc.py line 113 3298914] Train: [2/100][1114/2402] Data 0.004 (0.004) Batch 0.562 (0.483) Remain 31:43:46 loss: 1.4004 Lr: 0.00055
[2025-04-08 14:20:31,802 INFO misc.py line 113 3298914] Train: [2/100][1115/2402] Data 0.003 (0.004) Batch 0.348 (0.482) Remain 31:43:17 loss: 1.1798 Lr: 0.00055
[2025-04-08 14:20:32,330 INFO misc.py line 113 3298914] Train: [2/100][1116/2402] Data 0.003 (0.004) Batch 0.528 (0.483) Remain 31:43:26 loss: 1.4166 Lr: 0.00055
[2025-04-08 14:20:32,807 INFO misc.py line 113 3298914] Train: [2/100][1117/2402] Data 0.004 (0.004) Batch 0.477 (0.483) Remain 31:43:25 loss: 1.2188 Lr: 0.00055
[2025-04-08 14:20:33,218 INFO misc.py line 113 3298914] Train: [2/100][1118/2402] Data 0.004 (0.004) Batch 0.411 (0.482) Remain 31:43:09 loss: 1.4324 Lr: 0.00055
[2025-04-08 14:20:33,732 INFO misc.py line 113 3298914] Train: [2/100][1119/2402] Data 0.004 (0.004) Batch 0.514 (0.482) Remain 31:43:15 loss: 1.0823 Lr: 0.00055
[2025-04-08 14:20:34,235 INFO misc.py line 113 3298914] Train: [2/100][1120/2402] Data 0.004 (0.004) Batch 0.503 (0.483) Remain 31:43:19 loss: 0.9477 Lr: 0.00055
[2025-04-08 14:20:34,730 INFO misc.py line 113 3298914] Train: [2/100][1121/2402] Data 0.003 (0.004) Batch 0.495 (0.483) Remain 31:43:21 loss: 1.0350 Lr: 0.00056
[2025-04-08 14:20:35,377 INFO misc.py line 113 3298914] Train: [2/100][1122/2402] Data 0.003 (0.004) Batch 0.647 (0.483) Remain 31:43:56 loss: 1.2428 Lr: 0.00056
[2025-04-08 14:20:35,881 INFO misc.py line 113 3298914] Train: [2/100][1123/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:44:00 loss: 1.2493 Lr: 0.00056
[2025-04-08 14:20:36,322 INFO misc.py line 113 3298914] Train: [2/100][1124/2402] Data 0.004 (0.004) Batch 0.441 (0.483) Remain 31:43:50 loss: 1.2026 Lr: 0.00056
[2025-04-08 14:20:36,693 INFO misc.py line 113 3298914] Train: [2/100][1125/2402] Data 0.004 (0.004) Batch 0.371 (0.483) Remain 31:43:26 loss: 1.4026 Lr: 0.00056
[2025-04-08 14:20:37,212 INFO misc.py line 113 3298914] Train: [2/100][1126/2402] Data 0.003 (0.004) Batch 0.519 (0.483) Remain 31:43:33 loss: 1.4295 Lr: 0.00056
[2025-04-08 14:20:37,606 INFO misc.py line 113 3298914] Train: [2/100][1127/2402] Data 0.004 (0.004) Batch 0.394 (0.483) Remain 31:43:14 loss: 1.2907 Lr: 0.00056
[2025-04-08 14:20:38,199 INFO misc.py line 113 3298914] Train: [2/100][1128/2402] Data 0.003 (0.004) Batch 0.593 (0.483) Remain 31:43:37 loss: 1.3437 Lr: 0.00056
[2025-04-08 14:20:38,648 INFO misc.py line 113 3298914] Train: [2/100][1129/2402] Data 0.004 (0.004) Batch 0.449 (0.483) Remain 31:43:30 loss: 1.2152 Lr: 0.00056
[2025-04-08 14:20:39,166 INFO misc.py line 113 3298914] Train: [2/100][1130/2402] Data 0.004 (0.004) Batch 0.518 (0.483) Remain 31:43:37 loss: 1.3789 Lr: 0.00056
[2025-04-08 14:20:39,635 INFO misc.py line 113 3298914] Train: [2/100][1131/2402] Data 0.004 (0.004) Batch 0.468 (0.483) Remain 31:43:33 loss: 1.2257 Lr: 0.00056
[2025-04-08 14:20:40,168 INFO misc.py line 113 3298914] Train: [2/100][1132/2402] Data 0.003 (0.004) Batch 0.534 (0.483) Remain 31:43:43 loss: 1.3729 Lr: 0.00056
[2025-04-08 14:20:40,667 INFO misc.py line 113 3298914] Train: [2/100][1133/2402] Data 0.004 (0.004) Batch 0.498 (0.483) Remain 31:43:46 loss: 1.2291 Lr: 0.00056
[2025-04-08 14:20:41,100 INFO misc.py line 113 3298914] Train: [2/100][1134/2402] Data 0.004 (0.004) Batch 0.433 (0.483) Remain 31:43:35 loss: 1.4316 Lr: 0.00056
[2025-04-08 14:20:41,548 INFO misc.py line 113 3298914] Train: [2/100][1135/2402] Data 0.004 (0.004) Batch 0.449 (0.483) Remain 31:43:28 loss: 1.1055 Lr: 0.00056
[2025-04-08 14:20:42,067 INFO misc.py line 113 3298914] Train: [2/100][1136/2402] Data 0.004 (0.004) Batch 0.519 (0.483) Remain 31:43:35 loss: 1.1468 Lr: 0.00056
[2025-04-08 14:20:42,455 INFO misc.py line 113 3298914] Train: [2/100][1137/2402] Data 0.004 (0.004) Batch 0.388 (0.483) Remain 31:43:14 loss: 1.5253 Lr: 0.00056
[2025-04-08 14:20:42,990 INFO misc.py line 113 3298914] Train: [2/100][1138/2402] Data 0.004 (0.004) Batch 0.536 (0.483) Remain 31:43:25 loss: 1.8200 Lr: 0.00056
[2025-04-08 14:20:43,416 INFO misc.py line 113 3298914] Train: [2/100][1139/2402] Data 0.004 (0.004) Batch 0.426 (0.483) Remain 31:43:13 loss: 1.4146 Lr: 0.00056
[2025-04-08 14:20:43,862 INFO misc.py line 113 3298914] Train: [2/100][1140/2402] Data 0.003 (0.004) Batch 0.446 (0.482) Remain 31:43:05 loss: 1.2345 Lr: 0.00056
[2025-04-08 14:20:44,377 INFO misc.py line 113 3298914] Train: [2/100][1141/2402] Data 0.004 (0.004) Batch 0.515 (0.483) Remain 31:43:11 loss: 1.3275 Lr: 0.00056
[2025-04-08 14:20:44,929 INFO misc.py line 113 3298914] Train: [2/100][1142/2402] Data 0.004 (0.004) Batch 0.553 (0.483) Remain 31:43:25 loss: 1.2114 Lr: 0.00056
[2025-04-08 14:20:45,432 INFO misc.py line 113 3298914] Train: [2/100][1143/2402] Data 0.004 (0.004) Batch 0.503 (0.483) Remain 31:43:29 loss: 1.5027 Lr: 0.00056
[2025-04-08 14:20:45,889 INFO misc.py line 113 3298914] Train: [2/100][1144/2402] Data 0.004 (0.004) Batch 0.457 (0.483) Remain 31:43:23 loss: 1.3118 Lr: 0.00056
[2025-04-08 14:20:46,315 INFO misc.py line 113 3298914] Train: [2/100][1145/2402] Data 0.003 (0.004) Batch 0.426 (0.483) Remain 31:43:10 loss: 1.3308 Lr: 0.00056
[2025-04-08 14:20:46,803 INFO misc.py line 113 3298914] Train: [2/100][1146/2402] Data 0.004 (0.004) Batch 0.488 (0.483) Remain 31:43:11 loss: 1.1877 Lr: 0.00056
[2025-04-08 14:20:47,232 INFO misc.py line 113 3298914] Train: [2/100][1147/2402] Data 0.004 (0.004) Batch 0.429 (0.482) Remain 31:43:00 loss: 1.3374 Lr: 0.00056
[2025-04-08 14:20:47,788 INFO misc.py line 113 3298914] Train: [2/100][1148/2402] Data 0.004 (0.004) Batch 0.556 (0.483) Remain 31:43:14 loss: 1.4867 Lr: 0.00056
[2025-04-08 14:20:48,316 INFO misc.py line 113 3298914] Train: [2/100][1149/2402] Data 0.004 (0.004) Batch 0.528 (0.483) Remain 31:43:23 loss: 1.4509 Lr: 0.00056
[2025-04-08 14:20:48,838 INFO misc.py line 113 3298914] Train: [2/100][1150/2402] Data 0.004 (0.004) Batch 0.521 (0.483) Remain 31:43:31 loss: 1.1332 Lr: 0.00056
[2025-04-08 14:20:49,349 INFO misc.py line 113 3298914] Train: [2/100][1151/2402] Data 0.004 (0.004) Batch 0.512 (0.483) Remain 31:43:36 loss: 1.2856 Lr: 0.00056
[2025-04-08 14:20:49,839 INFO misc.py line 113 3298914] Train: [2/100][1152/2402] Data 0.003 (0.004) Batch 0.489 (0.483) Remain 31:43:37 loss: 1.3381 Lr: 0.00056
[2025-04-08 14:20:50,349 INFO misc.py line 113 3298914] Train: [2/100][1153/2402] Data 0.004 (0.004) Batch 0.510 (0.483) Remain 31:43:42 loss: 1.3454 Lr: 0.00056
[2025-04-08 14:20:50,873 INFO misc.py line 113 3298914] Train: [2/100][1154/2402] Data 0.004 (0.004) Batch 0.525 (0.483) Remain 31:43:50 loss: 1.2289 Lr: 0.00056
[2025-04-08 14:20:51,377 INFO misc.py line 113 3298914] Train: [2/100][1155/2402] Data 0.004 (0.004) Batch 0.504 (0.483) Remain 31:43:54 loss: 1.3174 Lr: 0.00056
[2025-04-08 14:20:51,755 INFO misc.py line 113 3298914] Train: [2/100][1156/2402] Data 0.004 (0.004) Batch 0.379 (0.483) Remain 31:43:32 loss: 1.2758 Lr: 0.00056
[2025-04-08 14:20:52,240 INFO misc.py line 113 3298914] Train: [2/100][1157/2402] Data 0.004 (0.004) Batch 0.485 (0.483) Remain 31:43:32 loss: 1.3360 Lr: 0.00056
[2025-04-08 14:20:52,720 INFO misc.py line 113 3298914] Train: [2/100][1158/2402] Data 0.003 (0.004) Batch 0.479 (0.483) Remain 31:43:31 loss: 1.2635 Lr: 0.00056
[2025-04-08 14:20:53,262 INFO misc.py line 113 3298914] Train: [2/100][1159/2402] Data 0.004 (0.004) Batch 0.542 (0.483) Remain 31:43:43 loss: 1.4767 Lr: 0.00056
[2025-04-08 14:20:53,709 INFO misc.py line 113 3298914] Train: [2/100][1160/2402] Data 0.004 (0.004) Batch 0.447 (0.483) Remain 31:43:35 loss: 1.5931 Lr: 0.00056
[2025-04-08 14:20:54,238 INFO misc.py line 113 3298914] Train: [2/100][1161/2402] Data 0.003 (0.004) Batch 0.529 (0.483) Remain 31:43:44 loss: 1.3963 Lr: 0.00056
[2025-04-08 14:20:54,814 INFO misc.py line 113 3298914] Train: [2/100][1162/2402] Data 0.004 (0.004) Batch 0.577 (0.483) Remain 31:44:03 loss: 1.2657 Lr: 0.00056
[2025-04-08 14:20:55,313 INFO misc.py line 113 3298914] Train: [2/100][1163/2402] Data 0.004 (0.004) Batch 0.498 (0.483) Remain 31:44:05 loss: 1.2111 Lr: 0.00056
[2025-04-08 14:20:55,832 INFO misc.py line 113 3298914] Train: [2/100][1164/2402] Data 0.004 (0.004) Batch 0.520 (0.483) Remain 31:44:13 loss: 1.1186 Lr: 0.00056
[2025-04-08 14:20:56,326 INFO misc.py line 113 3298914] Train: [2/100][1165/2402] Data 0.004 (0.004) Batch 0.493 (0.483) Remain 31:44:14 loss: 1.2007 Lr: 0.00056
[2025-04-08 14:20:56,827 INFO misc.py line 113 3298914] Train: [2/100][1166/2402] Data 0.004 (0.004) Batch 0.501 (0.483) Remain 31:44:17 loss: 1.2792 Lr: 0.00056
[2025-04-08 14:20:57,374 INFO misc.py line 113 3298914] Train: [2/100][1167/2402] Data 0.004 (0.004) Batch 0.547 (0.483) Remain 31:44:30 loss: 1.4926 Lr: 0.00056
[2025-04-08 14:20:57,787 INFO misc.py line 113 3298914] Train: [2/100][1168/2402] Data 0.003 (0.004) Batch 0.413 (0.483) Remain 31:44:15 loss: 1.0881 Lr: 0.00056
[2025-04-08 14:20:58,183 INFO misc.py line 113 3298914] Train: [2/100][1169/2402] Data 0.004 (0.004) Batch 0.396 (0.483) Remain 31:43:57 loss: 1.3019 Lr: 0.00056
[2025-04-08 14:20:58,587 INFO misc.py line 113 3298914] Train: [2/100][1170/2402] Data 0.004 (0.004) Batch 0.404 (0.483) Remain 31:43:41 loss: 1.3405 Lr: 0.00056
[2025-04-08 14:20:59,018 INFO misc.py line 113 3298914] Train: [2/100][1171/2402] Data 0.003 (0.004) Batch 0.431 (0.483) Remain 31:43:30 loss: 1.1556 Lr: 0.00056
[2025-04-08 14:20:59,444 INFO misc.py line 113 3298914] Train: [2/100][1172/2402] Data 0.004 (0.004) Batch 0.426 (0.483) Remain 31:43:18 loss: 1.0192 Lr: 0.00056
[2025-04-08 14:20:59,890 INFO misc.py line 113 3298914] Train: [2/100][1173/2402] Data 0.004 (0.004) Batch 0.447 (0.483) Remain 31:43:10 loss: 1.8389 Lr: 0.00056
[2025-04-08 14:21:00,474 INFO misc.py line 113 3298914] Train: [2/100][1174/2402] Data 0.004 (0.004) Batch 0.583 (0.483) Remain 31:43:30 loss: 1.0341 Lr: 0.00057
[2025-04-08 14:21:00,923 INFO misc.py line 113 3298914] Train: [2/100][1175/2402] Data 0.004 (0.004) Batch 0.449 (0.483) Remain 31:43:23 loss: 1.3176 Lr: 0.00057
[2025-04-08 14:21:01,424 INFO misc.py line 113 3298914] Train: [2/100][1176/2402] Data 0.003 (0.004) Batch 0.501 (0.483) Remain 31:43:26 loss: 1.0987 Lr: 0.00057
[2025-04-08 14:21:01,884 INFO misc.py line 113 3298914] Train: [2/100][1177/2402] Data 0.003 (0.004) Batch 0.460 (0.483) Remain 31:43:21 loss: 1.2190 Lr: 0.00057
[2025-04-08 14:21:02,416 INFO misc.py line 113 3298914] Train: [2/100][1178/2402] Data 0.003 (0.004) Batch 0.532 (0.483) Remain 31:43:30 loss: 1.5717 Lr: 0.00057
[2025-04-08 14:21:02,951 INFO misc.py line 113 3298914] Train: [2/100][1179/2402] Data 0.003 (0.004) Batch 0.535 (0.483) Remain 31:43:40 loss: 1.3712 Lr: 0.00057
[2025-04-08 14:21:03,469 INFO misc.py line 113 3298914] Train: [2/100][1180/2402] Data 0.004 (0.004) Batch 0.517 (0.483) Remain 31:43:47 loss: 1.1067 Lr: 0.00057
[2025-04-08 14:21:03,981 INFO misc.py line 113 3298914] Train: [2/100][1181/2402] Data 0.004 (0.004) Batch 0.512 (0.483) Remain 31:43:52 loss: 0.9393 Lr: 0.00057
[2025-04-08 14:21:04,356 INFO misc.py line 113 3298914] Train: [2/100][1182/2402] Data 0.003 (0.004) Batch 0.375 (0.483) Remain 31:43:30 loss: 1.4101 Lr: 0.00057
[2025-04-08 14:21:04,787 INFO misc.py line 113 3298914] Train: [2/100][1183/2402] Data 0.004 (0.004) Batch 0.431 (0.483) Remain 31:43:20 loss: 1.5772 Lr: 0.00057
[2025-04-08 14:21:05,316 INFO misc.py line 113 3298914] Train: [2/100][1184/2402] Data 0.004 (0.004) Batch 0.529 (0.483) Remain 31:43:28 loss: 1.6833 Lr: 0.00057
[2025-04-08 14:21:05,703 INFO misc.py line 113 3298914] Train: [2/100][1185/2402] Data 0.003 (0.004) Batch 0.387 (0.483) Remain 31:43:09 loss: 1.3137 Lr: 0.00057
[2025-04-08 14:21:06,122 INFO misc.py line 113 3298914] Train: [2/100][1186/2402] Data 0.004 (0.004) Batch 0.419 (0.483) Remain 31:42:55 loss: 1.3612 Lr: 0.00057
[2025-04-08 14:21:06,596 INFO misc.py line 113 3298914] Train: [2/100][1187/2402] Data 0.004 (0.004) Batch 0.473 (0.483) Remain 31:42:53 loss: 1.3511 Lr: 0.00057
[2025-04-08 14:21:06,975 INFO misc.py line 113 3298914] Train: [2/100][1188/2402] Data 0.004 (0.004) Batch 0.380 (0.482) Remain 31:42:32 loss: 1.6598 Lr: 0.00057
[2025-04-08 14:21:07,489 INFO misc.py line 113 3298914] Train: [2/100][1189/2402] Data 0.004 (0.004) Batch 0.514 (0.482) Remain 31:42:38 loss: 1.1105 Lr: 0.00057
[2025-04-08 14:21:07,968 INFO misc.py line 113 3298914] Train: [2/100][1190/2402] Data 0.004 (0.004) Batch 0.479 (0.482) Remain 31:42:37 loss: 1.1717 Lr: 0.00057
[2025-04-08 14:21:08,363 INFO misc.py line 113 3298914] Train: [2/100][1191/2402] Data 0.004 (0.004) Batch 0.395 (0.482) Remain 31:42:19 loss: 1.2850 Lr: 0.00057
[2025-04-08 14:21:08,833 INFO misc.py line 113 3298914] Train: [2/100][1192/2402] Data 0.003 (0.004) Batch 0.470 (0.482) Remain 31:42:16 loss: 1.3092 Lr: 0.00057
[2025-04-08 14:21:09,308 INFO misc.py line 113 3298914] Train: [2/100][1193/2402] Data 0.003 (0.004) Batch 0.475 (0.482) Remain 31:42:14 loss: 1.8032 Lr: 0.00057
[2025-04-08 14:21:09,866 INFO misc.py line 113 3298914] Train: [2/100][1194/2402] Data 0.004 (0.004) Batch 0.558 (0.482) Remain 31:42:28 loss: 0.9205 Lr: 0.00057
[2025-04-08 14:21:10,269 INFO misc.py line 113 3298914] Train: [2/100][1195/2402] Data 0.004 (0.004) Batch 0.403 (0.482) Remain 31:42:12 loss: 1.1116 Lr: 0.00057
[2025-04-08 14:21:10,707 INFO misc.py line 113 3298914] Train: [2/100][1196/2402] Data 0.003 (0.004) Batch 0.438 (0.482) Remain 31:42:03 loss: 1.0420 Lr: 0.00057
[2025-04-08 14:21:11,140 INFO misc.py line 113 3298914] Train: [2/100][1197/2402] Data 0.004 (0.004) Batch 0.434 (0.482) Remain 31:41:53 loss: 1.3478 Lr: 0.00057
[2025-04-08 14:21:11,642 INFO misc.py line 113 3298914] Train: [2/100][1198/2402] Data 0.004 (0.004) Batch 0.502 (0.482) Remain 31:41:56 loss: 1.5815 Lr: 0.00057
[2025-04-08 14:21:12,180 INFO misc.py line 113 3298914] Train: [2/100][1199/2402] Data 0.004 (0.004) Batch 0.538 (0.482) Remain 31:42:07 loss: 1.3631 Lr: 0.00057
[2025-04-08 14:21:12,542 INFO misc.py line 113 3298914] Train: [2/100][1200/2402] Data 0.003 (0.004) Batch 0.362 (0.482) Remain 31:41:42 loss: 1.6305 Lr: 0.00057
[2025-04-08 14:21:13,011 INFO misc.py line 113 3298914] Train: [2/100][1201/2402] Data 0.003 (0.004) Batch 0.469 (0.482) Remain 31:41:39 loss: 1.2216 Lr: 0.00057
[2025-04-08 14:21:13,521 INFO misc.py line 113 3298914] Train: [2/100][1202/2402] Data 0.004 (0.004) Batch 0.510 (0.482) Remain 31:41:44 loss: 1.7835 Lr: 0.00057
[2025-04-08 14:21:13,972 INFO misc.py line 113 3298914] Train: [2/100][1203/2402] Data 0.004 (0.004) Batch 0.451 (0.482) Remain 31:41:38 loss: 1.1451 Lr: 0.00057
[2025-04-08 14:21:14,462 INFO misc.py line 113 3298914] Train: [2/100][1204/2402] Data 0.003 (0.004) Batch 0.490 (0.482) Remain 31:41:39 loss: 1.4217 Lr: 0.00057
[2025-04-08 14:21:15,027 INFO misc.py line 113 3298914] Train: [2/100][1205/2402] Data 0.004 (0.004) Batch 0.565 (0.482) Remain 31:41:54 loss: 1.4994 Lr: 0.00057
[2025-04-08 14:21:15,537 INFO misc.py line 113 3298914] Train: [2/100][1206/2402] Data 0.004 (0.004) Batch 0.510 (0.482) Remain 31:41:59 loss: 1.5964 Lr: 0.00057
[2025-04-08 14:21:16,102 INFO misc.py line 113 3298914] Train: [2/100][1207/2402] Data 0.004 (0.004) Batch 0.565 (0.482) Remain 31:42:15 loss: 1.2430 Lr: 0.00057
[2025-04-08 14:21:16,531 INFO misc.py line 113 3298914] Train: [2/100][1208/2402] Data 0.004 (0.004) Batch 0.429 (0.482) Remain 31:42:04 loss: 0.8878 Lr: 0.00057
[2025-04-08 14:21:16,954 INFO misc.py line 113 3298914] Train: [2/100][1209/2402] Data 0.003 (0.004) Batch 0.423 (0.482) Remain 31:41:52 loss: 0.9731 Lr: 0.00057
[2025-04-08 14:21:17,530 INFO misc.py line 113 3298914] Train: [2/100][1210/2402] Data 0.004 (0.004) Batch 0.576 (0.482) Remain 31:42:10 loss: 1.5069 Lr: 0.00057
[2025-04-08 14:21:18,013 INFO misc.py line 113 3298914] Train: [2/100][1211/2402] Data 0.003 (0.004) Batch 0.483 (0.482) Remain 31:42:10 loss: 1.3078 Lr: 0.00057
[2025-04-08 14:21:18,542 INFO misc.py line 113 3298914] Train: [2/100][1212/2402] Data 0.004 (0.004) Batch 0.529 (0.482) Remain 31:42:18 loss: 1.1092 Lr: 0.00057
[2025-04-08 14:21:19,007 INFO misc.py line 113 3298914] Train: [2/100][1213/2402] Data 0.004 (0.004) Batch 0.465 (0.482) Remain 31:42:14 loss: 1.0854 Lr: 0.00057
[2025-04-08 14:21:19,463 INFO misc.py line 113 3298914] Train: [2/100][1214/2402] Data 0.004 (0.004) Batch 0.455 (0.482) Remain 31:42:09 loss: 1.5117 Lr: 0.00057
[2025-04-08 14:21:19,882 INFO misc.py line 113 3298914] Train: [2/100][1215/2402] Data 0.004 (0.004) Batch 0.419 (0.482) Remain 31:41:56 loss: 1.0649 Lr: 0.00057
[2025-04-08 14:21:20,342 INFO misc.py line 113 3298914] Train: [2/100][1216/2402] Data 0.004 (0.004) Batch 0.460 (0.482) Remain 31:41:51 loss: 1.6293 Lr: 0.00057
[2025-04-08 14:21:20,811 INFO misc.py line 113 3298914] Train: [2/100][1217/2402] Data 0.003 (0.004) Batch 0.469 (0.482) Remain 31:41:48 loss: 1.5486 Lr: 0.00057
[2025-04-08 14:21:21,347 INFO misc.py line 113 3298914] Train: [2/100][1218/2402] Data 0.003 (0.004) Batch 0.535 (0.482) Remain 31:41:58 loss: 1.4285 Lr: 0.00057
[2025-04-08 14:21:21,746 INFO misc.py line 113 3298914] Train: [2/100][1219/2402] Data 0.004 (0.004) Batch 0.399 (0.482) Remain 31:41:41 loss: 1.2789 Lr: 0.00057
[2025-04-08 14:21:22,278 INFO misc.py line 113 3298914] Train: [2/100][1220/2402] Data 0.004 (0.004) Batch 0.532 (0.482) Remain 31:41:50 loss: 1.6213 Lr: 0.00057
[2025-04-08 14:21:22,718 INFO misc.py line 113 3298914] Train: [2/100][1221/2402] Data 0.004 (0.004) Batch 0.440 (0.482) Remain 31:41:42 loss: 1.0479 Lr: 0.00057
[2025-04-08 14:21:23,218 INFO misc.py line 113 3298914] Train: [2/100][1222/2402] Data 0.004 (0.004) Batch 0.500 (0.482) Remain 31:41:45 loss: 1.3910 Lr: 0.00057
[2025-04-08 14:21:23,618 INFO misc.py line 113 3298914] Train: [2/100][1223/2402] Data 0.003 (0.004) Batch 0.399 (0.482) Remain 31:41:28 loss: 1.4416 Lr: 0.00057
[2025-04-08 14:21:24,128 INFO misc.py line 113 3298914] Train: [2/100][1224/2402] Data 0.004 (0.004) Batch 0.510 (0.482) Remain 31:41:33 loss: 1.3900 Lr: 0.00057
[2025-04-08 14:21:24,582 INFO misc.py line 113 3298914] Train: [2/100][1225/2402] Data 0.004 (0.004) Batch 0.454 (0.482) Remain 31:41:27 loss: 1.4723 Lr: 0.00057
[2025-04-08 14:21:25,050 INFO misc.py line 113 3298914] Train: [2/100][1226/2402] Data 0.004 (0.004) Batch 0.468 (0.482) Remain 31:41:24 loss: 1.0527 Lr: 0.00058
[2025-04-08 14:21:25,543 INFO misc.py line 113 3298914] Train: [2/100][1227/2402] Data 0.004 (0.004) Batch 0.493 (0.482) Remain 31:41:25 loss: 1.2779 Lr: 0.00058
[2025-04-08 14:21:26,113 INFO misc.py line 113 3298914] Train: [2/100][1228/2402] Data 0.004 (0.004) Batch 0.570 (0.482) Remain 31:41:42 loss: 0.9487 Lr: 0.00058
[2025-04-08 14:21:26,625 INFO misc.py line 113 3298914] Train: [2/100][1229/2402] Data 0.004 (0.004) Batch 0.512 (0.482) Remain 31:41:47 loss: 1.2340 Lr: 0.00058
[2025-04-08 14:21:27,138 INFO misc.py line 113 3298914] Train: [2/100][1230/2402] Data 0.004 (0.004) Batch 0.513 (0.482) Remain 31:41:52 loss: 1.4283 Lr: 0.00058
[2025-04-08 14:21:27,546 INFO misc.py line 113 3298914] Train: [2/100][1231/2402] Data 0.004 (0.004) Batch 0.409 (0.482) Remain 31:41:38 loss: 1.2324 Lr: 0.00058
[2025-04-08 14:21:28,003 INFO misc.py line 113 3298914] Train: [2/100][1232/2402] Data 0.003 (0.004) Batch 0.457 (0.482) Remain 31:41:32 loss: 1.0481 Lr: 0.00058
[2025-04-08 14:21:28,486 INFO misc.py line 113 3298914] Train: [2/100][1233/2402] Data 0.003 (0.004) Batch 0.483 (0.482) Remain 31:41:32 loss: 1.3331 Lr: 0.00058
[2025-04-08 14:21:29,003 INFO misc.py line 113 3298914] Train: [2/100][1234/2402] Data 0.004 (0.004) Batch 0.517 (0.482) Remain 31:41:38 loss: 1.6568 Lr: 0.00058
[2025-04-08 14:21:29,511 INFO misc.py line 113 3298914] Train: [2/100][1235/2402] Data 0.003 (0.004) Batch 0.507 (0.482) Remain 31:41:43 loss: 1.1844 Lr: 0.00058
[2025-04-08 14:21:29,951 INFO misc.py line 113 3298914] Train: [2/100][1236/2402] Data 0.004 (0.004) Batch 0.441 (0.482) Remain 31:41:34 loss: 1.0120 Lr: 0.00058
[2025-04-08 14:21:30,315 INFO misc.py line 113 3298914] Train: [2/100][1237/2402] Data 0.003 (0.004) Batch 0.363 (0.482) Remain 31:41:11 loss: 1.4267 Lr: 0.00058
[2025-04-08 14:21:30,862 INFO misc.py line 113 3298914] Train: [2/100][1238/2402] Data 0.004 (0.004) Batch 0.547 (0.482) Remain 31:41:23 loss: 1.5267 Lr: 0.00058
[2025-04-08 14:21:31,385 INFO misc.py line 113 3298914] Train: [2/100][1239/2402] Data 0.004 (0.004) Batch 0.523 (0.482) Remain 31:41:30 loss: 1.6116 Lr: 0.00058
[2025-04-08 14:21:31,815 INFO misc.py line 113 3298914] Train: [2/100][1240/2402] Data 0.003 (0.004) Batch 0.429 (0.482) Remain 31:41:20 loss: 1.0358 Lr: 0.00058
[2025-04-08 14:21:32,256 INFO misc.py line 113 3298914] Train: [2/100][1241/2402] Data 0.004 (0.004) Batch 0.441 (0.482) Remain 31:41:11 loss: 1.0764 Lr: 0.00058
[2025-04-08 14:21:32,701 INFO misc.py line 113 3298914] Train: [2/100][1242/2402] Data 0.004 (0.004) Batch 0.446 (0.482) Remain 31:41:04 loss: 1.5237 Lr: 0.00058
[2025-04-08 14:21:33,246 INFO misc.py line 113 3298914] Train: [2/100][1243/2402] Data 0.003 (0.004) Batch 0.545 (0.482) Remain 31:41:15 loss: 1.3797 Lr: 0.00058
[2025-04-08 14:21:33,677 INFO misc.py line 113 3298914] Train: [2/100][1244/2402] Data 0.004 (0.004) Batch 0.431 (0.482) Remain 31:41:05 loss: 1.1512 Lr: 0.00058
[2025-04-08 14:21:34,071 INFO misc.py line 113 3298914] Train: [2/100][1245/2402] Data 0.004 (0.004) Batch 0.393 (0.482) Remain 31:40:48 loss: 1.5124 Lr: 0.00058
[2025-04-08 14:21:34,507 INFO misc.py line 113 3298914] Train: [2/100][1246/2402] Data 0.003 (0.004) Batch 0.436 (0.482) Remain 31:40:38 loss: 1.1748 Lr: 0.00058
[2025-04-08 14:21:35,117 INFO misc.py line 113 3298914] Train: [2/100][1247/2402] Data 0.003 (0.004) Batch 0.610 (0.482) Remain 31:41:02 loss: 1.3451 Lr: 0.00058
[2025-04-08 14:21:35,530 INFO misc.py line 113 3298914] Train: [2/100][1248/2402] Data 0.004 (0.004) Batch 0.413 (0.482) Remain 31:40:49 loss: 1.2303 Lr: 0.00058
[2025-04-08 14:21:36,040 INFO misc.py line 113 3298914] Train: [2/100][1249/2402] Data 0.004 (0.004) Batch 0.510 (0.482) Remain 31:40:53 loss: 1.7161 Lr: 0.00058
[2025-04-08 14:21:36,392 INFO misc.py line 113 3298914] Train: [2/100][1250/2402] Data 0.004 (0.004) Batch 0.352 (0.482) Remain 31:40:28 loss: 1.1114 Lr: 0.00058
[2025-04-08 14:21:36,856 INFO misc.py line 113 3298914] Train: [2/100][1251/2402] Data 0.004 (0.004) Batch 0.464 (0.482) Remain 31:40:24 loss: 1.4729 Lr: 0.00058
[2025-04-08 14:21:37,292 INFO misc.py line 113 3298914] Train: [2/100][1252/2402] Data 0.004 (0.004) Batch 0.436 (0.482) Remain 31:40:15 loss: 1.6492 Lr: 0.00058
[2025-04-08 14:21:37,821 INFO misc.py line 113 3298914] Train: [2/100][1253/2402] Data 0.004 (0.004) Batch 0.528 (0.482) Remain 31:40:23 loss: 1.2774 Lr: 0.00058
[2025-04-08 14:21:38,389 INFO misc.py line 113 3298914] Train: [2/100][1254/2402] Data 0.004 (0.004) Batch 0.569 (0.482) Remain 31:40:39 loss: 1.3244 Lr: 0.00058
[2025-04-08 14:21:38,835 INFO misc.py line 113 3298914] Train: [2/100][1255/2402] Data 0.004 (0.004) Batch 0.445 (0.482) Remain 31:40:32 loss: 1.3320 Lr: 0.00058
[2025-04-08 14:21:39,387 INFO misc.py line 113 3298914] Train: [2/100][1256/2402] Data 0.004 (0.004) Batch 0.552 (0.482) Remain 31:40:45 loss: 1.3580 Lr: 0.00058
[2025-04-08 14:21:39,906 INFO misc.py line 113 3298914] Train: [2/100][1257/2402] Data 0.004 (0.004) Batch 0.519 (0.482) Remain 31:40:51 loss: 1.5128 Lr: 0.00058
[2025-04-08 14:21:40,443 INFO misc.py line 113 3298914] Train: [2/100][1258/2402] Data 0.004 (0.004) Batch 0.537 (0.482) Remain 31:41:01 loss: 1.3428 Lr: 0.00058
[2025-04-08 14:21:40,983 INFO misc.py line 113 3298914] Train: [2/100][1259/2402] Data 0.004 (0.004) Batch 0.540 (0.482) Remain 31:41:11 loss: 1.5724 Lr: 0.00058
[2025-04-08 14:21:41,492 INFO misc.py line 113 3298914] Train: [2/100][1260/2402] Data 0.004 (0.004) Batch 0.509 (0.482) Remain 31:41:16 loss: 1.2945 Lr: 0.00058
[2025-04-08 14:21:42,040 INFO misc.py line 113 3298914] Train: [2/100][1261/2402] Data 0.003 (0.004) Batch 0.548 (0.482) Remain 31:41:28 loss: 1.6507 Lr: 0.00058
[2025-04-08 14:21:42,421 INFO misc.py line 113 3298914] Train: [2/100][1262/2402] Data 0.004 (0.004) Batch 0.381 (0.482) Remain 31:41:08 loss: 1.1753 Lr: 0.00058
[2025-04-08 14:21:42,810 INFO misc.py line 113 3298914] Train: [2/100][1263/2402] Data 0.004 (0.004) Batch 0.389 (0.482) Remain 31:40:50 loss: 1.1137 Lr: 0.00058
[2025-04-08 14:21:43,244 INFO misc.py line 113 3298914] Train: [2/100][1264/2402] Data 0.003 (0.004) Batch 0.433 (0.482) Remain 31:40:41 loss: 0.8319 Lr: 0.00058
[2025-04-08 14:21:43,792 INFO misc.py line 113 3298914] Train: [2/100][1265/2402] Data 0.004 (0.004) Batch 0.548 (0.482) Remain 31:40:53 loss: 1.2151 Lr: 0.00058
[2025-04-08 14:21:44,169 INFO misc.py line 113 3298914] Train: [2/100][1266/2402] Data 0.004 (0.004) Batch 0.376 (0.482) Remain 31:40:32 loss: 1.3743 Lr: 0.00058
[2025-04-08 14:21:44,686 INFO misc.py line 113 3298914] Train: [2/100][1267/2402] Data 0.004 (0.004) Batch 0.518 (0.482) Remain 31:40:39 loss: 1.5345 Lr: 0.00058
[2025-04-08 14:21:45,174 INFO misc.py line 113 3298914] Train: [2/100][1268/2402] Data 0.003 (0.004) Batch 0.488 (0.482) Remain 31:40:39 loss: 1.2493 Lr: 0.00058
[2025-04-08 14:21:45,580 INFO misc.py line 113 3298914] Train: [2/100][1269/2402] Data 0.003 (0.004) Batch 0.406 (0.482) Remain 31:40:24 loss: 1.6617 Lr: 0.00058
[2025-04-08 14:21:46,095 INFO misc.py line 113 3298914] Train: [2/100][1270/2402] Data 0.004 (0.004) Batch 0.515 (0.482) Remain 31:40:30 loss: 1.3332 Lr: 0.00058
[2025-04-08 14:21:46,573 INFO misc.py line 113 3298914] Train: [2/100][1271/2402] Data 0.003 (0.004) Batch 0.478 (0.482) Remain 31:40:29 loss: 1.2678 Lr: 0.00058
[2025-04-08 14:21:46,976 INFO misc.py line 113 3298914] Train: [2/100][1272/2402] Data 0.004 (0.004) Batch 0.403 (0.482) Remain 31:40:14 loss: 1.1716 Lr: 0.00058
[2025-04-08 14:21:47,418 INFO misc.py line 113 3298914] Train: [2/100][1273/2402] Data 0.004 (0.004) Batch 0.442 (0.482) Remain 31:40:06 loss: 1.8743 Lr: 0.00058
[2025-04-08 14:21:47,886 INFO misc.py line 113 3298914] Train: [2/100][1274/2402] Data 0.003 (0.004) Batch 0.468 (0.482) Remain 31:40:03 loss: 1.4393 Lr: 0.00058
[2025-04-08 14:21:48,286 INFO misc.py line 113 3298914] Train: [2/100][1275/2402] Data 0.004 (0.004) Batch 0.400 (0.482) Remain 31:39:47 loss: 1.0957 Lr: 0.00058
[2025-04-08 14:21:48,760 INFO misc.py line 113 3298914] Train: [2/100][1276/2402] Data 0.003 (0.004) Batch 0.474 (0.482) Remain 31:39:45 loss: 1.3454 Lr: 0.00058
[2025-04-08 14:21:49,240 INFO misc.py line 113 3298914] Train: [2/100][1277/2402] Data 0.003 (0.004) Batch 0.480 (0.482) Remain 31:39:44 loss: 1.2615 Lr: 0.00058
[2025-04-08 14:21:49,724 INFO misc.py line 113 3298914] Train: [2/100][1278/2402] Data 0.004 (0.004) Batch 0.484 (0.482) Remain 31:39:44 loss: 1.3989 Lr: 0.00059
[2025-04-08 14:21:50,195 INFO misc.py line 113 3298914] Train: [2/100][1279/2402] Data 0.004 (0.004) Batch 0.470 (0.482) Remain 31:39:41 loss: 1.1776 Lr: 0.00059
[2025-04-08 14:21:50,736 INFO misc.py line 113 3298914] Train: [2/100][1280/2402] Data 0.004 (0.004) Batch 0.542 (0.482) Remain 31:39:52 loss: 1.4302 Lr: 0.00059
[2025-04-08 14:21:51,223 INFO misc.py line 113 3298914] Train: [2/100][1281/2402] Data 0.004 (0.004) Batch 0.487 (0.482) Remain 31:39:52 loss: 1.1948 Lr: 0.00059
[2025-04-08 14:21:51,636 INFO misc.py line 113 3298914] Train: [2/100][1282/2402] Data 0.003 (0.004) Batch 0.413 (0.482) Remain 31:39:39 loss: 0.9380 Lr: 0.00059
[2025-04-08 14:21:52,137 INFO misc.py line 113 3298914] Train: [2/100][1283/2402] Data 0.004 (0.004) Batch 0.501 (0.482) Remain 31:39:42 loss: 1.3977 Lr: 0.00059
[2025-04-08 14:21:52,582 INFO misc.py line 113 3298914] Train: [2/100][1284/2402] Data 0.004 (0.004) Batch 0.445 (0.482) Remain 31:39:35 loss: 1.1520 Lr: 0.00059
[2025-04-08 14:21:53,070 INFO misc.py line 113 3298914] Train: [2/100][1285/2402] Data 0.004 (0.004) Batch 0.488 (0.482) Remain 31:39:36 loss: 1.4317 Lr: 0.00059
[2025-04-08 14:21:53,538 INFO misc.py line 113 3298914] Train: [2/100][1286/2402] Data 0.004 (0.004) Batch 0.468 (0.482) Remain 31:39:32 loss: 1.2793 Lr: 0.00059
[2025-04-08 14:21:53,990 INFO misc.py line 113 3298914] Train: [2/100][1287/2402] Data 0.003 (0.004) Batch 0.452 (0.482) Remain 31:39:27 loss: 1.4594 Lr: 0.00059
[2025-04-08 14:21:54,471 INFO misc.py line 113 3298914] Train: [2/100][1288/2402] Data 0.005 (0.004) Batch 0.481 (0.482) Remain 31:39:26 loss: 1.2039 Lr: 0.00059
[2025-04-08 14:21:54,912 INFO misc.py line 113 3298914] Train: [2/100][1289/2402] Data 0.004 (0.004) Batch 0.441 (0.482) Remain 31:39:18 loss: 0.9281 Lr: 0.00059
[2025-04-08 14:21:55,335 INFO misc.py line 113 3298914] Train: [2/100][1290/2402] Data 0.003 (0.004) Batch 0.423 (0.482) Remain 31:39:07 loss: 0.9821 Lr: 0.00059
[2025-04-08 14:21:55,754 INFO misc.py line 113 3298914] Train: [2/100][1291/2402] Data 0.004 (0.004) Batch 0.419 (0.482) Remain 31:38:55 loss: 1.0779 Lr: 0.00059
[2025-04-08 14:21:56,313 INFO misc.py line 113 3298914] Train: [2/100][1292/2402] Data 0.004 (0.004) Batch 0.559 (0.482) Remain 31:39:08 loss: 1.1617 Lr: 0.00059
[2025-04-08 14:21:56,820 INFO misc.py line 113 3298914] Train: [2/100][1293/2402] Data 0.003 (0.004) Batch 0.507 (0.482) Remain 31:39:12 loss: 1.1418 Lr: 0.00059
[2025-04-08 14:21:57,291 INFO misc.py line 113 3298914] Train: [2/100][1294/2402] Data 0.004 (0.004) Batch 0.471 (0.482) Remain 31:39:10 loss: 1.1519 Lr: 0.00059
[2025-04-08 14:21:57,775 INFO misc.py line 113 3298914] Train: [2/100][1295/2402] Data 0.003 (0.004) Batch 0.484 (0.482) Remain 31:39:10 loss: 1.6901 Lr: 0.00059
[2025-04-08 14:21:58,234 INFO misc.py line 113 3298914] Train: [2/100][1296/2402] Data 0.004 (0.004) Batch 0.459 (0.482) Remain 31:39:05 loss: 1.5955 Lr: 0.00059
[2025-04-08 14:21:58,701 INFO misc.py line 113 3298914] Train: [2/100][1297/2402] Data 0.004 (0.004) Batch 0.467 (0.482) Remain 31:39:02 loss: 0.8045 Lr: 0.00059
[2025-04-08 14:21:59,181 INFO misc.py line 113 3298914] Train: [2/100][1298/2402] Data 0.004 (0.004) Batch 0.480 (0.482) Remain 31:39:01 loss: 1.0276 Lr: 0.00059
[2025-04-08 14:21:59,556 INFO misc.py line 113 3298914] Train: [2/100][1299/2402] Data 0.004 (0.004) Batch 0.374 (0.482) Remain 31:38:41 loss: 1.2216 Lr: 0.00059
[2025-04-08 14:22:00,116 INFO misc.py line 113 3298914] Train: [2/100][1300/2402] Data 0.004 (0.004) Batch 0.560 (0.482) Remain 31:38:55 loss: 1.2409 Lr: 0.00059
[2025-04-08 14:22:00,693 INFO misc.py line 113 3298914] Train: [2/100][1301/2402] Data 0.004 (0.004) Batch 0.577 (0.482) Remain 31:39:12 loss: 1.1154 Lr: 0.00059
[2025-04-08 14:22:01,212 INFO misc.py line 113 3298914] Train: [2/100][1302/2402] Data 0.004 (0.004) Batch 0.519 (0.482) Remain 31:39:18 loss: 1.3602 Lr: 0.00059
[2025-04-08 14:22:01,698 INFO misc.py line 113 3298914] Train: [2/100][1303/2402] Data 0.004 (0.004) Batch 0.485 (0.482) Remain 31:39:18 loss: 0.9894 Lr: 0.00059
[2025-04-08 14:22:02,173 INFO misc.py line 113 3298914] Train: [2/100][1304/2402] Data 0.004 (0.004) Batch 0.475 (0.482) Remain 31:39:17 loss: 1.2224 Lr: 0.00059
[2025-04-08 14:22:02,656 INFO misc.py line 113 3298914] Train: [2/100][1305/2402] Data 0.004 (0.004) Batch 0.484 (0.482) Remain 31:39:17 loss: 1.3511 Lr: 0.00059
[2025-04-08 14:22:03,136 INFO misc.py line 113 3298914] Train: [2/100][1306/2402] Data 0.003 (0.004) Batch 0.480 (0.482) Remain 31:39:16 loss: 1.4163 Lr: 0.00059
[2025-04-08 14:22:03,660 INFO misc.py line 113 3298914] Train: [2/100][1307/2402] Data 0.004 (0.004) Batch 0.524 (0.482) Remain 31:39:23 loss: 1.2702 Lr: 0.00059
[2025-04-08 14:22:04,163 INFO misc.py line 113 3298914] Train: [2/100][1308/2402] Data 0.004 (0.004) Batch 0.503 (0.482) Remain 31:39:26 loss: 1.2698 Lr: 0.00059
[2025-04-08 14:22:04,863 INFO misc.py line 113 3298914] Train: [2/100][1309/2402] Data 0.003 (0.004) Batch 0.700 (0.482) Remain 31:40:05 loss: 1.0988 Lr: 0.00059
[2025-04-08 14:22:05,377 INFO misc.py line 113 3298914] Train: [2/100][1310/2402] Data 0.004 (0.004) Batch 0.515 (0.482) Remain 31:40:11 loss: 1.0886 Lr: 0.00059
[2025-04-08 14:22:05,792 INFO misc.py line 113 3298914] Train: [2/100][1311/2402] Data 0.003 (0.004) Batch 0.415 (0.482) Remain 31:39:58 loss: 1.4939 Lr: 0.00059
[2025-04-08 14:22:06,172 INFO misc.py line 113 3298914] Train: [2/100][1312/2402] Data 0.004 (0.004) Batch 0.379 (0.482) Remain 31:39:39 loss: 1.0652 Lr: 0.00059
[2025-04-08 14:22:06,696 INFO misc.py line 113 3298914] Train: [2/100][1313/2402] Data 0.004 (0.004) Batch 0.524 (0.482) Remain 31:39:46 loss: 1.1423 Lr: 0.00059
[2025-04-08 14:22:07,037 INFO misc.py line 113 3298914] Train: [2/100][1314/2402] Data 0.004 (0.004) Batch 0.341 (0.482) Remain 31:39:20 loss: 1.7134 Lr: 0.00059
[2025-04-08 14:22:07,458 INFO misc.py line 113 3298914] Train: [2/100][1315/2402] Data 0.004 (0.004) Batch 0.421 (0.482) Remain 31:39:09 loss: 1.3137 Lr: 0.00059
[2025-04-08 14:22:07,952 INFO misc.py line 113 3298914] Train: [2/100][1316/2402] Data 0.004 (0.004) Batch 0.493 (0.482) Remain 31:39:10 loss: 1.2958 Lr: 0.00059
[2025-04-08 14:22:08,429 INFO misc.py line 113 3298914] Train: [2/100][1317/2402] Data 0.004 (0.004) Batch 0.478 (0.482) Remain 31:39:09 loss: 1.1285 Lr: 0.00059
[2025-04-08 14:22:08,807 INFO misc.py line 113 3298914] Train: [2/100][1318/2402] Data 0.003 (0.004) Batch 0.378 (0.482) Remain 31:38:50 loss: 1.8545 Lr: 0.00059
[2025-04-08 14:22:09,289 INFO misc.py line 113 3298914] Train: [2/100][1319/2402] Data 0.003 (0.004) Batch 0.482 (0.482) Remain 31:38:49 loss: 1.0879 Lr: 0.00059
[2025-04-08 14:22:09,853 INFO misc.py line 113 3298914] Train: [2/100][1320/2402] Data 0.004 (0.004) Batch 0.563 (0.482) Remain 31:39:04 loss: 1.3520 Lr: 0.00059
[2025-04-08 14:22:10,338 INFO misc.py line 113 3298914] Train: [2/100][1321/2402] Data 0.004 (0.004) Batch 0.486 (0.482) Remain 31:39:04 loss: 1.1948 Lr: 0.00059
[2025-04-08 14:22:10,862 INFO misc.py line 113 3298914] Train: [2/100][1322/2402] Data 0.004 (0.004) Batch 0.524 (0.482) Remain 31:39:11 loss: 1.5956 Lr: 0.00059
[2025-04-08 14:22:11,256 INFO misc.py line 113 3298914] Train: [2/100][1323/2402] Data 0.004 (0.004) Batch 0.394 (0.482) Remain 31:38:55 loss: 0.8701 Lr: 0.00059
[2025-04-08 14:22:11,754 INFO misc.py line 113 3298914] Train: [2/100][1324/2402] Data 0.004 (0.004) Batch 0.498 (0.482) Remain 31:38:57 loss: 1.0750 Lr: 0.00059
[2025-04-08 14:22:12,190 INFO misc.py line 113 3298914] Train: [2/100][1325/2402] Data 0.003 (0.004) Batch 0.435 (0.482) Remain 31:38:48 loss: 1.2205 Lr: 0.00059
[2025-04-08 14:22:12,696 INFO misc.py line 113 3298914] Train: [2/100][1326/2402] Data 0.004 (0.004) Batch 0.506 (0.482) Remain 31:38:52 loss: 1.3823 Lr: 0.00059
[2025-04-08 14:22:13,074 INFO misc.py line 113 3298914] Train: [2/100][1327/2402] Data 0.004 (0.004) Batch 0.378 (0.482) Remain 31:38:33 loss: 1.5073 Lr: 0.00059
[2025-04-08 14:22:13,628 INFO misc.py line 113 3298914] Train: [2/100][1328/2402] Data 0.004 (0.004) Batch 0.554 (0.482) Remain 31:38:46 loss: 1.4032 Lr: 0.00059
[2025-04-08 14:22:14,150 INFO misc.py line 113 3298914] Train: [2/100][1329/2402] Data 0.004 (0.004) Batch 0.522 (0.482) Remain 31:38:52 loss: 1.2553 Lr: 0.00059
[2025-04-08 14:22:14,584 INFO misc.py line 113 3298914] Train: [2/100][1330/2402] Data 0.004 (0.004) Batch 0.434 (0.482) Remain 31:38:43 loss: 1.2068 Lr: 0.00060
[2025-04-08 14:22:15,063 INFO misc.py line 113 3298914] Train: [2/100][1331/2402] Data 0.004 (0.004) Batch 0.479 (0.482) Remain 31:38:42 loss: 1.1821 Lr: 0.00060
[2025-04-08 14:22:15,531 INFO misc.py line 113 3298914] Train: [2/100][1332/2402] Data 0.004 (0.004) Batch 0.467 (0.482) Remain 31:38:39 loss: 1.4223 Lr: 0.00060
[2025-04-08 14:22:15,895 INFO misc.py line 113 3298914] Train: [2/100][1333/2402] Data 0.004 (0.004) Batch 0.364 (0.482) Remain 31:38:18 loss: 1.4711 Lr: 0.00060
[2025-04-08 14:22:16,445 INFO misc.py line 113 3298914] Train: [2/100][1334/2402] Data 0.004 (0.004) Batch 0.550 (0.482) Remain 31:38:30 loss: 1.4768 Lr: 0.00060
[2025-04-08 14:22:16,959 INFO misc.py line 113 3298914] Train: [2/100][1335/2402] Data 0.004 (0.004) Batch 0.514 (0.482) Remain 31:38:35 loss: 1.0521 Lr: 0.00060
[2025-04-08 14:22:17,367 INFO misc.py line 113 3298914] Train: [2/100][1336/2402] Data 0.004 (0.004) Batch 0.408 (0.482) Remain 31:38:21 loss: 1.0150 Lr: 0.00060
[2025-04-08 14:22:17,907 INFO misc.py line 113 3298914] Train: [2/100][1337/2402] Data 0.003 (0.004) Batch 0.540 (0.482) Remain 31:38:31 loss: 1.4219 Lr: 0.00060
[2025-04-08 14:22:18,364 INFO misc.py line 113 3298914] Train: [2/100][1338/2402] Data 0.004 (0.004) Batch 0.457 (0.482) Remain 31:38:26 loss: 1.2787 Lr: 0.00060
[2025-04-08 14:22:18,772 INFO misc.py line 113 3298914] Train: [2/100][1339/2402] Data 0.004 (0.004) Batch 0.408 (0.482) Remain 31:38:13 loss: 1.5258 Lr: 0.00060
[2025-04-08 14:22:19,259 INFO misc.py line 113 3298914] Train: [2/100][1340/2402] Data 0.004 (0.004) Batch 0.486 (0.482) Remain 31:38:13 loss: 1.3864 Lr: 0.00060
[2025-04-08 14:22:19,792 INFO misc.py line 113 3298914] Train: [2/100][1341/2402] Data 0.004 (0.004) Batch 0.534 (0.482) Remain 31:38:22 loss: 1.2422 Lr: 0.00060
[2025-04-08 14:22:20,292 INFO misc.py line 113 3298914] Train: [2/100][1342/2402] Data 0.004 (0.004) Batch 0.500 (0.482) Remain 31:38:25 loss: 1.4326 Lr: 0.00060
[2025-04-08 14:22:20,776 INFO misc.py line 113 3298914] Train: [2/100][1343/2402] Data 0.004 (0.004) Batch 0.484 (0.482) Remain 31:38:25 loss: 0.6934 Lr: 0.00060
[2025-04-08 14:22:21,173 INFO misc.py line 113 3298914] Train: [2/100][1344/2402] Data 0.004 (0.004) Batch 0.397 (0.482) Remain 31:38:09 loss: 0.8655 Lr: 0.00060
[2025-04-08 14:22:21,667 INFO misc.py line 113 3298914] Train: [2/100][1345/2402] Data 0.004 (0.004) Batch 0.494 (0.482) Remain 31:38:11 loss: 1.3183 Lr: 0.00060
[2025-04-08 14:22:22,107 INFO misc.py line 113 3298914] Train: [2/100][1346/2402] Data 0.004 (0.004) Batch 0.439 (0.482) Remain 31:38:03 loss: 1.4047 Lr: 0.00060
[2025-04-08 14:22:22,640 INFO misc.py line 113 3298914] Train: [2/100][1347/2402] Data 0.004 (0.004) Batch 0.534 (0.482) Remain 31:38:12 loss: 1.1911 Lr: 0.00060
[2025-04-08 14:22:23,174 INFO misc.py line 113 3298914] Train: [2/100][1348/2402] Data 0.004 (0.004) Batch 0.533 (0.482) Remain 31:38:20 loss: 1.5109 Lr: 0.00060
[2025-04-08 14:22:23,705 INFO misc.py line 113 3298914] Train: [2/100][1349/2402] Data 0.004 (0.004) Batch 0.532 (0.482) Remain 31:38:28 loss: 1.4573 Lr: 0.00060
[2025-04-08 14:22:24,173 INFO misc.py line 113 3298914] Train: [2/100][1350/2402] Data 0.003 (0.004) Batch 0.468 (0.482) Remain 31:38:26 loss: 1.7168 Lr: 0.00060
[2025-04-08 14:22:24,697 INFO misc.py line 113 3298914] Train: [2/100][1351/2402] Data 0.003 (0.004) Batch 0.524 (0.482) Remain 31:38:32 loss: 1.0708 Lr: 0.00060
[2025-04-08 14:22:25,281 INFO misc.py line 113 3298914] Train: [2/100][1352/2402] Data 0.004 (0.004) Batch 0.584 (0.482) Remain 31:38:50 loss: 1.2757 Lr: 0.00060
[2025-04-08 14:22:25,737 INFO misc.py line 113 3298914] Train: [2/100][1353/2402] Data 0.003 (0.004) Batch 0.456 (0.482) Remain 31:38:45 loss: 1.5562 Lr: 0.00060
[2025-04-08 14:22:26,225 INFO misc.py line 113 3298914] Train: [2/100][1354/2402] Data 0.004 (0.004) Batch 0.488 (0.482) Remain 31:38:45 loss: 1.2461 Lr: 0.00060
[2025-04-08 14:22:26,690 INFO misc.py line 113 3298914] Train: [2/100][1355/2402] Data 0.004 (0.004) Batch 0.465 (0.482) Remain 31:38:42 loss: 1.1826 Lr: 0.00060
[2025-04-08 14:22:27,139 INFO misc.py line 113 3298914] Train: [2/100][1356/2402] Data 0.004 (0.004) Batch 0.450 (0.482) Remain 31:38:36 loss: 1.6408 Lr: 0.00060
[2025-04-08 14:22:27,625 INFO misc.py line 113 3298914] Train: [2/100][1357/2402] Data 0.004 (0.004) Batch 0.485 (0.482) Remain 31:38:36 loss: 1.6743 Lr: 0.00060
[2025-04-08 14:22:28,066 INFO misc.py line 113 3298914] Train: [2/100][1358/2402] Data 0.004 (0.004) Batch 0.442 (0.482) Remain 31:38:29 loss: 1.7673 Lr: 0.00060
[2025-04-08 14:22:28,433 INFO misc.py line 113 3298914] Train: [2/100][1359/2402] Data 0.003 (0.004) Batch 0.367 (0.482) Remain 31:38:08 loss: 1.9351 Lr: 0.00060
[2025-04-08 14:22:28,814 INFO misc.py line 113 3298914] Train: [2/100][1360/2402] Data 0.004 (0.004) Batch 0.381 (0.482) Remain 31:37:50 loss: 1.5410 Lr: 0.00060
[2025-04-08 14:22:29,321 INFO misc.py line 113 3298914] Train: [2/100][1361/2402] Data 0.003 (0.004) Batch 0.507 (0.482) Remain 31:37:54 loss: 1.4507 Lr: 0.00060
[2025-04-08 14:22:29,924 INFO misc.py line 113 3298914] Train: [2/100][1362/2402] Data 0.004 (0.004) Batch 0.602 (0.482) Remain 31:38:14 loss: 1.4629 Lr: 0.00060
[2025-04-08 14:22:30,343 INFO misc.py line 113 3298914] Train: [2/100][1363/2402] Data 0.004 (0.004) Batch 0.420 (0.482) Remain 31:38:03 loss: 1.1372 Lr: 0.00060
[2025-04-08 14:22:30,830 INFO misc.py line 113 3298914] Train: [2/100][1364/2402] Data 0.003 (0.004) Batch 0.487 (0.482) Remain 31:38:04 loss: 1.5501 Lr: 0.00060
[2025-04-08 14:22:31,294 INFO misc.py line 113 3298914] Train: [2/100][1365/2402] Data 0.004 (0.004) Batch 0.464 (0.482) Remain 31:38:00 loss: 1.5519 Lr: 0.00060
[2025-04-08 14:22:31,773 INFO misc.py line 113 3298914] Train: [2/100][1366/2402] Data 0.003 (0.004) Batch 0.479 (0.482) Remain 31:37:59 loss: 1.3339 Lr: 0.00060
[2025-04-08 14:22:32,205 INFO misc.py line 113 3298914] Train: [2/100][1367/2402] Data 0.003 (0.004) Batch 0.432 (0.482) Remain 31:37:50 loss: 0.9614 Lr: 0.00060
[2025-04-08 14:22:32,706 INFO misc.py line 113 3298914] Train: [2/100][1368/2402] Data 0.004 (0.004) Batch 0.501 (0.482) Remain 31:37:53 loss: 1.1787 Lr: 0.00060
[2025-04-08 14:22:33,265 INFO misc.py line 113 3298914] Train: [2/100][1369/2402] Data 0.004 (0.004) Batch 0.559 (0.482) Remain 31:38:06 loss: 0.9647 Lr: 0.00060
[2025-04-08 14:22:33,739 INFO misc.py line 113 3298914] Train: [2/100][1370/2402] Data 0.003 (0.004) Batch 0.474 (0.482) Remain 31:38:04 loss: 1.4786 Lr: 0.00060
[2025-04-08 14:22:34,236 INFO misc.py line 113 3298914] Train: [2/100][1371/2402] Data 0.004 (0.004) Batch 0.496 (0.482) Remain 31:38:06 loss: 1.1612 Lr: 0.00060
[2025-04-08 14:22:34,706 INFO misc.py line 113 3298914] Train: [2/100][1372/2402] Data 0.004 (0.004) Batch 0.470 (0.482) Remain 31:38:04 loss: 1.4850 Lr: 0.00060
[2025-04-08 14:22:35,138 INFO misc.py line 113 3298914] Train: [2/100][1373/2402] Data 0.003 (0.004) Batch 0.432 (0.482) Remain 31:37:55 loss: 1.2622 Lr: 0.00060
[2025-04-08 14:22:35,611 INFO misc.py line 113 3298914] Train: [2/100][1374/2402] Data 0.004 (0.004) Batch 0.473 (0.482) Remain 31:37:52 loss: 1.2647 Lr: 0.00060
[2025-04-08 14:22:36,074 INFO misc.py line 113 3298914] Train: [2/100][1375/2402] Data 0.004 (0.004) Batch 0.464 (0.482) Remain 31:37:49 loss: 1.2648 Lr: 0.00060
[2025-04-08 14:22:36,566 INFO misc.py line 113 3298914] Train: [2/100][1376/2402] Data 0.003 (0.004) Batch 0.492 (0.482) Remain 31:37:50 loss: 0.7373 Lr: 0.00060
[2025-04-08 14:22:37,098 INFO misc.py line 113 3298914] Train: [2/100][1377/2402] Data 0.003 (0.004) Batch 0.532 (0.482) Remain 31:37:58 loss: 1.4483 Lr: 0.00060
[2025-04-08 14:22:37,546 INFO misc.py line 113 3298914] Train: [2/100][1378/2402] Data 0.004 (0.004) Batch 0.448 (0.482) Remain 31:37:52 loss: 1.1037 Lr: 0.00060
[2025-04-08 14:22:38,044 INFO misc.py line 113 3298914] Train: [2/100][1379/2402] Data 0.003 (0.004) Batch 0.498 (0.482) Remain 31:37:54 loss: 1.4294 Lr: 0.00060
[2025-04-08 14:22:38,549 INFO misc.py line 113 3298914] Train: [2/100][1380/2402] Data 0.004 (0.004) Batch 0.505 (0.482) Remain 31:37:58 loss: 1.3592 Lr: 0.00060
[2025-04-08 14:22:38,981 INFO misc.py line 113 3298914] Train: [2/100][1381/2402] Data 0.004 (0.004) Batch 0.432 (0.482) Remain 31:37:49 loss: 1.0109 Lr: 0.00061
[2025-04-08 14:22:39,410 INFO misc.py line 113 3298914] Train: [2/100][1382/2402] Data 0.004 (0.004) Batch 0.429 (0.482) Remain 31:37:39 loss: 1.5007 Lr: 0.00061
[2025-04-08 14:22:39,907 INFO misc.py line 113 3298914] Train: [2/100][1383/2402] Data 0.004 (0.004) Batch 0.497 (0.482) Remain 31:37:42 loss: 1.4856 Lr: 0.00061
[2025-04-08 14:22:40,431 INFO misc.py line 113 3298914] Train: [2/100][1384/2402] Data 0.003 (0.004) Batch 0.524 (0.482) Remain 31:37:48 loss: 1.1956 Lr: 0.00061
[2025-04-08 14:22:40,885 INFO misc.py line 113 3298914] Train: [2/100][1385/2402] Data 0.004 (0.004) Batch 0.454 (0.482) Remain 31:37:43 loss: 1.0843 Lr: 0.00061
[2025-04-08 14:22:41,406 INFO misc.py line 113 3298914] Train: [2/100][1386/2402] Data 0.004 (0.004) Batch 0.521 (0.482) Remain 31:37:49 loss: 1.3328 Lr: 0.00061
[2025-04-08 14:22:41,879 INFO misc.py line 113 3298914] Train: [2/100][1387/2402] Data 0.004 (0.004) Batch 0.473 (0.482) Remain 31:37:47 loss: 1.1178 Lr: 0.00061
[2025-04-08 14:22:42,461 INFO misc.py line 113 3298914] Train: [2/100][1388/2402] Data 0.004 (0.004) Batch 0.582 (0.482) Remain 31:38:04 loss: 1.6139 Lr: 0.00061
[2025-04-08 14:22:42,828 INFO misc.py line 113 3298914] Train: [2/100][1389/2402] Data 0.003 (0.004) Batch 0.367 (0.482) Remain 31:37:44 loss: 1.6509 Lr: 0.00061
[2025-04-08 14:22:43,254 INFO misc.py line 113 3298914] Train: [2/100][1390/2402] Data 0.004 (0.004) Batch 0.426 (0.482) Remain 31:37:34 loss: 1.5238 Lr: 0.00061
[2025-04-08 14:22:43,744 INFO misc.py line 113 3298914] Train: [2/100][1391/2402] Data 0.004 (0.004) Batch 0.490 (0.482) Remain 31:37:35 loss: 1.6656 Lr: 0.00061
[2025-04-08 14:22:44,231 INFO misc.py line 113 3298914] Train: [2/100][1392/2402] Data 0.004 (0.004) Batch 0.487 (0.482) Remain 31:37:35 loss: 1.4490 Lr: 0.00061
[2025-04-08 14:22:44,700 INFO misc.py line 113 3298914] Train: [2/100][1393/2402] Data 0.003 (0.004) Batch 0.469 (0.482) Remain 31:37:33 loss: 0.9561 Lr: 0.00061
[2025-04-08 14:22:45,225 INFO misc.py line 113 3298914] Train: [2/100][1394/2402] Data 0.003 (0.004) Batch 0.525 (0.482) Remain 31:37:40 loss: 1.1436 Lr: 0.00061
[2025-04-08 14:22:45,712 INFO misc.py line 113 3298914] Train: [2/100][1395/2402] Data 0.004 (0.004) Batch 0.487 (0.482) Remain 31:37:40 loss: 0.9616 Lr: 0.00061
[2025-04-08 14:22:46,172 INFO misc.py line 113 3298914] Train: [2/100][1396/2402] Data 0.004 (0.004) Batch 0.460 (0.482) Remain 31:37:36 loss: 1.3236 Lr: 0.00061
[2025-04-08 14:22:46,651 INFO misc.py line 113 3298914] Train: [2/100][1397/2402] Data 0.004 (0.004) Batch 0.479 (0.482) Remain 31:37:35 loss: 1.5495 Lr: 0.00061
[2025-04-08 14:22:47,056 INFO misc.py line 113 3298914] Train: [2/100][1398/2402] Data 0.004 (0.004) Batch 0.405 (0.482) Remain 31:37:22 loss: 1.3733 Lr: 0.00061
[2025-04-08 14:22:47,525 INFO misc.py line 113 3298914] Train: [2/100][1399/2402] Data 0.004 (0.004) Batch 0.469 (0.482) Remain 31:37:19 loss: 1.4158 Lr: 0.00061
[2025-04-08 14:22:47,992 INFO misc.py line 113 3298914] Train: [2/100][1400/2402] Data 0.003 (0.004) Batch 0.466 (0.482) Remain 31:37:16 loss: 1.3353 Lr: 0.00061
[2025-04-08 14:22:48,550 INFO misc.py line 113 3298914] Train: [2/100][1401/2402] Data 0.004 (0.004) Batch 0.559 (0.482) Remain 31:37:29 loss: 1.1304 Lr: 0.00061
[2025-04-08 14:22:49,039 INFO misc.py line 113 3298914] Train: [2/100][1402/2402] Data 0.003 (0.004) Batch 0.488 (0.482) Remain 31:37:29 loss: 1.4235 Lr: 0.00061
[2025-04-08 14:22:49,521 INFO misc.py line 113 3298914] Train: [2/100][1403/2402] Data 0.004 (0.004) Batch 0.482 (0.482) Remain 31:37:29 loss: 1.0609 Lr: 0.00061
[2025-04-08 14:22:50,032 INFO misc.py line 113 3298914] Train: [2/100][1404/2402] Data 0.003 (0.004) Batch 0.511 (0.482) Remain 31:37:33 loss: 1.5089 Lr: 0.00061
[2025-04-08 14:22:50,505 INFO misc.py line 113 3298914] Train: [2/100][1405/2402] Data 0.004 (0.004) Batch 0.473 (0.482) Remain 31:37:31 loss: 1.3558 Lr: 0.00061
[2025-04-08 14:22:50,909 INFO misc.py line 113 3298914] Train: [2/100][1406/2402] Data 0.004 (0.004) Batch 0.404 (0.482) Remain 31:37:18 loss: 1.1826 Lr: 0.00061
[2025-04-08 14:22:51,400 INFO misc.py line 113 3298914] Train: [2/100][1407/2402] Data 0.003 (0.004) Batch 0.492 (0.482) Remain 31:37:19 loss: 1.1775 Lr: 0.00061
[2025-04-08 14:22:51,784 INFO misc.py line 113 3298914] Train: [2/100][1408/2402] Data 0.003 (0.004) Batch 0.384 (0.482) Remain 31:37:02 loss: 1.0884 Lr: 0.00061
[2025-04-08 14:22:52,223 INFO misc.py line 113 3298914] Train: [2/100][1409/2402] Data 0.004 (0.004) Batch 0.438 (0.481) Remain 31:36:54 loss: 1.3729 Lr: 0.00061
[2025-04-08 14:22:52,802 INFO misc.py line 113 3298914] Train: [2/100][1410/2402] Data 0.003 (0.004) Batch 0.579 (0.482) Remain 31:37:10 loss: 1.0246 Lr: 0.00061
[2025-04-08 14:22:53,278 INFO misc.py line 113 3298914] Train: [2/100][1411/2402] Data 0.004 (0.004) Batch 0.476 (0.482) Remain 31:37:09 loss: 1.4363 Lr: 0.00061
[2025-04-08 14:22:53,736 INFO misc.py line 113 3298914] Train: [2/100][1412/2402] Data 0.003 (0.004) Batch 0.458 (0.482) Remain 31:37:05 loss: 0.9883 Lr: 0.00061
[2025-04-08 14:22:54,189 INFO misc.py line 113 3298914] Train: [2/100][1413/2402] Data 0.004 (0.004) Batch 0.452 (0.482) Remain 31:36:59 loss: 1.0206 Lr: 0.00061
[2025-04-08 14:22:54,704 INFO misc.py line 113 3298914] Train: [2/100][1414/2402] Data 0.004 (0.004) Batch 0.516 (0.482) Remain 31:37:04 loss: 1.0730 Lr: 0.00061
[2025-04-08 14:22:55,132 INFO misc.py line 113 3298914] Train: [2/100][1415/2402] Data 0.003 (0.004) Batch 0.427 (0.481) Remain 31:36:55 loss: 1.4683 Lr: 0.00061
[2025-04-08 14:22:55,548 INFO misc.py line 113 3298914] Train: [2/100][1416/2402] Data 0.004 (0.004) Batch 0.415 (0.481) Remain 31:36:43 loss: 1.5078 Lr: 0.00061
[2025-04-08 14:22:55,966 INFO misc.py line 113 3298914] Train: [2/100][1417/2402] Data 0.004 (0.004) Batch 0.418 (0.481) Remain 31:36:32 loss: 0.6183 Lr: 0.00061
[2025-04-08 14:22:56,440 INFO misc.py line 113 3298914] Train: [2/100][1418/2402] Data 0.004 (0.004) Batch 0.474 (0.481) Remain 31:36:31 loss: 1.3165 Lr: 0.00061
[2025-04-08 14:22:56,898 INFO misc.py line 113 3298914] Train: [2/100][1419/2402] Data 0.003 (0.004) Batch 0.458 (0.481) Remain 31:36:26 loss: 1.6286 Lr: 0.00061
[2025-04-08 14:22:57,381 INFO misc.py line 113 3298914] Train: [2/100][1420/2402] Data 0.004 (0.004) Batch 0.483 (0.481) Remain 31:36:26 loss: 1.4745 Lr: 0.00061
[2025-04-08 14:22:57,790 INFO misc.py line 113 3298914] Train: [2/100][1421/2402] Data 0.004 (0.004) Batch 0.409 (0.481) Remain 31:36:13 loss: 1.0503 Lr: 0.00061
[2025-04-08 14:22:58,158 INFO misc.py line 113 3298914] Train: [2/100][1422/2402] Data 0.004 (0.004) Batch 0.368 (0.481) Remain 31:35:54 loss: 1.2829 Lr: 0.00061
[2025-04-08 14:22:58,642 INFO misc.py line 113 3298914] Train: [2/100][1423/2402] Data 0.004 (0.004) Batch 0.484 (0.481) Remain 31:35:54 loss: 1.2874 Lr: 0.00061
[2025-04-08 14:22:59,145 INFO misc.py line 113 3298914] Train: [2/100][1424/2402] Data 0.004 (0.004) Batch 0.503 (0.481) Remain 31:35:57 loss: 1.0436 Lr: 0.00061
[2025-04-08 14:22:59,666 INFO misc.py line 113 3298914] Train: [2/100][1425/2402] Data 0.003 (0.004) Batch 0.522 (0.481) Remain 31:36:03 loss: 1.1490 Lr: 0.00061
[2025-04-08 14:23:00,182 INFO misc.py line 113 3298914] Train: [2/100][1426/2402] Data 0.004 (0.004) Batch 0.515 (0.481) Remain 31:36:09 loss: 1.3384 Lr: 0.00061
[2025-04-08 14:23:00,724 INFO misc.py line 113 3298914] Train: [2/100][1427/2402] Data 0.004 (0.004) Batch 0.542 (0.481) Remain 31:36:18 loss: 1.5527 Lr: 0.00061
[2025-04-08 14:23:01,174 INFO misc.py line 113 3298914] Train: [2/100][1428/2402] Data 0.004 (0.004) Batch 0.450 (0.481) Remain 31:36:13 loss: 1.3999 Lr: 0.00061
[2025-04-08 14:23:01,547 INFO misc.py line 113 3298914] Train: [2/100][1429/2402] Data 0.003 (0.004) Batch 0.373 (0.481) Remain 31:35:54 loss: 1.1307 Lr: 0.00061
[2025-04-08 14:23:01,914 INFO misc.py line 113 3298914] Train: [2/100][1430/2402] Data 0.004 (0.004) Batch 0.367 (0.481) Remain 31:35:35 loss: 1.4026 Lr: 0.00061
[2025-04-08 14:23:02,389 INFO misc.py line 113 3298914] Train: [2/100][1431/2402] Data 0.004 (0.004) Batch 0.474 (0.481) Remain 31:35:33 loss: 1.7017 Lr: 0.00061
[2025-04-08 14:23:02,768 INFO misc.py line 113 3298914] Train: [2/100][1432/2402] Data 0.004 (0.004) Batch 0.380 (0.481) Remain 31:35:16 loss: 1.4850 Lr: 0.00062
[2025-04-08 14:23:03,290 INFO misc.py line 113 3298914] Train: [2/100][1433/2402] Data 0.003 (0.004) Batch 0.522 (0.481) Remain 31:35:22 loss: 1.5132 Lr: 0.00062
[2025-04-08 14:23:03,787 INFO misc.py line 113 3298914] Train: [2/100][1434/2402] Data 0.004 (0.004) Batch 0.498 (0.481) Remain 31:35:24 loss: 1.6203 Lr: 0.00062
[2025-04-08 14:23:04,226 INFO misc.py line 113 3298914] Train: [2/100][1435/2402] Data 0.003 (0.004) Batch 0.438 (0.481) Remain 31:35:17 loss: 1.6703 Lr: 0.00062
[2025-04-08 14:23:04,628 INFO misc.py line 113 3298914] Train: [2/100][1436/2402] Data 0.004 (0.004) Batch 0.402 (0.481) Remain 31:35:03 loss: 1.3362 Lr: 0.00062
[2025-04-08 14:23:05,156 INFO misc.py line 113 3298914] Train: [2/100][1437/2402] Data 0.004 (0.004) Batch 0.527 (0.481) Remain 31:35:10 loss: 1.3736 Lr: 0.00062
[2025-04-08 14:23:05,583 INFO misc.py line 113 3298914] Train: [2/100][1438/2402] Data 0.004 (0.004) Batch 0.427 (0.481) Remain 31:35:01 loss: 1.2040 Lr: 0.00062
[2025-04-08 14:23:06,135 INFO misc.py line 113 3298914] Train: [2/100][1439/2402] Data 0.003 (0.004) Batch 0.552 (0.481) Remain 31:35:12 loss: 1.6410 Lr: 0.00062
[2025-04-08 14:23:06,610 INFO misc.py line 113 3298914] Train: [2/100][1440/2402] Data 0.004 (0.004) Batch 0.475 (0.481) Remain 31:35:11 loss: 1.6459 Lr: 0.00062
[2025-04-08 14:23:07,069 INFO misc.py line 113 3298914] Train: [2/100][1441/2402] Data 0.004 (0.004) Batch 0.459 (0.481) Remain 31:35:07 loss: 1.0897 Lr: 0.00062
[2025-04-08 14:23:07,472 INFO misc.py line 113 3298914] Train: [2/100][1442/2402] Data 0.003 (0.004) Batch 0.403 (0.481) Remain 31:34:53 loss: 1.2121 Lr: 0.00062
[2025-04-08 14:23:07,964 INFO misc.py line 113 3298914] Train: [2/100][1443/2402] Data 0.004 (0.004) Batch 0.492 (0.481) Remain 31:34:55 loss: 1.5815 Lr: 0.00062
[2025-04-08 14:23:08,416 INFO misc.py line 113 3298914] Train: [2/100][1444/2402] Data 0.004 (0.004) Batch 0.452 (0.481) Remain 31:34:50 loss: 1.1760 Lr: 0.00062
[2025-04-08 14:23:08,901 INFO misc.py line 113 3298914] Train: [2/100][1445/2402] Data 0.004 (0.004) Batch 0.485 (0.481) Remain 31:34:50 loss: 1.0116 Lr: 0.00062
[2025-04-08 14:23:09,402 INFO misc.py line 113 3298914] Train: [2/100][1446/2402] Data 0.004 (0.004) Batch 0.501 (0.481) Remain 31:34:52 loss: 1.3933 Lr: 0.00062
[2025-04-08 14:23:09,955 INFO misc.py line 113 3298914] Train: [2/100][1447/2402] Data 0.003 (0.004) Batch 0.553 (0.481) Remain 31:35:04 loss: 1.1916 Lr: 0.00062
[2025-04-08 14:23:10,358 INFO misc.py line 113 3298914] Train: [2/100][1448/2402] Data 0.003 (0.004) Batch 0.403 (0.481) Remain 31:34:51 loss: 1.2442 Lr: 0.00062
[2025-04-08 14:23:10,813 INFO misc.py line 113 3298914] Train: [2/100][1449/2402] Data 0.004 (0.004) Batch 0.455 (0.481) Remain 31:34:46 loss: 1.4377 Lr: 0.00062
[2025-04-08 14:23:11,179 INFO misc.py line 113 3298914] Train: [2/100][1450/2402] Data 0.004 (0.004) Batch 0.365 (0.481) Remain 31:34:26 loss: 0.8680 Lr: 0.00062
[2025-04-08 14:23:11,760 INFO misc.py line 113 3298914] Train: [2/100][1451/2402] Data 0.004 (0.004) Batch 0.582 (0.481) Remain 31:34:42 loss: 1.7691 Lr: 0.00062
[2025-04-08 14:23:12,209 INFO misc.py line 113 3298914] Train: [2/100][1452/2402] Data 0.004 (0.004) Batch 0.449 (0.481) Remain 31:34:37 loss: 1.5031 Lr: 0.00062
[2025-04-08 14:23:12,743 INFO misc.py line 113 3298914] Train: [2/100][1453/2402] Data 0.004 (0.004) Batch 0.534 (0.481) Remain 31:34:45 loss: 1.8537 Lr: 0.00062
[2025-04-08 14:23:13,227 INFO misc.py line 113 3298914] Train: [2/100][1454/2402] Data 0.003 (0.004) Batch 0.484 (0.481) Remain 31:34:45 loss: 1.3187 Lr: 0.00062
[2025-04-08 14:23:13,802 INFO misc.py line 113 3298914] Train: [2/100][1455/2402] Data 0.004 (0.004) Batch 0.575 (0.481) Remain 31:35:00 loss: 1.2803 Lr: 0.00062
[2025-04-08 14:23:14,238 INFO misc.py line 113 3298914] Train: [2/100][1456/2402] Data 0.004 (0.004) Batch 0.436 (0.481) Remain 31:34:52 loss: 1.6984 Lr: 0.00062
[2025-04-08 14:23:14,788 INFO misc.py line 113 3298914] Train: [2/100][1457/2402] Data 0.003 (0.004) Batch 0.549 (0.481) Remain 31:35:03 loss: 1.2382 Lr: 0.00062
[2025-04-08 14:23:15,358 INFO misc.py line 113 3298914] Train: [2/100][1458/2402] Data 0.004 (0.004) Batch 0.571 (0.481) Remain 31:35:17 loss: 1.2116 Lr: 0.00062
[2025-04-08 14:23:15,836 INFO misc.py line 113 3298914] Train: [2/100][1459/2402] Data 0.003 (0.004) Batch 0.478 (0.481) Remain 31:35:16 loss: 1.6707 Lr: 0.00062
[2025-04-08 14:23:16,285 INFO misc.py line 113 3298914] Train: [2/100][1460/2402] Data 0.004 (0.004) Batch 0.449 (0.481) Remain 31:35:10 loss: 1.0732 Lr: 0.00062
[2025-04-08 14:23:16,795 INFO misc.py line 113 3298914] Train: [2/100][1461/2402] Data 0.004 (0.004) Batch 0.510 (0.481) Remain 31:35:14 loss: 1.3189 Lr: 0.00062
[2025-04-08 14:23:17,148 INFO misc.py line 113 3298914] Train: [2/100][1462/2402] Data 0.004 (0.004) Batch 0.352 (0.481) Remain 31:34:53 loss: 1.6297 Lr: 0.00062
[2025-04-08 14:23:17,591 INFO misc.py line 113 3298914] Train: [2/100][1463/2402] Data 0.004 (0.004) Batch 0.443 (0.481) Remain 31:34:46 loss: 1.2557 Lr: 0.00062
[2025-04-08 14:23:18,061 INFO misc.py line 113 3298914] Train: [2/100][1464/2402] Data 0.003 (0.004) Batch 0.470 (0.481) Remain 31:34:44 loss: 1.3978 Lr: 0.00062
[2025-04-08 14:23:18,431 INFO misc.py line 113 3298914] Train: [2/100][1465/2402] Data 0.004 (0.004) Batch 0.371 (0.481) Remain 31:34:25 loss: 1.7119 Lr: 0.00062
[2025-04-08 14:23:18,990 INFO misc.py line 113 3298914] Train: [2/100][1466/2402] Data 0.003 (0.004) Batch 0.558 (0.481) Remain 31:34:38 loss: 1.6886 Lr: 0.00062
[2025-04-08 14:23:19,380 INFO misc.py line 113 3298914] Train: [2/100][1467/2402] Data 0.004 (0.004) Batch 0.391 (0.481) Remain 31:34:23 loss: 1.7983 Lr: 0.00062
[2025-04-08 14:23:19,873 INFO misc.py line 113 3298914] Train: [2/100][1468/2402] Data 0.003 (0.004) Batch 0.492 (0.481) Remain 31:34:24 loss: 1.2823 Lr: 0.00062
[2025-04-08 14:23:20,261 INFO misc.py line 113 3298914] Train: [2/100][1469/2402] Data 0.004 (0.004) Batch 0.388 (0.481) Remain 31:34:08 loss: 1.3615 Lr: 0.00062
[2025-04-08 14:23:20,622 INFO misc.py line 113 3298914] Train: [2/100][1470/2402] Data 0.003 (0.004) Batch 0.361 (0.481) Remain 31:33:49 loss: 0.9374 Lr: 0.00062
[2025-04-08 14:23:21,108 INFO misc.py line 113 3298914] Train: [2/100][1471/2402] Data 0.004 (0.004) Batch 0.486 (0.481) Remain 31:33:49 loss: 1.3385 Lr: 0.00062
[2025-04-08 14:23:21,699 INFO misc.py line 113 3298914] Train: [2/100][1472/2402] Data 0.004 (0.004) Batch 0.591 (0.481) Remain 31:34:06 loss: 1.3626 Lr: 0.00062
[2025-04-08 14:23:22,199 INFO misc.py line 113 3298914] Train: [2/100][1473/2402] Data 0.003 (0.004) Batch 0.499 (0.481) Remain 31:34:09 loss: 1.1780 Lr: 0.00062
[2025-04-08 14:23:22,707 INFO misc.py line 113 3298914] Train: [2/100][1474/2402] Data 0.004 (0.004) Batch 0.508 (0.481) Remain 31:34:13 loss: 1.4355 Lr: 0.00062
[2025-04-08 14:23:23,196 INFO misc.py line 113 3298914] Train: [2/100][1475/2402] Data 0.004 (0.004) Batch 0.489 (0.481) Remain 31:34:13 loss: 1.6595 Lr: 0.00062
[2025-04-08 14:23:23,587 INFO misc.py line 113 3298914] Train: [2/100][1476/2402] Data 0.003 (0.004) Batch 0.391 (0.481) Remain 31:33:59 loss: 1.3466 Lr: 0.00062
[2025-04-08 14:23:24,028 INFO misc.py line 113 3298914] Train: [2/100][1477/2402] Data 0.004 (0.004) Batch 0.441 (0.481) Remain 31:33:52 loss: 1.5078 Lr: 0.00062
[2025-04-08 14:23:24,478 INFO misc.py line 113 3298914] Train: [2/100][1478/2402] Data 0.003 (0.004) Batch 0.451 (0.481) Remain 31:33:46 loss: 1.6840 Lr: 0.00062
[2025-04-08 14:23:25,129 INFO misc.py line 113 3298914] Train: [2/100][1479/2402] Data 0.003 (0.004) Batch 0.651 (0.481) Remain 31:34:13 loss: 1.3755 Lr: 0.00062
[2025-04-08 14:23:25,554 INFO misc.py line 113 3298914] Train: [2/100][1480/2402] Data 0.005 (0.004) Batch 0.424 (0.481) Remain 31:34:04 loss: 1.0203 Lr: 0.00062
[2025-04-08 14:23:26,042 INFO misc.py line 113 3298914] Train: [2/100][1481/2402] Data 0.003 (0.004) Batch 0.488 (0.481) Remain 31:34:04 loss: 0.9852 Lr: 0.00062
[2025-04-08 14:23:26,483 INFO misc.py line 113 3298914] Train: [2/100][1482/2402] Data 0.003 (0.004) Batch 0.441 (0.481) Remain 31:33:57 loss: 1.4328 Lr: 0.00063
[2025-04-08 14:23:26,974 INFO misc.py line 113 3298914] Train: [2/100][1483/2402] Data 0.004 (0.004) Batch 0.492 (0.481) Remain 31:33:59 loss: 1.0262 Lr: 0.00063
[2025-04-08 14:23:27,514 INFO misc.py line 113 3298914] Train: [2/100][1484/2402] Data 0.004 (0.004) Batch 0.540 (0.481) Remain 31:34:08 loss: 0.9124 Lr: 0.00063
[2025-04-08 14:23:27,852 INFO misc.py line 113 3298914] Train: [2/100][1485/2402] Data 0.004 (0.004) Batch 0.338 (0.481) Remain 31:33:44 loss: 1.3440 Lr: 0.00063
[2025-04-08 14:23:28,330 INFO misc.py line 113 3298914] Train: [2/100][1486/2402] Data 0.004 (0.004) Batch 0.478 (0.481) Remain 31:33:43 loss: 1.4155 Lr: 0.00063
[2025-04-08 14:23:28,828 INFO misc.py line 113 3298914] Train: [2/100][1487/2402] Data 0.003 (0.004) Batch 0.498 (0.481) Remain 31:33:45 loss: 1.1182 Lr: 0.00063
[2025-04-08 14:23:29,358 INFO misc.py line 113 3298914] Train: [2/100][1488/2402] Data 0.004 (0.004) Batch 0.531 (0.481) Remain 31:33:53 loss: 1.3355 Lr: 0.00063
[2025-04-08 14:23:29,938 INFO misc.py line 113 3298914] Train: [2/100][1489/2402] Data 0.003 (0.004) Batch 0.579 (0.481) Remain 31:34:08 loss: 1.1732 Lr: 0.00063
[2025-04-08 14:23:30,399 INFO misc.py line 113 3298914] Train: [2/100][1490/2402] Data 0.004 (0.004) Batch 0.461 (0.481) Remain 31:34:05 loss: 1.8513 Lr: 0.00063
[2025-04-08 14:23:30,796 INFO misc.py line 113 3298914] Train: [2/100][1491/2402] Data 0.004 (0.004) Batch 0.397 (0.481) Remain 31:33:51 loss: 1.1145 Lr: 0.00063
[2025-04-08 14:23:31,275 INFO misc.py line 113 3298914] Train: [2/100][1492/2402] Data 0.003 (0.004) Batch 0.479 (0.481) Remain 31:33:50 loss: 1.2761 Lr: 0.00063
[2025-04-08 14:23:31,819 INFO misc.py line 113 3298914] Train: [2/100][1493/2402] Data 0.004 (0.004) Batch 0.543 (0.481) Remain 31:33:59 loss: 1.3268 Lr: 0.00063
[2025-04-08 14:23:32,170 INFO misc.py line 113 3298914] Train: [2/100][1494/2402] Data 0.003 (0.004) Batch 0.352 (0.481) Remain 31:33:39 loss: 1.2414 Lr: 0.00063
[2025-04-08 14:23:32,721 INFO misc.py line 113 3298914] Train: [2/100][1495/2402] Data 0.003 (0.004) Batch 0.550 (0.481) Remain 31:33:49 loss: 1.3382 Lr: 0.00063
[2025-04-08 14:23:33,216 INFO misc.py line 113 3298914] Train: [2/100][1496/2402] Data 0.004 (0.004) Batch 0.495 (0.481) Remain 31:33:51 loss: 1.1215 Lr: 0.00063
[2025-04-08 14:23:33,708 INFO misc.py line 113 3298914] Train: [2/100][1497/2402] Data 0.003 (0.004) Batch 0.492 (0.481) Remain 31:33:52 loss: 1.4669 Lr: 0.00063
[2025-04-08 14:23:34,115 INFO misc.py line 113 3298914] Train: [2/100][1498/2402] Data 0.004 (0.004) Batch 0.407 (0.481) Remain 31:33:40 loss: 1.4633 Lr: 0.00063
[2025-04-08 14:23:34,662 INFO misc.py line 113 3298914] Train: [2/100][1499/2402] Data 0.004 (0.004) Batch 0.548 (0.481) Remain 31:33:50 loss: 1.0850 Lr: 0.00063
[2025-04-08 14:23:35,147 INFO misc.py line 113 3298914] Train: [2/100][1500/2402] Data 0.003 (0.004) Batch 0.485 (0.481) Remain 31:33:50 loss: 1.1968 Lr: 0.00063
[2025-04-08 14:23:35,520 INFO misc.py line 113 3298914] Train: [2/100][1501/2402] Data 0.004 (0.004) Batch 0.373 (0.481) Remain 31:33:33 loss: 1.1945 Lr: 0.00063
[2025-04-08 14:23:36,000 INFO misc.py line 113 3298914] Train: [2/100][1502/2402] Data 0.004 (0.004) Batch 0.480 (0.481) Remain 31:33:32 loss: 0.9505 Lr: 0.00063
[2025-04-08 14:23:36,403 INFO misc.py line 113 3298914] Train: [2/100][1503/2402] Data 0.004 (0.004) Batch 0.403 (0.481) Remain 31:33:19 loss: 1.4330 Lr: 0.00063
[2025-04-08 14:23:36,865 INFO misc.py line 113 3298914] Train: [2/100][1504/2402] Data 0.004 (0.004) Batch 0.462 (0.481) Remain 31:33:16 loss: 1.4869 Lr: 0.00063
[2025-04-08 14:23:37,333 INFO misc.py line 113 3298914] Train: [2/100][1505/2402] Data 0.003 (0.004) Batch 0.467 (0.481) Remain 31:33:13 loss: 1.6715 Lr: 0.00063
[2025-04-08 14:23:37,669 INFO misc.py line 113 3298914] Train: [2/100][1506/2402] Data 0.004 (0.004) Batch 0.337 (0.481) Remain 31:32:50 loss: 1.4313 Lr: 0.00063
[2025-04-08 14:23:38,145 INFO misc.py line 113 3298914] Train: [2/100][1507/2402] Data 0.004 (0.004) Batch 0.475 (0.481) Remain 31:32:49 loss: 1.2238 Lr: 0.00063
[2025-04-08 14:23:38,631 INFO misc.py line 113 3298914] Train: [2/100][1508/2402] Data 0.004 (0.004) Batch 0.486 (0.481) Remain 31:32:49 loss: 1.3776 Lr: 0.00063
[2025-04-08 14:23:38,975 INFO misc.py line 113 3298914] Train: [2/100][1509/2402] Data 0.004 (0.004) Batch 0.344 (0.481) Remain 31:32:27 loss: 1.4455 Lr: 0.00063
[2025-04-08 14:23:39,458 INFO misc.py line 113 3298914] Train: [2/100][1510/2402] Data 0.004 (0.004) Batch 0.483 (0.481) Remain 31:32:27 loss: 1.0895 Lr: 0.00063
[2025-04-08 14:23:39,991 INFO misc.py line 113 3298914] Train: [2/100][1511/2402] Data 0.004 (0.004) Batch 0.534 (0.481) Remain 31:32:35 loss: 1.4720 Lr: 0.00063
[2025-04-08 14:23:40,540 INFO misc.py line 113 3298914] Train: [2/100][1512/2402] Data 0.004 (0.004) Batch 0.549 (0.481) Remain 31:32:45 loss: 1.1927 Lr: 0.00063
[2025-04-08 14:23:41,024 INFO misc.py line 113 3298914] Train: [2/100][1513/2402] Data 0.003 (0.004) Batch 0.484 (0.481) Remain 31:32:45 loss: 0.8755 Lr: 0.00063
[2025-04-08 14:23:41,527 INFO misc.py line 113 3298914] Train: [2/100][1514/2402] Data 0.003 (0.004) Batch 0.504 (0.481) Remain 31:32:48 loss: 1.1297 Lr: 0.00063
[2025-04-08 14:23:41,997 INFO misc.py line 113 3298914] Train: [2/100][1515/2402] Data 0.004 (0.004) Batch 0.469 (0.481) Remain 31:32:46 loss: 1.3642 Lr: 0.00063
[2025-04-08 14:23:42,369 INFO misc.py line 113 3298914] Train: [2/100][1516/2402] Data 0.004 (0.004) Batch 0.372 (0.481) Remain 31:32:29 loss: 1.3401 Lr: 0.00063
[2025-04-08 14:23:42,736 INFO misc.py line 113 3298914] Train: [2/100][1517/2402] Data 0.003 (0.004) Batch 0.367 (0.480) Remain 31:32:10 loss: 1.1918 Lr: 0.00063
[2025-04-08 14:23:43,238 INFO misc.py line 113 3298914] Train: [2/100][1518/2402] Data 0.004 (0.004) Batch 0.502 (0.481) Remain 31:32:13 loss: 1.1653 Lr: 0.00063
[2025-04-08 14:23:43,807 INFO misc.py line 113 3298914] Train: [2/100][1519/2402] Data 0.004 (0.004) Batch 0.569 (0.481) Remain 31:32:27 loss: 1.8700 Lr: 0.00063
[2025-04-08 14:23:44,357 INFO misc.py line 113 3298914] Train: [2/100][1520/2402] Data 0.003 (0.004) Batch 0.551 (0.481) Remain 31:32:37 loss: 1.5803 Lr: 0.00063
[2025-04-08 14:23:44,877 INFO misc.py line 113 3298914] Train: [2/100][1521/2402] Data 0.003 (0.004) Batch 0.520 (0.481) Remain 31:32:43 loss: 1.2509 Lr: 0.00063
[2025-04-08 14:23:45,383 INFO misc.py line 113 3298914] Train: [2/100][1522/2402] Data 0.004 (0.004) Batch 0.505 (0.481) Remain 31:32:46 loss: 1.5215 Lr: 0.00063
[2025-04-08 14:23:45,862 INFO misc.py line 113 3298914] Train: [2/100][1523/2402] Data 0.003 (0.004) Batch 0.479 (0.481) Remain 31:32:45 loss: 1.2842 Lr: 0.00063
[2025-04-08 14:23:46,385 INFO misc.py line 113 3298914] Train: [2/100][1524/2402] Data 0.004 (0.004) Batch 0.523 (0.481) Remain 31:32:51 loss: 1.3378 Lr: 0.00063
[2025-04-08 14:23:46,840 INFO misc.py line 113 3298914] Train: [2/100][1525/2402] Data 0.004 (0.004) Batch 0.455 (0.481) Remain 31:32:47 loss: 1.4264 Lr: 0.00063
[2025-04-08 14:23:47,239 INFO misc.py line 113 3298914] Train: [2/100][1526/2402] Data 0.004 (0.004) Batch 0.399 (0.481) Remain 31:32:34 loss: 1.3632 Lr: 0.00063
[2025-04-08 14:23:47,626 INFO misc.py line 113 3298914] Train: [2/100][1527/2402] Data 0.004 (0.004) Batch 0.387 (0.481) Remain 31:32:19 loss: 1.2676 Lr: 0.00063
[2025-04-08 14:23:48,001 INFO misc.py line 113 3298914] Train: [2/100][1528/2402] Data 0.003 (0.004) Batch 0.374 (0.480) Remain 31:32:02 loss: 0.7843 Lr: 0.00063
[2025-04-08 14:23:48,574 INFO misc.py line 113 3298914] Train: [2/100][1529/2402] Data 0.004 (0.004) Batch 0.574 (0.481) Remain 31:32:16 loss: 1.6069 Lr: 0.00063
[2025-04-08 14:23:49,045 INFO misc.py line 113 3298914] Train: [2/100][1530/2402] Data 0.004 (0.004) Batch 0.472 (0.481) Remain 31:32:14 loss: 0.9383 Lr: 0.00063
[2025-04-08 14:23:49,549 INFO misc.py line 113 3298914] Train: [2/100][1531/2402] Data 0.004 (0.004) Batch 0.503 (0.481) Remain 31:32:17 loss: 1.1240 Lr: 0.00063
[2025-04-08 14:23:50,040 INFO misc.py line 113 3298914] Train: [2/100][1532/2402] Data 0.003 (0.004) Batch 0.491 (0.481) Remain 31:32:18 loss: 1.4139 Lr: 0.00064
[2025-04-08 14:23:50,550 INFO misc.py line 113 3298914] Train: [2/100][1533/2402] Data 0.004 (0.004) Batch 0.510 (0.481) Remain 31:32:22 loss: 1.5991 Lr: 0.00064
[2025-04-08 14:23:51,019 INFO misc.py line 113 3298914] Train: [2/100][1534/2402] Data 0.004 (0.004) Batch 0.470 (0.481) Remain 31:32:20 loss: 1.6749 Lr: 0.00064
[2025-04-08 14:23:51,564 INFO misc.py line 113 3298914] Train: [2/100][1535/2402] Data 0.003 (0.004) Batch 0.545 (0.481) Remain 31:32:29 loss: 1.3999 Lr: 0.00064
[2025-04-08 14:23:52,005 INFO misc.py line 113 3298914] Train: [2/100][1536/2402] Data 0.004 (0.004) Batch 0.441 (0.481) Remain 31:32:23 loss: 0.9936 Lr: 0.00064
[2025-04-08 14:23:52,519 INFO misc.py line 113 3298914] Train: [2/100][1537/2402] Data 0.004 (0.004) Batch 0.514 (0.481) Remain 31:32:27 loss: 1.8785 Lr: 0.00064
[2025-04-08 14:23:52,973 INFO misc.py line 113 3298914] Train: [2/100][1538/2402] Data 0.003 (0.004) Batch 0.453 (0.481) Remain 31:32:23 loss: 1.4330 Lr: 0.00064
[2025-04-08 14:23:53,509 INFO misc.py line 113 3298914] Train: [2/100][1539/2402] Data 0.004 (0.004) Batch 0.536 (0.481) Remain 31:32:31 loss: 1.1167 Lr: 0.00064
[2025-04-08 14:23:53,948 INFO misc.py line 113 3298914] Train: [2/100][1540/2402] Data 0.004 (0.004) Batch 0.440 (0.481) Remain 31:32:24 loss: 1.6034 Lr: 0.00064
[2025-04-08 14:23:54,404 INFO misc.py line 113 3298914] Train: [2/100][1541/2402] Data 0.003 (0.004) Batch 0.456 (0.481) Remain 31:32:20 loss: 1.7671 Lr: 0.00064
[2025-04-08 14:23:54,947 INFO misc.py line 113 3298914] Train: [2/100][1542/2402] Data 0.004 (0.004) Batch 0.543 (0.481) Remain 31:32:29 loss: 1.3084 Lr: 0.00064
[2025-04-08 14:23:55,408 INFO misc.py line 113 3298914] Train: [2/100][1543/2402] Data 0.004 (0.004) Batch 0.461 (0.481) Remain 31:32:25 loss: 1.4259 Lr: 0.00064
[2025-04-08 14:23:55,782 INFO misc.py line 113 3298914] Train: [2/100][1544/2402] Data 0.004 (0.004) Batch 0.374 (0.481) Remain 31:32:09 loss: 1.2351 Lr: 0.00064
[2025-04-08 14:23:56,145 INFO misc.py line 113 3298914] Train: [2/100][1545/2402] Data 0.003 (0.004) Batch 0.363 (0.480) Remain 31:31:50 loss: 1.0811 Lr: 0.00064
[2025-04-08 14:23:56,681 INFO misc.py line 113 3298914] Train: [2/100][1546/2402] Data 0.004 (0.004) Batch 0.536 (0.480) Remain 31:31:58 loss: 1.5714 Lr: 0.00064
[2025-04-08 14:23:57,139 INFO misc.py line 113 3298914] Train: [2/100][1547/2402] Data 0.004 (0.004) Batch 0.459 (0.480) Remain 31:31:54 loss: 1.4106 Lr: 0.00064
[2025-04-08 14:23:57,640 INFO misc.py line 113 3298914] Train: [2/100][1548/2402] Data 0.004 (0.004) Batch 0.500 (0.480) Remain 31:31:57 loss: 1.3858 Lr: 0.00064
[2025-04-08 14:23:58,157 INFO misc.py line 113 3298914] Train: [2/100][1549/2402] Data 0.004 (0.004) Batch 0.517 (0.481) Remain 31:32:02 loss: 1.4627 Lr: 0.00064
[2025-04-08 14:23:58,503 INFO misc.py line 113 3298914] Train: [2/100][1550/2402] Data 0.003 (0.004) Batch 0.347 (0.480) Remain 31:31:41 loss: 1.5467 Lr: 0.00064
[2025-04-08 14:23:59,077 INFO misc.py line 113 3298914] Train: [2/100][1551/2402] Data 0.003 (0.004) Batch 0.574 (0.480) Remain 31:31:55 loss: 1.4539 Lr: 0.00064
[2025-04-08 14:23:59,584 INFO misc.py line 113 3298914] Train: [2/100][1552/2402] Data 0.004 (0.004) Batch 0.507 (0.481) Remain 31:31:58 loss: 1.2036 Lr: 0.00064
[2025-04-08 14:24:00,103 INFO misc.py line 113 3298914] Train: [2/100][1553/2402] Data 0.004 (0.004) Batch 0.519 (0.481) Remain 31:32:04 loss: 1.2658 Lr: 0.00064
[2025-04-08 14:24:00,597 INFO misc.py line 113 3298914] Train: [2/100][1554/2402] Data 0.003 (0.004) Batch 0.494 (0.481) Remain 31:32:05 loss: 1.3016 Lr: 0.00064
[2025-04-08 14:24:01,183 INFO misc.py line 113 3298914] Train: [2/100][1555/2402] Data 0.004 (0.004) Batch 0.586 (0.481) Remain 31:32:21 loss: 1.3490 Lr: 0.00064
[2025-04-08 14:24:01,659 INFO misc.py line 113 3298914] Train: [2/100][1556/2402] Data 0.004 (0.004) Batch 0.476 (0.481) Remain 31:32:20 loss: 1.2820 Lr: 0.00064
[2025-04-08 14:24:02,042 INFO misc.py line 113 3298914] Train: [2/100][1557/2402] Data 0.004 (0.004) Batch 0.383 (0.481) Remain 31:32:04 loss: 0.9076 Lr: 0.00064
[2025-04-08 14:24:02,481 INFO misc.py line 113 3298914] Train: [2/100][1558/2402] Data 0.004 (0.004) Batch 0.440 (0.481) Remain 31:31:58 loss: 1.3689 Lr: 0.00064
[2025-04-08 14:24:03,002 INFO misc.py line 113 3298914] Train: [2/100][1559/2402] Data 0.003 (0.004) Batch 0.521 (0.481) Remain 31:32:03 loss: 1.2770 Lr: 0.00064
[2025-04-08 14:24:03,547 INFO misc.py line 113 3298914] Train: [2/100][1560/2402] Data 0.004 (0.004) Batch 0.545 (0.481) Remain 31:32:12 loss: 1.3145 Lr: 0.00064
[2025-04-08 14:24:03,976 INFO misc.py line 113 3298914] Train: [2/100][1561/2402] Data 0.004 (0.004) Batch 0.429 (0.481) Remain 31:32:04 loss: 1.6610 Lr: 0.00064
[2025-04-08 14:24:04,411 INFO misc.py line 113 3298914] Train: [2/100][1562/2402] Data 0.004 (0.004) Batch 0.435 (0.481) Remain 31:31:57 loss: 1.4022 Lr: 0.00064
[2025-04-08 14:24:04,804 INFO misc.py line 113 3298914] Train: [2/100][1563/2402] Data 0.003 (0.004) Batch 0.393 (0.480) Remain 31:31:43 loss: 1.1716 Lr: 0.00064
[2025-04-08 14:24:05,355 INFO misc.py line 113 3298914] Train: [2/100][1564/2402] Data 0.004 (0.004) Batch 0.550 (0.481) Remain 31:31:53 loss: 1.3312 Lr: 0.00064
[2025-04-08 14:24:05,854 INFO misc.py line 113 3298914] Train: [2/100][1565/2402] Data 0.005 (0.004) Batch 0.500 (0.481) Remain 31:31:56 loss: 1.6208 Lr: 0.00064
[2025-04-08 14:24:06,346 INFO misc.py line 113 3298914] Train: [2/100][1566/2402] Data 0.004 (0.004) Batch 0.492 (0.481) Remain 31:31:57 loss: 1.4850 Lr: 0.00064
[2025-04-08 14:24:06,775 INFO misc.py line 113 3298914] Train: [2/100][1567/2402] Data 0.004 (0.004) Batch 0.430 (0.481) Remain 31:31:49 loss: 1.4094 Lr: 0.00064
[2025-04-08 14:24:07,257 INFO misc.py line 113 3298914] Train: [2/100][1568/2402] Data 0.003 (0.004) Batch 0.482 (0.481) Remain 31:31:48 loss: 1.0917 Lr: 0.00064
[2025-04-08 14:24:07,818 INFO misc.py line 113 3298914] Train: [2/100][1569/2402] Data 0.003 (0.004) Batch 0.561 (0.481) Remain 31:32:00 loss: 1.0328 Lr: 0.00064
[2025-04-08 14:24:08,207 INFO misc.py line 113 3298914] Train: [2/100][1570/2402] Data 0.003 (0.004) Batch 0.388 (0.480) Remain 31:31:46 loss: 0.8111 Lr: 0.00064
[2025-04-08 14:24:08,658 INFO misc.py line 113 3298914] Train: [2/100][1571/2402] Data 0.004 (0.004) Batch 0.452 (0.480) Remain 31:31:41 loss: 1.2834 Lr: 0.00064
[2025-04-08 14:24:09,036 INFO misc.py line 113 3298914] Train: [2/100][1572/2402] Data 0.003 (0.004) Batch 0.378 (0.480) Remain 31:31:25 loss: 1.2558 Lr: 0.00064
[2025-04-08 14:24:09,434 INFO misc.py line 113 3298914] Train: [2/100][1573/2402] Data 0.004 (0.004) Batch 0.398 (0.480) Remain 31:31:12 loss: 1.4552 Lr: 0.00064
[2025-04-08 14:24:09,830 INFO misc.py line 113 3298914] Train: [2/100][1574/2402] Data 0.004 (0.004) Batch 0.397 (0.480) Remain 31:30:59 loss: 1.2791 Lr: 0.00064
[2025-04-08 14:24:10,171 INFO misc.py line 113 3298914] Train: [2/100][1575/2402] Data 0.004 (0.004) Batch 0.341 (0.480) Remain 31:30:37 loss: 0.9908 Lr: 0.00064
[2025-04-08 14:24:10,621 INFO misc.py line 113 3298914] Train: [2/100][1576/2402] Data 0.004 (0.004) Batch 0.450 (0.480) Remain 31:30:32 loss: 1.3364 Lr: 0.00064
[2025-04-08 14:24:11,086 INFO misc.py line 113 3298914] Train: [2/100][1577/2402] Data 0.003 (0.004) Batch 0.465 (0.480) Remain 31:30:30 loss: 1.0172 Lr: 0.00064
[2025-04-08 14:24:11,621 INFO misc.py line 113 3298914] Train: [2/100][1578/2402] Data 0.004 (0.004) Batch 0.535 (0.480) Remain 31:30:37 loss: 0.7577 Lr: 0.00064
[2025-04-08 14:24:12,121 INFO misc.py line 113 3298914] Train: [2/100][1579/2402] Data 0.003 (0.004) Batch 0.500 (0.480) Remain 31:30:40 loss: 1.2357 Lr: 0.00064
[2025-04-08 14:24:12,685 INFO misc.py line 113 3298914] Train: [2/100][1580/2402] Data 0.004 (0.004) Batch 0.563 (0.480) Remain 31:30:52 loss: 1.5469 Lr: 0.00064
[2025-04-08 14:24:13,081 INFO misc.py line 113 3298914] Train: [2/100][1581/2402] Data 0.004 (0.004) Batch 0.397 (0.480) Remain 31:30:39 loss: 1.3020 Lr: 0.00065
[2025-04-08 14:24:13,644 INFO misc.py line 113 3298914] Train: [2/100][1582/2402] Data 0.004 (0.004) Batch 0.563 (0.480) Remain 31:30:51 loss: 1.7234 Lr: 0.00065
[2025-04-08 14:24:14,160 INFO misc.py line 113 3298914] Train: [2/100][1583/2402] Data 0.003 (0.004) Batch 0.516 (0.480) Remain 31:30:56 loss: 1.3352 Lr: 0.00065
[2025-04-08 14:24:14,604 INFO misc.py line 113 3298914] Train: [2/100][1584/2402] Data 0.004 (0.004) Batch 0.444 (0.480) Remain 31:30:50 loss: 1.4252 Lr: 0.00065
[2025-04-08 14:24:15,058 INFO misc.py line 113 3298914] Train: [2/100][1585/2402] Data 0.004 (0.004) Batch 0.455 (0.480) Remain 31:30:45 loss: 1.3379 Lr: 0.00065
[2025-04-08 14:24:15,594 INFO misc.py line 113 3298914] Train: [2/100][1586/2402] Data 0.003 (0.004) Batch 0.535 (0.480) Remain 31:30:53 loss: 1.5488 Lr: 0.00065
[2025-04-08 14:24:16,085 INFO misc.py line 113 3298914] Train: [2/100][1587/2402] Data 0.004 (0.004) Batch 0.491 (0.480) Remain 31:30:54 loss: 1.4467 Lr: 0.00065
[2025-04-08 14:24:16,553 INFO misc.py line 113 3298914] Train: [2/100][1588/2402] Data 0.004 (0.004) Batch 0.467 (0.480) Remain 31:30:52 loss: 1.0966 Lr: 0.00065
[2025-04-08 14:24:17,058 INFO misc.py line 113 3298914] Train: [2/100][1589/2402] Data 0.004 (0.004) Batch 0.505 (0.480) Remain 31:30:55 loss: 1.0823 Lr: 0.00065
[2025-04-08 14:24:17,488 INFO misc.py line 113 3298914] Train: [2/100][1590/2402] Data 0.004 (0.004) Batch 0.430 (0.480) Remain 31:30:47 loss: 1.4113 Lr: 0.00065
[2025-04-08 14:24:17,944 INFO misc.py line 113 3298914] Train: [2/100][1591/2402] Data 0.004 (0.004) Batch 0.456 (0.480) Remain 31:30:43 loss: 1.7412 Lr: 0.00065
[2025-04-08 14:24:18,333 INFO misc.py line 113 3298914] Train: [2/100][1592/2402] Data 0.004 (0.004) Batch 0.389 (0.480) Remain 31:30:29 loss: 1.0714 Lr: 0.00065
[2025-04-08 14:24:18,776 INFO misc.py line 113 3298914] Train: [2/100][1593/2402] Data 0.004 (0.004) Batch 0.443 (0.480) Remain 31:30:23 loss: 1.3744 Lr: 0.00065
[2025-04-08 14:24:19,248 INFO misc.py line 113 3298914] Train: [2/100][1594/2402] Data 0.004 (0.004) Batch 0.472 (0.480) Remain 31:30:21 loss: 1.4726 Lr: 0.00065
[2025-04-08 14:24:19,666 INFO misc.py line 113 3298914] Train: [2/100][1595/2402] Data 0.004 (0.004) Batch 0.418 (0.480) Remain 31:30:12 loss: 1.6005 Lr: 0.00065
[2025-04-08 14:24:20,090 INFO misc.py line 113 3298914] Train: [2/100][1596/2402] Data 0.003 (0.004) Batch 0.424 (0.480) Remain 31:30:03 loss: 1.1750 Lr: 0.00065
[2025-04-08 14:24:20,615 INFO misc.py line 113 3298914] Train: [2/100][1597/2402] Data 0.004 (0.004) Batch 0.524 (0.480) Remain 31:30:09 loss: 1.4068 Lr: 0.00065
[2025-04-08 14:24:21,129 INFO misc.py line 113 3298914] Train: [2/100][1598/2402] Data 0.004 (0.004) Batch 0.515 (0.480) Remain 31:30:14 loss: 1.0194 Lr: 0.00065
[2025-04-08 14:24:21,669 INFO misc.py line 113 3298914] Train: [2/100][1599/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:30:22 loss: 1.4640 Lr: 0.00065
[2025-04-08 14:24:22,142 INFO misc.py line 113 3298914] Train: [2/100][1600/2402] Data 0.003 (0.004) Batch 0.473 (0.480) Remain 31:30:20 loss: 1.2170 Lr: 0.00065
[2025-04-08 14:24:22,557 INFO misc.py line 113 3298914] Train: [2/100][1601/2402] Data 0.003 (0.004) Batch 0.415 (0.480) Remain 31:30:10 loss: 0.7938 Lr: 0.00065
[2025-04-08 14:24:23,063 INFO misc.py line 113 3298914] Train: [2/100][1602/2402] Data 0.004 (0.004) Batch 0.507 (0.480) Remain 31:30:14 loss: 1.7361 Lr: 0.00065
[2025-04-08 14:24:23,576 INFO misc.py line 113 3298914] Train: [2/100][1603/2402] Data 0.003 (0.004) Batch 0.512 (0.480) Remain 31:30:18 loss: 1.3718 Lr: 0.00065
[2025-04-08 14:24:24,135 INFO misc.py line 113 3298914] Train: [2/100][1604/2402] Data 0.004 (0.004) Batch 0.560 (0.480) Remain 31:30:29 loss: 1.2534 Lr: 0.00065
[2025-04-08 14:24:24,621 INFO misc.py line 113 3298914] Train: [2/100][1605/2402] Data 0.004 (0.004) Batch 0.486 (0.480) Remain 31:30:29 loss: 1.3639 Lr: 0.00065
[2025-04-08 14:24:25,139 INFO misc.py line 113 3298914] Train: [2/100][1606/2402] Data 0.004 (0.004) Batch 0.518 (0.480) Remain 31:30:35 loss: 1.4405 Lr: 0.00065
[2025-04-08 14:24:25,587 INFO misc.py line 113 3298914] Train: [2/100][1607/2402] Data 0.003 (0.004) Batch 0.448 (0.480) Remain 31:30:29 loss: 1.5049 Lr: 0.00065
[2025-04-08 14:24:26,089 INFO misc.py line 113 3298914] Train: [2/100][1608/2402] Data 0.003 (0.004) Batch 0.502 (0.480) Remain 31:30:32 loss: 1.1234 Lr: 0.00065
[2025-04-08 14:24:26,566 INFO misc.py line 113 3298914] Train: [2/100][1609/2402] Data 0.004 (0.004) Batch 0.476 (0.480) Remain 31:30:31 loss: 1.5953 Lr: 0.00065
[2025-04-08 14:24:27,061 INFO misc.py line 113 3298914] Train: [2/100][1610/2402] Data 0.004 (0.004) Batch 0.496 (0.480) Remain 31:30:33 loss: 1.1236 Lr: 0.00065
[2025-04-08 14:24:27,468 INFO misc.py line 113 3298914] Train: [2/100][1611/2402] Data 0.003 (0.004) Batch 0.407 (0.480) Remain 31:30:22 loss: 1.5221 Lr: 0.00065
[2025-04-08 14:24:27,911 INFO misc.py line 113 3298914] Train: [2/100][1612/2402] Data 0.004 (0.004) Batch 0.443 (0.480) Remain 31:30:16 loss: 1.1977 Lr: 0.00065
[2025-04-08 14:24:28,417 INFO misc.py line 113 3298914] Train: [2/100][1613/2402] Data 0.003 (0.004) Batch 0.505 (0.480) Remain 31:30:19 loss: 1.4624 Lr: 0.00065
[2025-04-08 14:24:28,883 INFO misc.py line 113 3298914] Train: [2/100][1614/2402] Data 0.003 (0.004) Batch 0.467 (0.480) Remain 31:30:16 loss: 1.3675 Lr: 0.00065
[2025-04-08 14:24:29,416 INFO misc.py line 113 3298914] Train: [2/100][1615/2402] Data 0.004 (0.004) Batch 0.533 (0.480) Remain 31:30:24 loss: 1.2225 Lr: 0.00065
[2025-04-08 14:24:29,819 INFO misc.py line 113 3298914] Train: [2/100][1616/2402] Data 0.003 (0.004) Batch 0.403 (0.480) Remain 31:30:12 loss: 1.2843 Lr: 0.00065
[2025-04-08 14:24:30,241 INFO misc.py line 113 3298914] Train: [2/100][1617/2402] Data 0.003 (0.004) Batch 0.422 (0.480) Remain 31:30:03 loss: 0.9809 Lr: 0.00065
[2025-04-08 14:24:30,756 INFO misc.py line 113 3298914] Train: [2/100][1618/2402] Data 0.004 (0.004) Batch 0.515 (0.480) Remain 31:30:07 loss: 1.5130 Lr: 0.00065
[2025-04-08 14:24:31,284 INFO misc.py line 113 3298914] Train: [2/100][1619/2402] Data 0.004 (0.004) Batch 0.529 (0.480) Remain 31:30:14 loss: 1.1481 Lr: 0.00065
[2025-04-08 14:24:31,709 INFO misc.py line 113 3298914] Train: [2/100][1620/2402] Data 0.003 (0.004) Batch 0.424 (0.480) Remain 31:30:05 loss: 1.1482 Lr: 0.00065
[2025-04-08 14:24:32,156 INFO misc.py line 113 3298914] Train: [2/100][1621/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:30:00 loss: 1.2417 Lr: 0.00065
[2025-04-08 14:24:32,608 INFO misc.py line 113 3298914] Train: [2/100][1622/2402] Data 0.003 (0.004) Batch 0.452 (0.480) Remain 31:29:55 loss: 1.3021 Lr: 0.00065
[2025-04-08 14:24:33,133 INFO misc.py line 113 3298914] Train: [2/100][1623/2402] Data 0.003 (0.004) Batch 0.525 (0.480) Remain 31:30:02 loss: 1.2745 Lr: 0.00065
[2025-04-08 14:24:33,626 INFO misc.py line 113 3298914] Train: [2/100][1624/2402] Data 0.004 (0.004) Batch 0.492 (0.480) Remain 31:30:03 loss: 1.6360 Lr: 0.00065
[2025-04-08 14:24:34,144 INFO misc.py line 113 3298914] Train: [2/100][1625/2402] Data 0.004 (0.004) Batch 0.518 (0.480) Remain 31:30:08 loss: 1.4560 Lr: 0.00065
[2025-04-08 14:24:34,606 INFO misc.py line 113 3298914] Train: [2/100][1626/2402] Data 0.004 (0.004) Batch 0.463 (0.480) Remain 31:30:05 loss: 1.2431 Lr: 0.00065
[2025-04-08 14:24:35,086 INFO misc.py line 113 3298914] Train: [2/100][1627/2402] Data 0.004 (0.004) Batch 0.479 (0.480) Remain 31:30:04 loss: 1.7290 Lr: 0.00065
[2025-04-08 14:24:35,626 INFO misc.py line 113 3298914] Train: [2/100][1628/2402] Data 0.004 (0.004) Batch 0.541 (0.480) Remain 31:30:13 loss: 1.4467 Lr: 0.00065
[2025-04-08 14:24:36,051 INFO misc.py line 113 3298914] Train: [2/100][1629/2402] Data 0.004 (0.004) Batch 0.425 (0.480) Remain 31:30:04 loss: 1.1996 Lr: 0.00065
[2025-04-08 14:24:36,531 INFO misc.py line 113 3298914] Train: [2/100][1630/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:30:03 loss: 1.3939 Lr: 0.00066
[2025-04-08 14:24:36,899 INFO misc.py line 113 3298914] Train: [2/100][1631/2402] Data 0.003 (0.004) Batch 0.368 (0.480) Remain 31:29:47 loss: 1.1912 Lr: 0.00066
[2025-04-08 14:24:37,294 INFO misc.py line 113 3298914] Train: [2/100][1632/2402] Data 0.004 (0.004) Batch 0.395 (0.480) Remain 31:29:34 loss: 1.9594 Lr: 0.00066
[2025-04-08 14:24:37,852 INFO misc.py line 113 3298914] Train: [2/100][1633/2402] Data 0.003 (0.004) Batch 0.559 (0.480) Remain 31:29:45 loss: 1.6916 Lr: 0.00066
[2025-04-08 14:24:38,275 INFO misc.py line 113 3298914] Train: [2/100][1634/2402] Data 0.003 (0.004) Batch 0.423 (0.480) Remain 31:29:36 loss: 1.4758 Lr: 0.00066
[2025-04-08 14:24:38,648 INFO misc.py line 113 3298914] Train: [2/100][1635/2402] Data 0.004 (0.004) Batch 0.374 (0.480) Remain 31:29:20 loss: 1.5290 Lr: 0.00066
[2025-04-08 14:24:39,086 INFO misc.py line 113 3298914] Train: [2/100][1636/2402] Data 0.003 (0.004) Batch 0.437 (0.480) Remain 31:29:13 loss: 1.1113 Lr: 0.00066
[2025-04-08 14:24:39,608 INFO misc.py line 113 3298914] Train: [2/100][1637/2402] Data 0.004 (0.004) Batch 0.523 (0.480) Remain 31:29:19 loss: 1.2388 Lr: 0.00066
[2025-04-08 14:24:40,035 INFO misc.py line 113 3298914] Train: [2/100][1638/2402] Data 0.003 (0.004) Batch 0.426 (0.480) Remain 31:29:11 loss: 1.6758 Lr: 0.00066
[2025-04-08 14:24:40,682 INFO misc.py line 113 3298914] Train: [2/100][1639/2402] Data 0.004 (0.004) Batch 0.647 (0.480) Remain 31:29:35 loss: 1.6357 Lr: 0.00066
[2025-04-08 14:24:41,205 INFO misc.py line 113 3298914] Train: [2/100][1640/2402] Data 0.004 (0.004) Batch 0.523 (0.480) Remain 31:29:40 loss: 1.3261 Lr: 0.00066
[2025-04-08 14:24:41,729 INFO misc.py line 113 3298914] Train: [2/100][1641/2402] Data 0.003 (0.004) Batch 0.524 (0.480) Remain 31:29:46 loss: 1.7599 Lr: 0.00066
[2025-04-08 14:24:42,275 INFO misc.py line 113 3298914] Train: [2/100][1642/2402] Data 0.004 (0.004) Batch 0.546 (0.480) Remain 31:29:55 loss: 1.6388 Lr: 0.00066
[2025-04-08 14:24:42,836 INFO misc.py line 113 3298914] Train: [2/100][1643/2402] Data 0.004 (0.004) Batch 0.561 (0.480) Remain 31:30:06 loss: 1.1623 Lr: 0.00066
[2025-04-08 14:24:43,271 INFO misc.py line 113 3298914] Train: [2/100][1644/2402] Data 0.004 (0.004) Batch 0.434 (0.480) Remain 31:29:59 loss: 1.3956 Lr: 0.00066
[2025-04-08 14:24:43,770 INFO misc.py line 113 3298914] Train: [2/100][1645/2402] Data 0.004 (0.004) Batch 0.499 (0.480) Remain 31:30:01 loss: 1.1793 Lr: 0.00066
[2025-04-08 14:24:44,200 INFO misc.py line 113 3298914] Train: [2/100][1646/2402] Data 0.003 (0.004) Batch 0.430 (0.480) Remain 31:29:54 loss: 1.2253 Lr: 0.00066
[2025-04-08 14:24:44,692 INFO misc.py line 113 3298914] Train: [2/100][1647/2402] Data 0.004 (0.004) Batch 0.492 (0.480) Remain 31:29:55 loss: 1.3945 Lr: 0.00066
[2025-04-08 14:24:45,204 INFO misc.py line 113 3298914] Train: [2/100][1648/2402] Data 0.004 (0.004) Batch 0.512 (0.480) Remain 31:29:59 loss: 1.9444 Lr: 0.00066
[2025-04-08 14:24:45,644 INFO misc.py line 113 3298914] Train: [2/100][1649/2402] Data 0.003 (0.004) Batch 0.441 (0.480) Remain 31:29:53 loss: 1.2376 Lr: 0.00066
[2025-04-08 14:24:46,089 INFO misc.py line 113 3298914] Train: [2/100][1650/2402] Data 0.003 (0.004) Batch 0.444 (0.480) Remain 31:29:47 loss: 0.9961 Lr: 0.00066
[2025-04-08 14:24:46,462 INFO misc.py line 113 3298914] Train: [2/100][1651/2402] Data 0.003 (0.004) Batch 0.373 (0.480) Remain 31:29:31 loss: 0.9835 Lr: 0.00066
[2025-04-08 14:24:46,915 INFO misc.py line 113 3298914] Train: [2/100][1652/2402] Data 0.004 (0.004) Batch 0.453 (0.480) Remain 31:29:27 loss: 1.2613 Lr: 0.00066
[2025-04-08 14:24:47,380 INFO misc.py line 113 3298914] Train: [2/100][1653/2402] Data 0.004 (0.004) Batch 0.465 (0.480) Remain 31:29:24 loss: 1.6102 Lr: 0.00066
[2025-04-08 14:24:47,887 INFO misc.py line 113 3298914] Train: [2/100][1654/2402] Data 0.003 (0.004) Batch 0.507 (0.480) Remain 31:29:28 loss: 1.2114 Lr: 0.00066
[2025-04-08 14:24:48,428 INFO misc.py line 113 3298914] Train: [2/100][1655/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:29:36 loss: 1.6892 Lr: 0.00066
[2025-04-08 14:24:48,934 INFO misc.py line 113 3298914] Train: [2/100][1656/2402] Data 0.004 (0.004) Batch 0.507 (0.480) Remain 31:29:39 loss: 1.4633 Lr: 0.00066
[2025-04-08 14:24:49,418 INFO misc.py line 113 3298914] Train: [2/100][1657/2402] Data 0.003 (0.004) Batch 0.484 (0.480) Remain 31:29:39 loss: 1.3784 Lr: 0.00066
[2025-04-08 14:24:49,920 INFO misc.py line 113 3298914] Train: [2/100][1658/2402] Data 0.003 (0.004) Batch 0.501 (0.480) Remain 31:29:42 loss: 1.0859 Lr: 0.00066
[2025-04-08 14:24:50,505 INFO misc.py line 113 3298914] Train: [2/100][1659/2402] Data 0.004 (0.004) Batch 0.585 (0.480) Remain 31:29:56 loss: 1.2740 Lr: 0.00066
[2025-04-08 14:24:51,087 INFO misc.py line 113 3298914] Train: [2/100][1660/2402] Data 0.004 (0.004) Batch 0.582 (0.480) Remain 31:30:10 loss: 1.6271 Lr: 0.00066
[2025-04-08 14:24:51,585 INFO misc.py line 113 3298914] Train: [2/100][1661/2402] Data 0.004 (0.004) Batch 0.499 (0.480) Remain 31:30:13 loss: 1.2486 Lr: 0.00066
[2025-04-08 14:24:52,105 INFO misc.py line 113 3298914] Train: [2/100][1662/2402] Data 0.003 (0.004) Batch 0.519 (0.480) Remain 31:30:18 loss: 1.1009 Lr: 0.00066
[2025-04-08 14:24:52,554 INFO misc.py line 113 3298914] Train: [2/100][1663/2402] Data 0.004 (0.004) Batch 0.450 (0.480) Remain 31:30:13 loss: 0.8957 Lr: 0.00066
[2025-04-08 14:24:53,024 INFO misc.py line 113 3298914] Train: [2/100][1664/2402] Data 0.003 (0.004) Batch 0.469 (0.480) Remain 31:30:11 loss: 1.3846 Lr: 0.00066
[2025-04-08 14:24:53,522 INFO misc.py line 113 3298914] Train: [2/100][1665/2402] Data 0.003 (0.004) Batch 0.498 (0.480) Remain 31:30:13 loss: 1.4918 Lr: 0.00066
[2025-04-08 14:24:54,075 INFO misc.py line 113 3298914] Train: [2/100][1666/2402] Data 0.004 (0.004) Batch 0.553 (0.480) Remain 31:30:23 loss: 1.0886 Lr: 0.00066
[2025-04-08 14:24:54,536 INFO misc.py line 113 3298914] Train: [2/100][1667/2402] Data 0.003 (0.004) Batch 0.461 (0.480) Remain 31:30:19 loss: 1.2718 Lr: 0.00066
[2025-04-08 14:24:55,085 INFO misc.py line 113 3298914] Train: [2/100][1668/2402] Data 0.003 (0.004) Batch 0.550 (0.480) Remain 31:30:29 loss: 1.4566 Lr: 0.00066
[2025-04-08 14:24:55,690 INFO misc.py line 113 3298914] Train: [2/100][1669/2402] Data 0.003 (0.004) Batch 0.605 (0.480) Remain 31:30:46 loss: 1.0258 Lr: 0.00066
[2025-04-08 14:24:56,131 INFO misc.py line 113 3298914] Train: [2/100][1670/2402] Data 0.003 (0.004) Batch 0.441 (0.480) Remain 31:30:40 loss: 1.2800 Lr: 0.00066
[2025-04-08 14:24:56,686 INFO misc.py line 113 3298914] Train: [2/100][1671/2402] Data 0.003 (0.004) Batch 0.556 (0.480) Remain 31:30:50 loss: 1.3415 Lr: 0.00066
[2025-04-08 14:24:57,154 INFO misc.py line 113 3298914] Train: [2/100][1672/2402] Data 0.003 (0.004) Batch 0.467 (0.480) Remain 31:30:48 loss: 0.8562 Lr: 0.00066
[2025-04-08 14:24:57,654 INFO misc.py line 113 3298914] Train: [2/100][1673/2402] Data 0.004 (0.004) Batch 0.500 (0.480) Remain 31:30:50 loss: 1.2059 Lr: 0.00066
[2025-04-08 14:24:58,257 INFO misc.py line 113 3298914] Train: [2/100][1674/2402] Data 0.004 (0.004) Batch 0.603 (0.481) Remain 31:31:07 loss: 1.2781 Lr: 0.00066
[2025-04-08 14:24:58,783 INFO misc.py line 113 3298914] Train: [2/100][1675/2402] Data 0.003 (0.004) Batch 0.526 (0.481) Remain 31:31:13 loss: 1.4591 Lr: 0.00066
[2025-04-08 14:24:59,345 INFO misc.py line 113 3298914] Train: [2/100][1676/2402] Data 0.003 (0.004) Batch 0.561 (0.481) Remain 31:31:24 loss: 1.1637 Lr: 0.00066
[2025-04-08 14:24:59,797 INFO misc.py line 113 3298914] Train: [2/100][1677/2402] Data 0.003 (0.004) Batch 0.453 (0.481) Remain 31:31:19 loss: 1.5064 Lr: 0.00066
[2025-04-08 14:25:00,346 INFO misc.py line 113 3298914] Train: [2/100][1678/2402] Data 0.003 (0.004) Batch 0.548 (0.481) Remain 31:31:28 loss: 1.2006 Lr: 0.00066
[2025-04-08 14:25:00,769 INFO misc.py line 113 3298914] Train: [2/100][1679/2402] Data 0.003 (0.004) Batch 0.424 (0.481) Remain 31:31:20 loss: 0.9219 Lr: 0.00067
[2025-04-08 14:25:01,235 INFO misc.py line 113 3298914] Train: [2/100][1680/2402] Data 0.004 (0.004) Batch 0.466 (0.481) Remain 31:31:17 loss: 1.2791 Lr: 0.00067
[2025-04-08 14:25:01,726 INFO misc.py line 113 3298914] Train: [2/100][1681/2402] Data 0.003 (0.004) Batch 0.491 (0.481) Remain 31:31:18 loss: 1.5968 Lr: 0.00067
[2025-04-08 14:25:02,141 INFO misc.py line 113 3298914] Train: [2/100][1682/2402] Data 0.003 (0.004) Batch 0.415 (0.481) Remain 31:31:09 loss: 1.2945 Lr: 0.00067
[2025-04-08 14:25:02,574 INFO misc.py line 113 3298914] Train: [2/100][1683/2402] Data 0.003 (0.004) Batch 0.432 (0.481) Remain 31:31:01 loss: 0.9419 Lr: 0.00067
[2025-04-08 14:25:03,017 INFO misc.py line 113 3298914] Train: [2/100][1684/2402] Data 0.003 (0.004) Batch 0.443 (0.481) Remain 31:30:56 loss: 1.2801 Lr: 0.00067
[2025-04-08 14:25:03,531 INFO misc.py line 113 3298914] Train: [2/100][1685/2402] Data 0.003 (0.004) Batch 0.515 (0.481) Remain 31:31:00 loss: 1.1210 Lr: 0.00067
[2025-04-08 14:25:03,946 INFO misc.py line 113 3298914] Train: [2/100][1686/2402] Data 0.003 (0.004) Batch 0.414 (0.480) Remain 31:30:50 loss: 1.1923 Lr: 0.00067
[2025-04-08 14:25:04,462 INFO misc.py line 113 3298914] Train: [2/100][1687/2402] Data 0.004 (0.004) Batch 0.516 (0.481) Remain 31:30:55 loss: 1.5088 Lr: 0.00067
[2025-04-08 14:25:05,023 INFO misc.py line 113 3298914] Train: [2/100][1688/2402] Data 0.003 (0.004) Batch 0.561 (0.481) Remain 31:31:05 loss: 1.1329 Lr: 0.00067
[2025-04-08 14:25:05,538 INFO misc.py line 113 3298914] Train: [2/100][1689/2402] Data 0.003 (0.004) Batch 0.516 (0.481) Remain 31:31:10 loss: 1.5558 Lr: 0.00067
[2025-04-08 14:25:05,974 INFO misc.py line 113 3298914] Train: [2/100][1690/2402] Data 0.003 (0.004) Batch 0.436 (0.481) Remain 31:31:03 loss: 1.3156 Lr: 0.00067
[2025-04-08 14:25:06,453 INFO misc.py line 113 3298914] Train: [2/100][1691/2402] Data 0.003 (0.004) Batch 0.479 (0.481) Remain 31:31:02 loss: 1.2070 Lr: 0.00067
[2025-04-08 14:25:06,948 INFO misc.py line 113 3298914] Train: [2/100][1692/2402] Data 0.004 (0.004) Batch 0.495 (0.481) Remain 31:31:04 loss: 1.2403 Lr: 0.00067
[2025-04-08 14:25:07,489 INFO misc.py line 113 3298914] Train: [2/100][1693/2402] Data 0.004 (0.004) Batch 0.541 (0.481) Remain 31:31:12 loss: 0.9710 Lr: 0.00067
[2025-04-08 14:25:07,888 INFO misc.py line 113 3298914] Train: [2/100][1694/2402] Data 0.004 (0.004) Batch 0.398 (0.481) Remain 31:31:00 loss: 1.3329 Lr: 0.00067
[2025-04-08 14:25:08,309 INFO misc.py line 113 3298914] Train: [2/100][1695/2402] Data 0.004 (0.004) Batch 0.421 (0.481) Remain 31:30:51 loss: 1.0478 Lr: 0.00067
[2025-04-08 14:25:08,735 INFO misc.py line 113 3298914] Train: [2/100][1696/2402] Data 0.004 (0.004) Batch 0.427 (0.480) Remain 31:30:43 loss: 0.8972 Lr: 0.00067
[2025-04-08 14:25:09,179 INFO misc.py line 113 3298914] Train: [2/100][1697/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:30:38 loss: 1.8198 Lr: 0.00067
[2025-04-08 14:25:09,695 INFO misc.py line 113 3298914] Train: [2/100][1698/2402] Data 0.004 (0.004) Batch 0.517 (0.480) Remain 31:30:42 loss: 1.4643 Lr: 0.00067
[2025-04-08 14:25:10,116 INFO misc.py line 113 3298914] Train: [2/100][1699/2402] Data 0.003 (0.004) Batch 0.421 (0.480) Remain 31:30:33 loss: 1.2110 Lr: 0.00067
[2025-04-08 14:25:10,688 INFO misc.py line 113 3298914] Train: [2/100][1700/2402] Data 0.004 (0.004) Batch 0.572 (0.481) Remain 31:30:46 loss: 1.1141 Lr: 0.00067
[2025-04-08 14:25:11,063 INFO misc.py line 113 3298914] Train: [2/100][1701/2402] Data 0.003 (0.004) Batch 0.374 (0.480) Remain 31:30:30 loss: 1.0507 Lr: 0.00067
[2025-04-08 14:25:11,591 INFO misc.py line 113 3298914] Train: [2/100][1702/2402] Data 0.003 (0.004) Batch 0.528 (0.480) Remain 31:30:36 loss: 1.5056 Lr: 0.00067
[2025-04-08 14:25:12,103 INFO misc.py line 113 3298914] Train: [2/100][1703/2402] Data 0.004 (0.004) Batch 0.512 (0.480) Remain 31:30:40 loss: 1.1305 Lr: 0.00067
[2025-04-08 14:25:12,614 INFO misc.py line 113 3298914] Train: [2/100][1704/2402] Data 0.003 (0.004) Batch 0.511 (0.481) Remain 31:30:44 loss: 1.4811 Lr: 0.00067
[2025-04-08 14:25:13,167 INFO misc.py line 113 3298914] Train: [2/100][1705/2402] Data 0.004 (0.004) Batch 0.553 (0.481) Remain 31:30:54 loss: 1.1845 Lr: 0.00067
[2025-04-08 14:25:13,708 INFO misc.py line 113 3298914] Train: [2/100][1706/2402] Data 0.004 (0.004) Batch 0.541 (0.481) Remain 31:31:02 loss: 1.4263 Lr: 0.00067
[2025-04-08 14:25:14,219 INFO misc.py line 113 3298914] Train: [2/100][1707/2402] Data 0.004 (0.004) Batch 0.511 (0.481) Remain 31:31:05 loss: 1.5643 Lr: 0.00067
[2025-04-08 14:25:14,732 INFO misc.py line 113 3298914] Train: [2/100][1708/2402] Data 0.004 (0.004) Batch 0.513 (0.481) Remain 31:31:09 loss: 0.8335 Lr: 0.00067
[2025-04-08 14:25:15,261 INFO misc.py line 113 3298914] Train: [2/100][1709/2402] Data 0.004 (0.004) Batch 0.530 (0.481) Remain 31:31:16 loss: 1.4760 Lr: 0.00067
[2025-04-08 14:25:15,774 INFO misc.py line 113 3298914] Train: [2/100][1710/2402] Data 0.004 (0.004) Batch 0.513 (0.481) Remain 31:31:20 loss: 1.3737 Lr: 0.00067
[2025-04-08 14:25:16,312 INFO misc.py line 113 3298914] Train: [2/100][1711/2402] Data 0.004 (0.004) Batch 0.538 (0.481) Remain 31:31:27 loss: 1.7630 Lr: 0.00067
[2025-04-08 14:25:16,857 INFO misc.py line 113 3298914] Train: [2/100][1712/2402] Data 0.004 (0.004) Batch 0.545 (0.481) Remain 31:31:35 loss: 1.3636 Lr: 0.00067
[2025-04-08 14:25:17,322 INFO misc.py line 113 3298914] Train: [2/100][1713/2402] Data 0.004 (0.004) Batch 0.465 (0.481) Remain 31:31:33 loss: 0.8528 Lr: 0.00067
[2025-04-08 14:25:17,796 INFO misc.py line 113 3298914] Train: [2/100][1714/2402] Data 0.003 (0.004) Batch 0.473 (0.481) Remain 31:31:31 loss: 1.4583 Lr: 0.00067
[2025-04-08 14:25:18,291 INFO misc.py line 113 3298914] Train: [2/100][1715/2402] Data 0.003 (0.004) Batch 0.496 (0.481) Remain 31:31:33 loss: 1.2221 Lr: 0.00067
[2025-04-08 14:25:18,779 INFO misc.py line 113 3298914] Train: [2/100][1716/2402] Data 0.004 (0.004) Batch 0.487 (0.481) Remain 31:31:33 loss: 1.1918 Lr: 0.00067
[2025-04-08 14:25:19,287 INFO misc.py line 113 3298914] Train: [2/100][1717/2402] Data 0.004 (0.004) Batch 0.508 (0.481) Remain 31:31:37 loss: 1.3568 Lr: 0.00067
[2025-04-08 14:25:19,701 INFO misc.py line 113 3298914] Train: [2/100][1718/2402] Data 0.003 (0.004) Batch 0.414 (0.481) Remain 31:31:27 loss: 1.3229 Lr: 0.00067
[2025-04-08 14:25:20,081 INFO misc.py line 113 3298914] Train: [2/100][1719/2402] Data 0.004 (0.004) Batch 0.380 (0.481) Remain 31:31:13 loss: 1.9608 Lr: 0.00067
[2025-04-08 14:25:20,597 INFO misc.py line 113 3298914] Train: [2/100][1720/2402] Data 0.004 (0.004) Batch 0.516 (0.481) Remain 31:31:17 loss: 1.0111 Lr: 0.00067
[2025-04-08 14:25:21,096 INFO misc.py line 113 3298914] Train: [2/100][1721/2402] Data 0.003 (0.004) Batch 0.499 (0.481) Remain 31:31:19 loss: 1.4092 Lr: 0.00067
[2025-04-08 14:25:21,526 INFO misc.py line 113 3298914] Train: [2/100][1722/2402] Data 0.004 (0.004) Batch 0.430 (0.481) Remain 31:31:12 loss: 0.9581 Lr: 0.00067
[2025-04-08 14:25:21,955 INFO misc.py line 113 3298914] Train: [2/100][1723/2402] Data 0.003 (0.004) Batch 0.430 (0.481) Remain 31:31:04 loss: 1.2015 Lr: 0.00067
[2025-04-08 14:25:22,492 INFO misc.py line 113 3298914] Train: [2/100][1724/2402] Data 0.003 (0.004) Batch 0.536 (0.481) Remain 31:31:11 loss: 1.2888 Lr: 0.00067
[2025-04-08 14:25:22,995 INFO misc.py line 113 3298914] Train: [2/100][1725/2402] Data 0.003 (0.004) Batch 0.503 (0.481) Remain 31:31:14 loss: 1.3132 Lr: 0.00067
[2025-04-08 14:25:23,542 INFO misc.py line 113 3298914] Train: [2/100][1726/2402] Data 0.003 (0.004) Batch 0.547 (0.481) Remain 31:31:22 loss: 1.2782 Lr: 0.00067
[2025-04-08 14:25:24,084 INFO misc.py line 113 3298914] Train: [2/100][1727/2402] Data 0.003 (0.004) Batch 0.542 (0.481) Remain 31:31:30 loss: 1.3579 Lr: 0.00068
[2025-04-08 14:25:24,457 INFO misc.py line 113 3298914] Train: [2/100][1728/2402] Data 0.003 (0.004) Batch 0.374 (0.481) Remain 31:31:15 loss: 0.7507 Lr: 0.00068
[2025-04-08 14:25:24,995 INFO misc.py line 113 3298914] Train: [2/100][1729/2402] Data 0.003 (0.004) Batch 0.538 (0.481) Remain 31:31:23 loss: 1.2534 Lr: 0.00068
[2025-04-08 14:25:25,440 INFO misc.py line 113 3298914] Train: [2/100][1730/2402] Data 0.003 (0.004) Batch 0.445 (0.481) Remain 31:31:17 loss: 1.0836 Lr: 0.00068
[2025-04-08 14:25:25,915 INFO misc.py line 113 3298914] Train: [2/100][1731/2402] Data 0.004 (0.004) Batch 0.475 (0.481) Remain 31:31:16 loss: 1.6724 Lr: 0.00068
[2025-04-08 14:25:26,436 INFO misc.py line 113 3298914] Train: [2/100][1732/2402] Data 0.003 (0.004) Batch 0.522 (0.481) Remain 31:31:21 loss: 1.5328 Lr: 0.00068
[2025-04-08 14:25:26,901 INFO misc.py line 113 3298914] Train: [2/100][1733/2402] Data 0.003 (0.004) Batch 0.465 (0.481) Remain 31:31:18 loss: 1.3240 Lr: 0.00068
[2025-04-08 14:25:27,314 INFO misc.py line 113 3298914] Train: [2/100][1734/2402] Data 0.004 (0.004) Batch 0.413 (0.481) Remain 31:31:09 loss: 1.1396 Lr: 0.00068
[2025-04-08 14:25:27,767 INFO misc.py line 113 3298914] Train: [2/100][1735/2402] Data 0.003 (0.004) Batch 0.452 (0.481) Remain 31:31:04 loss: 1.2395 Lr: 0.00068
[2025-04-08 14:25:28,181 INFO misc.py line 113 3298914] Train: [2/100][1736/2402] Data 0.004 (0.004) Batch 0.414 (0.481) Remain 31:30:55 loss: 0.7257 Lr: 0.00068
[2025-04-08 14:25:28,776 INFO misc.py line 113 3298914] Train: [2/100][1737/2402] Data 0.003 (0.004) Batch 0.595 (0.481) Remain 31:31:10 loss: 1.3644 Lr: 0.00068
[2025-04-08 14:25:29,225 INFO misc.py line 113 3298914] Train: [2/100][1738/2402] Data 0.003 (0.004) Batch 0.448 (0.481) Remain 31:31:05 loss: 1.4155 Lr: 0.00068
[2025-04-08 14:25:29,602 INFO misc.py line 113 3298914] Train: [2/100][1739/2402] Data 0.004 (0.004) Batch 0.377 (0.481) Remain 31:30:50 loss: 1.2425 Lr: 0.00068
[2025-04-08 14:25:30,141 INFO misc.py line 113 3298914] Train: [2/100][1740/2402] Data 0.003 (0.004) Batch 0.539 (0.481) Remain 31:30:58 loss: 1.3470 Lr: 0.00068
[2025-04-08 14:25:30,581 INFO misc.py line 113 3298914] Train: [2/100][1741/2402] Data 0.003 (0.004) Batch 0.439 (0.481) Remain 31:30:52 loss: 1.2321 Lr: 0.00068
[2025-04-08 14:25:31,079 INFO misc.py line 113 3298914] Train: [2/100][1742/2402] Data 0.004 (0.004) Batch 0.499 (0.481) Remain 31:30:54 loss: 1.0455 Lr: 0.00068
[2025-04-08 14:25:31,645 INFO misc.py line 113 3298914] Train: [2/100][1743/2402] Data 0.003 (0.004) Batch 0.566 (0.481) Remain 31:31:05 loss: 1.6445 Lr: 0.00068
[2025-04-08 14:25:32,165 INFO misc.py line 113 3298914] Train: [2/100][1744/2402] Data 0.004 (0.004) Batch 0.520 (0.481) Remain 31:31:10 loss: 1.2065 Lr: 0.00068
[2025-04-08 14:25:32,611 INFO misc.py line 113 3298914] Train: [2/100][1745/2402] Data 0.003 (0.004) Batch 0.445 (0.481) Remain 31:31:05 loss: 1.0860 Lr: 0.00068
[2025-04-08 14:25:33,133 INFO misc.py line 113 3298914] Train: [2/100][1746/2402] Data 0.003 (0.004) Batch 0.522 (0.481) Remain 31:31:10 loss: 1.2820 Lr: 0.00068
[2025-04-08 14:25:33,533 INFO misc.py line 113 3298914] Train: [2/100][1747/2402] Data 0.003 (0.004) Batch 0.400 (0.481) Remain 31:30:58 loss: 1.4570 Lr: 0.00068
[2025-04-08 14:25:33,985 INFO misc.py line 113 3298914] Train: [2/100][1748/2402] Data 0.004 (0.004) Batch 0.452 (0.481) Remain 31:30:54 loss: 1.6258 Lr: 0.00068
[2025-04-08 14:25:34,466 INFO misc.py line 113 3298914] Train: [2/100][1749/2402] Data 0.003 (0.004) Batch 0.481 (0.481) Remain 31:30:54 loss: 1.7862 Lr: 0.00068
[2025-04-08 14:25:34,917 INFO misc.py line 113 3298914] Train: [2/100][1750/2402] Data 0.004 (0.004) Batch 0.451 (0.481) Remain 31:30:49 loss: 1.0806 Lr: 0.00068
[2025-04-08 14:25:35,352 INFO misc.py line 113 3298914] Train: [2/100][1751/2402] Data 0.003 (0.004) Batch 0.435 (0.481) Remain 31:30:42 loss: 1.4124 Lr: 0.00068
[2025-04-08 14:25:35,739 INFO misc.py line 113 3298914] Train: [2/100][1752/2402] Data 0.003 (0.004) Batch 0.388 (0.481) Remain 31:30:29 loss: 1.4418 Lr: 0.00068
[2025-04-08 14:25:36,106 INFO misc.py line 113 3298914] Train: [2/100][1753/2402] Data 0.004 (0.004) Batch 0.367 (0.480) Remain 31:30:14 loss: 0.8517 Lr: 0.00068
[2025-04-08 14:25:36,550 INFO misc.py line 113 3298914] Train: [2/100][1754/2402] Data 0.003 (0.004) Batch 0.444 (0.480) Remain 31:30:08 loss: 1.4485 Lr: 0.00068
[2025-04-08 14:25:36,993 INFO misc.py line 113 3298914] Train: [2/100][1755/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:30:03 loss: 1.3369 Lr: 0.00068
[2025-04-08 14:25:37,438 INFO misc.py line 113 3298914] Train: [2/100][1756/2402] Data 0.004 (0.004) Batch 0.446 (0.480) Remain 31:29:57 loss: 1.3843 Lr: 0.00068
[2025-04-08 14:25:37,990 INFO misc.py line 113 3298914] Train: [2/100][1757/2402] Data 0.003 (0.004) Batch 0.551 (0.480) Remain 31:30:06 loss: 1.8513 Lr: 0.00068
[2025-04-08 14:25:38,519 INFO misc.py line 113 3298914] Train: [2/100][1758/2402] Data 0.003 (0.004) Batch 0.529 (0.480) Remain 31:30:12 loss: 1.0028 Lr: 0.00068
[2025-04-08 14:25:38,995 INFO misc.py line 113 3298914] Train: [2/100][1759/2402] Data 0.003 (0.004) Batch 0.476 (0.480) Remain 31:30:11 loss: 2.0849 Lr: 0.00068
[2025-04-08 14:25:39,492 INFO misc.py line 113 3298914] Train: [2/100][1760/2402] Data 0.003 (0.004) Batch 0.497 (0.480) Remain 31:30:13 loss: 1.8461 Lr: 0.00068
[2025-04-08 14:25:40,009 INFO misc.py line 113 3298914] Train: [2/100][1761/2402] Data 0.004 (0.004) Batch 0.517 (0.481) Remain 31:30:18 loss: 1.3623 Lr: 0.00068
[2025-04-08 14:25:40,468 INFO misc.py line 113 3298914] Train: [2/100][1762/2402] Data 0.003 (0.004) Batch 0.459 (0.480) Remain 31:30:14 loss: 1.4798 Lr: 0.00068
[2025-04-08 14:25:40,914 INFO misc.py line 113 3298914] Train: [2/100][1763/2402] Data 0.003 (0.004) Batch 0.446 (0.480) Remain 31:30:09 loss: 1.0358 Lr: 0.00068
[2025-04-08 14:25:41,374 INFO misc.py line 113 3298914] Train: [2/100][1764/2402] Data 0.004 (0.004) Batch 0.460 (0.480) Remain 31:30:06 loss: 1.5201 Lr: 0.00068
[2025-04-08 14:25:41,851 INFO misc.py line 113 3298914] Train: [2/100][1765/2402] Data 0.004 (0.004) Batch 0.477 (0.480) Remain 31:30:05 loss: 1.0727 Lr: 0.00068
[2025-04-08 14:25:42,411 INFO misc.py line 113 3298914] Train: [2/100][1766/2402] Data 0.004 (0.004) Batch 0.560 (0.481) Remain 31:30:15 loss: 1.1504 Lr: 0.00068
[2025-04-08 14:25:42,925 INFO misc.py line 113 3298914] Train: [2/100][1767/2402] Data 0.003 (0.004) Batch 0.514 (0.481) Remain 31:30:19 loss: 1.3888 Lr: 0.00068
[2025-04-08 14:25:43,409 INFO misc.py line 113 3298914] Train: [2/100][1768/2402] Data 0.004 (0.004) Batch 0.485 (0.481) Remain 31:30:19 loss: 1.3188 Lr: 0.00068
[2025-04-08 14:25:43,879 INFO misc.py line 113 3298914] Train: [2/100][1769/2402] Data 0.003 (0.004) Batch 0.470 (0.481) Remain 31:30:17 loss: 1.2253 Lr: 0.00068
[2025-04-08 14:25:44,346 INFO misc.py line 113 3298914] Train: [2/100][1770/2402] Data 0.004 (0.004) Batch 0.466 (0.481) Remain 31:30:15 loss: 0.7984 Lr: 0.00068
[2025-04-08 14:25:44,822 INFO misc.py line 113 3298914] Train: [2/100][1771/2402] Data 0.004 (0.004) Batch 0.477 (0.481) Remain 31:30:14 loss: 1.5508 Lr: 0.00068
[2025-04-08 14:25:45,272 INFO misc.py line 113 3298914] Train: [2/100][1772/2402] Data 0.004 (0.004) Batch 0.450 (0.480) Remain 31:30:09 loss: 1.3302 Lr: 0.00068
[2025-04-08 14:25:45,798 INFO misc.py line 113 3298914] Train: [2/100][1773/2402] Data 0.003 (0.004) Batch 0.527 (0.481) Remain 31:30:15 loss: 1.2003 Lr: 0.00068
[2025-04-08 14:25:46,266 INFO misc.py line 113 3298914] Train: [2/100][1774/2402] Data 0.003 (0.004) Batch 0.468 (0.481) Remain 31:30:13 loss: 1.0067 Lr: 0.00068
[2025-04-08 14:25:46,734 INFO misc.py line 113 3298914] Train: [2/100][1775/2402] Data 0.004 (0.004) Batch 0.468 (0.481) Remain 31:30:11 loss: 1.4361 Lr: 0.00069
[2025-04-08 14:25:47,227 INFO misc.py line 113 3298914] Train: [2/100][1776/2402] Data 0.004 (0.004) Batch 0.492 (0.481) Remain 31:30:12 loss: 1.2382 Lr: 0.00069
[2025-04-08 14:25:47,679 INFO misc.py line 113 3298914] Train: [2/100][1777/2402] Data 0.003 (0.004) Batch 0.452 (0.480) Remain 31:30:07 loss: 1.0447 Lr: 0.00069
[2025-04-08 14:25:48,253 INFO misc.py line 113 3298914] Train: [2/100][1778/2402] Data 0.003 (0.004) Batch 0.574 (0.481) Remain 31:30:19 loss: 1.2137 Lr: 0.00069
[2025-04-08 14:25:48,784 INFO misc.py line 113 3298914] Train: [2/100][1779/2402] Data 0.003 (0.004) Batch 0.532 (0.481) Remain 31:30:26 loss: 1.4691 Lr: 0.00069
[2025-04-08 14:25:49,294 INFO misc.py line 113 3298914] Train: [2/100][1780/2402] Data 0.003 (0.004) Batch 0.510 (0.481) Remain 31:30:29 loss: 1.2627 Lr: 0.00069
[2025-04-08 14:25:49,832 INFO misc.py line 113 3298914] Train: [2/100][1781/2402] Data 0.003 (0.004) Batch 0.537 (0.481) Remain 31:30:36 loss: 1.5353 Lr: 0.00069
[2025-04-08 14:25:50,419 INFO misc.py line 113 3298914] Train: [2/100][1782/2402] Data 0.003 (0.004) Batch 0.587 (0.481) Remain 31:30:50 loss: 1.1661 Lr: 0.00069
[2025-04-08 14:25:50,827 INFO misc.py line 113 3298914] Train: [2/100][1783/2402] Data 0.004 (0.004) Batch 0.408 (0.481) Remain 31:30:40 loss: 1.0634 Lr: 0.00069
[2025-04-08 14:25:51,381 INFO misc.py line 113 3298914] Train: [2/100][1784/2402] Data 0.003 (0.004) Batch 0.555 (0.481) Remain 31:30:49 loss: 1.2767 Lr: 0.00069
[2025-04-08 14:25:51,835 INFO misc.py line 113 3298914] Train: [2/100][1785/2402] Data 0.003 (0.004) Batch 0.454 (0.481) Remain 31:30:45 loss: 1.3060 Lr: 0.00069
[2025-04-08 14:25:52,306 INFO misc.py line 113 3298914] Train: [2/100][1786/2402] Data 0.003 (0.004) Batch 0.471 (0.481) Remain 31:30:43 loss: 1.2408 Lr: 0.00069
[2025-04-08 14:25:52,729 INFO misc.py line 113 3298914] Train: [2/100][1787/2402] Data 0.003 (0.004) Batch 0.423 (0.481) Remain 31:30:35 loss: 1.2146 Lr: 0.00069
[2025-04-08 14:25:53,196 INFO misc.py line 113 3298914] Train: [2/100][1788/2402] Data 0.004 (0.004) Batch 0.467 (0.481) Remain 31:30:33 loss: 0.8334 Lr: 0.00069
[2025-04-08 14:25:53,649 INFO misc.py line 113 3298914] Train: [2/100][1789/2402] Data 0.003 (0.004) Batch 0.452 (0.481) Remain 31:30:29 loss: 1.1785 Lr: 0.00069
[2025-04-08 14:25:54,182 INFO misc.py line 113 3298914] Train: [2/100][1790/2402] Data 0.003 (0.004) Batch 0.533 (0.481) Remain 31:30:35 loss: 1.2756 Lr: 0.00069
[2025-04-08 14:25:54,596 INFO misc.py line 113 3298914] Train: [2/100][1791/2402] Data 0.003 (0.004) Batch 0.414 (0.481) Remain 31:30:26 loss: 1.2682 Lr: 0.00069
[2025-04-08 14:25:55,118 INFO misc.py line 113 3298914] Train: [2/100][1792/2402] Data 0.003 (0.004) Batch 0.522 (0.481) Remain 31:30:31 loss: 1.0660 Lr: 0.00069
[2025-04-08 14:25:55,626 INFO misc.py line 113 3298914] Train: [2/100][1793/2402] Data 0.003 (0.004) Batch 0.508 (0.481) Remain 31:30:34 loss: 1.3574 Lr: 0.00069
[2025-04-08 14:25:56,067 INFO misc.py line 113 3298914] Train: [2/100][1794/2402] Data 0.003 (0.004) Batch 0.441 (0.481) Remain 31:30:28 loss: 1.2071 Lr: 0.00069
[2025-04-08 14:25:56,428 INFO misc.py line 113 3298914] Train: [2/100][1795/2402] Data 0.003 (0.004) Batch 0.361 (0.481) Remain 31:30:12 loss: 0.7473 Lr: 0.00069
[2025-04-08 14:25:56,937 INFO misc.py line 113 3298914] Train: [2/100][1796/2402] Data 0.004 (0.004) Batch 0.508 (0.481) Remain 31:30:15 loss: 1.2469 Lr: 0.00069
[2025-04-08 14:25:57,487 INFO misc.py line 113 3298914] Train: [2/100][1797/2402] Data 0.003 (0.004) Batch 0.551 (0.481) Remain 31:30:24 loss: 1.3484 Lr: 0.00069
[2025-04-08 14:25:57,907 INFO misc.py line 113 3298914] Train: [2/100][1798/2402] Data 0.003 (0.004) Batch 0.419 (0.481) Remain 31:30:15 loss: 0.9921 Lr: 0.00069
[2025-04-08 14:25:58,400 INFO misc.py line 113 3298914] Train: [2/100][1799/2402] Data 0.003 (0.004) Batch 0.493 (0.481) Remain 31:30:17 loss: 1.4115 Lr: 0.00069
[2025-04-08 14:25:58,999 INFO misc.py line 113 3298914] Train: [2/100][1800/2402] Data 0.004 (0.004) Batch 0.599 (0.481) Remain 31:30:32 loss: 1.0340 Lr: 0.00069
[2025-04-08 14:25:59,343 INFO misc.py line 113 3298914] Train: [2/100][1801/2402] Data 0.003 (0.004) Batch 0.344 (0.481) Remain 31:30:13 loss: 1.1430 Lr: 0.00069
[2025-04-08 14:25:59,795 INFO misc.py line 113 3298914] Train: [2/100][1802/2402] Data 0.003 (0.004) Batch 0.452 (0.481) Remain 31:30:09 loss: 1.1860 Lr: 0.00069
[2025-04-08 14:26:00,277 INFO misc.py line 113 3298914] Train: [2/100][1803/2402] Data 0.004 (0.004) Batch 0.483 (0.481) Remain 31:30:09 loss: 1.3489 Lr: 0.00069
[2025-04-08 14:26:00,765 INFO misc.py line 113 3298914] Train: [2/100][1804/2402] Data 0.003 (0.004) Batch 0.487 (0.481) Remain 31:30:09 loss: 0.8966 Lr: 0.00069
[2025-04-08 14:26:01,261 INFO misc.py line 113 3298914] Train: [2/100][1805/2402] Data 0.003 (0.004) Batch 0.496 (0.481) Remain 31:30:11 loss: 1.4130 Lr: 0.00069
[2025-04-08 14:26:01,706 INFO misc.py line 113 3298914] Train: [2/100][1806/2402] Data 0.003 (0.004) Batch 0.445 (0.481) Remain 31:30:06 loss: 1.3827 Lr: 0.00069
[2025-04-08 14:26:02,280 INFO misc.py line 113 3298914] Train: [2/100][1807/2402] Data 0.003 (0.004) Batch 0.574 (0.481) Remain 31:30:17 loss: 1.0663 Lr: 0.00069
[2025-04-08 14:26:02,718 INFO misc.py line 113 3298914] Train: [2/100][1808/2402] Data 0.004 (0.004) Batch 0.437 (0.481) Remain 31:30:11 loss: 1.1775 Lr: 0.00069
[2025-04-08 14:26:03,281 INFO misc.py line 113 3298914] Train: [2/100][1809/2402] Data 0.003 (0.004) Batch 0.564 (0.481) Remain 31:30:22 loss: 1.5267 Lr: 0.00069
[2025-04-08 14:26:03,727 INFO misc.py line 113 3298914] Train: [2/100][1810/2402] Data 0.004 (0.004) Batch 0.446 (0.481) Remain 31:30:17 loss: 1.2783 Lr: 0.00069
[2025-04-08 14:26:04,259 INFO misc.py line 113 3298914] Train: [2/100][1811/2402] Data 0.003 (0.004) Batch 0.532 (0.481) Remain 31:30:23 loss: 1.4684 Lr: 0.00069
[2025-04-08 14:26:04,698 INFO misc.py line 113 3298914] Train: [2/100][1812/2402] Data 0.003 (0.004) Batch 0.439 (0.481) Remain 31:30:17 loss: 0.9436 Lr: 0.00069
[2025-04-08 14:26:05,301 INFO misc.py line 113 3298914] Train: [2/100][1813/2402] Data 0.003 (0.004) Batch 0.603 (0.481) Remain 31:30:32 loss: 1.4797 Lr: 0.00069
[2025-04-08 14:26:05,727 INFO misc.py line 113 3298914] Train: [2/100][1814/2402] Data 0.004 (0.004) Batch 0.426 (0.481) Remain 31:30:25 loss: 1.3472 Lr: 0.00069
[2025-04-08 14:26:06,200 INFO misc.py line 113 3298914] Train: [2/100][1815/2402] Data 0.003 (0.004) Batch 0.472 (0.481) Remain 31:30:23 loss: 1.2500 Lr: 0.00069
[2025-04-08 14:26:06,650 INFO misc.py line 113 3298914] Train: [2/100][1816/2402] Data 0.003 (0.004) Batch 0.450 (0.481) Remain 31:30:19 loss: 1.5632 Lr: 0.00069
[2025-04-08 14:26:07,037 INFO misc.py line 113 3298914] Train: [2/100][1817/2402] Data 0.004 (0.004) Batch 0.388 (0.481) Remain 31:30:06 loss: 1.0200 Lr: 0.00069
[2025-04-08 14:26:07,561 INFO misc.py line 113 3298914] Train: [2/100][1818/2402] Data 0.004 (0.004) Batch 0.524 (0.481) Remain 31:30:11 loss: 1.1649 Lr: 0.00069
[2025-04-08 14:26:08,100 INFO misc.py line 113 3298914] Train: [2/100][1819/2402] Data 0.003 (0.004) Batch 0.539 (0.481) Remain 31:30:18 loss: 1.4305 Lr: 0.00069
[2025-04-08 14:26:08,602 INFO misc.py line 113 3298914] Train: [2/100][1820/2402] Data 0.004 (0.004) Batch 0.502 (0.481) Remain 31:30:21 loss: 1.6803 Lr: 0.00069
[2025-04-08 14:26:09,007 INFO misc.py line 113 3298914] Train: [2/100][1821/2402] Data 0.003 (0.004) Batch 0.405 (0.481) Remain 31:30:10 loss: 1.5937 Lr: 0.00069
[2025-04-08 14:26:09,426 INFO misc.py line 113 3298914] Train: [2/100][1822/2402] Data 0.003 (0.004) Batch 0.418 (0.481) Remain 31:30:02 loss: 1.3193 Lr: 0.00069
[2025-04-08 14:26:09,993 INFO misc.py line 113 3298914] Train: [2/100][1823/2402] Data 0.004 (0.004) Batch 0.567 (0.481) Remain 31:30:13 loss: 1.4128 Lr: 0.00070
[2025-04-08 14:26:10,329 INFO misc.py line 113 3298914] Train: [2/100][1824/2402] Data 0.003 (0.004) Batch 0.336 (0.481) Remain 31:29:54 loss: 1.3218 Lr: 0.00070
[2025-04-08 14:26:10,848 INFO misc.py line 113 3298914] Train: [2/100][1825/2402] Data 0.003 (0.004) Batch 0.518 (0.481) Remain 31:29:58 loss: 1.1367 Lr: 0.00070
[2025-04-08 14:26:11,367 INFO misc.py line 113 3298914] Train: [2/100][1826/2402] Data 0.003 (0.004) Batch 0.519 (0.481) Remain 31:30:02 loss: 1.5656 Lr: 0.00070
[2025-04-08 14:26:11,762 INFO misc.py line 113 3298914] Train: [2/100][1827/2402] Data 0.003 (0.004) Batch 0.395 (0.481) Remain 31:29:51 loss: 1.4925 Lr: 0.00070
[2025-04-08 14:26:12,168 INFO misc.py line 113 3298914] Train: [2/100][1828/2402] Data 0.003 (0.004) Batch 0.406 (0.480) Remain 31:29:41 loss: 1.0658 Lr: 0.00070
[2025-04-08 14:26:12,621 INFO misc.py line 113 3298914] Train: [2/100][1829/2402] Data 0.003 (0.004) Batch 0.453 (0.480) Remain 31:29:37 loss: 0.8857 Lr: 0.00070
[2025-04-08 14:26:13,143 INFO misc.py line 113 3298914] Train: [2/100][1830/2402] Data 0.004 (0.004) Batch 0.522 (0.480) Remain 31:29:42 loss: 1.5283 Lr: 0.00070
[2025-04-08 14:26:13,669 INFO misc.py line 113 3298914] Train: [2/100][1831/2402] Data 0.004 (0.004) Batch 0.526 (0.481) Remain 31:29:47 loss: 1.3330 Lr: 0.00070
[2025-04-08 14:26:14,101 INFO misc.py line 113 3298914] Train: [2/100][1832/2402] Data 0.004 (0.004) Batch 0.432 (0.480) Remain 31:29:40 loss: 1.2479 Lr: 0.00070
[2025-04-08 14:26:14,506 INFO misc.py line 113 3298914] Train: [2/100][1833/2402] Data 0.003 (0.004) Batch 0.404 (0.480) Remain 31:29:30 loss: 1.5114 Lr: 0.00070
[2025-04-08 14:26:14,979 INFO misc.py line 113 3298914] Train: [2/100][1834/2402] Data 0.004 (0.004) Batch 0.473 (0.480) Remain 31:29:29 loss: 1.3051 Lr: 0.00070
[2025-04-08 14:26:15,498 INFO misc.py line 113 3298914] Train: [2/100][1835/2402] Data 0.003 (0.004) Batch 0.520 (0.480) Remain 31:29:33 loss: 1.5821 Lr: 0.00070
[2025-04-08 14:26:15,848 INFO misc.py line 113 3298914] Train: [2/100][1836/2402] Data 0.003 (0.004) Batch 0.349 (0.480) Remain 31:29:16 loss: 0.9459 Lr: 0.00070
[2025-04-08 14:26:16,268 INFO misc.py line 113 3298914] Train: [2/100][1837/2402] Data 0.004 (0.004) Batch 0.420 (0.480) Remain 31:29:08 loss: 1.2096 Lr: 0.00070
[2025-04-08 14:26:16,715 INFO misc.py line 113 3298914] Train: [2/100][1838/2402] Data 0.003 (0.004) Batch 0.447 (0.480) Remain 31:29:03 loss: 0.7447 Lr: 0.00070
[2025-04-08 14:26:17,115 INFO misc.py line 113 3298914] Train: [2/100][1839/2402] Data 0.004 (0.004) Batch 0.400 (0.480) Remain 31:28:52 loss: 1.1266 Lr: 0.00070
[2025-04-08 14:26:17,625 INFO misc.py line 113 3298914] Train: [2/100][1840/2402] Data 0.003 (0.004) Batch 0.510 (0.480) Remain 31:28:55 loss: 1.4937 Lr: 0.00070
[2025-04-08 14:26:18,072 INFO misc.py line 113 3298914] Train: [2/100][1841/2402] Data 0.003 (0.004) Batch 0.447 (0.480) Remain 31:28:51 loss: 0.8917 Lr: 0.00070
[2025-04-08 14:26:18,456 INFO misc.py line 113 3298914] Train: [2/100][1842/2402] Data 0.004 (0.004) Batch 0.384 (0.480) Remain 31:28:38 loss: 1.1634 Lr: 0.00070
[2025-04-08 14:26:18,897 INFO misc.py line 113 3298914] Train: [2/100][1843/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:28:32 loss: 1.2552 Lr: 0.00070
[2025-04-08 14:26:19,419 INFO misc.py line 113 3298914] Train: [2/100][1844/2402] Data 0.004 (0.004) Batch 0.523 (0.480) Remain 31:28:37 loss: 1.1061 Lr: 0.00070
[2025-04-08 14:26:19,833 INFO misc.py line 113 3298914] Train: [2/100][1845/2402] Data 0.003 (0.004) Batch 0.414 (0.480) Remain 31:28:28 loss: 1.2153 Lr: 0.00070
[2025-04-08 14:26:20,291 INFO misc.py line 113 3298914] Train: [2/100][1846/2402] Data 0.004 (0.004) Batch 0.458 (0.480) Remain 31:28:25 loss: 1.7124 Lr: 0.00070
[2025-04-08 14:26:20,762 INFO misc.py line 113 3298914] Train: [2/100][1847/2402] Data 0.004 (0.004) Batch 0.472 (0.480) Remain 31:28:23 loss: 1.5914 Lr: 0.00070
[2025-04-08 14:26:21,262 INFO misc.py line 113 3298914] Train: [2/100][1848/2402] Data 0.003 (0.004) Batch 0.500 (0.480) Remain 31:28:25 loss: 0.8911 Lr: 0.00070
[2025-04-08 14:26:21,655 INFO misc.py line 113 3298914] Train: [2/100][1849/2402] Data 0.003 (0.004) Batch 0.393 (0.480) Remain 31:28:14 loss: 1.2298 Lr: 0.00070
[2025-04-08 14:26:22,124 INFO misc.py line 113 3298914] Train: [2/100][1850/2402] Data 0.004 (0.004) Batch 0.469 (0.480) Remain 31:28:12 loss: 1.1383 Lr: 0.00070
[2025-04-08 14:26:22,476 INFO misc.py line 113 3298914] Train: [2/100][1851/2402] Data 0.003 (0.004) Batch 0.352 (0.480) Remain 31:27:55 loss: 1.2566 Lr: 0.00070
[2025-04-08 14:26:22,899 INFO misc.py line 113 3298914] Train: [2/100][1852/2402] Data 0.004 (0.004) Batch 0.423 (0.480) Remain 31:27:47 loss: 1.5203 Lr: 0.00070
[2025-04-08 14:26:23,438 INFO misc.py line 113 3298914] Train: [2/100][1853/2402] Data 0.004 (0.004) Batch 0.539 (0.480) Remain 31:27:54 loss: 1.4358 Lr: 0.00070
[2025-04-08 14:26:23,887 INFO misc.py line 113 3298914] Train: [2/100][1854/2402] Data 0.004 (0.004) Batch 0.449 (0.480) Remain 31:27:50 loss: 1.3224 Lr: 0.00070
[2025-04-08 14:26:24,442 INFO misc.py line 113 3298914] Train: [2/100][1855/2402] Data 0.004 (0.004) Batch 0.555 (0.480) Remain 31:27:59 loss: 1.6433 Lr: 0.00070
[2025-04-08 14:26:24,820 INFO misc.py line 113 3298914] Train: [2/100][1856/2402] Data 0.003 (0.004) Batch 0.378 (0.480) Remain 31:27:45 loss: 1.2863 Lr: 0.00070
[2025-04-08 14:26:25,354 INFO misc.py line 113 3298914] Train: [2/100][1857/2402] Data 0.004 (0.004) Batch 0.534 (0.480) Remain 31:27:52 loss: 1.2653 Lr: 0.00070
[2025-04-08 14:26:25,781 INFO misc.py line 113 3298914] Train: [2/100][1858/2402] Data 0.004 (0.004) Batch 0.426 (0.480) Remain 31:27:44 loss: 1.2004 Lr: 0.00070
[2025-04-08 14:26:26,259 INFO misc.py line 113 3298914] Train: [2/100][1859/2402] Data 0.004 (0.004) Batch 0.478 (0.480) Remain 31:27:44 loss: 1.3934 Lr: 0.00070
[2025-04-08 14:26:26,687 INFO misc.py line 113 3298914] Train: [2/100][1860/2402] Data 0.004 (0.004) Batch 0.428 (0.480) Remain 31:27:37 loss: 1.1640 Lr: 0.00070
[2025-04-08 14:26:27,229 INFO misc.py line 113 3298914] Train: [2/100][1861/2402] Data 0.004 (0.004) Batch 0.542 (0.480) Remain 31:27:44 loss: 1.8552 Lr: 0.00070
[2025-04-08 14:26:27,625 INFO misc.py line 113 3298914] Train: [2/100][1862/2402] Data 0.004 (0.004) Batch 0.396 (0.480) Remain 31:27:33 loss: 1.4690 Lr: 0.00070
[2025-04-08 14:26:28,055 INFO misc.py line 113 3298914] Train: [2/100][1863/2402] Data 0.003 (0.004) Batch 0.430 (0.480) Remain 31:27:26 loss: 1.2755 Lr: 0.00070
[2025-04-08 14:26:28,504 INFO misc.py line 113 3298914] Train: [2/100][1864/2402] Data 0.004 (0.004) Batch 0.448 (0.480) Remain 31:27:22 loss: 1.6230 Lr: 0.00070
[2025-04-08 14:26:28,996 INFO misc.py line 113 3298914] Train: [2/100][1865/2402] Data 0.004 (0.004) Batch 0.492 (0.480) Remain 31:27:23 loss: 1.2238 Lr: 0.00070
[2025-04-08 14:26:29,416 INFO misc.py line 113 3298914] Train: [2/100][1866/2402] Data 0.004 (0.004) Batch 0.420 (0.480) Remain 31:27:15 loss: 1.1136 Lr: 0.00070
[2025-04-08 14:26:29,935 INFO misc.py line 113 3298914] Train: [2/100][1867/2402] Data 0.004 (0.004) Batch 0.519 (0.480) Remain 31:27:19 loss: 1.2151 Lr: 0.00070
[2025-04-08 14:26:30,365 INFO misc.py line 113 3298914] Train: [2/100][1868/2402] Data 0.003 (0.004) Batch 0.430 (0.480) Remain 31:27:12 loss: 1.0440 Lr: 0.00070
[2025-04-08 14:26:30,845 INFO misc.py line 113 3298914] Train: [2/100][1869/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:27:12 loss: 1.5457 Lr: 0.00070
[2025-04-08 14:26:31,343 INFO misc.py line 113 3298914] Train: [2/100][1870/2402] Data 0.004 (0.004) Batch 0.498 (0.480) Remain 31:27:14 loss: 1.8594 Lr: 0.00071
[2025-04-08 14:26:31,836 INFO misc.py line 113 3298914] Train: [2/100][1871/2402] Data 0.003 (0.004) Batch 0.493 (0.480) Remain 31:27:15 loss: 1.6032 Lr: 0.00071
[2025-04-08 14:26:32,421 INFO misc.py line 113 3298914] Train: [2/100][1872/2402] Data 0.003 (0.004) Batch 0.585 (0.480) Remain 31:27:27 loss: 1.7229 Lr: 0.00071
[2025-04-08 14:26:32,901 INFO misc.py line 113 3298914] Train: [2/100][1873/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:27:27 loss: 0.9751 Lr: 0.00071
[2025-04-08 14:26:33,383 INFO misc.py line 113 3298914] Train: [2/100][1874/2402] Data 0.003 (0.004) Batch 0.482 (0.480) Remain 31:27:27 loss: 1.2114 Lr: 0.00071
[2025-04-08 14:26:33,917 INFO misc.py line 113 3298914] Train: [2/100][1875/2402] Data 0.003 (0.004) Batch 0.534 (0.480) Remain 31:27:33 loss: 1.2414 Lr: 0.00071
[2025-04-08 14:26:34,439 INFO misc.py line 113 3298914] Train: [2/100][1876/2402] Data 0.004 (0.004) Batch 0.522 (0.480) Remain 31:27:38 loss: 0.8504 Lr: 0.00071
[2025-04-08 14:26:34,863 INFO misc.py line 113 3298914] Train: [2/100][1877/2402] Data 0.004 (0.004) Batch 0.425 (0.480) Remain 31:27:30 loss: 1.1834 Lr: 0.00071
[2025-04-08 14:26:35,380 INFO misc.py line 113 3298914] Train: [2/100][1878/2402] Data 0.003 (0.004) Batch 0.518 (0.480) Remain 31:27:35 loss: 1.4883 Lr: 0.00071
[2025-04-08 14:26:35,962 INFO misc.py line 113 3298914] Train: [2/100][1879/2402] Data 0.003 (0.004) Batch 0.581 (0.480) Remain 31:27:47 loss: 1.4791 Lr: 0.00071
[2025-04-08 14:26:36,398 INFO misc.py line 113 3298914] Train: [2/100][1880/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:27:41 loss: 1.2964 Lr: 0.00071
[2025-04-08 14:26:36,892 INFO misc.py line 113 3298914] Train: [2/100][1881/2402] Data 0.004 (0.004) Batch 0.493 (0.480) Remain 31:27:42 loss: 1.7691 Lr: 0.00071
[2025-04-08 14:26:37,394 INFO misc.py line 113 3298914] Train: [2/100][1882/2402] Data 0.004 (0.004) Batch 0.502 (0.480) Remain 31:27:44 loss: 1.5261 Lr: 0.00071
[2025-04-08 14:26:37,902 INFO misc.py line 113 3298914] Train: [2/100][1883/2402] Data 0.004 (0.004) Batch 0.509 (0.480) Remain 31:27:47 loss: 1.5823 Lr: 0.00071
[2025-04-08 14:26:38,323 INFO misc.py line 113 3298914] Train: [2/100][1884/2402] Data 0.003 (0.004) Batch 0.420 (0.480) Remain 31:27:39 loss: 0.7643 Lr: 0.00071
[2025-04-08 14:26:38,867 INFO misc.py line 113 3298914] Train: [2/100][1885/2402] Data 0.004 (0.004) Batch 0.545 (0.480) Remain 31:27:47 loss: 1.0304 Lr: 0.00071
[2025-04-08 14:26:39,332 INFO misc.py line 113 3298914] Train: [2/100][1886/2402] Data 0.004 (0.004) Batch 0.465 (0.480) Remain 31:27:45 loss: 1.2559 Lr: 0.00071
[2025-04-08 14:26:39,826 INFO misc.py line 113 3298914] Train: [2/100][1887/2402] Data 0.004 (0.004) Batch 0.493 (0.480) Remain 31:27:46 loss: 1.2143 Lr: 0.00071
[2025-04-08 14:26:40,303 INFO misc.py line 113 3298914] Train: [2/100][1888/2402] Data 0.004 (0.004) Batch 0.477 (0.480) Remain 31:27:45 loss: 1.1789 Lr: 0.00071
[2025-04-08 14:26:40,894 INFO misc.py line 113 3298914] Train: [2/100][1889/2402] Data 0.003 (0.004) Batch 0.592 (0.480) Remain 31:27:58 loss: 1.5881 Lr: 0.00071
[2025-04-08 14:26:41,390 INFO misc.py line 113 3298914] Train: [2/100][1890/2402] Data 0.004 (0.004) Batch 0.496 (0.480) Remain 31:28:00 loss: 1.3075 Lr: 0.00071
[2025-04-08 14:26:41,823 INFO misc.py line 113 3298914] Train: [2/100][1891/2402] Data 0.004 (0.004) Batch 0.434 (0.480) Remain 31:27:54 loss: 1.6690 Lr: 0.00071
[2025-04-08 14:26:42,270 INFO misc.py line 113 3298914] Train: [2/100][1892/2402] Data 0.003 (0.004) Batch 0.447 (0.480) Remain 31:27:49 loss: 1.5722 Lr: 0.00071
[2025-04-08 14:26:42,701 INFO misc.py line 113 3298914] Train: [2/100][1893/2402] Data 0.004 (0.004) Batch 0.431 (0.480) Remain 31:27:42 loss: 1.0179 Lr: 0.00071
[2025-04-08 14:26:43,184 INFO misc.py line 113 3298914] Train: [2/100][1894/2402] Data 0.004 (0.004) Batch 0.483 (0.480) Remain 31:27:42 loss: 1.4089 Lr: 0.00071
[2025-04-08 14:26:43,773 INFO misc.py line 113 3298914] Train: [2/100][1895/2402] Data 0.003 (0.004) Batch 0.590 (0.480) Remain 31:27:55 loss: 1.2039 Lr: 0.00071
[2025-04-08 14:26:44,094 INFO misc.py line 113 3298914] Train: [2/100][1896/2402] Data 0.004 (0.004) Batch 0.320 (0.480) Remain 31:27:35 loss: 1.5208 Lr: 0.00071
[2025-04-08 14:26:44,537 INFO misc.py line 113 3298914] Train: [2/100][1897/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:27:30 loss: 1.1351 Lr: 0.00071
[2025-04-08 14:26:45,019 INFO misc.py line 113 3298914] Train: [2/100][1898/2402] Data 0.004 (0.004) Batch 0.482 (0.480) Remain 31:27:30 loss: 1.5606 Lr: 0.00071
[2025-04-08 14:26:45,579 INFO misc.py line 113 3298914] Train: [2/100][1899/2402] Data 0.003 (0.004) Batch 0.560 (0.480) Remain 31:27:39 loss: 1.3361 Lr: 0.00071
[2025-04-08 14:26:46,109 INFO misc.py line 113 3298914] Train: [2/100][1900/2402] Data 0.003 (0.004) Batch 0.530 (0.480) Remain 31:27:45 loss: 1.2569 Lr: 0.00071
[2025-04-08 14:26:46,641 INFO misc.py line 113 3298914] Train: [2/100][1901/2402] Data 0.004 (0.004) Batch 0.531 (0.480) Remain 31:27:51 loss: 1.2719 Lr: 0.00071
[2025-04-08 14:26:47,044 INFO misc.py line 113 3298914] Train: [2/100][1902/2402] Data 0.004 (0.004) Batch 0.403 (0.480) Remain 31:27:41 loss: 0.9984 Lr: 0.00071
[2025-04-08 14:26:47,538 INFO misc.py line 113 3298914] Train: [2/100][1903/2402] Data 0.004 (0.004) Batch 0.495 (0.480) Remain 31:27:42 loss: 1.2518 Lr: 0.00071
[2025-04-08 14:26:48,013 INFO misc.py line 113 3298914] Train: [2/100][1904/2402] Data 0.004 (0.004) Batch 0.474 (0.480) Remain 31:27:41 loss: 1.3639 Lr: 0.00071
[2025-04-08 14:26:48,475 INFO misc.py line 113 3298914] Train: [2/100][1905/2402] Data 0.003 (0.004) Batch 0.462 (0.480) Remain 31:27:38 loss: 1.4393 Lr: 0.00071
[2025-04-08 14:26:48,868 INFO misc.py line 113 3298914] Train: [2/100][1906/2402] Data 0.003 (0.004) Batch 0.393 (0.480) Remain 31:27:27 loss: 0.7584 Lr: 0.00071
[2025-04-08 14:26:49,339 INFO misc.py line 113 3298914] Train: [2/100][1907/2402] Data 0.004 (0.004) Batch 0.472 (0.480) Remain 31:27:25 loss: 1.0489 Lr: 0.00071
[2025-04-08 14:26:49,665 INFO misc.py line 113 3298914] Train: [2/100][1908/2402] Data 0.003 (0.004) Batch 0.326 (0.480) Remain 31:27:06 loss: 1.2885 Lr: 0.00071
[2025-04-08 14:26:50,166 INFO misc.py line 113 3298914] Train: [2/100][1909/2402] Data 0.004 (0.004) Batch 0.501 (0.480) Remain 31:27:08 loss: 1.3309 Lr: 0.00071
[2025-04-08 14:26:50,653 INFO misc.py line 113 3298914] Train: [2/100][1910/2402] Data 0.003 (0.004) Batch 0.487 (0.480) Remain 31:27:08 loss: 1.3061 Lr: 0.00071
[2025-04-08 14:26:51,173 INFO misc.py line 113 3298914] Train: [2/100][1911/2402] Data 0.003 (0.004) Batch 0.521 (0.480) Remain 31:27:13 loss: 1.0383 Lr: 0.00071
[2025-04-08 14:26:51,663 INFO misc.py line 113 3298914] Train: [2/100][1912/2402] Data 0.006 (0.004) Batch 0.490 (0.480) Remain 31:27:13 loss: 1.0436 Lr: 0.00071
[2025-04-08 14:26:52,221 INFO misc.py line 113 3298914] Train: [2/100][1913/2402] Data 0.004 (0.004) Batch 0.558 (0.480) Remain 31:27:23 loss: 1.3126 Lr: 0.00071
[2025-04-08 14:26:52,668 INFO misc.py line 113 3298914] Train: [2/100][1914/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:27:18 loss: 1.2493 Lr: 0.00071
[2025-04-08 14:26:53,162 INFO misc.py line 113 3298914] Train: [2/100][1915/2402] Data 0.003 (0.004) Batch 0.494 (0.480) Remain 31:27:19 loss: 1.1558 Lr: 0.00071
[2025-04-08 14:26:53,677 INFO misc.py line 113 3298914] Train: [2/100][1916/2402] Data 0.003 (0.004) Batch 0.516 (0.480) Remain 31:27:23 loss: 1.4410 Lr: 0.00071
[2025-04-08 14:26:54,027 INFO misc.py line 113 3298914] Train: [2/100][1917/2402] Data 0.004 (0.004) Batch 0.349 (0.480) Remain 31:27:06 loss: 1.2565 Lr: 0.00072
[2025-04-08 14:26:54,621 INFO misc.py line 113 3298914] Train: [2/100][1918/2402] Data 0.004 (0.004) Batch 0.594 (0.480) Remain 31:27:20 loss: 0.9716 Lr: 0.00072
[2025-04-08 14:26:55,006 INFO misc.py line 113 3298914] Train: [2/100][1919/2402] Data 0.003 (0.004) Batch 0.385 (0.480) Remain 31:27:08 loss: 1.1935 Lr: 0.00072
[2025-04-08 14:26:55,445 INFO misc.py line 113 3298914] Train: [2/100][1920/2402] Data 0.004 (0.004) Batch 0.438 (0.480) Remain 31:27:02 loss: 1.0591 Lr: 0.00072
[2025-04-08 14:26:55,845 INFO misc.py line 113 3298914] Train: [2/100][1921/2402] Data 0.003 (0.004) Batch 0.400 (0.480) Remain 31:26:52 loss: 1.1473 Lr: 0.00072
[2025-04-08 14:26:56,323 INFO misc.py line 113 3298914] Train: [2/100][1922/2402] Data 0.004 (0.004) Batch 0.479 (0.480) Remain 31:26:51 loss: 1.3072 Lr: 0.00072
[2025-04-08 14:26:56,871 INFO misc.py line 113 3298914] Train: [2/100][1923/2402] Data 0.004 (0.004) Batch 0.548 (0.480) Remain 31:26:59 loss: 0.9267 Lr: 0.00072
[2025-04-08 14:26:57,459 INFO misc.py line 113 3298914] Train: [2/100][1924/2402] Data 0.003 (0.004) Batch 0.588 (0.480) Remain 31:27:12 loss: 1.8482 Lr: 0.00072
[2025-04-08 14:26:57,927 INFO misc.py line 113 3298914] Train: [2/100][1925/2402] Data 0.004 (0.004) Batch 0.469 (0.480) Remain 31:27:10 loss: 1.3556 Lr: 0.00072
[2025-04-08 14:26:58,345 INFO misc.py line 113 3298914] Train: [2/100][1926/2402] Data 0.003 (0.004) Batch 0.418 (0.480) Remain 31:27:02 loss: 1.5088 Lr: 0.00072
[2025-04-08 14:26:58,721 INFO misc.py line 113 3298914] Train: [2/100][1927/2402] Data 0.003 (0.004) Batch 0.376 (0.480) Remain 31:26:49 loss: 0.9039 Lr: 0.00072
[2025-04-08 14:26:59,240 INFO misc.py line 113 3298914] Train: [2/100][1928/2402] Data 0.004 (0.004) Batch 0.520 (0.480) Remain 31:26:53 loss: 1.2462 Lr: 0.00072
[2025-04-08 14:26:59,733 INFO misc.py line 113 3298914] Train: [2/100][1929/2402] Data 0.003 (0.004) Batch 0.493 (0.480) Remain 31:26:54 loss: 1.4365 Lr: 0.00072
[2025-04-08 14:27:00,163 INFO misc.py line 113 3298914] Train: [2/100][1930/2402] Data 0.004 (0.004) Batch 0.429 (0.480) Remain 31:26:48 loss: 1.1785 Lr: 0.00072
[2025-04-08 14:27:00,693 INFO misc.py line 113 3298914] Train: [2/100][1931/2402] Data 0.003 (0.004) Batch 0.530 (0.480) Remain 31:26:53 loss: 1.3376 Lr: 0.00072
[2025-04-08 14:27:01,117 INFO misc.py line 113 3298914] Train: [2/100][1932/2402] Data 0.003 (0.004) Batch 0.424 (0.480) Remain 31:26:46 loss: 1.3722 Lr: 0.00072
[2025-04-08 14:27:01,545 INFO misc.py line 113 3298914] Train: [2/100][1933/2402] Data 0.003 (0.004) Batch 0.427 (0.480) Remain 31:26:39 loss: 1.6050 Lr: 0.00072
[2025-04-08 14:27:02,136 INFO misc.py line 113 3298914] Train: [2/100][1934/2402] Data 0.004 (0.004) Batch 0.591 (0.480) Remain 31:26:52 loss: 1.2047 Lr: 0.00072
[2025-04-08 14:27:02,643 INFO misc.py line 113 3298914] Train: [2/100][1935/2402] Data 0.003 (0.004) Batch 0.507 (0.480) Remain 31:26:55 loss: 1.2207 Lr: 0.00072
[2025-04-08 14:27:03,190 INFO misc.py line 113 3298914] Train: [2/100][1936/2402] Data 0.004 (0.004) Batch 0.547 (0.480) Remain 31:27:03 loss: 1.5910 Lr: 0.00072
[2025-04-08 14:27:03,664 INFO misc.py line 113 3298914] Train: [2/100][1937/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:27:01 loss: 1.4631 Lr: 0.00072
[2025-04-08 14:27:04,106 INFO misc.py line 113 3298914] Train: [2/100][1938/2402] Data 0.004 (0.004) Batch 0.442 (0.480) Remain 31:26:56 loss: 1.4727 Lr: 0.00072
[2025-04-08 14:27:04,638 INFO misc.py line 113 3298914] Train: [2/100][1939/2402] Data 0.003 (0.004) Batch 0.532 (0.480) Remain 31:27:02 loss: 1.2989 Lr: 0.00072
[2025-04-08 14:27:05,153 INFO misc.py line 113 3298914] Train: [2/100][1940/2402] Data 0.003 (0.004) Batch 0.515 (0.480) Remain 31:27:06 loss: 1.2154 Lr: 0.00072
[2025-04-08 14:27:05,583 INFO misc.py line 113 3298914] Train: [2/100][1941/2402] Data 0.004 (0.004) Batch 0.429 (0.480) Remain 31:26:59 loss: 1.2862 Lr: 0.00072
[2025-04-08 14:27:06,007 INFO misc.py line 113 3298914] Train: [2/100][1942/2402] Data 0.003 (0.004) Batch 0.424 (0.480) Remain 31:26:52 loss: 1.2620 Lr: 0.00072
[2025-04-08 14:27:06,510 INFO misc.py line 113 3298914] Train: [2/100][1943/2402] Data 0.004 (0.004) Batch 0.503 (0.480) Remain 31:26:54 loss: 0.8559 Lr: 0.00072
[2025-04-08 14:27:06,911 INFO misc.py line 113 3298914] Train: [2/100][1944/2402] Data 0.003 (0.004) Batch 0.401 (0.480) Remain 31:26:44 loss: 1.2221 Lr: 0.00072
[2025-04-08 14:27:07,223 INFO misc.py line 113 3298914] Train: [2/100][1945/2402] Data 0.003 (0.004) Batch 0.312 (0.480) Remain 31:26:23 loss: 1.0688 Lr: 0.00072
[2025-04-08 14:27:07,668 INFO misc.py line 113 3298914] Train: [2/100][1946/2402] Data 0.003 (0.004) Batch 0.445 (0.480) Remain 31:26:19 loss: 1.0666 Lr: 0.00072
[2025-04-08 14:27:08,211 INFO misc.py line 113 3298914] Train: [2/100][1947/2402] Data 0.004 (0.004) Batch 0.543 (0.480) Remain 31:26:26 loss: 1.2869 Lr: 0.00072
[2025-04-08 14:27:08,656 INFO misc.py line 113 3298914] Train: [2/100][1948/2402] Data 0.003 (0.004) Batch 0.444 (0.480) Remain 31:26:21 loss: 1.3106 Lr: 0.00072
[2025-04-08 14:27:09,129 INFO misc.py line 113 3298914] Train: [2/100][1949/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:26:20 loss: 0.8532 Lr: 0.00072
[2025-04-08 14:27:09,513 INFO misc.py line 113 3298914] Train: [2/100][1950/2402] Data 0.004 (0.004) Batch 0.384 (0.480) Remain 31:26:08 loss: 1.2534 Lr: 0.00072
[2025-04-08 14:27:09,960 INFO misc.py line 113 3298914] Train: [2/100][1951/2402] Data 0.004 (0.004) Batch 0.446 (0.480) Remain 31:26:03 loss: 1.4322 Lr: 0.00072
[2025-04-08 14:27:10,397 INFO misc.py line 113 3298914] Train: [2/100][1952/2402] Data 0.003 (0.004) Batch 0.438 (0.480) Remain 31:25:58 loss: 1.1089 Lr: 0.00072
[2025-04-08 14:27:10,882 INFO misc.py line 113 3298914] Train: [2/100][1953/2402] Data 0.004 (0.004) Batch 0.485 (0.480) Remain 31:25:58 loss: 1.2939 Lr: 0.00072
[2025-04-08 14:27:11,417 INFO misc.py line 113 3298914] Train: [2/100][1954/2402] Data 0.004 (0.004) Batch 0.535 (0.480) Remain 31:26:04 loss: 0.9691 Lr: 0.00072
[2025-04-08 14:27:11,989 INFO misc.py line 113 3298914] Train: [2/100][1955/2402] Data 0.004 (0.004) Batch 0.572 (0.480) Remain 31:26:15 loss: 1.0450 Lr: 0.00072
[2025-04-08 14:27:12,506 INFO misc.py line 113 3298914] Train: [2/100][1956/2402] Data 0.003 (0.004) Batch 0.517 (0.480) Remain 31:26:19 loss: 1.9844 Lr: 0.00072
[2025-04-08 14:27:12,963 INFO misc.py line 113 3298914] Train: [2/100][1957/2402] Data 0.004 (0.004) Batch 0.457 (0.480) Remain 31:26:15 loss: 1.2843 Lr: 0.00072
[2025-04-08 14:27:13,540 INFO misc.py line 113 3298914] Train: [2/100][1958/2402] Data 0.003 (0.004) Batch 0.578 (0.480) Remain 31:26:27 loss: 1.7950 Lr: 0.00072
[2025-04-08 14:27:13,995 INFO misc.py line 113 3298914] Train: [2/100][1959/2402] Data 0.004 (0.004) Batch 0.455 (0.480) Remain 31:26:23 loss: 1.3354 Lr: 0.00072
[2025-04-08 14:27:14,397 INFO misc.py line 113 3298914] Train: [2/100][1960/2402] Data 0.003 (0.004) Batch 0.402 (0.480) Remain 31:26:13 loss: 1.1538 Lr: 0.00072
[2025-04-08 14:27:14,852 INFO misc.py line 113 3298914] Train: [2/100][1961/2402] Data 0.003 (0.004) Batch 0.455 (0.480) Remain 31:26:10 loss: 1.4355 Lr: 0.00072
[2025-04-08 14:27:15,331 INFO misc.py line 113 3298914] Train: [2/100][1962/2402] Data 0.004 (0.004) Batch 0.479 (0.480) Remain 31:26:09 loss: 1.3489 Lr: 0.00072
[2025-04-08 14:27:15,921 INFO misc.py line 113 3298914] Train: [2/100][1963/2402] Data 0.004 (0.004) Batch 0.589 (0.480) Remain 31:26:22 loss: 1.0536 Lr: 0.00072
[2025-04-08 14:27:16,294 INFO misc.py line 113 3298914] Train: [2/100][1964/2402] Data 0.003 (0.004) Batch 0.373 (0.480) Remain 31:26:09 loss: 1.4349 Lr: 0.00073
[2025-04-08 14:27:16,812 INFO misc.py line 113 3298914] Train: [2/100][1965/2402] Data 0.004 (0.004) Batch 0.518 (0.480) Remain 31:26:13 loss: 1.5728 Lr: 0.00073
[2025-04-08 14:27:17,294 INFO misc.py line 113 3298914] Train: [2/100][1966/2402] Data 0.004 (0.004) Batch 0.482 (0.480) Remain 31:26:12 loss: 1.3780 Lr: 0.00073
[2025-04-08 14:27:17,783 INFO misc.py line 113 3298914] Train: [2/100][1967/2402] Data 0.003 (0.004) Batch 0.489 (0.480) Remain 31:26:13 loss: 1.2954 Lr: 0.00073
[2025-04-08 14:27:18,265 INFO misc.py line 113 3298914] Train: [2/100][1968/2402] Data 0.003 (0.004) Batch 0.482 (0.480) Remain 31:26:13 loss: 1.5450 Lr: 0.00073
[2025-04-08 14:27:18,752 INFO misc.py line 113 3298914] Train: [2/100][1969/2402] Data 0.004 (0.004) Batch 0.487 (0.480) Remain 31:26:13 loss: 1.1096 Lr: 0.00073
[2025-04-08 14:27:19,266 INFO misc.py line 113 3298914] Train: [2/100][1970/2402] Data 0.003 (0.004) Batch 0.514 (0.480) Remain 31:26:17 loss: 1.3460 Lr: 0.00073
[2025-04-08 14:27:19,724 INFO misc.py line 113 3298914] Train: [2/100][1971/2402] Data 0.004 (0.004) Batch 0.457 (0.480) Remain 31:26:14 loss: 1.2153 Lr: 0.00073
[2025-04-08 14:27:20,151 INFO misc.py line 113 3298914] Train: [2/100][1972/2402] Data 0.004 (0.004) Batch 0.427 (0.480) Remain 31:26:07 loss: 1.1697 Lr: 0.00073
[2025-04-08 14:27:20,660 INFO misc.py line 113 3298914] Train: [2/100][1973/2402] Data 0.004 (0.004) Batch 0.509 (0.480) Remain 31:26:10 loss: 1.2183 Lr: 0.00073
[2025-04-08 14:27:21,079 INFO misc.py line 113 3298914] Train: [2/100][1974/2402] Data 0.004 (0.004) Batch 0.420 (0.480) Remain 31:26:02 loss: 1.2980 Lr: 0.00073
[2025-04-08 14:27:21,502 INFO misc.py line 113 3298914] Train: [2/100][1975/2402] Data 0.004 (0.004) Batch 0.423 (0.480) Remain 31:25:55 loss: 1.2422 Lr: 0.00073
[2025-04-08 14:27:22,004 INFO misc.py line 113 3298914] Train: [2/100][1976/2402] Data 0.004 (0.004) Batch 0.501 (0.480) Remain 31:25:57 loss: 1.5840 Lr: 0.00073
[2025-04-08 14:27:22,510 INFO misc.py line 113 3298914] Train: [2/100][1977/2402] Data 0.004 (0.004) Batch 0.506 (0.480) Remain 31:26:00 loss: 1.2921 Lr: 0.00073
[2025-04-08 14:27:22,931 INFO misc.py line 113 3298914] Train: [2/100][1978/2402] Data 0.004 (0.004) Batch 0.421 (0.480) Remain 31:25:52 loss: 0.9178 Lr: 0.00073
[2025-04-08 14:27:23,339 INFO misc.py line 113 3298914] Train: [2/100][1979/2402] Data 0.003 (0.004) Batch 0.408 (0.480) Remain 31:25:43 loss: 1.3238 Lr: 0.00073
[2025-04-08 14:27:23,814 INFO misc.py line 113 3298914] Train: [2/100][1980/2402] Data 0.004 (0.004) Batch 0.475 (0.480) Remain 31:25:42 loss: 1.2042 Lr: 0.00073
[2025-04-08 14:27:24,277 INFO misc.py line 113 3298914] Train: [2/100][1981/2402] Data 0.003 (0.004) Batch 0.463 (0.480) Remain 31:25:40 loss: 1.2905 Lr: 0.00073
[2025-04-08 14:27:24,726 INFO misc.py line 113 3298914] Train: [2/100][1982/2402] Data 0.003 (0.004) Batch 0.449 (0.480) Remain 31:25:35 loss: 1.1527 Lr: 0.00073
[2025-04-08 14:27:25,116 INFO misc.py line 113 3298914] Train: [2/100][1983/2402] Data 0.003 (0.004) Batch 0.390 (0.480) Remain 31:25:24 loss: 1.5047 Lr: 0.00073
[2025-04-08 14:27:25,556 INFO misc.py line 113 3298914] Train: [2/100][1984/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:25:19 loss: 0.9686 Lr: 0.00073
[2025-04-08 14:27:25,965 INFO misc.py line 113 3298914] Train: [2/100][1985/2402] Data 0.003 (0.004) Batch 0.409 (0.480) Remain 31:25:10 loss: 1.4031 Lr: 0.00073
[2025-04-08 14:27:26,448 INFO misc.py line 113 3298914] Train: [2/100][1986/2402] Data 0.003 (0.004) Batch 0.482 (0.480) Remain 31:25:10 loss: 1.2639 Lr: 0.00073
[2025-04-08 14:27:27,022 INFO misc.py line 113 3298914] Train: [2/100][1987/2402] Data 0.003 (0.004) Batch 0.574 (0.480) Remain 31:25:21 loss: 1.3617 Lr: 0.00073
[2025-04-08 14:27:27,427 INFO misc.py line 113 3298914] Train: [2/100][1988/2402] Data 0.004 (0.004) Batch 0.405 (0.480) Remain 31:25:12 loss: 1.0158 Lr: 0.00073
[2025-04-08 14:27:28,032 INFO misc.py line 113 3298914] Train: [2/100][1989/2402] Data 0.003 (0.004) Batch 0.605 (0.480) Remain 31:25:26 loss: 1.0962 Lr: 0.00073
[2025-04-08 14:27:28,479 INFO misc.py line 113 3298914] Train: [2/100][1990/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:25:22 loss: 0.7591 Lr: 0.00073
[2025-04-08 14:27:29,018 INFO misc.py line 113 3298914] Train: [2/100][1991/2402] Data 0.004 (0.004) Batch 0.538 (0.480) Remain 31:25:28 loss: 1.0733 Lr: 0.00073
[2025-04-08 14:27:29,542 INFO misc.py line 113 3298914] Train: [2/100][1992/2402] Data 0.004 (0.004) Batch 0.524 (0.480) Remain 31:25:33 loss: 1.3711 Lr: 0.00073
[2025-04-08 14:27:30,029 INFO misc.py line 113 3298914] Train: [2/100][1993/2402] Data 0.004 (0.004) Batch 0.487 (0.480) Remain 31:25:33 loss: 1.3427 Lr: 0.00073
[2025-04-08 14:27:30,386 INFO misc.py line 113 3298914] Train: [2/100][1994/2402] Data 0.003 (0.004) Batch 0.357 (0.480) Remain 31:25:18 loss: 1.4066 Lr: 0.00073
[2025-04-08 14:27:30,828 INFO misc.py line 113 3298914] Train: [2/100][1995/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:25:13 loss: 1.3121 Lr: 0.00073
[2025-04-08 14:27:31,299 INFO misc.py line 113 3298914] Train: [2/100][1996/2402] Data 0.004 (0.004) Batch 0.471 (0.480) Remain 31:25:12 loss: 0.8754 Lr: 0.00073
[2025-04-08 14:27:31,716 INFO misc.py line 113 3298914] Train: [2/100][1997/2402] Data 0.003 (0.004) Batch 0.417 (0.480) Remain 31:25:04 loss: 2.0220 Lr: 0.00073
[2025-04-08 14:27:32,293 INFO misc.py line 113 3298914] Train: [2/100][1998/2402] Data 0.003 (0.004) Batch 0.577 (0.480) Remain 31:25:15 loss: 1.0319 Lr: 0.00073
[2025-04-08 14:27:32,643 INFO misc.py line 113 3298914] Train: [2/100][1999/2402] Data 0.004 (0.004) Batch 0.349 (0.480) Remain 31:24:59 loss: 0.9853 Lr: 0.00073
[2025-04-08 14:27:33,074 INFO misc.py line 113 3298914] Train: [2/100][2000/2402] Data 0.003 (0.004) Batch 0.432 (0.480) Remain 31:24:53 loss: 1.3385 Lr: 0.00073
[2025-04-08 14:27:33,556 INFO misc.py line 113 3298914] Train: [2/100][2001/2402] Data 0.003 (0.004) Batch 0.482 (0.480) Remain 31:24:53 loss: 1.2447 Lr: 0.00073
[2025-04-08 14:27:34,004 INFO misc.py line 113 3298914] Train: [2/100][2002/2402] Data 0.004 (0.004) Batch 0.448 (0.480) Remain 31:24:48 loss: 1.2215 Lr: 0.00073
[2025-04-08 14:27:34,451 INFO misc.py line 113 3298914] Train: [2/100][2003/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:24:44 loss: 1.1509 Lr: 0.00073
[2025-04-08 14:27:34,979 INFO misc.py line 113 3298914] Train: [2/100][2004/2402] Data 0.003 (0.004) Batch 0.528 (0.480) Remain 31:24:49 loss: 1.3911 Lr: 0.00073
[2025-04-08 14:27:35,528 INFO misc.py line 113 3298914] Train: [2/100][2005/2402] Data 0.004 (0.004) Batch 0.549 (0.480) Remain 31:24:57 loss: 0.9694 Lr: 0.00073
[2025-04-08 14:27:36,085 INFO misc.py line 113 3298914] Train: [2/100][2006/2402] Data 0.004 (0.004) Batch 0.557 (0.480) Remain 31:25:06 loss: 1.3262 Lr: 0.00073
[2025-04-08 14:27:36,540 INFO misc.py line 113 3298914] Train: [2/100][2007/2402] Data 0.003 (0.004) Batch 0.455 (0.480) Remain 31:25:02 loss: 1.4673 Lr: 0.00073
[2025-04-08 14:27:37,034 INFO misc.py line 113 3298914] Train: [2/100][2008/2402] Data 0.003 (0.004) Batch 0.494 (0.480) Remain 31:25:03 loss: 1.0966 Lr: 0.00073
[2025-04-08 14:27:37,499 INFO misc.py line 113 3298914] Train: [2/100][2009/2402] Data 0.004 (0.004) Batch 0.466 (0.480) Remain 31:25:01 loss: 1.4256 Lr: 0.00073
[2025-04-08 14:27:37,978 INFO misc.py line 113 3298914] Train: [2/100][2010/2402] Data 0.003 (0.004) Batch 0.478 (0.480) Remain 31:25:01 loss: 0.9950 Lr: 0.00073
[2025-04-08 14:27:38,503 INFO misc.py line 113 3298914] Train: [2/100][2011/2402] Data 0.003 (0.004) Batch 0.524 (0.480) Remain 31:25:06 loss: 1.1403 Lr: 0.00074
[2025-04-08 14:27:38,986 INFO misc.py line 113 3298914] Train: [2/100][2012/2402] Data 0.004 (0.004) Batch 0.483 (0.480) Remain 31:25:05 loss: 1.2936 Lr: 0.00074
[2025-04-08 14:27:39,471 INFO misc.py line 113 3298914] Train: [2/100][2013/2402] Data 0.003 (0.004) Batch 0.485 (0.480) Remain 31:25:06 loss: 1.4850 Lr: 0.00074
[2025-04-08 14:27:39,940 INFO misc.py line 113 3298914] Train: [2/100][2014/2402] Data 0.004 (0.004) Batch 0.470 (0.480) Remain 31:25:04 loss: 0.8294 Lr: 0.00074
[2025-04-08 14:27:40,474 INFO misc.py line 113 3298914] Train: [2/100][2015/2402] Data 0.004 (0.004) Batch 0.534 (0.480) Remain 31:25:10 loss: 1.5147 Lr: 0.00074
[2025-04-08 14:27:40,863 INFO misc.py line 113 3298914] Train: [2/100][2016/2402] Data 0.003 (0.004) Batch 0.389 (0.480) Remain 31:24:59 loss: 1.1423 Lr: 0.00074
[2025-04-08 14:27:41,406 INFO misc.py line 113 3298914] Train: [2/100][2017/2402] Data 0.004 (0.004) Batch 0.543 (0.480) Remain 31:25:06 loss: 1.2633 Lr: 0.00074
[2025-04-08 14:27:41,952 INFO misc.py line 113 3298914] Train: [2/100][2018/2402] Data 0.003 (0.004) Batch 0.546 (0.480) Remain 31:25:13 loss: 1.1879 Lr: 0.00074
[2025-04-08 14:27:42,335 INFO misc.py line 113 3298914] Train: [2/100][2019/2402] Data 0.003 (0.004) Batch 0.382 (0.480) Remain 31:25:01 loss: 0.9965 Lr: 0.00074
[2025-04-08 14:27:42,735 INFO misc.py line 113 3298914] Train: [2/100][2020/2402] Data 0.004 (0.004) Batch 0.400 (0.480) Remain 31:24:51 loss: 1.1589 Lr: 0.00074
[2025-04-08 14:27:43,208 INFO misc.py line 113 3298914] Train: [2/100][2021/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:24:50 loss: 0.9636 Lr: 0.00074
[2025-04-08 14:27:43,761 INFO misc.py line 113 3298914] Train: [2/100][2022/2402] Data 0.003 (0.004) Batch 0.552 (0.480) Remain 31:24:58 loss: 1.1139 Lr: 0.00074
[2025-04-08 14:27:44,234 INFO misc.py line 113 3298914] Train: [2/100][2023/2402] Data 0.004 (0.004) Batch 0.474 (0.480) Remain 31:24:57 loss: 1.1720 Lr: 0.00074
[2025-04-08 14:27:44,709 INFO misc.py line 113 3298914] Train: [2/100][2024/2402] Data 0.003 (0.004) Batch 0.475 (0.480) Remain 31:24:56 loss: 1.5328 Lr: 0.00074
[2025-04-08 14:27:45,234 INFO misc.py line 113 3298914] Train: [2/100][2025/2402] Data 0.004 (0.004) Batch 0.525 (0.480) Remain 31:25:01 loss: 1.4086 Lr: 0.00074
[2025-04-08 14:27:45,773 INFO misc.py line 113 3298914] Train: [2/100][2026/2402] Data 0.003 (0.004) Batch 0.538 (0.480) Remain 31:25:07 loss: 1.2800 Lr: 0.00074
[2025-04-08 14:27:46,275 INFO misc.py line 113 3298914] Train: [2/100][2027/2402] Data 0.004 (0.004) Batch 0.502 (0.480) Remain 31:25:09 loss: 1.6117 Lr: 0.00074
[2025-04-08 14:27:46,739 INFO misc.py line 113 3298914] Train: [2/100][2028/2402] Data 0.003 (0.004) Batch 0.464 (0.480) Remain 31:25:07 loss: 0.9711 Lr: 0.00074
[2025-04-08 14:27:47,204 INFO misc.py line 113 3298914] Train: [2/100][2029/2402] Data 0.004 (0.004) Batch 0.465 (0.480) Remain 31:25:05 loss: 0.8912 Lr: 0.00074
[2025-04-08 14:27:47,686 INFO misc.py line 113 3298914] Train: [2/100][2030/2402] Data 0.003 (0.004) Batch 0.482 (0.480) Remain 31:25:04 loss: 1.2480 Lr: 0.00074
[2025-04-08 14:27:48,224 INFO misc.py line 113 3298914] Train: [2/100][2031/2402] Data 0.004 (0.004) Batch 0.538 (0.480) Remain 31:25:11 loss: 1.2410 Lr: 0.00074
[2025-04-08 14:27:48,704 INFO misc.py line 113 3298914] Train: [2/100][2032/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:25:10 loss: 1.5642 Lr: 0.00074
[2025-04-08 14:27:49,250 INFO misc.py line 113 3298914] Train: [2/100][2033/2402] Data 0.004 (0.004) Batch 0.545 (0.480) Remain 31:25:17 loss: 1.2111 Lr: 0.00074
[2025-04-08 14:27:49,711 INFO misc.py line 113 3298914] Train: [2/100][2034/2402] Data 0.004 (0.004) Batch 0.461 (0.480) Remain 31:25:15 loss: 1.3791 Lr: 0.00074
[2025-04-08 14:27:50,168 INFO misc.py line 113 3298914] Train: [2/100][2035/2402] Data 0.004 (0.004) Batch 0.457 (0.480) Remain 31:25:12 loss: 1.2758 Lr: 0.00074
[2025-04-08 14:27:50,642 INFO misc.py line 113 3298914] Train: [2/100][2036/2402] Data 0.003 (0.004) Batch 0.474 (0.480) Remain 31:25:11 loss: 1.4701 Lr: 0.00074
[2025-04-08 14:27:51,135 INFO misc.py line 113 3298914] Train: [2/100][2037/2402] Data 0.004 (0.004) Batch 0.493 (0.480) Remain 31:25:12 loss: 1.3391 Lr: 0.00074
[2025-04-08 14:27:51,628 INFO misc.py line 113 3298914] Train: [2/100][2038/2402] Data 0.003 (0.004) Batch 0.493 (0.480) Remain 31:25:13 loss: 0.9607 Lr: 0.00074
[2025-04-08 14:27:52,007 INFO misc.py line 113 3298914] Train: [2/100][2039/2402] Data 0.003 (0.004) Batch 0.379 (0.480) Remain 31:25:01 loss: 1.5123 Lr: 0.00074
[2025-04-08 14:27:52,509 INFO misc.py line 113 3298914] Train: [2/100][2040/2402] Data 0.003 (0.004) Batch 0.502 (0.480) Remain 31:25:03 loss: 1.5475 Lr: 0.00074
[2025-04-08 14:27:52,929 INFO misc.py line 113 3298914] Train: [2/100][2041/2402] Data 0.004 (0.004) Batch 0.420 (0.480) Remain 31:24:55 loss: 1.4398 Lr: 0.00074
[2025-04-08 14:27:53,392 INFO misc.py line 113 3298914] Train: [2/100][2042/2402] Data 0.004 (0.004) Batch 0.463 (0.480) Remain 31:24:53 loss: 1.0901 Lr: 0.00074
[2025-04-08 14:27:54,002 INFO misc.py line 113 3298914] Train: [2/100][2043/2402] Data 0.003 (0.004) Batch 0.610 (0.480) Remain 31:25:07 loss: 1.2077 Lr: 0.00074
[2025-04-08 14:27:54,494 INFO misc.py line 113 3298914] Train: [2/100][2044/2402] Data 0.003 (0.004) Batch 0.492 (0.480) Remain 31:25:08 loss: 0.9788 Lr: 0.00074
[2025-04-08 14:27:54,992 INFO misc.py line 113 3298914] Train: [2/100][2045/2402] Data 0.003 (0.004) Batch 0.498 (0.480) Remain 31:25:10 loss: 1.0493 Lr: 0.00074
[2025-04-08 14:27:55,494 INFO misc.py line 113 3298914] Train: [2/100][2046/2402] Data 0.004 (0.004) Batch 0.501 (0.480) Remain 31:25:12 loss: 1.3119 Lr: 0.00074
[2025-04-08 14:27:55,935 INFO misc.py line 113 3298914] Train: [2/100][2047/2402] Data 0.004 (0.004) Batch 0.441 (0.480) Remain 31:25:07 loss: 1.4119 Lr: 0.00074
[2025-04-08 14:27:56,515 INFO misc.py line 113 3298914] Train: [2/100][2048/2402] Data 0.004 (0.004) Batch 0.581 (0.480) Remain 31:25:18 loss: 1.5426 Lr: 0.00074
[2025-04-08 14:27:57,085 INFO misc.py line 113 3298914] Train: [2/100][2049/2402] Data 0.003 (0.004) Batch 0.569 (0.480) Remain 31:25:28 loss: 1.4005 Lr: 0.00074
[2025-04-08 14:27:57,667 INFO misc.py line 113 3298914] Train: [2/100][2050/2402] Data 0.003 (0.004) Batch 0.582 (0.480) Remain 31:25:39 loss: 1.4017 Lr: 0.00074
[2025-04-08 14:27:58,178 INFO misc.py line 113 3298914] Train: [2/100][2051/2402] Data 0.004 (0.004) Batch 0.511 (0.480) Remain 31:25:42 loss: 1.1491 Lr: 0.00074
[2025-04-08 14:27:58,668 INFO misc.py line 113 3298914] Train: [2/100][2052/2402] Data 0.004 (0.004) Batch 0.490 (0.480) Remain 31:25:43 loss: 1.1573 Lr: 0.00074
[2025-04-08 14:27:59,130 INFO misc.py line 113 3298914] Train: [2/100][2053/2402] Data 0.004 (0.004) Batch 0.462 (0.480) Remain 31:25:41 loss: 1.4523 Lr: 0.00074
[2025-04-08 14:27:59,567 INFO misc.py line 113 3298914] Train: [2/100][2054/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:25:35 loss: 1.0896 Lr: 0.00074
[2025-04-08 14:28:00,081 INFO misc.py line 113 3298914] Train: [2/100][2055/2402] Data 0.004 (0.004) Batch 0.515 (0.480) Remain 31:25:39 loss: 1.2113 Lr: 0.00074
[2025-04-08 14:28:00,574 INFO misc.py line 113 3298914] Train: [2/100][2056/2402] Data 0.004 (0.004) Batch 0.493 (0.480) Remain 31:25:40 loss: 1.3621 Lr: 0.00074
[2025-04-08 14:28:01,054 INFO misc.py line 113 3298914] Train: [2/100][2057/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:25:39 loss: 1.3801 Lr: 0.00075
[2025-04-08 14:28:01,563 INFO misc.py line 113 3298914] Train: [2/100][2058/2402] Data 0.003 (0.004) Batch 0.508 (0.480) Remain 31:25:42 loss: 1.4190 Lr: 0.00075
[2025-04-08 14:28:02,138 INFO misc.py line 113 3298914] Train: [2/100][2059/2402] Data 0.004 (0.004) Batch 0.575 (0.480) Remain 31:25:52 loss: 1.6668 Lr: 0.00075
[2025-04-08 14:28:02,609 INFO misc.py line 113 3298914] Train: [2/100][2060/2402] Data 0.003 (0.004) Batch 0.470 (0.480) Remain 31:25:51 loss: 2.1581 Lr: 0.00075
[2025-04-08 14:28:03,142 INFO misc.py line 113 3298914] Train: [2/100][2061/2402] Data 0.004 (0.004) Batch 0.534 (0.480) Remain 31:25:57 loss: 1.5066 Lr: 0.00075
[2025-04-08 14:28:03,624 INFO misc.py line 113 3298914] Train: [2/100][2062/2402] Data 0.003 (0.004) Batch 0.481 (0.480) Remain 31:25:56 loss: 1.2276 Lr: 0.00075
[2025-04-08 14:28:04,036 INFO misc.py line 113 3298914] Train: [2/100][2063/2402] Data 0.003 (0.004) Batch 0.412 (0.480) Remain 31:25:48 loss: 1.3982 Lr: 0.00075
[2025-04-08 14:28:04,514 INFO misc.py line 113 3298914] Train: [2/100][2064/2402] Data 0.004 (0.004) Batch 0.478 (0.480) Remain 31:25:47 loss: 1.5360 Lr: 0.00075
[2025-04-08 14:28:05,007 INFO misc.py line 113 3298914] Train: [2/100][2065/2402] Data 0.004 (0.004) Batch 0.492 (0.480) Remain 31:25:48 loss: 1.1578 Lr: 0.00075
[2025-04-08 14:28:05,423 INFO misc.py line 113 3298914] Train: [2/100][2066/2402] Data 0.004 (0.004) Batch 0.417 (0.480) Remain 31:25:41 loss: 1.0265 Lr: 0.00075
[2025-04-08 14:28:05,929 INFO misc.py line 113 3298914] Train: [2/100][2067/2402] Data 0.003 (0.004) Batch 0.506 (0.480) Remain 31:25:43 loss: 0.9866 Lr: 0.00075
[2025-04-08 14:28:06,499 INFO misc.py line 113 3298914] Train: [2/100][2068/2402] Data 0.004 (0.004) Batch 0.569 (0.480) Remain 31:25:53 loss: 1.5851 Lr: 0.00075
[2025-04-08 14:28:06,946 INFO misc.py line 113 3298914] Train: [2/100][2069/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:25:49 loss: 1.1886 Lr: 0.00075
[2025-04-08 14:28:07,382 INFO misc.py line 113 3298914] Train: [2/100][2070/2402] Data 0.003 (0.004) Batch 0.436 (0.480) Remain 31:25:43 loss: 1.0276 Lr: 0.00075
[2025-04-08 14:28:07,824 INFO misc.py line 113 3298914] Train: [2/100][2071/2402] Data 0.003 (0.004) Batch 0.442 (0.480) Remain 31:25:38 loss: 1.1387 Lr: 0.00075
[2025-04-08 14:28:08,327 INFO misc.py line 113 3298914] Train: [2/100][2072/2402] Data 0.003 (0.004) Batch 0.504 (0.480) Remain 31:25:40 loss: 1.5257 Lr: 0.00075
[2025-04-08 14:28:08,800 INFO misc.py line 113 3298914] Train: [2/100][2073/2402] Data 0.004 (0.004) Batch 0.472 (0.480) Remain 31:25:39 loss: 1.1718 Lr: 0.00075
[2025-04-08 14:28:09,301 INFO misc.py line 113 3298914] Train: [2/100][2074/2402] Data 0.004 (0.004) Batch 0.502 (0.480) Remain 31:25:41 loss: 1.1960 Lr: 0.00075
[2025-04-08 14:28:09,795 INFO misc.py line 113 3298914] Train: [2/100][2075/2402] Data 0.004 (0.004) Batch 0.493 (0.480) Remain 31:25:42 loss: 1.5477 Lr: 0.00075
[2025-04-08 14:28:10,278 INFO misc.py line 113 3298914] Train: [2/100][2076/2402] Data 0.004 (0.004) Batch 0.484 (0.480) Remain 31:25:42 loss: 1.4038 Lr: 0.00075
[2025-04-08 14:28:10,799 INFO misc.py line 113 3298914] Train: [2/100][2077/2402] Data 0.003 (0.004) Batch 0.521 (0.480) Remain 31:25:46 loss: 1.4842 Lr: 0.00075
[2025-04-08 14:28:11,257 INFO misc.py line 113 3298914] Train: [2/100][2078/2402] Data 0.004 (0.004) Batch 0.458 (0.480) Remain 31:25:43 loss: 1.0470 Lr: 0.00075
[2025-04-08 14:28:11,711 INFO misc.py line 113 3298914] Train: [2/100][2079/2402] Data 0.004 (0.004) Batch 0.454 (0.480) Remain 31:25:40 loss: 1.4916 Lr: 0.00075
[2025-04-08 14:28:12,220 INFO misc.py line 113 3298914] Train: [2/100][2080/2402] Data 0.003 (0.004) Batch 0.509 (0.480) Remain 31:25:43 loss: 1.1390 Lr: 0.00075
[2025-04-08 14:28:12,728 INFO misc.py line 113 3298914] Train: [2/100][2081/2402] Data 0.004 (0.004) Batch 0.508 (0.480) Remain 31:25:45 loss: 1.3209 Lr: 0.00075
[2025-04-08 14:28:13,179 INFO misc.py line 113 3298914] Train: [2/100][2082/2402] Data 0.003 (0.004) Batch 0.451 (0.480) Remain 31:25:41 loss: 1.1223 Lr: 0.00075
[2025-04-08 14:28:13,603 INFO misc.py line 113 3298914] Train: [2/100][2083/2402] Data 0.004 (0.004) Batch 0.425 (0.480) Remain 31:25:35 loss: 1.0983 Lr: 0.00075
[2025-04-08 14:28:14,010 INFO misc.py line 113 3298914] Train: [2/100][2084/2402] Data 0.003 (0.004) Batch 0.407 (0.480) Remain 31:25:26 loss: 1.0899 Lr: 0.00075
[2025-04-08 14:28:14,322 INFO misc.py line 113 3298914] Train: [2/100][2085/2402] Data 0.003 (0.004) Batch 0.312 (0.480) Remain 31:25:06 loss: 1.3037 Lr: 0.00075
[2025-04-08 14:28:14,875 INFO misc.py line 113 3298914] Train: [2/100][2086/2402] Data 0.004 (0.004) Batch 0.553 (0.480) Remain 31:25:14 loss: 1.5436 Lr: 0.00075
[2025-04-08 14:28:15,381 INFO misc.py line 113 3298914] Train: [2/100][2087/2402] Data 0.003 (0.004) Batch 0.507 (0.480) Remain 31:25:17 loss: 0.7931 Lr: 0.00075
[2025-04-08 14:28:15,869 INFO misc.py line 113 3298914] Train: [2/100][2088/2402] Data 0.004 (0.004) Batch 0.487 (0.480) Remain 31:25:17 loss: 1.1301 Lr: 0.00075
[2025-04-08 14:28:16,312 INFO misc.py line 113 3298914] Train: [2/100][2089/2402] Data 0.004 (0.004) Batch 0.443 (0.480) Remain 31:25:12 loss: 1.2067 Lr: 0.00075
[2025-04-08 14:28:16,756 INFO misc.py line 113 3298914] Train: [2/100][2090/2402] Data 0.004 (0.004) Batch 0.445 (0.480) Remain 31:25:08 loss: 1.2479 Lr: 0.00075
[2025-04-08 14:28:17,158 INFO misc.py line 113 3298914] Train: [2/100][2091/2402] Data 0.004 (0.004) Batch 0.401 (0.480) Remain 31:24:59 loss: 1.1216 Lr: 0.00075
[2025-04-08 14:28:17,531 INFO misc.py line 113 3298914] Train: [2/100][2092/2402] Data 0.003 (0.004) Batch 0.374 (0.480) Remain 31:24:46 loss: 1.4426 Lr: 0.00075
[2025-04-08 14:28:18,089 INFO misc.py line 113 3298914] Train: [2/100][2093/2402] Data 0.003 (0.004) Batch 0.557 (0.480) Remain 31:24:54 loss: 0.9901 Lr: 0.00075
[2025-04-08 14:28:18,524 INFO misc.py line 113 3298914] Train: [2/100][2094/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:24:49 loss: 1.0565 Lr: 0.00075
[2025-04-08 14:28:18,990 INFO misc.py line 113 3298914] Train: [2/100][2095/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:24:47 loss: 1.1935 Lr: 0.00075
[2025-04-08 14:28:19,475 INFO misc.py line 113 3298914] Train: [2/100][2096/2402] Data 0.004 (0.004) Batch 0.485 (0.480) Remain 31:24:47 loss: 1.3966 Lr: 0.00075
[2025-04-08 14:28:19,994 INFO misc.py line 113 3298914] Train: [2/100][2097/2402] Data 0.004 (0.004) Batch 0.519 (0.480) Remain 31:24:51 loss: 1.4648 Lr: 0.00075
[2025-04-08 14:28:20,454 INFO misc.py line 113 3298914] Train: [2/100][2098/2402] Data 0.003 (0.004) Batch 0.460 (0.480) Remain 31:24:48 loss: 0.8345 Lr: 0.00075
[2025-04-08 14:28:20,921 INFO misc.py line 113 3298914] Train: [2/100][2099/2402] Data 0.004 (0.004) Batch 0.468 (0.480) Remain 31:24:46 loss: 1.2920 Lr: 0.00075
[2025-04-08 14:28:21,354 INFO misc.py line 113 3298914] Train: [2/100][2100/2402] Data 0.004 (0.004) Batch 0.433 (0.480) Remain 31:24:41 loss: 1.4369 Lr: 0.00075
[2025-04-08 14:28:21,798 INFO misc.py line 113 3298914] Train: [2/100][2101/2402] Data 0.004 (0.004) Batch 0.444 (0.480) Remain 31:24:36 loss: 1.1513 Lr: 0.00075
[2025-04-08 14:28:22,207 INFO misc.py line 113 3298914] Train: [2/100][2102/2402] Data 0.004 (0.004) Batch 0.410 (0.480) Remain 31:24:28 loss: 1.1273 Lr: 0.00075
[2025-04-08 14:28:22,688 INFO misc.py line 113 3298914] Train: [2/100][2103/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:24:27 loss: 1.3482 Lr: 0.00076
[2025-04-08 14:28:23,145 INFO misc.py line 113 3298914] Train: [2/100][2104/2402] Data 0.004 (0.004) Batch 0.458 (0.480) Remain 31:24:24 loss: 1.3893 Lr: 0.00076
[2025-04-08 14:28:23,517 INFO misc.py line 113 3298914] Train: [2/100][2105/2402] Data 0.003 (0.004) Batch 0.372 (0.480) Remain 31:24:12 loss: 1.1145 Lr: 0.00076
[2025-04-08 14:28:23,961 INFO misc.py line 113 3298914] Train: [2/100][2106/2402] Data 0.004 (0.004) Batch 0.444 (0.480) Remain 31:24:07 loss: 1.8957 Lr: 0.00076
[2025-04-08 14:28:24,522 INFO misc.py line 113 3298914] Train: [2/100][2107/2402] Data 0.016 (0.004) Batch 0.561 (0.480) Remain 31:24:16 loss: 1.1874 Lr: 0.00076
[2025-04-08 14:28:24,967 INFO misc.py line 113 3298914] Train: [2/100][2108/2402] Data 0.004 (0.004) Batch 0.445 (0.480) Remain 31:24:12 loss: 1.2504 Lr: 0.00076
[2025-04-08 14:28:25,414 INFO misc.py line 113 3298914] Train: [2/100][2109/2402] Data 0.004 (0.004) Batch 0.447 (0.480) Remain 31:24:07 loss: 0.9619 Lr: 0.00076
[2025-04-08 14:28:25,958 INFO misc.py line 113 3298914] Train: [2/100][2110/2402] Data 0.004 (0.004) Batch 0.544 (0.480) Remain 31:24:14 loss: 1.6868 Lr: 0.00076
[2025-04-08 14:28:26,438 INFO misc.py line 113 3298914] Train: [2/100][2111/2402] Data 0.004 (0.004) Batch 0.480 (0.480) Remain 31:24:14 loss: 1.3676 Lr: 0.00076
[2025-04-08 14:28:26,904 INFO misc.py line 113 3298914] Train: [2/100][2112/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:24:12 loss: 1.0005 Lr: 0.00076
[2025-04-08 14:28:27,270 INFO misc.py line 113 3298914] Train: [2/100][2113/2402] Data 0.003 (0.004) Batch 0.366 (0.480) Remain 31:23:58 loss: 1.1879 Lr: 0.00076
[2025-04-08 14:28:27,809 INFO misc.py line 113 3298914] Train: [2/100][2114/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:24:05 loss: 1.2141 Lr: 0.00076
[2025-04-08 14:28:28,410 INFO misc.py line 113 3298914] Train: [2/100][2115/2402] Data 0.003 (0.004) Batch 0.601 (0.480) Remain 31:24:18 loss: 1.2689 Lr: 0.00076
[2025-04-08 14:28:28,896 INFO misc.py line 113 3298914] Train: [2/100][2116/2402] Data 0.004 (0.004) Batch 0.485 (0.480) Remain 31:24:18 loss: 1.2448 Lr: 0.00076
[2025-04-08 14:28:29,344 INFO misc.py line 113 3298914] Train: [2/100][2117/2402] Data 0.003 (0.004) Batch 0.448 (0.480) Remain 31:24:14 loss: 1.1008 Lr: 0.00076
[2025-04-08 14:28:29,811 INFO misc.py line 113 3298914] Train: [2/100][2118/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:24:12 loss: 1.2254 Lr: 0.00076
[2025-04-08 14:28:30,359 INFO misc.py line 113 3298914] Train: [2/100][2119/2402] Data 0.004 (0.004) Batch 0.549 (0.480) Remain 31:24:19 loss: 0.9941 Lr: 0.00076
[2025-04-08 14:28:30,905 INFO misc.py line 113 3298914] Train: [2/100][2120/2402] Data 0.003 (0.004) Batch 0.546 (0.480) Remain 31:24:26 loss: 1.2598 Lr: 0.00076
[2025-04-08 14:28:31,464 INFO misc.py line 113 3298914] Train: [2/100][2121/2402] Data 0.004 (0.004) Batch 0.559 (0.480) Remain 31:24:34 loss: 1.1934 Lr: 0.00076
[2025-04-08 14:28:31,976 INFO misc.py line 113 3298914] Train: [2/100][2122/2402] Data 0.004 (0.004) Batch 0.512 (0.480) Remain 31:24:38 loss: 1.0989 Lr: 0.00076
[2025-04-08 14:28:32,422 INFO misc.py line 113 3298914] Train: [2/100][2123/2402] Data 0.004 (0.004) Batch 0.446 (0.480) Remain 31:24:33 loss: 1.2709 Lr: 0.00076
[2025-04-08 14:28:32,916 INFO misc.py line 113 3298914] Train: [2/100][2124/2402] Data 0.003 (0.004) Batch 0.494 (0.480) Remain 31:24:34 loss: 1.3641 Lr: 0.00076
[2025-04-08 14:28:33,350 INFO misc.py line 113 3298914] Train: [2/100][2125/2402] Data 0.003 (0.004) Batch 0.434 (0.480) Remain 31:24:29 loss: 1.4415 Lr: 0.00076
[2025-04-08 14:28:33,867 INFO misc.py line 113 3298914] Train: [2/100][2126/2402] Data 0.004 (0.004) Batch 0.518 (0.480) Remain 31:24:32 loss: 0.9195 Lr: 0.00076
[2025-04-08 14:28:34,326 INFO misc.py line 113 3298914] Train: [2/100][2127/2402] Data 0.003 (0.004) Batch 0.459 (0.480) Remain 31:24:30 loss: 0.9632 Lr: 0.00076
[2025-04-08 14:28:34,806 INFO misc.py line 113 3298914] Train: [2/100][2128/2402] Data 0.004 (0.004) Batch 0.480 (0.480) Remain 31:24:29 loss: 1.1229 Lr: 0.00076
[2025-04-08 14:28:35,364 INFO misc.py line 113 3298914] Train: [2/100][2129/2402] Data 0.004 (0.004) Batch 0.558 (0.480) Remain 31:24:37 loss: 1.0032 Lr: 0.00076
[2025-04-08 14:28:35,912 INFO misc.py line 113 3298914] Train: [2/100][2130/2402] Data 0.003 (0.004) Batch 0.548 (0.480) Remain 31:24:45 loss: 1.2456 Lr: 0.00076
[2025-04-08 14:28:36,339 INFO misc.py line 113 3298914] Train: [2/100][2131/2402] Data 0.004 (0.004) Batch 0.427 (0.480) Remain 31:24:38 loss: 1.4194 Lr: 0.00076
[2025-04-08 14:28:36,875 INFO misc.py line 113 3298914] Train: [2/100][2132/2402] Data 0.003 (0.004) Batch 0.536 (0.480) Remain 31:24:44 loss: 1.4393 Lr: 0.00076
[2025-04-08 14:28:37,330 INFO misc.py line 113 3298914] Train: [2/100][2133/2402] Data 0.003 (0.004) Batch 0.455 (0.480) Remain 31:24:41 loss: 1.0159 Lr: 0.00076
[2025-04-08 14:28:37,744 INFO misc.py line 113 3298914] Train: [2/100][2134/2402] Data 0.004 (0.004) Batch 0.414 (0.480) Remain 31:24:33 loss: 1.3110 Lr: 0.00076
[2025-04-08 14:28:38,070 INFO misc.py line 113 3298914] Train: [2/100][2135/2402] Data 0.003 (0.004) Batch 0.326 (0.480) Remain 31:24:15 loss: 1.0520 Lr: 0.00076
[2025-04-08 14:28:38,564 INFO misc.py line 113 3298914] Train: [2/100][2136/2402] Data 0.003 (0.004) Batch 0.494 (0.480) Remain 31:24:17 loss: 1.0727 Lr: 0.00076
[2025-04-08 14:28:39,110 INFO misc.py line 113 3298914] Train: [2/100][2137/2402] Data 0.003 (0.004) Batch 0.546 (0.480) Remain 31:24:23 loss: 1.1730 Lr: 0.00076
[2025-04-08 14:28:39,484 INFO misc.py line 113 3298914] Train: [2/100][2138/2402] Data 0.003 (0.004) Batch 0.375 (0.480) Remain 31:24:11 loss: 0.7103 Lr: 0.00076
[2025-04-08 14:28:40,052 INFO misc.py line 113 3298914] Train: [2/100][2139/2402] Data 0.003 (0.004) Batch 0.568 (0.480) Remain 31:24:20 loss: 1.2668 Lr: 0.00076
[2025-04-08 14:28:40,541 INFO misc.py line 113 3298914] Train: [2/100][2140/2402] Data 0.004 (0.004) Batch 0.489 (0.480) Remain 31:24:21 loss: 1.0288 Lr: 0.00076
[2025-04-08 14:28:41,110 INFO misc.py line 113 3298914] Train: [2/100][2141/2402] Data 0.003 (0.004) Batch 0.569 (0.480) Remain 31:24:30 loss: 1.3797 Lr: 0.00076
[2025-04-08 14:28:41,610 INFO misc.py line 113 3298914] Train: [2/100][2142/2402] Data 0.004 (0.004) Batch 0.500 (0.480) Remain 31:24:32 loss: 1.3822 Lr: 0.00076
[2025-04-08 14:28:42,181 INFO misc.py line 113 3298914] Train: [2/100][2143/2402] Data 0.003 (0.004) Batch 0.571 (0.480) Remain 31:24:42 loss: 1.2427 Lr: 0.00076
[2025-04-08 14:28:42,536 INFO misc.py line 113 3298914] Train: [2/100][2144/2402] Data 0.004 (0.004) Batch 0.355 (0.480) Remain 31:24:27 loss: 1.2163 Lr: 0.00076
[2025-04-08 14:28:42,890 INFO misc.py line 113 3298914] Train: [2/100][2145/2402] Data 0.004 (0.004) Batch 0.355 (0.480) Remain 31:24:13 loss: 1.1875 Lr: 0.00076
[2025-04-08 14:28:43,330 INFO misc.py line 113 3298914] Train: [2/100][2146/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:24:08 loss: 1.0913 Lr: 0.00076
[2025-04-08 14:28:43,918 INFO misc.py line 113 3298914] Train: [2/100][2147/2402] Data 0.003 (0.004) Batch 0.588 (0.480) Remain 31:24:20 loss: 1.4547 Lr: 0.00076
[2025-04-08 14:28:44,329 INFO misc.py line 113 3298914] Train: [2/100][2148/2402] Data 0.004 (0.004) Batch 0.411 (0.480) Remain 31:24:12 loss: 0.7892 Lr: 0.00076
[2025-04-08 14:28:44,737 INFO misc.py line 113 3298914] Train: [2/100][2149/2402] Data 0.003 (0.004) Batch 0.408 (0.480) Remain 31:24:03 loss: 1.3942 Lr: 0.00077
[2025-04-08 14:28:45,217 INFO misc.py line 113 3298914] Train: [2/100][2150/2402] Data 0.004 (0.004) Batch 0.479 (0.480) Remain 31:24:03 loss: 1.8016 Lr: 0.00077
[2025-04-08 14:28:45,692 INFO misc.py line 113 3298914] Train: [2/100][2151/2402] Data 0.004 (0.004) Batch 0.475 (0.480) Remain 31:24:02 loss: 1.0636 Lr: 0.00077
[2025-04-08 14:28:46,227 INFO misc.py line 113 3298914] Train: [2/100][2152/2402] Data 0.003 (0.004) Batch 0.536 (0.480) Remain 31:24:07 loss: 1.2980 Lr: 0.00077
[2025-04-08 14:28:46,526 INFO misc.py line 113 3298914] Train: [2/100][2153/2402] Data 0.004 (0.004) Batch 0.299 (0.480) Remain 31:23:47 loss: 1.0981 Lr: 0.00077
[2025-04-08 14:28:47,064 INFO misc.py line 113 3298914] Train: [2/100][2154/2402] Data 0.004 (0.004) Batch 0.538 (0.480) Remain 31:23:53 loss: 1.4431 Lr: 0.00077
[2025-04-08 14:28:47,635 INFO misc.py line 113 3298914] Train: [2/100][2155/2402] Data 0.003 (0.004) Batch 0.572 (0.480) Remain 31:24:03 loss: 1.2202 Lr: 0.00077
[2025-04-08 14:28:48,166 INFO misc.py line 113 3298914] Train: [2/100][2156/2402] Data 0.004 (0.004) Batch 0.531 (0.480) Remain 31:24:08 loss: 1.4039 Lr: 0.00077
[2025-04-08 14:28:48,624 INFO misc.py line 113 3298914] Train: [2/100][2157/2402] Data 0.004 (0.004) Batch 0.457 (0.480) Remain 31:24:05 loss: 1.4034 Lr: 0.00077
[2025-04-08 14:28:49,112 INFO misc.py line 113 3298914] Train: [2/100][2158/2402] Data 0.004 (0.004) Batch 0.488 (0.480) Remain 31:24:05 loss: 1.3418 Lr: 0.00077
[2025-04-08 14:28:49,566 INFO misc.py line 113 3298914] Train: [2/100][2159/2402] Data 0.004 (0.004) Batch 0.454 (0.480) Remain 31:24:02 loss: 1.2444 Lr: 0.00077
[2025-04-08 14:28:50,116 INFO misc.py line 113 3298914] Train: [2/100][2160/2402] Data 0.003 (0.004) Batch 0.550 (0.480) Remain 31:24:09 loss: 1.4232 Lr: 0.00077
[2025-04-08 14:28:50,551 INFO misc.py line 113 3298914] Train: [2/100][2161/2402] Data 0.004 (0.004) Batch 0.435 (0.480) Remain 31:24:04 loss: 1.0939 Lr: 0.00077
[2025-04-08 14:28:51,058 INFO misc.py line 113 3298914] Train: [2/100][2162/2402] Data 0.003 (0.004) Batch 0.507 (0.480) Remain 31:24:06 loss: 1.3215 Lr: 0.00077
[2025-04-08 14:28:51,650 INFO misc.py line 113 3298914] Train: [2/100][2163/2402] Data 0.003 (0.004) Batch 0.592 (0.480) Remain 31:24:18 loss: 1.3151 Lr: 0.00077
[2025-04-08 14:28:52,217 INFO misc.py line 113 3298914] Train: [2/100][2164/2402] Data 0.004 (0.004) Batch 0.567 (0.480) Remain 31:24:27 loss: 1.2862 Lr: 0.00077
[2025-04-08 14:28:52,777 INFO misc.py line 113 3298914] Train: [2/100][2165/2402] Data 0.003 (0.004) Batch 0.560 (0.480) Remain 31:24:35 loss: 1.4096 Lr: 0.00077
[2025-04-08 14:28:53,188 INFO misc.py line 113 3298914] Train: [2/100][2166/2402] Data 0.004 (0.004) Batch 0.411 (0.480) Remain 31:24:27 loss: 1.1963 Lr: 0.00077
[2025-04-08 14:28:53,633 INFO misc.py line 113 3298914] Train: [2/100][2167/2402] Data 0.003 (0.004) Batch 0.444 (0.480) Remain 31:24:23 loss: 1.2738 Lr: 0.00077
[2025-04-08 14:28:54,123 INFO misc.py line 113 3298914] Train: [2/100][2168/2402] Data 0.003 (0.004) Batch 0.490 (0.480) Remain 31:24:24 loss: 1.5941 Lr: 0.00077
[2025-04-08 14:28:54,679 INFO misc.py line 113 3298914] Train: [2/100][2169/2402] Data 0.004 (0.004) Batch 0.555 (0.480) Remain 31:24:31 loss: 1.4068 Lr: 0.00077
[2025-04-08 14:28:55,140 INFO misc.py line 113 3298914] Train: [2/100][2170/2402] Data 0.003 (0.004) Batch 0.462 (0.480) Remain 31:24:29 loss: 1.2751 Lr: 0.00077
[2025-04-08 14:28:55,557 INFO misc.py line 113 3298914] Train: [2/100][2171/2402] Data 0.003 (0.004) Batch 0.416 (0.480) Remain 31:24:22 loss: 1.0113 Lr: 0.00077
[2025-04-08 14:28:56,086 INFO misc.py line 113 3298914] Train: [2/100][2172/2402] Data 0.003 (0.004) Batch 0.529 (0.480) Remain 31:24:27 loss: 1.4987 Lr: 0.00077
[2025-04-08 14:28:56,588 INFO misc.py line 113 3298914] Train: [2/100][2173/2402] Data 0.003 (0.004) Batch 0.502 (0.480) Remain 31:24:28 loss: 1.3944 Lr: 0.00077
[2025-04-08 14:28:57,129 INFO misc.py line 113 3298914] Train: [2/100][2174/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:24:35 loss: 1.5190 Lr: 0.00077
[2025-04-08 14:28:57,637 INFO misc.py line 113 3298914] Train: [2/100][2175/2402] Data 0.003 (0.004) Batch 0.508 (0.480) Remain 31:24:37 loss: 1.2966 Lr: 0.00077
[2025-04-08 14:28:58,149 INFO misc.py line 113 3298914] Train: [2/100][2176/2402] Data 0.004 (0.004) Batch 0.512 (0.480) Remain 31:24:40 loss: 1.6152 Lr: 0.00077
[2025-04-08 14:28:58,589 INFO misc.py line 113 3298914] Train: [2/100][2177/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:24:35 loss: 1.4186 Lr: 0.00077
[2025-04-08 14:28:58,915 INFO misc.py line 113 3298914] Train: [2/100][2178/2402] Data 0.003 (0.004) Batch 0.326 (0.480) Remain 31:24:18 loss: 1.8563 Lr: 0.00077
[2025-04-08 14:28:59,345 INFO misc.py line 113 3298914] Train: [2/100][2179/2402] Data 0.004 (0.004) Batch 0.430 (0.480) Remain 31:24:12 loss: 1.3941 Lr: 0.00077
[2025-04-08 14:28:59,902 INFO misc.py line 113 3298914] Train: [2/100][2180/2402] Data 0.003 (0.004) Batch 0.556 (0.480) Remain 31:24:20 loss: 1.1755 Lr: 0.00077
[2025-04-08 14:29:00,420 INFO misc.py line 113 3298914] Train: [2/100][2181/2402] Data 0.003 (0.004) Batch 0.518 (0.480) Remain 31:24:24 loss: 1.4126 Lr: 0.00077
[2025-04-08 14:29:00,948 INFO misc.py line 113 3298914] Train: [2/100][2182/2402] Data 0.004 (0.004) Batch 0.528 (0.480) Remain 31:24:29 loss: 1.4465 Lr: 0.00077
[2025-04-08 14:29:01,379 INFO misc.py line 113 3298914] Train: [2/100][2183/2402] Data 0.004 (0.004) Batch 0.431 (0.480) Remain 31:24:23 loss: 1.1833 Lr: 0.00077
[2025-04-08 14:29:01,769 INFO misc.py line 113 3298914] Train: [2/100][2184/2402] Data 0.003 (0.004) Batch 0.390 (0.480) Remain 31:24:13 loss: 1.1620 Lr: 0.00077
[2025-04-08 14:29:02,256 INFO misc.py line 113 3298914] Train: [2/100][2185/2402] Data 0.004 (0.004) Batch 0.487 (0.480) Remain 31:24:13 loss: 1.0753 Lr: 0.00077
[2025-04-08 14:29:02,714 INFO misc.py line 113 3298914] Train: [2/100][2186/2402] Data 0.003 (0.004) Batch 0.458 (0.480) Remain 31:24:10 loss: 1.4831 Lr: 0.00077
[2025-04-08 14:29:03,085 INFO misc.py line 113 3298914] Train: [2/100][2187/2402] Data 0.003 (0.004) Batch 0.371 (0.480) Remain 31:23:58 loss: 1.5169 Lr: 0.00077
[2025-04-08 14:29:03,478 INFO misc.py line 113 3298914] Train: [2/100][2188/2402] Data 0.003 (0.004) Batch 0.393 (0.480) Remain 31:23:48 loss: 1.0931 Lr: 0.00077
[2025-04-08 14:29:03,987 INFO misc.py line 113 3298914] Train: [2/100][2189/2402] Data 0.003 (0.004) Batch 0.509 (0.480) Remain 31:23:51 loss: 0.9335 Lr: 0.00077
[2025-04-08 14:29:04,460 INFO misc.py line 113 3298914] Train: [2/100][2190/2402] Data 0.003 (0.004) Batch 0.473 (0.480) Remain 31:23:49 loss: 1.4940 Lr: 0.00077
[2025-04-08 14:29:04,935 INFO misc.py line 113 3298914] Train: [2/100][2191/2402] Data 0.004 (0.004) Batch 0.475 (0.480) Remain 31:23:48 loss: 1.4326 Lr: 0.00077
[2025-04-08 14:29:05,393 INFO misc.py line 113 3298914] Train: [2/100][2192/2402] Data 0.003 (0.004) Batch 0.458 (0.480) Remain 31:23:46 loss: 1.4773 Lr: 0.00077
[2025-04-08 14:29:05,880 INFO misc.py line 113 3298914] Train: [2/100][2193/2402] Data 0.003 (0.004) Batch 0.487 (0.480) Remain 31:23:46 loss: 1.1793 Lr: 0.00077
[2025-04-08 14:29:06,405 INFO misc.py line 113 3298914] Train: [2/100][2194/2402] Data 0.004 (0.004) Batch 0.525 (0.480) Remain 31:23:50 loss: 1.6466 Lr: 0.00077
[2025-04-08 14:29:06,890 INFO misc.py line 113 3298914] Train: [2/100][2195/2402] Data 0.003 (0.004) Batch 0.484 (0.480) Remain 31:23:50 loss: 1.2848 Lr: 0.00078
[2025-04-08 14:29:07,331 INFO misc.py line 113 3298914] Train: [2/100][2196/2402] Data 0.004 (0.004) Batch 0.441 (0.480) Remain 31:23:46 loss: 1.0428 Lr: 0.00078
[2025-04-08 14:29:07,819 INFO misc.py line 113 3298914] Train: [2/100][2197/2402] Data 0.003 (0.004) Batch 0.487 (0.480) Remain 31:23:46 loss: 1.3272 Lr: 0.00078
[2025-04-08 14:29:08,208 INFO misc.py line 113 3298914] Train: [2/100][2198/2402] Data 0.004 (0.004) Batch 0.389 (0.480) Remain 31:23:36 loss: 1.2164 Lr: 0.00078
[2025-04-08 14:29:08,644 INFO misc.py line 113 3298914] Train: [2/100][2199/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:23:31 loss: 1.2936 Lr: 0.00078
[2025-04-08 14:29:08,998 INFO misc.py line 113 3298914] Train: [2/100][2200/2402] Data 0.004 (0.004) Batch 0.355 (0.480) Remain 31:23:17 loss: 1.3455 Lr: 0.00078
[2025-04-08 14:29:09,510 INFO misc.py line 113 3298914] Train: [2/100][2201/2402] Data 0.004 (0.004) Batch 0.512 (0.480) Remain 31:23:20 loss: 1.6261 Lr: 0.00078
[2025-04-08 14:29:09,935 INFO misc.py line 113 3298914] Train: [2/100][2202/2402] Data 0.004 (0.004) Batch 0.425 (0.480) Remain 31:23:14 loss: 1.1542 Lr: 0.00078
[2025-04-08 14:29:10,388 INFO misc.py line 113 3298914] Train: [2/100][2203/2402] Data 0.003 (0.004) Batch 0.453 (0.480) Remain 31:23:10 loss: 1.2866 Lr: 0.00078
[2025-04-08 14:29:10,865 INFO misc.py line 113 3298914] Train: [2/100][2204/2402] Data 0.003 (0.004) Batch 0.477 (0.480) Remain 31:23:09 loss: 1.3343 Lr: 0.00078
[2025-04-08 14:29:11,443 INFO misc.py line 113 3298914] Train: [2/100][2205/2402] Data 0.003 (0.004) Batch 0.578 (0.480) Remain 31:23:19 loss: 1.3955 Lr: 0.00078
[2025-04-08 14:29:11,982 INFO misc.py line 113 3298914] Train: [2/100][2206/2402] Data 0.003 (0.004) Batch 0.539 (0.480) Remain 31:23:25 loss: 1.3000 Lr: 0.00078
[2025-04-08 14:29:12,474 INFO misc.py line 113 3298914] Train: [2/100][2207/2402] Data 0.004 (0.004) Batch 0.492 (0.480) Remain 31:23:26 loss: 1.4697 Lr: 0.00078
[2025-04-08 14:29:12,966 INFO misc.py line 113 3298914] Train: [2/100][2208/2402] Data 0.003 (0.004) Batch 0.491 (0.480) Remain 31:23:27 loss: 1.3839 Lr: 0.00078
[2025-04-08 14:29:13,432 INFO misc.py line 113 3298914] Train: [2/100][2209/2402] Data 0.003 (0.004) Batch 0.467 (0.480) Remain 31:23:25 loss: 1.4842 Lr: 0.00078
[2025-04-08 14:29:13,937 INFO misc.py line 113 3298914] Train: [2/100][2210/2402] Data 0.003 (0.004) Batch 0.504 (0.480) Remain 31:23:27 loss: 1.4091 Lr: 0.00078
[2025-04-08 14:29:14,477 INFO misc.py line 113 3298914] Train: [2/100][2211/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:23:33 loss: 1.3147 Lr: 0.00078
[2025-04-08 14:29:14,987 INFO misc.py line 113 3298914] Train: [2/100][2212/2402] Data 0.003 (0.004) Batch 0.510 (0.480) Remain 31:23:36 loss: 1.2379 Lr: 0.00078
[2025-04-08 14:29:15,588 INFO misc.py line 113 3298914] Train: [2/100][2213/2402] Data 0.003 (0.004) Batch 0.601 (0.480) Remain 31:23:48 loss: 1.3772 Lr: 0.00078
[2025-04-08 14:29:16,180 INFO misc.py line 113 3298914] Train: [2/100][2214/2402] Data 0.004 (0.004) Batch 0.592 (0.480) Remain 31:24:00 loss: 1.3155 Lr: 0.00078
[2025-04-08 14:29:16,615 INFO misc.py line 113 3298914] Train: [2/100][2215/2402] Data 0.003 (0.004) Batch 0.436 (0.480) Remain 31:23:55 loss: 1.5970 Lr: 0.00078
[2025-04-08 14:29:17,074 INFO misc.py line 113 3298914] Train: [2/100][2216/2402] Data 0.003 (0.004) Batch 0.458 (0.480) Remain 31:23:52 loss: 1.1643 Lr: 0.00078
[2025-04-08 14:29:17,591 INFO misc.py line 113 3298914] Train: [2/100][2217/2402] Data 0.003 (0.004) Batch 0.517 (0.480) Remain 31:23:55 loss: 1.3487 Lr: 0.00078
[2025-04-08 14:29:17,979 INFO misc.py line 113 3298914] Train: [2/100][2218/2402] Data 0.004 (0.004) Batch 0.388 (0.480) Remain 31:23:45 loss: 1.5041 Lr: 0.00078
[2025-04-08 14:29:18,412 INFO misc.py line 113 3298914] Train: [2/100][2219/2402] Data 0.004 (0.004) Batch 0.433 (0.480) Remain 31:23:40 loss: 1.2723 Lr: 0.00078
[2025-04-08 14:29:18,975 INFO misc.py line 113 3298914] Train: [2/100][2220/2402] Data 0.003 (0.004) Batch 0.563 (0.480) Remain 31:23:48 loss: 1.3469 Lr: 0.00078
[2025-04-08 14:29:19,590 INFO misc.py line 113 3298914] Train: [2/100][2221/2402] Data 0.003 (0.004) Batch 0.615 (0.480) Remain 31:24:02 loss: 1.1532 Lr: 0.00078
[2025-04-08 14:29:20,033 INFO misc.py line 113 3298914] Train: [2/100][2222/2402] Data 0.004 (0.004) Batch 0.443 (0.480) Remain 31:23:58 loss: 2.2102 Lr: 0.00078
[2025-04-08 14:29:20,498 INFO misc.py line 113 3298914] Train: [2/100][2223/2402] Data 0.003 (0.004) Batch 0.465 (0.480) Remain 31:23:56 loss: 0.9407 Lr: 0.00078
[2025-04-08 14:29:20,916 INFO misc.py line 113 3298914] Train: [2/100][2224/2402] Data 0.003 (0.004) Batch 0.419 (0.480) Remain 31:23:49 loss: 1.0422 Lr: 0.00078
[2025-04-08 14:29:21,326 INFO misc.py line 113 3298914] Train: [2/100][2225/2402] Data 0.003 (0.004) Batch 0.410 (0.480) Remain 31:23:41 loss: 1.3717 Lr: 0.00078
[2025-04-08 14:29:21,845 INFO misc.py line 113 3298914] Train: [2/100][2226/2402] Data 0.003 (0.004) Batch 0.519 (0.480) Remain 31:23:44 loss: 1.3967 Lr: 0.00078
[2025-04-08 14:29:22,360 INFO misc.py line 113 3298914] Train: [2/100][2227/2402] Data 0.004 (0.004) Batch 0.515 (0.480) Remain 31:23:48 loss: 1.3112 Lr: 0.00078
[2025-04-08 14:29:22,953 INFO misc.py line 113 3298914] Train: [2/100][2228/2402] Data 0.004 (0.004) Batch 0.593 (0.480) Remain 31:23:59 loss: 1.2495 Lr: 0.00078
[2025-04-08 14:29:23,418 INFO misc.py line 113 3298914] Train: [2/100][2229/2402] Data 0.003 (0.004) Batch 0.465 (0.480) Remain 31:23:57 loss: 1.4872 Lr: 0.00078
[2025-04-08 14:29:23,954 INFO misc.py line 113 3298914] Train: [2/100][2230/2402] Data 0.004 (0.004) Batch 0.536 (0.480) Remain 31:24:03 loss: 1.3693 Lr: 0.00078
[2025-04-08 14:29:24,394 INFO misc.py line 113 3298914] Train: [2/100][2231/2402] Data 0.003 (0.004) Batch 0.439 (0.480) Remain 31:23:58 loss: 1.0607 Lr: 0.00078
[2025-04-08 14:29:24,928 INFO misc.py line 113 3298914] Train: [2/100][2232/2402] Data 0.004 (0.004) Batch 0.534 (0.480) Remain 31:24:03 loss: 1.3928 Lr: 0.00078
[2025-04-08 14:29:25,439 INFO misc.py line 113 3298914] Train: [2/100][2233/2402] Data 0.004 (0.004) Batch 0.511 (0.480) Remain 31:24:06 loss: 1.6157 Lr: 0.00078
[2025-04-08 14:29:25,963 INFO misc.py line 113 3298914] Train: [2/100][2234/2402] Data 0.003 (0.004) Batch 0.524 (0.480) Remain 31:24:10 loss: 1.1170 Lr: 0.00078
[2025-04-08 14:29:26,487 INFO misc.py line 113 3298914] Train: [2/100][2235/2402] Data 0.004 (0.004) Batch 0.524 (0.480) Remain 31:24:14 loss: 0.9293 Lr: 0.00078
[2025-04-08 14:29:27,044 INFO misc.py line 113 3298914] Train: [2/100][2236/2402] Data 0.003 (0.004) Batch 0.557 (0.480) Remain 31:24:22 loss: 1.2382 Lr: 0.00078
[2025-04-08 14:29:27,530 INFO misc.py line 113 3298914] Train: [2/100][2237/2402] Data 0.004 (0.004) Batch 0.486 (0.480) Remain 31:24:22 loss: 1.2681 Lr: 0.00078
[2025-04-08 14:29:27,980 INFO misc.py line 113 3298914] Train: [2/100][2238/2402] Data 0.003 (0.004) Batch 0.450 (0.480) Remain 31:24:18 loss: 0.8618 Lr: 0.00078
[2025-04-08 14:29:28,495 INFO misc.py line 113 3298914] Train: [2/100][2239/2402] Data 0.004 (0.004) Batch 0.516 (0.480) Remain 31:24:22 loss: 1.2875 Lr: 0.00078
[2025-04-08 14:29:28,992 INFO misc.py line 113 3298914] Train: [2/100][2240/2402] Data 0.004 (0.004) Batch 0.497 (0.480) Remain 31:24:23 loss: 1.2389 Lr: 0.00079
[2025-04-08 14:29:29,509 INFO misc.py line 113 3298914] Train: [2/100][2241/2402] Data 0.003 (0.004) Batch 0.516 (0.480) Remain 31:24:26 loss: 1.2579 Lr: 0.00079
[2025-04-08 14:29:30,071 INFO misc.py line 113 3298914] Train: [2/100][2242/2402] Data 0.003 (0.004) Batch 0.562 (0.480) Remain 31:24:34 loss: 1.2269 Lr: 0.00079
[2025-04-08 14:29:30,497 INFO misc.py line 113 3298914] Train: [2/100][2243/2402] Data 0.004 (0.004) Batch 0.427 (0.480) Remain 31:24:28 loss: 1.1961 Lr: 0.00079
[2025-04-08 14:29:30,929 INFO misc.py line 113 3298914] Train: [2/100][2244/2402] Data 0.003 (0.004) Batch 0.432 (0.480) Remain 31:24:23 loss: 1.3526 Lr: 0.00079
[2025-04-08 14:29:31,470 INFO misc.py line 113 3298914] Train: [2/100][2245/2402] Data 0.003 (0.004) Batch 0.540 (0.480) Remain 31:24:29 loss: 1.0966 Lr: 0.00079
[2025-04-08 14:29:32,003 INFO misc.py line 113 3298914] Train: [2/100][2246/2402] Data 0.004 (0.004) Batch 0.534 (0.480) Remain 31:24:34 loss: 1.3194 Lr: 0.00079
[2025-04-08 14:29:32,463 INFO misc.py line 113 3298914] Train: [2/100][2247/2402] Data 0.004 (0.004) Batch 0.459 (0.480) Remain 31:24:31 loss: 1.1090 Lr: 0.00079
[2025-04-08 14:29:33,024 INFO misc.py line 113 3298914] Train: [2/100][2248/2402] Data 0.003 (0.004) Batch 0.562 (0.480) Remain 31:24:39 loss: 1.4223 Lr: 0.00079
[2025-04-08 14:29:33,422 INFO misc.py line 113 3298914] Train: [2/100][2249/2402] Data 0.004 (0.004) Batch 0.398 (0.480) Remain 31:24:30 loss: 1.1509 Lr: 0.00079
[2025-04-08 14:29:33,881 INFO misc.py line 113 3298914] Train: [2/100][2250/2402] Data 0.003 (0.004) Batch 0.459 (0.480) Remain 31:24:27 loss: 1.4069 Lr: 0.00079
[2025-04-08 14:29:34,272 INFO misc.py line 113 3298914] Train: [2/100][2251/2402] Data 0.003 (0.004) Batch 0.391 (0.480) Remain 31:24:18 loss: 1.4958 Lr: 0.00079
[2025-04-08 14:29:34,786 INFO misc.py line 113 3298914] Train: [2/100][2252/2402] Data 0.003 (0.004) Batch 0.513 (0.480) Remain 31:24:21 loss: 1.1971 Lr: 0.00079
[2025-04-08 14:29:35,325 INFO misc.py line 113 3298914] Train: [2/100][2253/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:24:26 loss: 1.1441 Lr: 0.00079
[2025-04-08 14:29:35,738 INFO misc.py line 113 3298914] Train: [2/100][2254/2402] Data 0.003 (0.004) Batch 0.412 (0.480) Remain 31:24:19 loss: 1.2966 Lr: 0.00079
[2025-04-08 14:29:36,301 INFO misc.py line 113 3298914] Train: [2/100][2255/2402] Data 0.003 (0.004) Batch 0.563 (0.480) Remain 31:24:27 loss: 1.2254 Lr: 0.00079
[2025-04-08 14:29:36,733 INFO misc.py line 113 3298914] Train: [2/100][2256/2402] Data 0.004 (0.004) Batch 0.432 (0.480) Remain 31:24:22 loss: 0.9171 Lr: 0.00079
[2025-04-08 14:29:37,095 INFO misc.py line 113 3298914] Train: [2/100][2257/2402] Data 0.003 (0.004) Batch 0.362 (0.480) Remain 31:24:09 loss: 1.6740 Lr: 0.00079
[2025-04-08 14:29:37,638 INFO misc.py line 113 3298914] Train: [2/100][2258/2402] Data 0.003 (0.004) Batch 0.542 (0.480) Remain 31:24:15 loss: 1.6392 Lr: 0.00079
[2025-04-08 14:29:38,145 INFO misc.py line 113 3298914] Train: [2/100][2259/2402] Data 0.004 (0.004) Batch 0.508 (0.480) Remain 31:24:17 loss: 1.2485 Lr: 0.00079
[2025-04-08 14:29:38,687 INFO misc.py line 113 3298914] Train: [2/100][2260/2402] Data 0.004 (0.004) Batch 0.541 (0.480) Remain 31:24:23 loss: 1.4208 Lr: 0.00079
[2025-04-08 14:29:39,123 INFO misc.py line 113 3298914] Train: [2/100][2261/2402] Data 0.004 (0.004) Batch 0.436 (0.480) Remain 31:24:18 loss: 0.9561 Lr: 0.00079
[2025-04-08 14:29:39,569 INFO misc.py line 113 3298914] Train: [2/100][2262/2402] Data 0.004 (0.004) Batch 0.446 (0.480) Remain 31:24:14 loss: 0.9582 Lr: 0.00079
[2025-04-08 14:29:39,947 INFO misc.py line 113 3298914] Train: [2/100][2263/2402] Data 0.004 (0.004) Batch 0.378 (0.480) Remain 31:24:03 loss: 0.9367 Lr: 0.00079
[2025-04-08 14:29:40,468 INFO misc.py line 113 3298914] Train: [2/100][2264/2402] Data 0.004 (0.004) Batch 0.521 (0.480) Remain 31:24:07 loss: 1.0672 Lr: 0.00079
[2025-04-08 14:29:41,129 INFO misc.py line 113 3298914] Train: [2/100][2265/2402] Data 0.017 (0.004) Batch 0.661 (0.480) Remain 31:24:25 loss: 1.5604 Lr: 0.00079
[2025-04-08 14:29:41,703 INFO misc.py line 113 3298914] Train: [2/100][2266/2402] Data 0.004 (0.004) Batch 0.574 (0.480) Remain 31:24:35 loss: 1.2287 Lr: 0.00079
[2025-04-08 14:29:42,186 INFO misc.py line 113 3298914] Train: [2/100][2267/2402] Data 0.003 (0.004) Batch 0.483 (0.480) Remain 31:24:34 loss: 1.0132 Lr: 0.00079
[2025-04-08 14:29:42,657 INFO misc.py line 113 3298914] Train: [2/100][2268/2402] Data 0.004 (0.004) Batch 0.470 (0.480) Remain 31:24:33 loss: 1.2477 Lr: 0.00079
[2025-04-08 14:29:43,149 INFO misc.py line 113 3298914] Train: [2/100][2269/2402] Data 0.004 (0.004) Batch 0.493 (0.480) Remain 31:24:34 loss: 1.2745 Lr: 0.00079
[2025-04-08 14:29:43,633 INFO misc.py line 113 3298914] Train: [2/100][2270/2402] Data 0.003 (0.004) Batch 0.483 (0.480) Remain 31:24:34 loss: 0.9602 Lr: 0.00079
[2025-04-08 14:29:44,103 INFO misc.py line 113 3298914] Train: [2/100][2271/2402] Data 0.004 (0.004) Batch 0.471 (0.480) Remain 31:24:32 loss: 1.5524 Lr: 0.00079
[2025-04-08 14:29:44,584 INFO misc.py line 113 3298914] Train: [2/100][2272/2402] Data 0.003 (0.004) Batch 0.480 (0.480) Remain 31:24:32 loss: 1.0614 Lr: 0.00079
[2025-04-08 14:29:45,065 INFO misc.py line 113 3298914] Train: [2/100][2273/2402] Data 0.004 (0.004) Batch 0.481 (0.480) Remain 31:24:31 loss: 1.3345 Lr: 0.00079
[2025-04-08 14:29:45,497 INFO misc.py line 113 3298914] Train: [2/100][2274/2402] Data 0.004 (0.004) Batch 0.432 (0.480) Remain 31:24:26 loss: 1.4745 Lr: 0.00079
[2025-04-08 14:29:46,037 INFO misc.py line 113 3298914] Train: [2/100][2275/2402] Data 0.004 (0.004) Batch 0.540 (0.480) Remain 31:24:32 loss: 1.3168 Lr: 0.00079
[2025-04-08 14:29:46,521 INFO misc.py line 113 3298914] Train: [2/100][2276/2402] Data 0.003 (0.004) Batch 0.483 (0.480) Remain 31:24:31 loss: 1.7424 Lr: 0.00079
[2025-04-08 14:29:47,089 INFO misc.py line 113 3298914] Train: [2/100][2277/2402] Data 0.004 (0.004) Batch 0.568 (0.480) Remain 31:24:40 loss: 1.2865 Lr: 0.00079
[2025-04-08 14:29:47,699 INFO misc.py line 113 3298914] Train: [2/100][2278/2402] Data 0.004 (0.004) Batch 0.610 (0.480) Remain 31:24:53 loss: 1.3410 Lr: 0.00079
[2025-04-08 14:29:48,225 INFO misc.py line 113 3298914] Train: [2/100][2279/2402] Data 0.004 (0.004) Batch 0.526 (0.480) Remain 31:24:57 loss: 1.1941 Lr: 0.00079
[2025-04-08 14:29:48,745 INFO misc.py line 113 3298914] Train: [2/100][2280/2402] Data 0.003 (0.004) Batch 0.521 (0.480) Remain 31:25:01 loss: 1.4213 Lr: 0.00079
[2025-04-08 14:29:49,196 INFO misc.py line 113 3298914] Train: [2/100][2281/2402] Data 0.003 (0.004) Batch 0.451 (0.480) Remain 31:24:58 loss: 1.4542 Lr: 0.00079
[2025-04-08 14:29:49,702 INFO misc.py line 113 3298914] Train: [2/100][2282/2402] Data 0.003 (0.004) Batch 0.506 (0.480) Remain 31:25:00 loss: 1.1963 Lr: 0.00079
[2025-04-08 14:29:50,185 INFO misc.py line 113 3298914] Train: [2/100][2283/2402] Data 0.004 (0.004) Batch 0.482 (0.480) Remain 31:24:59 loss: 1.2824 Lr: 0.00079
[2025-04-08 14:29:50,572 INFO misc.py line 113 3298914] Train: [2/100][2284/2402] Data 0.004 (0.004) Batch 0.388 (0.480) Remain 31:24:49 loss: 1.1988 Lr: 0.00079
[2025-04-08 14:29:50,985 INFO misc.py line 113 3298914] Train: [2/100][2285/2402] Data 0.004 (0.004) Batch 0.413 (0.480) Remain 31:24:42 loss: 1.2371 Lr: 0.00080
[2025-04-08 14:29:51,389 INFO misc.py line 113 3298914] Train: [2/100][2286/2402] Data 0.003 (0.004) Batch 0.403 (0.480) Remain 31:24:34 loss: 1.2560 Lr: 0.00080
[2025-04-08 14:29:51,804 INFO misc.py line 113 3298914] Train: [2/100][2287/2402] Data 0.004 (0.004) Batch 0.415 (0.480) Remain 31:24:26 loss: 0.9861 Lr: 0.00080
[2025-04-08 14:29:52,236 INFO misc.py line 113 3298914] Train: [2/100][2288/2402] Data 0.005 (0.004) Batch 0.433 (0.480) Remain 31:24:21 loss: 0.9504 Lr: 0.00080
[2025-04-08 14:29:52,654 INFO misc.py line 113 3298914] Train: [2/100][2289/2402] Data 0.004 (0.004) Batch 0.417 (0.480) Remain 31:24:14 loss: 1.2104 Lr: 0.00080
[2025-04-08 14:29:53,132 INFO misc.py line 113 3298914] Train: [2/100][2290/2402] Data 0.004 (0.004) Batch 0.478 (0.480) Remain 31:24:13 loss: 0.9738 Lr: 0.00080
[2025-04-08 14:29:53,655 INFO misc.py line 113 3298914] Train: [2/100][2291/2402] Data 0.004 (0.004) Batch 0.524 (0.480) Remain 31:24:17 loss: 1.2129 Lr: 0.00080
[2025-04-08 14:29:54,181 INFO misc.py line 113 3298914] Train: [2/100][2292/2402] Data 0.004 (0.004) Batch 0.526 (0.480) Remain 31:24:22 loss: 1.1077 Lr: 0.00080
[2025-04-08 14:29:54,653 INFO misc.py line 113 3298914] Train: [2/100][2293/2402] Data 0.003 (0.004) Batch 0.472 (0.480) Remain 31:24:20 loss: 1.4119 Lr: 0.00080
[2025-04-08 14:29:55,114 INFO misc.py line 113 3298914] Train: [2/100][2294/2402] Data 0.003 (0.004) Batch 0.461 (0.480) Remain 31:24:18 loss: 1.4148 Lr: 0.00080
[2025-04-08 14:29:55,558 INFO misc.py line 113 3298914] Train: [2/100][2295/2402] Data 0.003 (0.004) Batch 0.445 (0.480) Remain 31:24:14 loss: 1.2287 Lr: 0.00080
[2025-04-08 14:29:56,011 INFO misc.py line 113 3298914] Train: [2/100][2296/2402] Data 0.004 (0.004) Batch 0.453 (0.480) Remain 31:24:10 loss: 1.2187 Lr: 0.00080
[2025-04-08 14:29:56,331 INFO misc.py line 113 3298914] Train: [2/100][2297/2402] Data 0.003 (0.004) Batch 0.319 (0.480) Remain 31:23:53 loss: 1.1381 Lr: 0.00080
[2025-04-08 14:29:56,849 INFO misc.py line 113 3298914] Train: [2/100][2298/2402] Data 0.003 (0.004) Batch 0.518 (0.480) Remain 31:23:57 loss: 1.5108 Lr: 0.00080
[2025-04-08 14:29:57,409 INFO misc.py line 113 3298914] Train: [2/100][2299/2402] Data 0.004 (0.004) Batch 0.560 (0.480) Remain 31:24:05 loss: 1.4426 Lr: 0.00080
[2025-04-08 14:29:57,757 INFO misc.py line 113 3298914] Train: [2/100][2300/2402] Data 0.003 (0.004) Batch 0.348 (0.480) Remain 31:23:51 loss: 1.1154 Lr: 0.00080
[2025-04-08 14:29:58,229 INFO misc.py line 113 3298914] Train: [2/100][2301/2402] Data 0.003 (0.004) Batch 0.472 (0.480) Remain 31:23:49 loss: 1.8541 Lr: 0.00080
[2025-04-08 14:29:58,733 INFO misc.py line 113 3298914] Train: [2/100][2302/2402] Data 0.004 (0.004) Batch 0.504 (0.480) Remain 31:23:51 loss: 1.2112 Lr: 0.00080
[2025-04-08 14:29:59,178 INFO misc.py line 113 3298914] Train: [2/100][2303/2402] Data 0.003 (0.004) Batch 0.445 (0.480) Remain 31:23:47 loss: 1.2871 Lr: 0.00080
[2025-04-08 14:29:59,626 INFO misc.py line 113 3298914] Train: [2/100][2304/2402] Data 0.003 (0.004) Batch 0.448 (0.480) Remain 31:23:43 loss: 1.4248 Lr: 0.00080
[2025-04-08 14:30:00,164 INFO misc.py line 113 3298914] Train: [2/100][2305/2402] Data 0.004 (0.004) Batch 0.538 (0.480) Remain 31:23:49 loss: 1.3388 Lr: 0.00080
[2025-04-08 14:30:00,609 INFO misc.py line 113 3298914] Train: [2/100][2306/2402] Data 0.003 (0.004) Batch 0.445 (0.480) Remain 31:23:45 loss: 1.0033 Lr: 0.00080
[2025-04-08 14:30:01,114 INFO misc.py line 113 3298914] Train: [2/100][2307/2402] Data 0.004 (0.004) Batch 0.505 (0.480) Remain 31:23:47 loss: 1.6018 Lr: 0.00080
[2025-04-08 14:30:01,531 INFO misc.py line 113 3298914] Train: [2/100][2308/2402] Data 0.003 (0.004) Batch 0.417 (0.480) Remain 31:23:40 loss: 1.5575 Lr: 0.00080
[2025-04-08 14:30:02,062 INFO misc.py line 113 3298914] Train: [2/100][2309/2402] Data 0.003 (0.004) Batch 0.531 (0.480) Remain 31:23:45 loss: 1.3871 Lr: 0.00080
[2025-04-08 14:30:02,491 INFO misc.py line 113 3298914] Train: [2/100][2310/2402] Data 0.003 (0.004) Batch 0.429 (0.480) Remain 31:23:39 loss: 0.8840 Lr: 0.00080
[2025-04-08 14:30:02,970 INFO misc.py line 113 3298914] Train: [2/100][2311/2402] Data 0.004 (0.004) Batch 0.479 (0.480) Remain 31:23:39 loss: 1.1395 Lr: 0.00080
[2025-04-08 14:30:03,418 INFO misc.py line 113 3298914] Train: [2/100][2312/2402] Data 0.004 (0.004) Batch 0.448 (0.480) Remain 31:23:35 loss: 1.3855 Lr: 0.00080
[2025-04-08 14:30:03,846 INFO misc.py line 113 3298914] Train: [2/100][2313/2402] Data 0.004 (0.004) Batch 0.428 (0.480) Remain 31:23:29 loss: 1.7660 Lr: 0.00080
[2025-04-08 14:30:04,253 INFO misc.py line 113 3298914] Train: [2/100][2314/2402] Data 0.003 (0.004) Batch 0.406 (0.480) Remain 31:23:21 loss: 0.9701 Lr: 0.00080
[2025-04-08 14:30:04,674 INFO misc.py line 113 3298914] Train: [2/100][2315/2402] Data 0.003 (0.004) Batch 0.421 (0.480) Remain 31:23:15 loss: 1.4409 Lr: 0.00080
[2025-04-08 14:30:05,091 INFO misc.py line 113 3298914] Train: [2/100][2316/2402] Data 0.004 (0.004) Batch 0.418 (0.480) Remain 31:23:08 loss: 1.1525 Lr: 0.00080
[2025-04-08 14:30:05,652 INFO misc.py line 113 3298914] Train: [2/100][2317/2402] Data 0.003 (0.004) Batch 0.560 (0.480) Remain 31:23:15 loss: 1.8271 Lr: 0.00080
[2025-04-08 14:30:06,073 INFO misc.py line 113 3298914] Train: [2/100][2318/2402] Data 0.004 (0.004) Batch 0.421 (0.480) Remain 31:23:09 loss: 1.6477 Lr: 0.00080
[2025-04-08 14:30:06,604 INFO misc.py line 113 3298914] Train: [2/100][2319/2402] Data 0.003 (0.004) Batch 0.531 (0.480) Remain 31:23:14 loss: 1.0837 Lr: 0.00080
[2025-04-08 14:30:07,190 INFO misc.py line 113 3298914] Train: [2/100][2320/2402] Data 0.003 (0.004) Batch 0.587 (0.480) Remain 31:23:24 loss: 1.4162 Lr: 0.00080
[2025-04-08 14:30:07,738 INFO misc.py line 113 3298914] Train: [2/100][2321/2402] Data 0.003 (0.004) Batch 0.547 (0.480) Remain 31:23:30 loss: 1.3266 Lr: 0.00080
[2025-04-08 14:30:08,145 INFO misc.py line 113 3298914] Train: [2/100][2322/2402] Data 0.004 (0.004) Batch 0.408 (0.480) Remain 31:23:23 loss: 1.1327 Lr: 0.00080
[2025-04-08 14:30:08,646 INFO misc.py line 113 3298914] Train: [2/100][2323/2402] Data 0.003 (0.004) Batch 0.501 (0.480) Remain 31:23:24 loss: 0.9926 Lr: 0.00080
[2025-04-08 14:30:09,006 INFO misc.py line 113 3298914] Train: [2/100][2324/2402] Data 0.003 (0.004) Batch 0.360 (0.480) Remain 31:23:12 loss: 1.6238 Lr: 0.00080
[2025-04-08 14:30:09,563 INFO misc.py line 113 3298914] Train: [2/100][2325/2402] Data 0.003 (0.004) Batch 0.557 (0.480) Remain 31:23:19 loss: 0.8716 Lr: 0.00080
[2025-04-08 14:30:10,132 INFO misc.py line 113 3298914] Train: [2/100][2326/2402] Data 0.003 (0.004) Batch 0.569 (0.480) Remain 31:23:28 loss: 1.3621 Lr: 0.00080
[2025-04-08 14:30:10,663 INFO misc.py line 113 3298914] Train: [2/100][2327/2402] Data 0.003 (0.004) Batch 0.531 (0.480) Remain 31:23:32 loss: 0.9432 Lr: 0.00080
[2025-04-08 14:30:11,139 INFO misc.py line 113 3298914] Train: [2/100][2328/2402] Data 0.004 (0.004) Batch 0.476 (0.480) Remain 31:23:31 loss: 1.1637 Lr: 0.00080
[2025-04-08 14:30:11,600 INFO misc.py line 113 3298914] Train: [2/100][2329/2402] Data 0.003 (0.004) Batch 0.461 (0.480) Remain 31:23:29 loss: 1.1746 Lr: 0.00080
[2025-04-08 14:30:12,032 INFO misc.py line 113 3298914] Train: [2/100][2330/2402] Data 0.004 (0.004) Batch 0.433 (0.480) Remain 31:23:24 loss: 1.1947 Lr: 0.00081
[2025-04-08 14:30:12,420 INFO misc.py line 113 3298914] Train: [2/100][2331/2402] Data 0.004 (0.004) Batch 0.388 (0.480) Remain 31:23:14 loss: 1.1352 Lr: 0.00081
[2025-04-08 14:30:12,827 INFO misc.py line 113 3298914] Train: [2/100][2332/2402] Data 0.004 (0.004) Batch 0.406 (0.480) Remain 31:23:06 loss: 1.0098 Lr: 0.00081
[2025-04-08 14:30:13,274 INFO misc.py line 113 3298914] Train: [2/100][2333/2402] Data 0.003 (0.004) Batch 0.447 (0.480) Remain 31:23:02 loss: 1.2128 Lr: 0.00081
[2025-04-08 14:30:13,696 INFO misc.py line 113 3298914] Train: [2/100][2334/2402] Data 0.004 (0.004) Batch 0.422 (0.480) Remain 31:22:56 loss: 1.2929 Lr: 0.00081
[2025-04-08 14:30:14,134 INFO misc.py line 113 3298914] Train: [2/100][2335/2402] Data 0.004 (0.004) Batch 0.438 (0.480) Remain 31:22:51 loss: 1.5032 Lr: 0.00081
[2025-04-08 14:30:14,567 INFO misc.py line 113 3298914] Train: [2/100][2336/2402] Data 0.003 (0.004) Batch 0.433 (0.480) Remain 31:22:46 loss: 1.7914 Lr: 0.00081
[2025-04-08 14:30:15,054 INFO misc.py line 113 3298914] Train: [2/100][2337/2402] Data 0.004 (0.004) Batch 0.488 (0.480) Remain 31:22:46 loss: 1.4106 Lr: 0.00081
[2025-04-08 14:30:15,484 INFO misc.py line 113 3298914] Train: [2/100][2338/2402] Data 0.003 (0.004) Batch 0.431 (0.480) Remain 31:22:41 loss: 1.1356 Lr: 0.00081
[2025-04-08 14:30:15,920 INFO misc.py line 113 3298914] Train: [2/100][2339/2402] Data 0.003 (0.004) Batch 0.435 (0.480) Remain 31:22:36 loss: 0.9684 Lr: 0.00081
[2025-04-08 14:30:16,498 INFO misc.py line 113 3298914] Train: [2/100][2340/2402] Data 0.004 (0.004) Batch 0.578 (0.480) Remain 31:22:45 loss: 1.0691 Lr: 0.00081
[2025-04-08 14:30:16,998 INFO misc.py line 113 3298914] Train: [2/100][2341/2402] Data 0.003 (0.004) Batch 0.500 (0.480) Remain 31:22:47 loss: 1.4209 Lr: 0.00081
[2025-04-08 14:30:17,348 INFO misc.py line 113 3298914] Train: [2/100][2342/2402] Data 0.004 (0.004) Batch 0.350 (0.480) Remain 31:22:33 loss: 1.1512 Lr: 0.00081
[2025-04-08 14:30:17,760 INFO misc.py line 113 3298914] Train: [2/100][2343/2402] Data 0.003 (0.004) Batch 0.412 (0.480) Remain 31:22:26 loss: 1.0062 Lr: 0.00081
[2025-04-08 14:30:18,274 INFO misc.py line 113 3298914] Train: [2/100][2344/2402] Data 0.003 (0.004) Batch 0.513 (0.480) Remain 31:22:29 loss: 1.5190 Lr: 0.00081
[2025-04-08 14:30:18,712 INFO misc.py line 113 3298914] Train: [2/100][2345/2402] Data 0.004 (0.004) Batch 0.438 (0.480) Remain 31:22:24 loss: 1.3932 Lr: 0.00081
[2025-04-08 14:30:19,148 INFO misc.py line 113 3298914] Train: [2/100][2346/2402] Data 0.003 (0.004) Batch 0.437 (0.480) Remain 31:22:19 loss: 1.0053 Lr: 0.00081
[2025-04-08 14:30:19,678 INFO misc.py line 113 3298914] Train: [2/100][2347/2402] Data 0.003 (0.004) Batch 0.529 (0.480) Remain 31:22:24 loss: 0.8619 Lr: 0.00081
[2025-04-08 14:30:20,161 INFO misc.py line 113 3298914] Train: [2/100][2348/2402] Data 0.004 (0.004) Batch 0.483 (0.480) Remain 31:22:24 loss: 1.1559 Lr: 0.00081
[2025-04-08 14:30:20,701 INFO misc.py line 113 3298914] Train: [2/100][2349/2402] Data 0.004 (0.004) Batch 0.541 (0.480) Remain 31:22:29 loss: 1.0261 Lr: 0.00081
[2025-04-08 14:30:21,182 INFO misc.py line 113 3298914] Train: [2/100][2350/2402] Data 0.003 (0.004) Batch 0.481 (0.480) Remain 31:22:29 loss: 0.9670 Lr: 0.00081
[2025-04-08 14:30:21,654 INFO misc.py line 113 3298914] Train: [2/100][2351/2402] Data 0.004 (0.004) Batch 0.472 (0.480) Remain 31:22:28 loss: 0.9120 Lr: 0.00081
[2025-04-08 14:30:22,145 INFO misc.py line 113 3298914] Train: [2/100][2352/2402] Data 0.004 (0.004) Batch 0.491 (0.480) Remain 31:22:28 loss: 1.5706 Lr: 0.00081
[2025-04-08 14:30:22,591 INFO misc.py line 113 3298914] Train: [2/100][2353/2402] Data 0.003 (0.004) Batch 0.446 (0.480) Remain 31:22:25 loss: 1.5490 Lr: 0.00081
[2025-04-08 14:30:23,008 INFO misc.py line 113 3298914] Train: [2/100][2354/2402] Data 0.004 (0.004) Batch 0.417 (0.480) Remain 31:22:18 loss: 0.8104 Lr: 0.00081
[2025-04-08 14:30:23,555 INFO misc.py line 113 3298914] Train: [2/100][2355/2402] Data 0.004 (0.004) Batch 0.548 (0.480) Remain 31:22:24 loss: 1.3243 Lr: 0.00081
[2025-04-08 14:30:24,084 INFO misc.py line 113 3298914] Train: [2/100][2356/2402] Data 0.003 (0.004) Batch 0.529 (0.480) Remain 31:22:29 loss: 1.0026 Lr: 0.00081
[2025-04-08 14:30:24,592 INFO misc.py line 113 3298914] Train: [2/100][2357/2402] Data 0.004 (0.004) Batch 0.507 (0.480) Remain 31:22:31 loss: 1.3147 Lr: 0.00081
[2025-04-08 14:30:25,090 INFO misc.py line 113 3298914] Train: [2/100][2358/2402] Data 0.003 (0.004) Batch 0.499 (0.480) Remain 31:22:32 loss: 1.2218 Lr: 0.00081
[2025-04-08 14:30:25,614 INFO misc.py line 113 3298914] Train: [2/100][2359/2402] Data 0.004 (0.004) Batch 0.524 (0.480) Remain 31:22:36 loss: 1.5252 Lr: 0.00081
[2025-04-08 14:30:26,052 INFO misc.py line 113 3298914] Train: [2/100][2360/2402] Data 0.003 (0.004) Batch 0.437 (0.480) Remain 31:22:32 loss: 1.5126 Lr: 0.00081
[2025-04-08 14:30:26,565 INFO misc.py line 113 3298914] Train: [2/100][2361/2402] Data 0.004 (0.004) Batch 0.513 (0.480) Remain 31:22:34 loss: 1.2783 Lr: 0.00081
[2025-04-08 14:30:27,064 INFO misc.py line 113 3298914] Train: [2/100][2362/2402] Data 0.003 (0.004) Batch 0.499 (0.480) Remain 31:22:36 loss: 1.4929 Lr: 0.00081
[2025-04-08 14:30:27,509 INFO misc.py line 113 3298914] Train: [2/100][2363/2402] Data 0.004 (0.004) Batch 0.445 (0.480) Remain 31:22:32 loss: 0.9541 Lr: 0.00081
[2025-04-08 14:30:27,973 INFO misc.py line 113 3298914] Train: [2/100][2364/2402] Data 0.003 (0.004) Batch 0.464 (0.480) Remain 31:22:30 loss: 1.2026 Lr: 0.00081
[2025-04-08 14:30:28,416 INFO misc.py line 113 3298914] Train: [2/100][2365/2402] Data 0.003 (0.004) Batch 0.443 (0.480) Remain 31:22:26 loss: 1.5180 Lr: 0.00081
[2025-04-08 14:30:28,925 INFO misc.py line 113 3298914] Train: [2/100][2366/2402] Data 0.004 (0.004) Batch 0.509 (0.480) Remain 31:22:28 loss: 1.2221 Lr: 0.00081
[2025-04-08 14:30:29,460 INFO misc.py line 113 3298914] Train: [2/100][2367/2402] Data 0.003 (0.004) Batch 0.535 (0.480) Remain 31:22:33 loss: 0.8628 Lr: 0.00081
[2025-04-08 14:30:29,994 INFO misc.py line 113 3298914] Train: [2/100][2368/2402] Data 0.004 (0.004) Batch 0.534 (0.480) Remain 31:22:38 loss: 1.3155 Lr: 0.00081
[2025-04-08 14:30:30,544 INFO misc.py line 113 3298914] Train: [2/100][2369/2402] Data 0.004 (0.004) Batch 0.550 (0.480) Remain 31:22:45 loss: 1.2557 Lr: 0.00081
[2025-04-08 14:30:30,999 INFO misc.py line 113 3298914] Train: [2/100][2370/2402] Data 0.004 (0.004) Batch 0.456 (0.480) Remain 31:22:42 loss: 1.6722 Lr: 0.00081
[2025-04-08 14:30:31,517 INFO misc.py line 113 3298914] Train: [2/100][2371/2402] Data 0.003 (0.004) Batch 0.518 (0.480) Remain 31:22:45 loss: 0.9011 Lr: 0.00081
[2025-04-08 14:30:31,944 INFO misc.py line 113 3298914] Train: [2/100][2372/2402] Data 0.003 (0.004) Batch 0.427 (0.480) Remain 31:22:39 loss: 0.8798 Lr: 0.00081
[2025-04-08 14:30:32,383 INFO misc.py line 113 3298914] Train: [2/100][2373/2402] Data 0.004 (0.004) Batch 0.439 (0.480) Remain 31:22:35 loss: 0.8613 Lr: 0.00081
[2025-04-08 14:30:32,801 INFO misc.py line 113 3298914] Train: [2/100][2374/2402] Data 0.004 (0.004) Batch 0.418 (0.480) Remain 31:22:28 loss: 1.5232 Lr: 0.00081
[2025-04-08 14:30:33,243 INFO misc.py line 113 3298914] Train: [2/100][2375/2402] Data 0.004 (0.004) Batch 0.442 (0.480) Remain 31:22:24 loss: 1.3749 Lr: 0.00082
[2025-04-08 14:30:33,703 INFO misc.py line 113 3298914] Train: [2/100][2376/2402] Data 0.003 (0.004) Batch 0.461 (0.480) Remain 31:22:21 loss: 1.2531 Lr: 0.00082
[2025-04-08 14:30:34,244 INFO misc.py line 113 3298914] Train: [2/100][2377/2402] Data 0.003 (0.004) Batch 0.541 (0.480) Remain 31:22:27 loss: 1.4347 Lr: 0.00082
[2025-04-08 14:30:34,631 INFO misc.py line 113 3298914] Train: [2/100][2378/2402] Data 0.004 (0.004) Batch 0.387 (0.480) Remain 31:22:17 loss: 1.1228 Lr: 0.00082
[2025-04-08 14:30:35,298 INFO misc.py line 113 3298914] Train: [2/100][2379/2402] Data 0.003 (0.004) Batch 0.666 (0.480) Remain 31:22:35 loss: 1.6404 Lr: 0.00082
[2025-04-08 14:30:35,700 INFO misc.py line 113 3298914] Train: [2/100][2380/2402] Data 0.003 (0.004) Batch 0.403 (0.480) Remain 31:22:27 loss: 1.1494 Lr: 0.00082
[2025-04-08 14:30:36,103 INFO misc.py line 113 3298914] Train: [2/100][2381/2402] Data 0.003 (0.004) Batch 0.403 (0.480) Remain 31:22:19 loss: 1.2214 Lr: 0.00082
[2025-04-08 14:30:36,523 INFO misc.py line 113 3298914] Train: [2/100][2382/2402] Data 0.003 (0.004) Batch 0.420 (0.480) Remain 31:22:13 loss: 0.9396 Lr: 0.00082
[2025-04-08 14:30:37,016 INFO misc.py line 113 3298914] Train: [2/100][2383/2402] Data 0.004 (0.004) Batch 0.494 (0.480) Remain 31:22:14 loss: 1.1484 Lr: 0.00082
[2025-04-08 14:30:37,458 INFO misc.py line 113 3298914] Train: [2/100][2384/2402] Data 0.003 (0.004) Batch 0.441 (0.480) Remain 31:22:09 loss: 1.0373 Lr: 0.00082
[2025-04-08 14:30:37,900 INFO misc.py line 113 3298914] Train: [2/100][2385/2402] Data 0.003 (0.004) Batch 0.442 (0.480) Remain 31:22:05 loss: 1.3148 Lr: 0.00082
[2025-04-08 14:30:38,384 INFO misc.py line 113 3298914] Train: [2/100][2386/2402] Data 0.004 (0.004) Batch 0.484 (0.480) Remain 31:22:05 loss: 1.6240 Lr: 0.00082
[2025-04-08 14:30:38,916 INFO misc.py line 113 3298914] Train: [2/100][2387/2402] Data 0.004 (0.004) Batch 0.533 (0.480) Remain 31:22:10 loss: 1.1594 Lr: 0.00082
[2025-04-08 14:30:39,366 INFO misc.py line 113 3298914] Train: [2/100][2388/2402] Data 0.004 (0.004) Batch 0.450 (0.480) Remain 31:22:06 loss: 1.5232 Lr: 0.00082
[2025-04-08 14:30:39,832 INFO misc.py line 113 3298914] Train: [2/100][2389/2402] Data 0.003 (0.004) Batch 0.466 (0.480) Remain 31:22:05 loss: 1.1245 Lr: 0.00082
[2025-04-08 14:30:40,206 INFO misc.py line 113 3298914] Train: [2/100][2390/2402] Data 0.003 (0.004) Batch 0.374 (0.480) Remain 31:21:54 loss: 1.2144 Lr: 0.00082
[2025-04-08 14:30:40,511 INFO misc.py line 113 3298914] Train: [2/100][2391/2402] Data 0.004 (0.004) Batch 0.305 (0.480) Remain 31:21:36 loss: 1.0246 Lr: 0.00082
[2025-04-08 14:30:40,954 INFO misc.py line 113 3298914] Train: [2/100][2392/2402] Data 0.003 (0.004) Batch 0.442 (0.480) Remain 31:21:32 loss: 0.8660 Lr: 0.00082
[2025-04-08 14:30:41,462 INFO misc.py line 113 3298914] Train: [2/100][2393/2402] Data 0.003 (0.004) Batch 0.508 (0.480) Remain 31:21:34 loss: 1.0936 Lr: 0.00082
[2025-04-08 14:30:41,968 INFO misc.py line 113 3298914] Train: [2/100][2394/2402] Data 0.003 (0.004) Batch 0.506 (0.480) Remain 31:21:36 loss: 1.0693 Lr: 0.00082
[2025-04-08 14:30:42,394 INFO misc.py line 113 3298914] Train: [2/100][2395/2402] Data 0.003 (0.004) Batch 0.425 (0.480) Remain 31:21:31 loss: 1.1629 Lr: 0.00082
[2025-04-08 14:30:42,856 INFO misc.py line 113 3298914] Train: [2/100][2396/2402] Data 0.003 (0.004) Batch 0.462 (0.480) Remain 31:21:28 loss: 1.2060 Lr: 0.00082
[2025-04-08 14:30:43,260 INFO misc.py line 113 3298914] Train: [2/100][2397/2402] Data 0.003 (0.004) Batch 0.404 (0.480) Remain 31:21:20 loss: 0.9811 Lr: 0.00082
[2025-04-08 14:30:43,648 INFO misc.py line 113 3298914] Train: [2/100][2398/2402] Data 0.003 (0.004) Batch 0.388 (0.479) Remain 31:21:11 loss: 1.4626 Lr: 0.00082
[2025-04-08 14:30:44,151 INFO misc.py line 113 3298914] Train: [2/100][2399/2402] Data 0.003 (0.004) Batch 0.503 (0.479) Remain 31:21:13 loss: 1.1616 Lr: 0.00082
[2025-04-08 14:30:44,606 INFO misc.py line 113 3298914] Train: [2/100][2400/2402] Data 0.004 (0.004) Batch 0.455 (0.479) Remain 31:21:10 loss: 1.8470 Lr: 0.00082
[2025-04-08 14:30:45,091 INFO misc.py line 113 3298914] Train: [2/100][2401/2402] Data 0.003 (0.004) Batch 0.485 (0.479) Remain 31:21:10 loss: 1.1027 Lr: 0.00082
[2025-04-08 14:30:45,635 INFO misc.py line 113 3298914] Train: [2/100][2402/2402] Data 0.003 (0.004) Batch 0.544 (0.480) Remain 31:21:16 loss: 1.0786 Lr: 0.00082
[2025-04-08 14:30:45,636 INFO misc.py line 130 3298914] Train result: loss: 1.3394 
[2025-04-08 14:30:45,636 INFO evaluator.py line 115 3298914] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[2025-04-08 14:30:46,493 INFO evaluator.py line 162 3298914] Test: [1/312] Loss 1.1076 
[2025-04-08 14:30:46,657 INFO evaluator.py line 162 3298914] Test: [2/312] Loss 1.7748 
[2025-04-08 14:30:46,843 INFO evaluator.py line 162 3298914] Test: [3/312] Loss 1.3139 
[2025-04-08 14:30:46,952 INFO evaluator.py line 162 3298914] Test: [4/312] Loss 0.6334 
[2025-04-08 14:30:47,091 INFO evaluator.py line 162 3298914] Test: [5/312] Loss 0.2193 
[2025-04-08 14:30:47,278 INFO evaluator.py line 162 3298914] Test: [6/312] Loss 1.0694 
[2025-04-08 14:30:47,564 INFO evaluator.py line 162 3298914] Test: [7/312] Loss 1.2273 
[2025-04-08 14:30:47,718 INFO evaluator.py line 162 3298914] Test: [8/312] Loss 0.7797 
[2025-04-08 14:30:47,841 INFO evaluator.py line 162 3298914] Test: [9/312] Loss 1.2549 
[2025-04-08 14:30:48,023 INFO evaluator.py line 162 3298914] Test: [10/312] Loss 0.8815 
[2025-04-08 14:30:48,229 INFO evaluator.py line 162 3298914] Test: [11/312] Loss 1.8273 
[2025-04-08 14:30:48,338 INFO evaluator.py line 162 3298914] Test: [12/312] Loss 0.8345 
[2025-04-08 14:30:48,446 INFO evaluator.py line 162 3298914] Test: [13/312] Loss 1.0972 
[2025-04-08 14:30:48,616 INFO evaluator.py line 162 3298914] Test: [14/312] Loss 1.9586 
[2025-04-08 14:30:48,844 INFO evaluator.py line 162 3298914] Test: [15/312] Loss 1.2672 
[2025-04-08 14:30:48,973 INFO evaluator.py line 162 3298914] Test: [16/312] Loss 0.6186 
[2025-04-08 14:30:49,140 INFO evaluator.py line 162 3298914] Test: [17/312] Loss 1.0412 
[2025-04-08 14:30:49,242 INFO evaluator.py line 162 3298914] Test: [18/312] Loss 1.1415 
[2025-04-08 14:30:49,373 INFO evaluator.py line 162 3298914] Test: [19/312] Loss 1.3859 
[2025-04-08 14:30:49,495 INFO evaluator.py line 162 3298914] Test: [20/312] Loss 0.4512 
[2025-04-08 14:30:49,605 INFO evaluator.py line 162 3298914] Test: [21/312] Loss 1.3785 
[2025-04-08 14:30:49,780 INFO evaluator.py line 162 3298914] Test: [22/312] Loss 0.4528 
[2025-04-08 14:30:49,902 INFO evaluator.py line 162 3298914] Test: [23/312] Loss 0.7365 
[2025-04-08 14:30:50,109 INFO evaluator.py line 162 3298914] Test: [24/312] Loss 0.7714 
[2025-04-08 14:30:50,369 INFO evaluator.py line 162 3298914] Test: [25/312] Loss 1.4865 
[2025-04-08 14:30:50,605 INFO evaluator.py line 162 3298914] Test: [26/312] Loss 0.6315 
[2025-04-08 14:30:50,752 INFO evaluator.py line 162 3298914] Test: [27/312] Loss 0.3753 
[2025-04-08 14:30:50,864 INFO evaluator.py line 162 3298914] Test: [28/312] Loss 1.0645 
[2025-04-08 14:30:51,037 INFO evaluator.py line 162 3298914] Test: [29/312] Loss 1.1827 
[2025-04-08 14:30:51,175 INFO evaluator.py line 162 3298914] Test: [30/312] Loss 0.6641 
[2025-04-08 14:30:51,300 INFO evaluator.py line 162 3298914] Test: [31/312] Loss 0.9165 
[2025-04-08 14:30:51,404 INFO evaluator.py line 162 3298914] Test: [32/312] Loss 0.1723 
[2025-04-08 14:30:51,552 INFO evaluator.py line 162 3298914] Test: [33/312] Loss 1.9694 
[2025-04-08 14:30:51,660 INFO evaluator.py line 162 3298914] Test: [34/312] Loss 1.0558 
[2025-04-08 14:30:51,834 INFO evaluator.py line 162 3298914] Test: [35/312] Loss 1.6376 
[2025-04-08 14:30:52,040 INFO evaluator.py line 162 3298914] Test: [36/312] Loss 0.8389 
[2025-04-08 14:30:52,189 INFO evaluator.py line 162 3298914] Test: [37/312] Loss 0.5641 
[2025-04-08 14:30:52,379 INFO evaluator.py line 162 3298914] Test: [38/312] Loss 0.8580 
[2025-04-08 14:30:52,661 INFO evaluator.py line 162 3298914] Test: [39/312] Loss 0.7332 
[2025-04-08 14:30:52,792 INFO evaluator.py line 162 3298914] Test: [40/312] Loss 1.5618 
[2025-04-08 14:30:52,918 INFO evaluator.py line 162 3298914] Test: [41/312] Loss 1.1617 
[2025-04-08 14:30:53,157 INFO evaluator.py line 162 3298914] Test: [42/312] Loss 1.2661 
[2025-04-08 14:30:53,301 INFO evaluator.py line 162 3298914] Test: [43/312] Loss 1.9746 
[2025-04-08 14:30:53,499 INFO evaluator.py line 162 3298914] Test: [44/312] Loss 0.7202 
[2025-04-08 14:30:53,646 INFO evaluator.py line 162 3298914] Test: [45/312] Loss 1.0613 
[2025-04-08 14:30:53,801 INFO evaluator.py line 162 3298914] Test: [46/312] Loss 0.6595 
[2025-04-08 14:30:53,905 INFO evaluator.py line 162 3298914] Test: [47/312] Loss 0.5148 
[2025-04-08 14:30:54,097 INFO evaluator.py line 162 3298914] Test: [48/312] Loss 1.8028 
[2025-04-08 14:30:54,276 INFO evaluator.py line 162 3298914] Test: [49/312] Loss 2.0888 
[2025-04-08 14:30:54,432 INFO evaluator.py line 162 3298914] Test: [50/312] Loss 0.7148 
[2025-04-08 14:30:54,539 INFO evaluator.py line 162 3298914] Test: [51/312] Loss 0.8896 
[2025-04-08 14:30:54,717 INFO evaluator.py line 162 3298914] Test: [52/312] Loss 0.9379 
[2025-04-08 14:30:54,843 INFO evaluator.py line 162 3298914] Test: [53/312] Loss 1.0042 
[2025-04-08 14:30:55,001 INFO evaluator.py line 162 3298914] Test: [54/312] Loss 1.3830 
[2025-04-08 14:30:55,304 INFO evaluator.py line 162 3298914] Test: [55/312] Loss 0.9901 
[2025-04-08 14:30:55,528 INFO evaluator.py line 162 3298914] Test: [56/312] Loss 1.5566 
[2025-04-08 14:30:55,694 INFO evaluator.py line 162 3298914] Test: [57/312] Loss 1.1143 
[2025-04-08 14:30:55,864 INFO evaluator.py line 162 3298914] Test: [58/312] Loss 1.2054 
[2025-04-08 14:30:55,997 INFO evaluator.py line 162 3298914] Test: [59/312] Loss 1.0902 
[2025-04-08 14:30:56,120 INFO evaluator.py line 162 3298914] Test: [60/312] Loss 0.8867 
[2025-04-08 14:30:56,293 INFO evaluator.py line 162 3298914] Test: [61/312] Loss 1.3606 
[2025-04-08 14:30:56,477 INFO evaluator.py line 162 3298914] Test: [62/312] Loss 1.2525 
[2025-04-08 14:30:56,705 INFO evaluator.py line 162 3298914] Test: [63/312] Loss 1.5362 
[2025-04-08 14:30:56,879 INFO evaluator.py line 162 3298914] Test: [64/312] Loss 0.7705 
[2025-04-08 14:30:57,023 INFO evaluator.py line 162 3298914] Test: [65/312] Loss 0.9480 
[2025-04-08 14:30:57,189 INFO evaluator.py line 162 3298914] Test: [66/312] Loss 1.4218 
[2025-04-08 14:30:57,311 INFO evaluator.py line 162 3298914] Test: [67/312] Loss 1.3678 
[2025-04-08 14:30:57,436 INFO evaluator.py line 162 3298914] Test: [68/312] Loss 0.7145 
[2025-04-08 14:30:57,578 INFO evaluator.py line 162 3298914] Test: [69/312] Loss 0.8399 
[2025-04-08 14:30:57,687 INFO evaluator.py line 162 3298914] Test: [70/312] Loss 0.7962 
[2025-04-08 14:30:57,808 INFO evaluator.py line 162 3298914] Test: [71/312] Loss 0.6366 
[2025-04-08 14:30:58,088 INFO evaluator.py line 162 3298914] Test: [72/312] Loss 1.2366 
[2025-04-08 14:30:58,375 INFO evaluator.py line 162 3298914] Test: [73/312] Loss 2.7346 
[2025-04-08 14:30:58,558 INFO evaluator.py line 162 3298914] Test: [74/312] Loss 0.3224 
[2025-04-08 14:30:58,771 INFO evaluator.py line 162 3298914] Test: [75/312] Loss 0.7219 
[2025-04-08 14:30:58,933 INFO evaluator.py line 162 3298914] Test: [76/312] Loss 1.1124 
[2025-04-08 14:30:59,037 INFO evaluator.py line 162 3298914] Test: [77/312] Loss 0.5851 
[2025-04-08 14:30:59,166 INFO evaluator.py line 162 3298914] Test: [78/312] Loss 1.8732 
[2025-04-08 14:30:59,368 INFO evaluator.py line 162 3298914] Test: [79/312] Loss 1.5244 
[2025-04-08 14:30:59,519 INFO evaluator.py line 162 3298914] Test: [80/312] Loss 0.7503 
[2025-04-08 14:30:59,730 INFO evaluator.py line 162 3298914] Test: [81/312] Loss 1.1767 
[2025-04-08 14:30:59,910 INFO evaluator.py line 162 3298914] Test: [82/312] Loss 0.8807 
[2025-04-08 14:31:00,130 INFO evaluator.py line 162 3298914] Test: [83/312] Loss 1.3838 
[2025-04-08 14:31:00,304 INFO evaluator.py line 162 3298914] Test: [84/312] Loss 1.1432 
[2025-04-08 14:31:00,608 INFO evaluator.py line 162 3298914] Test: [85/312] Loss 1.6056 
[2025-04-08 14:31:00,736 INFO evaluator.py line 162 3298914] Test: [86/312] Loss 0.5822 
[2025-04-08 14:31:00,891 INFO evaluator.py line 162 3298914] Test: [87/312] Loss 0.5309 
[2025-04-08 14:31:01,037 INFO evaluator.py line 162 3298914] Test: [88/312] Loss 0.3891 
[2025-04-08 14:31:01,170 INFO evaluator.py line 162 3298914] Test: [89/312] Loss 1.6706 
[2025-04-08 14:31:01,318 INFO evaluator.py line 162 3298914] Test: [90/312] Loss 1.0794 
[2025-04-08 14:31:01,501 INFO evaluator.py line 162 3298914] Test: [91/312] Loss 1.0230 
[2025-04-08 14:31:01,639 INFO evaluator.py line 162 3298914] Test: [92/312] Loss 0.6596 
[2025-04-08 14:31:01,828 INFO evaluator.py line 162 3298914] Test: [93/312] Loss 1.7263 
[2025-04-08 14:31:01,982 INFO evaluator.py line 162 3298914] Test: [94/312] Loss 0.6807 
[2025-04-08 14:31:02,086 INFO evaluator.py line 162 3298914] Test: [95/312] Loss 0.5540 
[2025-04-08 14:31:02,209 INFO evaluator.py line 162 3298914] Test: [96/312] Loss 0.8051 
[2025-04-08 14:31:02,474 INFO evaluator.py line 162 3298914] Test: [97/312] Loss 1.1683 
[2025-04-08 14:31:02,644 INFO evaluator.py line 162 3298914] Test: [98/312] Loss 1.2707 
[2025-04-08 14:31:02,851 INFO evaluator.py line 162 3298914] Test: [99/312] Loss 1.6616 
[2025-04-08 14:31:03,007 INFO evaluator.py line 162 3298914] Test: [100/312] Loss 0.9341 
[2025-04-08 14:31:03,166 INFO evaluator.py line 162 3298914] Test: [101/312] Loss 0.4044 
[2025-04-08 14:31:03,368 INFO evaluator.py line 162 3298914] Test: [102/312] Loss 0.9682 
[2025-04-08 14:31:03,552 INFO evaluator.py line 162 3298914] Test: [103/312] Loss 1.2089 
[2025-04-08 14:31:03,682 INFO evaluator.py line 162 3298914] Test: [104/312] Loss 0.9426 
[2025-04-08 14:31:03,857 INFO evaluator.py line 162 3298914] Test: [105/312] Loss 1.0419 
[2025-04-08 14:31:04,019 INFO evaluator.py line 162 3298914] Test: [106/312] Loss 2.0301 
[2025-04-08 14:31:04,147 INFO evaluator.py line 162 3298914] Test: [107/312] Loss 1.5589 
[2025-04-08 14:31:04,348 INFO evaluator.py line 162 3298914] Test: [108/312] Loss 1.5172 
[2025-04-08 14:31:04,489 INFO evaluator.py line 162 3298914] Test: [109/312] Loss 1.1691 
[2025-04-08 14:31:04,601 INFO evaluator.py line 162 3298914] Test: [110/312] Loss 1.2506 
[2025-04-08 14:31:04,711 INFO evaluator.py line 162 3298914] Test: [111/312] Loss 1.0861 
[2025-04-08 14:31:04,860 INFO evaluator.py line 162 3298914] Test: [112/312] Loss 1.3559 
[2025-04-08 14:31:05,047 INFO evaluator.py line 162 3298914] Test: [113/312] Loss 0.8905 
[2025-04-08 14:31:05,150 INFO evaluator.py line 162 3298914] Test: [114/312] Loss 1.2443 
[2025-04-08 14:31:05,356 INFO evaluator.py line 162 3298914] Test: [115/312] Loss 1.2802 
[2025-04-08 14:31:05,544 INFO evaluator.py line 162 3298914] Test: [116/312] Loss 1.0398 
[2025-04-08 14:31:05,675 INFO evaluator.py line 162 3298914] Test: [117/312] Loss 0.7280 
[2025-04-08 14:31:05,803 INFO evaluator.py line 162 3298914] Test: [118/312] Loss 1.8781 
[2025-04-08 14:31:05,976 INFO evaluator.py line 162 3298914] Test: [119/312] Loss 1.7407 
[2025-04-08 14:31:06,154 INFO evaluator.py line 162 3298914] Test: [120/312] Loss 1.2179 
[2025-04-08 14:31:06,394 INFO evaluator.py line 162 3298914] Test: [121/312] Loss 1.1588 
[2025-04-08 14:31:06,568 INFO evaluator.py line 162 3298914] Test: [122/312] Loss 1.0417 
[2025-04-08 14:31:06,676 INFO evaluator.py line 162 3298914] Test: [123/312] Loss 1.1610 
[2025-04-08 14:31:06,826 INFO evaluator.py line 162 3298914] Test: [124/312] Loss 0.3357 
[2025-04-08 14:31:06,927 INFO evaluator.py line 162 3298914] Test: [125/312] Loss 1.0079 
[2025-04-08 14:31:07,097 INFO evaluator.py line 162 3298914] Test: [126/312] Loss 1.4482 
[2025-04-08 14:31:07,248 INFO evaluator.py line 162 3298914] Test: [127/312] Loss 1.7231 
[2025-04-08 14:31:07,396 INFO evaluator.py line 162 3298914] Test: [128/312] Loss 1.1995 
[2025-04-08 14:31:07,517 INFO evaluator.py line 162 3298914] Test: [129/312] Loss 0.3378 
[2025-04-08 14:31:07,622 INFO evaluator.py line 162 3298914] Test: [130/312] Loss 0.8241 
[2025-04-08 14:31:07,785 INFO evaluator.py line 162 3298914] Test: [131/312] Loss 1.2126 
[2025-04-08 14:31:07,981 INFO evaluator.py line 162 3298914] Test: [132/312] Loss 1.0661 
[2025-04-08 14:31:08,150 INFO evaluator.py line 162 3298914] Test: [133/312] Loss 1.9953 
[2025-04-08 14:31:08,332 INFO evaluator.py line 162 3298914] Test: [134/312] Loss 0.8766 
[2025-04-08 14:31:08,473 INFO evaluator.py line 162 3298914] Test: [135/312] Loss 0.8844 
[2025-04-08 14:31:08,666 INFO evaluator.py line 162 3298914] Test: [136/312] Loss 1.0914 
[2025-04-08 14:31:08,816 INFO evaluator.py line 162 3298914] Test: [137/312] Loss 1.0443 
[2025-04-08 14:31:08,942 INFO evaluator.py line 162 3298914] Test: [138/312] Loss 0.8612 
[2025-04-08 14:31:09,100 INFO evaluator.py line 162 3298914] Test: [139/312] Loss 1.6176 
[2025-04-08 14:31:09,271 INFO evaluator.py line 162 3298914] Test: [140/312] Loss 0.6660 
[2025-04-08 14:31:09,397 INFO evaluator.py line 162 3298914] Test: [141/312] Loss 0.9841 
[2025-04-08 14:31:09,564 INFO evaluator.py line 162 3298914] Test: [142/312] Loss 1.2581 
[2025-04-08 14:31:09,708 INFO evaluator.py line 162 3298914] Test: [143/312] Loss 1.3277 
[2025-04-08 14:31:09,831 INFO evaluator.py line 162 3298914] Test: [144/312] Loss 0.8318 
[2025-04-08 14:31:09,972 INFO evaluator.py line 162 3298914] Test: [145/312] Loss 1.8926 
[2025-04-08 14:31:10,112 INFO evaluator.py line 162 3298914] Test: [146/312] Loss 0.5663 
[2025-04-08 14:31:10,222 INFO evaluator.py line 162 3298914] Test: [147/312] Loss 0.6484 
[2025-04-08 14:31:10,489 INFO evaluator.py line 162 3298914] Test: [148/312] Loss 2.5696 
[2025-04-08 14:31:10,663 INFO evaluator.py line 162 3298914] Test: [149/312] Loss 1.1649 
[2025-04-08 14:31:10,979 INFO evaluator.py line 162 3298914] Test: [150/312] Loss 1.1224 
[2025-04-08 14:31:11,132 INFO evaluator.py line 162 3298914] Test: [151/312] Loss 0.1310 
[2025-04-08 14:31:11,286 INFO evaluator.py line 162 3298914] Test: [152/312] Loss 1.8016 
[2025-04-08 14:31:11,395 INFO evaluator.py line 162 3298914] Test: [153/312] Loss 1.1758 
[2025-04-08 14:31:11,633 INFO evaluator.py line 162 3298914] Test: [154/312] Loss 0.6428 
[2025-04-08 14:31:11,766 INFO evaluator.py line 162 3298914] Test: [155/312] Loss 0.2838 
[2025-04-08 14:31:11,962 INFO evaluator.py line 162 3298914] Test: [156/312] Loss 1.0371 
[2025-04-08 14:31:12,122 INFO evaluator.py line 162 3298914] Test: [157/312] Loss 0.5661 
[2025-04-08 14:31:12,369 INFO evaluator.py line 162 3298914] Test: [158/312] Loss 0.6559 
[2025-04-08 14:31:12,525 INFO evaluator.py line 162 3298914] Test: [159/312] Loss 1.8299 
[2025-04-08 14:31:12,716 INFO evaluator.py line 162 3298914] Test: [160/312] Loss 0.5490 
[2025-04-08 14:31:12,837 INFO evaluator.py line 162 3298914] Test: [161/312] Loss 0.7356 
[2025-04-08 14:31:12,980 INFO evaluator.py line 162 3298914] Test: [162/312] Loss 1.1151 
[2025-04-08 14:31:13,256 INFO evaluator.py line 162 3298914] Test: [163/312] Loss 0.8607 
[2025-04-08 14:31:13,371 INFO evaluator.py line 162 3298914] Test: [164/312] Loss 0.3265 
[2025-04-08 14:31:13,563 INFO evaluator.py line 162 3298914] Test: [165/312] Loss 1.8864 
[2025-04-08 14:31:13,735 INFO evaluator.py line 162 3298914] Test: [166/312] Loss 0.9746 
[2025-04-08 14:31:13,900 INFO evaluator.py line 162 3298914] Test: [167/312] Loss 1.1046 
[2025-04-08 14:31:14,098 INFO evaluator.py line 162 3298914] Test: [168/312] Loss 0.6073 
[2025-04-08 14:31:14,243 INFO evaluator.py line 162 3298914] Test: [169/312] Loss 1.1115 
[2025-04-08 14:31:14,399 INFO evaluator.py line 162 3298914] Test: [170/312] Loss 1.2352 
[2025-04-08 14:31:14,523 INFO evaluator.py line 162 3298914] Test: [171/312] Loss 0.9667 
[2025-04-08 14:31:14,693 INFO evaluator.py line 162 3298914] Test: [172/312] Loss 1.3614 
[2025-04-08 14:31:14,821 INFO evaluator.py line 162 3298914] Test: [173/312] Loss 0.7426 
[2025-04-08 14:31:14,930 INFO evaluator.py line 162 3298914] Test: [174/312] Loss 0.8406 
[2025-04-08 14:31:15,057 INFO evaluator.py line 162 3298914] Test: [175/312] Loss 1.1291 
[2025-04-08 14:31:15,208 INFO evaluator.py line 162 3298914] Test: [176/312] Loss 1.7107 
[2025-04-08 14:31:15,349 INFO evaluator.py line 162 3298914] Test: [177/312] Loss 1.2213 
[2025-04-08 14:31:15,490 INFO evaluator.py line 162 3298914] Test: [178/312] Loss 0.9831 
[2025-04-08 14:31:15,677 INFO evaluator.py line 162 3298914] Test: [179/312] Loss 1.5681 
[2025-04-08 14:31:15,805 INFO evaluator.py line 162 3298914] Test: [180/312] Loss 1.0728 
[2025-04-08 14:31:15,932 INFO evaluator.py line 162 3298914] Test: [181/312] Loss 1.4127 
[2025-04-08 14:31:16,042 INFO evaluator.py line 162 3298914] Test: [182/312] Loss 0.0780 
[2025-04-08 14:31:16,173 INFO evaluator.py line 162 3298914] Test: [183/312] Loss 1.1198 
[2025-04-08 14:31:16,333 INFO evaluator.py line 162 3298914] Test: [184/312] Loss 1.0248 
[2025-04-08 14:31:16,544 INFO evaluator.py line 162 3298914] Test: [185/312] Loss 1.4859 
[2025-04-08 14:31:16,733 INFO evaluator.py line 162 3298914] Test: [186/312] Loss 0.8741 
[2025-04-08 14:31:16,918 INFO evaluator.py line 162 3298914] Test: [187/312] Loss 1.6536 
[2025-04-08 14:31:17,213 INFO evaluator.py line 162 3298914] Test: [188/312] Loss 2.4871 
[2025-04-08 14:31:17,363 INFO evaluator.py line 162 3298914] Test: [189/312] Loss 0.8367 
[2025-04-08 14:31:17,520 INFO evaluator.py line 162 3298914] Test: [190/312] Loss 1.0125 
[2025-04-08 14:31:17,667 INFO evaluator.py line 162 3298914] Test: [191/312] Loss 1.4342 
[2025-04-08 14:31:17,857 INFO evaluator.py line 162 3298914] Test: [192/312] Loss 1.4460 
[2025-04-08 14:31:18,007 INFO evaluator.py line 162 3298914] Test: [193/312] Loss 1.5010 
[2025-04-08 14:31:18,208 INFO evaluator.py line 162 3298914] Test: [194/312] Loss 0.8871 
[2025-04-08 14:31:18,311 INFO evaluator.py line 162 3298914] Test: [195/312] Loss 0.1037 
[2025-04-08 14:31:18,456 INFO evaluator.py line 162 3298914] Test: [196/312] Loss 0.6647 
[2025-04-08 14:31:18,579 INFO evaluator.py line 162 3298914] Test: [197/312] Loss 0.6158 
[2025-04-08 14:31:18,747 INFO evaluator.py line 162 3298914] Test: [198/312] Loss 1.0985 
[2025-04-08 14:31:18,871 INFO evaluator.py line 162 3298914] Test: [199/312] Loss 1.0832 
[2025-04-08 14:31:19,159 INFO evaluator.py line 162 3298914] Test: [200/312] Loss 0.9648 
[2025-04-08 14:31:19,266 INFO evaluator.py line 162 3298914] Test: [201/312] Loss 0.5569 
[2025-04-08 14:31:19,439 INFO evaluator.py line 162 3298914] Test: [202/312] Loss 1.5706 
[2025-04-08 14:31:19,604 INFO evaluator.py line 162 3298914] Test: [203/312] Loss 0.1892 
[2025-04-08 14:31:19,768 INFO evaluator.py line 162 3298914] Test: [204/312] Loss 0.6662 
[2025-04-08 14:31:20,037 INFO evaluator.py line 162 3298914] Test: [205/312] Loss 1.0764 
[2025-04-08 14:31:20,195 INFO evaluator.py line 162 3298914] Test: [206/312] Loss 0.6187 
[2025-04-08 14:31:20,363 INFO evaluator.py line 162 3298914] Test: [207/312] Loss 0.8253 
[2025-04-08 14:31:20,501 INFO evaluator.py line 162 3298914] Test: [208/312] Loss 1.4853 
[2025-04-08 14:31:20,683 INFO evaluator.py line 162 3298914] Test: [209/312] Loss 0.6389 
[2025-04-08 14:31:20,960 INFO evaluator.py line 162 3298914] Test: [210/312] Loss 1.3200 
[2025-04-08 14:31:21,091 INFO evaluator.py line 162 3298914] Test: [211/312] Loss 1.8644 
[2025-04-08 14:31:21,231 INFO evaluator.py line 162 3298914] Test: [212/312] Loss 1.0363 
[2025-04-08 14:31:21,402 INFO evaluator.py line 162 3298914] Test: [213/312] Loss 1.3696 
[2025-04-08 14:31:21,561 INFO evaluator.py line 162 3298914] Test: [214/312] Loss 1.6008 
[2025-04-08 14:31:21,734 INFO evaluator.py line 162 3298914] Test: [215/312] Loss 1.8797 
[2025-04-08 14:31:21,870 INFO evaluator.py line 162 3298914] Test: [216/312] Loss 0.9111 
[2025-04-08 14:31:21,979 INFO evaluator.py line 162 3298914] Test: [217/312] Loss 0.7366 
[2025-04-08 14:31:22,178 INFO evaluator.py line 162 3298914] Test: [218/312] Loss 1.1789 
[2025-04-08 14:31:22,483 INFO evaluator.py line 162 3298914] Test: [219/312] Loss 0.5596 
[2025-04-08 14:31:22,718 INFO evaluator.py line 162 3298914] Test: [220/312] Loss 1.3959 
[2025-04-08 14:31:22,830 INFO evaluator.py line 162 3298914] Test: [221/312] Loss 1.4950 
[2025-04-08 14:31:22,970 INFO evaluator.py line 162 3298914] Test: [222/312] Loss 0.6230 
[2025-04-08 14:31:23,154 INFO evaluator.py line 162 3298914] Test: [223/312] Loss 1.6392 
[2025-04-08 14:31:23,262 INFO evaluator.py line 162 3298914] Test: [224/312] Loss 0.7244 
[2025-04-08 14:31:23,370 INFO evaluator.py line 162 3298914] Test: [225/312] Loss 0.9743 
[2025-04-08 14:31:23,657 INFO evaluator.py line 162 3298914] Test: [226/312] Loss 0.7088 
[2025-04-08 14:31:23,836 INFO evaluator.py line 162 3298914] Test: [227/312] Loss 1.3362 
[2025-04-08 14:31:24,017 INFO evaluator.py line 162 3298914] Test: [228/312] Loss 0.6083 
[2025-04-08 14:31:24,121 INFO evaluator.py line 162 3298914] Test: [229/312] Loss 0.1920 
[2025-04-08 14:31:24,245 INFO evaluator.py line 162 3298914] Test: [230/312] Loss 1.0296 
[2025-04-08 14:31:24,365 INFO evaluator.py line 162 3298914] Test: [231/312] Loss 0.6350 
[2025-04-08 14:31:24,548 INFO evaluator.py line 162 3298914] Test: [232/312] Loss 1.2048 
[2025-04-08 14:31:24,748 INFO evaluator.py line 162 3298914] Test: [233/312] Loss 1.1349 
[2025-04-08 14:31:24,942 INFO evaluator.py line 162 3298914] Test: [234/312] Loss 0.4307 
[2025-04-08 14:31:25,151 INFO evaluator.py line 162 3298914] Test: [235/312] Loss 0.7432 
[2025-04-08 14:31:25,336 INFO evaluator.py line 162 3298914] Test: [236/312] Loss 1.4239 
[2025-04-08 14:31:25,533 INFO evaluator.py line 162 3298914] Test: [237/312] Loss 1.5374 
[2025-04-08 14:31:25,722 INFO evaluator.py line 162 3298914] Test: [238/312] Loss 0.8670 
[2025-04-08 14:31:25,960 INFO evaluator.py line 162 3298914] Test: [239/312] Loss 0.7854 
[2025-04-08 14:31:26,082 INFO evaluator.py line 162 3298914] Test: [240/312] Loss 0.9369 
[2025-04-08 14:31:26,190 INFO evaluator.py line 162 3298914] Test: [241/312] Loss 0.8369 
[2025-04-08 14:31:26,474 INFO evaluator.py line 162 3298914] Test: [242/312] Loss 1.5223 
[2025-04-08 14:31:26,610 INFO evaluator.py line 162 3298914] Test: [243/312] Loss 0.5876 
[2025-04-08 14:31:26,800 INFO evaluator.py line 162 3298914] Test: [244/312] Loss 0.9606 
[2025-04-08 14:31:26,927 INFO evaluator.py line 162 3298914] Test: [245/312] Loss 1.0022 
[2025-04-08 14:31:27,196 INFO evaluator.py line 162 3298914] Test: [246/312] Loss 0.4931 
[2025-04-08 14:31:27,373 INFO evaluator.py line 162 3298914] Test: [247/312] Loss 1.1357 
[2025-04-08 14:31:27,594 INFO evaluator.py line 162 3298914] Test: [248/312] Loss 1.2823 
[2025-04-08 14:31:27,740 INFO evaluator.py line 162 3298914] Test: [249/312] Loss 1.4491 
[2025-04-08 14:31:27,865 INFO evaluator.py line 162 3298914] Test: [250/312] Loss 1.1308 
[2025-04-08 14:31:28,049 INFO evaluator.py line 162 3298914] Test: [251/312] Loss 0.6702 
[2025-04-08 14:31:28,166 INFO evaluator.py line 162 3298914] Test: [252/312] Loss 0.7476 
[2025-04-08 14:31:28,271 INFO evaluator.py line 162 3298914] Test: [253/312] Loss 0.9910 
[2025-04-08 14:31:28,381 INFO evaluator.py line 162 3298914] Test: [254/312] Loss 0.7765 
[2025-04-08 14:31:28,527 INFO evaluator.py line 162 3298914] Test: [255/312] Loss 1.0624 
[2025-04-08 14:31:28,670 INFO evaluator.py line 162 3298914] Test: [256/312] Loss 0.9954 
[2025-04-08 14:31:28,793 INFO evaluator.py line 162 3298914] Test: [257/312] Loss 1.3335 
[2025-04-08 14:31:28,984 INFO evaluator.py line 162 3298914] Test: [258/312] Loss 0.8741 
[2025-04-08 14:31:29,157 INFO evaluator.py line 162 3298914] Test: [259/312] Loss 1.5920 
[2025-04-08 14:31:29,335 INFO evaluator.py line 162 3298914] Test: [260/312] Loss 0.7078 
[2025-04-08 14:31:29,464 INFO evaluator.py line 162 3298914] Test: [261/312] Loss 1.5757 
[2025-04-08 14:31:29,668 INFO evaluator.py line 162 3298914] Test: [262/312] Loss 1.2348 
[2025-04-08 14:31:29,803 INFO evaluator.py line 162 3298914] Test: [263/312] Loss 0.7124 
[2025-04-08 14:31:29,980 INFO evaluator.py line 162 3298914] Test: [264/312] Loss 1.2177 
[2025-04-08 14:31:30,151 INFO evaluator.py line 162 3298914] Test: [265/312] Loss 1.8280 
[2025-04-08 14:31:30,279 INFO evaluator.py line 162 3298914] Test: [266/312] Loss 2.0638 
[2025-04-08 14:31:30,479 INFO evaluator.py line 162 3298914] Test: [267/312] Loss 1.4729 
[2025-04-08 14:31:30,652 INFO evaluator.py line 162 3298914] Test: [268/312] Loss 0.9743 
[2025-04-08 14:31:30,865 INFO evaluator.py line 162 3298914] Test: [269/312] Loss 1.6255 
[2025-04-08 14:31:31,078 INFO evaluator.py line 162 3298914] Test: [270/312] Loss 0.4242 
[2025-04-08 14:31:31,217 INFO evaluator.py line 162 3298914] Test: [271/312] Loss 0.8993 
[2025-04-08 14:31:31,403 INFO evaluator.py line 162 3298914] Test: [272/312] Loss 0.9765 
[2025-04-08 14:31:31,512 INFO evaluator.py line 162 3298914] Test: [273/312] Loss 1.0482 
[2025-04-08 14:31:31,731 INFO evaluator.py line 162 3298914] Test: [274/312] Loss 1.0861 
[2025-04-08 14:31:31,892 INFO evaluator.py line 162 3298914] Test: [275/312] Loss 0.9319 
[2025-04-08 14:31:32,014 INFO evaluator.py line 162 3298914] Test: [276/312] Loss 0.9505 
[2025-04-08 14:31:32,230 INFO evaluator.py line 162 3298914] Test: [277/312] Loss 1.0650 
[2025-04-08 14:31:32,383 INFO evaluator.py line 162 3298914] Test: [278/312] Loss 0.1519 
[2025-04-08 14:31:32,576 INFO evaluator.py line 162 3298914] Test: [279/312] Loss 1.2066 
[2025-04-08 14:31:32,723 INFO evaluator.py line 162 3298914] Test: [280/312] Loss 1.5467 
[2025-04-08 14:31:32,898 INFO evaluator.py line 162 3298914] Test: [281/312] Loss 0.8872 
[2025-04-08 14:31:33,006 INFO evaluator.py line 162 3298914] Test: [282/312] Loss 1.0750 
[2025-04-08 14:31:33,153 INFO evaluator.py line 162 3298914] Test: [283/312] Loss 1.6853 
[2025-04-08 14:31:33,270 INFO evaluator.py line 162 3298914] Test: [284/312] Loss 2.0039 
[2025-04-08 14:31:33,409 INFO evaluator.py line 162 3298914] Test: [285/312] Loss 1.3266 
[2025-04-08 14:31:33,657 INFO evaluator.py line 162 3298914] Test: [286/312] Loss 1.2260 
[2025-04-08 14:31:33,826 INFO evaluator.py line 162 3298914] Test: [287/312] Loss 1.5672 
[2025-04-08 14:31:33,953 INFO evaluator.py line 162 3298914] Test: [288/312] Loss 1.1040 
[2025-04-08 14:31:34,110 INFO evaluator.py line 162 3298914] Test: [289/312] Loss 0.9558 
[2025-04-08 14:31:34,271 INFO evaluator.py line 162 3298914] Test: [290/312] Loss 0.3070 
[2025-04-08 14:31:34,428 INFO evaluator.py line 162 3298914] Test: [291/312] Loss 0.9425 
[2025-04-08 14:31:34,610 INFO evaluator.py line 162 3298914] Test: [292/312] Loss 1.8333 
[2025-04-08 14:31:34,917 INFO evaluator.py line 162 3298914] Test: [293/312] Loss 1.5999 
[2025-04-08 14:31:35,025 INFO evaluator.py line 162 3298914] Test: [294/312] Loss 0.9218 
[2025-04-08 14:31:35,131 INFO evaluator.py line 162 3298914] Test: [295/312] Loss 0.7658 
[2025-04-08 14:31:35,364 INFO evaluator.py line 162 3298914] Test: [296/312] Loss 1.1112 
[2025-04-08 14:31:35,494 INFO evaluator.py line 162 3298914] Test: [297/312] Loss 1.7586 
[2025-04-08 14:31:35,707 INFO evaluator.py line 162 3298914] Test: [298/312] Loss 1.1484 
[2025-04-08 14:31:35,870 INFO evaluator.py line 162 3298914] Test: [299/312] Loss 1.0823 
[2025-04-08 14:31:36,043 INFO evaluator.py line 162 3298914] Test: [300/312] Loss 1.7239 
[2025-04-08 14:31:36,212 INFO evaluator.py line 162 3298914] Test: [301/312] Loss 0.3459 
[2025-04-08 14:31:36,407 INFO evaluator.py line 162 3298914] Test: [302/312] Loss 1.6283 
[2025-04-08 14:31:36,527 INFO evaluator.py line 162 3298914] Test: [303/312] Loss 0.2964 
[2025-04-08 14:31:36,733 INFO evaluator.py line 162 3298914] Test: [304/312] Loss 1.7447 
[2025-04-08 14:31:36,876 INFO evaluator.py line 162 3298914] Test: [305/312] Loss 1.2974 
[2025-04-08 14:31:36,976 INFO evaluator.py line 162 3298914] Test: [306/312] Loss 0.8398 
[2025-04-08 14:31:37,128 INFO evaluator.py line 162 3298914] Test: [307/312] Loss 1.1700 
[2025-04-08 14:31:37,358 INFO evaluator.py line 162 3298914] Test: [308/312] Loss 1.7436 
[2025-04-08 14:31:37,524 INFO evaluator.py line 162 3298914] Test: [309/312] Loss 0.7790 
[2025-04-08 14:31:37,632 INFO evaluator.py line 162 3298914] Test: [310/312] Loss 1.4129 
[2025-04-08 14:31:37,755 INFO evaluator.py line 162 3298914] Test: [311/312] Loss 0.6423 
[2025-04-08 14:31:37,944 INFO evaluator.py line 162 3298914] Test: [312/312] Loss 1.2927 
[2025-04-08 14:31:38,008 INFO evaluator.py line 177 3298914] Val result: mIoU/mAcc/allAcc 0.4860/0.6361/0.7956.
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_0-wall Result: iou/accuracy 0.7191/0.8491
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_1-floor Result: iou/accuracy 0.9498/0.9800
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_2-cabinet Result: iou/accuracy 0.4123/0.5799
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_3-bed Result: iou/accuracy 0.6439/0.6878
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_4-chair Result: iou/accuracy 0.7544/0.8799
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_5-sofa Result: iou/accuracy 0.6189/0.8356
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_6-table Result: iou/accuracy 0.5288/0.8189
[2025-04-08 14:31:38,008 INFO evaluator.py line 183 3298914] Class_7-door Result: iou/accuracy 0.2718/0.4624
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_8-window Result: iou/accuracy 0.4227/0.5525
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_9-bookshelf Result: iou/accuracy 0.6985/0.8888
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_10-picture Result: iou/accuracy 0.1562/0.2259
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_11-counter Result: iou/accuracy 0.4989/0.7143
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_12-desk Result: iou/accuracy 0.1451/0.1550
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_13-curtain Result: iou/accuracy 0.4715/0.6846
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_14-refridgerator Result: iou/accuracy 0.2534/0.4412
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_15-shower curtain Result: iou/accuracy 0.3069/0.3628
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_16-toilet Result: iou/accuracy 0.6808/0.9126
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_17-sink Result: iou/accuracy 0.4264/0.6006
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_18-bathtub Result: iou/accuracy 0.5531/0.8435
[2025-04-08 14:31:38,009 INFO evaluator.py line 183 3298914] Class_19-otherfurniture Result: iou/accuracy 0.2071/0.2473
[2025-04-08 14:31:38,009 INFO evaluator.py line 204 3298914] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2025-04-08 14:31:38,010 INFO misc.py line 154 3298914] Best validation mIoU updated to: 0.4860
[2025-04-08 14:31:38,010 INFO misc.py line 159 3298914] Currently Best mIoU: 0.4860
[2025-04-08 14:31:38,010 INFO misc.py line 168 3298914] Saving checkpoint to: /work3/s204157/data/ego3d/exp/sonata/debug/model/model_last.pth
[2025-04-08 14:31:49,524 INFO misc.py line 113 3298914] Train: [3/100][1/2402] Data 2.763 (2.763) Batch 3.714 (3.714) Remain 242:49:26 loss: 1.1025 Lr: 0.00082
[2025-04-08 14:31:50,418 INFO misc.py line 113 3298914] Train: [3/100][2/2402] Data 0.020 (0.020) Batch 0.894 (0.894) Remain 58:27:38 loss: 1.2354 Lr: 0.00082
[2025-04-08 14:31:50,861 INFO misc.py line 113 3298914] Train: [3/100][3/2402] Data 0.003 (0.003) Batch 0.443 (0.443) Remain 28:58:41 loss: 1.2095 Lr: 0.00082
[2025-04-08 14:31:51,455 INFO misc.py line 113 3298914] Train: [3/100][4/2402] Data 0.004 (0.004) Batch 0.594 (0.594) Remain 38:48:59 loss: 1.3782 Lr: 0.00082
[2025-04-08 14:31:51,961 INFO misc.py line 113 3298914] Train: [3/100][5/2402] Data 0.003 (0.004) Batch 0.507 (0.550) Remain 35:58:50 loss: 1.2062 Lr: 0.00082
[2025-04-08 14:31:52,317 INFO misc.py line 113 3298914] Train: [3/100][6/2402] Data 0.004 (0.004) Batch 0.356 (0.485) Remain 31:44:20 loss: 1.2197 Lr: 0.00082
[2025-04-08 14:31:52,743 INFO misc.py line 113 3298914] Train: [3/100][7/2402] Data 0.003 (0.004) Batch 0.426 (0.471) Remain 30:46:01 loss: 1.3388 Lr: 0.00082
[2025-04-08 14:31:53,156 INFO misc.py line 113 3298914] Train: [3/100][8/2402] Data 0.003 (0.003) Batch 0.413 (0.459) Remain 30:00:58 loss: 1.4583 Lr: 0.00082
[2025-04-08 14:31:53,729 INFO misc.py line 113 3298914] Train: [3/100][9/2402] Data 0.003 (0.003) Batch 0.573 (0.478) Remain 31:15:18 loss: 1.3944 Lr: 0.00082
[2025-04-08 14:31:54,249 INFO misc.py line 113 3298914] Train: [3/100][10/2402] Data 0.004 (0.004) Batch 0.520 (0.484) Remain 31:38:45 loss: 1.2508 Lr: 0.00082
[2025-04-08 14:31:54,830 INFO misc.py line 113 3298914] Train: [3/100][11/2402] Data 0.004 (0.004) Batch 0.581 (0.496) Remain 32:26:13 loss: 1.4434 Lr: 0.00082
[2025-04-08 14:31:55,268 INFO misc.py line 113 3298914] Train: [3/100][12/2402] Data 0.004 (0.004) Batch 0.438 (0.490) Remain 32:00:44 loss: 1.2603 Lr: 0.00082
[2025-04-08 14:31:55,879 INFO misc.py line 113 3298914] Train: [3/100][13/2402] Data 0.004 (0.004) Batch 0.611 (0.502) Remain 32:48:26 loss: 1.0898 Lr: 0.00082
[2025-04-08 14:31:56,365 INFO misc.py line 113 3298914] Train: [3/100][14/2402] Data 0.003 (0.004) Batch 0.486 (0.500) Remain 32:42:53 loss: 1.0744 Lr: 0.00082
[2025-04-08 14:31:56,849 INFO misc.py line 113 3298914] Train: [3/100][15/2402] Data 0.004 (0.004) Batch 0.484 (0.499) Remain 32:37:28 loss: 1.0400 Lr: 0.00082
[2025-04-08 14:31:57,332 INFO misc.py line 113 3298914] Train: [3/100][16/2402] Data 0.003 (0.004) Batch 0.483 (0.498) Remain 32:32:40 loss: 1.2630 Lr: 0.00082
[2025-04-08 14:31:57,678 INFO misc.py line 113 3298914] Train: [3/100][17/2402] Data 0.003 (0.004) Batch 0.346 (0.487) Remain 31:50:09 loss: 0.8733 Lr: 0.00082
[2025-04-08 14:31:58,103 INFO misc.py line 113 3298914] Train: [3/100][18/2402] Data 0.003 (0.004) Batch 0.425 (0.483) Remain 31:34:01 loss: 1.1134 Lr: 0.00083
[2025-04-08 14:31:58,539 INFO misc.py line 113 3298914] Train: [3/100][19/2402] Data 0.003 (0.003) Batch 0.435 (0.480) Remain 31:22:22 loss: 0.9386 Lr: 0.00083
[2025-04-08 14:31:58,931 INFO misc.py line 113 3298914] Train: [3/100][20/2402] Data 0.004 (0.004) Batch 0.393 (0.475) Remain 31:02:16 loss: 1.2089 Lr: 0.00083
[2025-04-08 14:31:59,415 INFO misc.py line 113 3298914] Train: [3/100][21/2402] Data 0.004 (0.004) Batch 0.483 (0.475) Remain 31:04:10 loss: 1.5393 Lr: 0.00083
[2025-04-08 14:31:59,830 INFO misc.py line 113 3298914] Train: [3/100][22/2402] Data 0.003 (0.004) Batch 0.416 (0.472) Remain 30:51:54 loss: 1.4131 Lr: 0.00083
[2025-04-08 14:32:00,400 INFO misc.py line 113 3298914] Train: [3/100][23/2402] Data 0.004 (0.004) Batch 0.569 (0.477) Remain 31:10:59 loss: 1.3670 Lr: 0.00083
[2025-04-08 14:32:00,976 INFO misc.py line 113 3298914] Train: [3/100][24/2402] Data 0.004 (0.004) Batch 0.576 (0.482) Remain 31:29:30 loss: 1.4233 Lr: 0.00083
[2025-04-08 14:32:01,456 INFO misc.py line 113 3298914] Train: [3/100][25/2402] Data 0.004 (0.004) Batch 0.479 (0.482) Remain 31:29:02 loss: 1.0013 Lr: 0.00083
[2025-04-08 14:32:01,904 INFO misc.py line 113 3298914] Train: [3/100][26/2402] Data 0.004 (0.004) Batch 0.449 (0.480) Remain 31:23:29 loss: 1.0149 Lr: 0.00083
[2025-04-08 14:32:02,387 INFO misc.py line 113 3298914] Train: [3/100][27/2402] Data 0.004 (0.004) Batch 0.482 (0.480) Remain 31:23:51 loss: 0.9254 Lr: 0.00083
[2025-04-08 14:32:02,802 INFO misc.py line 113 3298914] Train: [3/100][28/2402] Data 0.003 (0.004) Batch 0.415 (0.478) Remain 31:13:37 loss: 1.1335 Lr: 0.00083
[2025-04-08 14:32:03,324 INFO misc.py line 113 3298914] Train: [3/100][29/2402] Data 0.004 (0.004) Batch 0.522 (0.479) Remain 31:20:16 loss: 1.3872 Lr: 0.00083
[2025-04-08 14:32:03,792 INFO misc.py line 113 3298914] Train: [3/100][30/2402] Data 0.004 (0.004) Batch 0.468 (0.479) Remain 31:18:37 loss: 1.5144 Lr: 0.00083
[2025-04-08 14:32:04,291 INFO misc.py line 113 3298914] Train: [3/100][31/2402] Data 0.004 (0.004) Batch 0.499 (0.480) Remain 31:21:28 loss: 1.3361 Lr: 0.00083
[2025-04-08 14:32:04,801 INFO misc.py line 113 3298914] Train: [3/100][32/2402] Data 0.003 (0.004) Batch 0.511 (0.481) Remain 31:25:40 loss: 0.9815 Lr: 0.00083
[2025-04-08 14:32:05,276 INFO misc.py line 113 3298914] Train: [3/100][33/2402] Data 0.004 (0.004) Batch 0.474 (0.480) Remain 31:24:49 loss: 1.6176 Lr: 0.00083
[2025-04-08 14:32:05,805 INFO misc.py line 113 3298914] Train: [3/100][34/2402] Data 0.003 (0.004) Batch 0.529 (0.482) Remain 31:30:55 loss: 1.4133 Lr: 0.00083
[2025-04-08 14:32:06,305 INFO misc.py line 113 3298914] Train: [3/100][35/2402] Data 0.004 (0.004) Batch 0.501 (0.483) Remain 31:33:11 loss: 1.5549 Lr: 0.00083
[2025-04-08 14:32:06,729 INFO misc.py line 113 3298914] Train: [3/100][36/2402] Data 0.003 (0.004) Batch 0.424 (0.481) Remain 31:26:11 loss: 0.8783 Lr: 0.00083
[2025-04-08 14:32:07,260 INFO misc.py line 113 3298914] Train: [3/100][37/2402] Data 0.004 (0.004) Batch 0.530 (0.482) Remain 31:31:53 loss: 1.2975 Lr: 0.00083
[2025-04-08 14:32:07,703 INFO misc.py line 113 3298914] Train: [3/100][38/2402] Data 0.004 (0.004) Batch 0.444 (0.481) Remain 31:27:34 loss: 1.6929 Lr: 0.00083
[2025-04-08 14:32:08,191 INFO misc.py line 113 3298914] Train: [3/100][39/2402] Data 0.004 (0.004) Batch 0.488 (0.481) Remain 31:28:18 loss: 1.2202 Lr: 0.00083
[2025-04-08 14:32:08,584 INFO misc.py line 113 3298914] Train: [3/100][40/2402] Data 0.003 (0.004) Batch 0.392 (0.479) Remain 31:18:47 loss: 0.7890 Lr: 0.00083
[2025-04-08 14:32:09,157 INFO misc.py line 113 3298914] Train: [3/100][41/2402] Data 0.005 (0.004) Batch 0.574 (0.481) Remain 31:28:35 loss: 1.0806 Lr: 0.00083
[2025-04-08 14:32:09,533 INFO misc.py line 113 3298914] Train: [3/100][42/2402] Data 0.003 (0.004) Batch 0.376 (0.479) Remain 31:17:59 loss: 1.4315 Lr: 0.00083
[2025-04-08 14:32:10,033 INFO misc.py line 113 3298914] Train: [3/100][43/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:20:04 loss: 1.4206 Lr: 0.00083
[2025-04-08 14:32:10,463 INFO misc.py line 113 3298914] Train: [3/100][44/2402] Data 0.003 (0.004) Batch 0.430 (0.478) Remain 31:15:18 loss: 1.1404 Lr: 0.00083
[2025-04-08 14:32:10,841 INFO misc.py line 113 3298914] Train: [3/100][45/2402] Data 0.004 (0.004) Batch 0.378 (0.476) Remain 31:05:56 loss: 0.7927 Lr: 0.00083
[2025-04-08 14:32:11,287 INFO misc.py line 113 3298914] Train: [3/100][46/2402] Data 0.003 (0.004) Batch 0.446 (0.475) Remain 31:03:14 loss: 1.1837 Lr: 0.00083
[2025-04-08 14:32:11,760 INFO misc.py line 113 3298914] Train: [3/100][47/2402] Data 0.004 (0.004) Batch 0.474 (0.475) Remain 31:03:07 loss: 0.8888 Lr: 0.00083
[2025-04-08 14:32:12,281 INFO misc.py line 113 3298914] Train: [3/100][48/2402] Data 0.004 (0.004) Batch 0.520 (0.476) Remain 31:07:03 loss: 1.1396 Lr: 0.00083
[2025-04-08 14:32:12,796 INFO misc.py line 113 3298914] Train: [3/100][49/2402] Data 0.003 (0.004) Batch 0.515 (0.477) Remain 31:10:24 loss: 1.2878 Lr: 0.00083
[2025-04-08 14:32:13,273 INFO misc.py line 113 3298914] Train: [3/100][50/2402] Data 0.004 (0.004) Batch 0.477 (0.477) Remain 31:10:24 loss: 1.2023 Lr: 0.00083
[2025-04-08 14:32:13,809 INFO misc.py line 113 3298914] Train: [3/100][51/2402] Data 0.004 (0.004) Batch 0.535 (0.478) Remain 31:15:11 loss: 1.7374 Lr: 0.00083
[2025-04-08 14:32:14,324 INFO misc.py line 113 3298914] Train: [3/100][52/2402] Data 0.004 (0.004) Batch 0.515 (0.479) Remain 31:18:09 loss: 1.2179 Lr: 0.00083
[2025-04-08 14:32:14,740 INFO misc.py line 113 3298914] Train: [3/100][53/2402] Data 0.004 (0.004) Batch 0.416 (0.478) Remain 31:13:13 loss: 1.2948 Lr: 0.00083
[2025-04-08 14:32:15,277 INFO misc.py line 113 3298914] Train: [3/100][54/2402] Data 0.003 (0.004) Batch 0.537 (0.479) Remain 31:17:44 loss: 1.4060 Lr: 0.00083
[2025-04-08 14:32:15,866 INFO misc.py line 113 3298914] Train: [3/100][55/2402] Data 0.004 (0.004) Batch 0.589 (0.481) Remain 31:26:03 loss: 1.3510 Lr: 0.00083
[2025-04-08 14:32:16,294 INFO misc.py line 113 3298914] Train: [3/100][56/2402] Data 0.004 (0.004) Batch 0.429 (0.480) Remain 31:22:13 loss: 1.2767 Lr: 0.00083
[2025-04-08 14:32:16,803 INFO misc.py line 113 3298914] Train: [3/100][57/2402] Data 0.004 (0.004) Batch 0.508 (0.480) Remain 31:24:17 loss: 1.2963 Lr: 0.00083
[2025-04-08 14:32:17,244 INFO misc.py line 113 3298914] Train: [3/100][58/2402] Data 0.003 (0.004) Batch 0.440 (0.480) Remain 31:21:25 loss: 1.4823 Lr: 0.00083
[2025-04-08 14:32:17,734 INFO misc.py line 113 3298914] Train: [3/100][59/2402] Data 0.004 (0.004) Batch 0.491 (0.480) Remain 31:22:10 loss: 1.1426 Lr: 0.00083
[2025-04-08 14:32:18,277 INFO misc.py line 113 3298914] Train: [3/100][60/2402] Data 0.003 (0.004) Batch 0.543 (0.481) Remain 31:26:30 loss: 1.7073 Lr: 0.00083
[2025-04-08 14:32:18,818 INFO misc.py line 113 3298914] Train: [3/100][61/2402] Data 0.004 (0.004) Batch 0.541 (0.482) Remain 31:30:33 loss: 1.3941 Lr: 0.00083
[2025-04-08 14:32:19,304 INFO misc.py line 113 3298914] Train: [3/100][62/2402] Data 0.004 (0.004) Batch 0.486 (0.482) Remain 31:30:48 loss: 1.0902 Lr: 0.00083
[2025-04-08 14:32:19,727 INFO misc.py line 113 3298914] Train: [3/100][63/2402] Data 0.004 (0.004) Batch 0.424 (0.481) Remain 31:26:59 loss: 1.4260 Lr: 0.00084
[2025-04-08 14:32:20,201 INFO misc.py line 113 3298914] Train: [3/100][64/2402] Data 0.004 (0.004) Batch 0.474 (0.481) Remain 31:26:29 loss: 1.1158 Lr: 0.00084
[2025-04-08 14:32:20,659 INFO misc.py line 113 3298914] Train: [3/100][65/2402] Data 0.004 (0.004) Batch 0.458 (0.481) Remain 31:25:01 loss: 1.4831 Lr: 0.00084
[2025-04-08 14:32:21,227 INFO misc.py line 113 3298914] Train: [3/100][66/2402] Data 0.004 (0.004) Batch 0.569 (0.482) Remain 31:30:29 loss: 1.2044 Lr: 0.00084
[2025-04-08 14:32:21,718 INFO misc.py line 113 3298914] Train: [3/100][67/2402] Data 0.004 (0.004) Batch 0.491 (0.482) Remain 31:31:01 loss: 1.3297 Lr: 0.00084
[2025-04-08 14:32:22,243 INFO misc.py line 113 3298914] Train: [3/100][68/2402] Data 0.004 (0.004) Batch 0.525 (0.483) Remain 31:33:35 loss: 1.1118 Lr: 0.00084
[2025-04-08 14:32:22,731 INFO misc.py line 113 3298914] Train: [3/100][69/2402] Data 0.004 (0.004) Batch 0.489 (0.483) Remain 31:33:56 loss: 0.9365 Lr: 0.00084
[2025-04-08 14:32:23,219 INFO misc.py line 113 3298914] Train: [3/100][70/2402] Data 0.003 (0.004) Batch 0.488 (0.483) Remain 31:34:12 loss: 1.1620 Lr: 0.00084
[2025-04-08 14:32:23,724 INFO misc.py line 113 3298914] Train: [3/100][71/2402] Data 0.003 (0.004) Batch 0.505 (0.483) Remain 31:35:29 loss: 1.1729 Lr: 0.00084
[2025-04-08 14:32:24,153 INFO misc.py line 113 3298914] Train: [3/100][72/2402] Data 0.003 (0.004) Batch 0.428 (0.482) Remain 31:32:19 loss: 0.9302 Lr: 0.00084
[2025-04-08 14:32:24,537 INFO misc.py line 113 3298914] Train: [3/100][73/2402] Data 0.004 (0.004) Batch 0.384 (0.481) Remain 31:26:49 loss: 1.3057 Lr: 0.00084
[2025-04-08 14:32:25,003 INFO misc.py line 113 3298914] Train: [3/100][74/2402] Data 0.003 (0.004) Batch 0.466 (0.481) Remain 31:25:58 loss: 1.2588 Lr: 0.00084
[2025-04-08 14:32:25,380 INFO misc.py line 113 3298914] Train: [3/100][75/2402] Data 0.004 (0.004) Batch 0.377 (0.479) Remain 31:20:18 loss: 1.2442 Lr: 0.00084
[2025-04-08 14:32:25,841 INFO misc.py line 113 3298914] Train: [3/100][76/2402] Data 0.004 (0.004) Batch 0.462 (0.479) Remain 31:19:20 loss: 1.2104 Lr: 0.00084
[2025-04-08 14:32:26,175 INFO misc.py line 113 3298914] Train: [3/100][77/2402] Data 0.003 (0.004) Batch 0.334 (0.477) Remain 31:11:39 loss: 1.3554 Lr: 0.00084
[2025-04-08 14:32:26,593 INFO misc.py line 113 3298914] Train: [3/100][78/2402] Data 0.003 (0.004) Batch 0.418 (0.476) Remain 31:08:32 loss: 1.5361 Lr: 0.00084
[2025-04-08 14:32:27,101 INFO misc.py line 113 3298914] Train: [3/100][79/2402] Data 0.003 (0.004) Batch 0.508 (0.477) Remain 31:10:08 loss: 1.5868 Lr: 0.00084
[2025-04-08 14:32:27,655 INFO misc.py line 113 3298914] Train: [3/100][80/2402] Data 0.004 (0.004) Batch 0.554 (0.478) Remain 31:14:04 loss: 1.1774 Lr: 0.00084
[2025-04-08 14:32:28,153 INFO misc.py line 113 3298914] Train: [3/100][81/2402] Data 0.004 (0.004) Batch 0.497 (0.478) Remain 31:15:02 loss: 1.1739 Lr: 0.00084
[2025-04-08 14:32:28,657 INFO misc.py line 113 3298914] Train: [3/100][82/2402] Data 0.004 (0.004) Batch 0.504 (0.478) Remain 31:16:19 loss: 1.0612 Lr: 0.00084
[2025-04-08 14:32:29,113 INFO misc.py line 113 3298914] Train: [3/100][83/2402] Data 0.003 (0.004) Batch 0.456 (0.478) Remain 31:15:13 loss: 1.1130 Lr: 0.00084
[2025-04-08 14:32:29,581 INFO misc.py line 113 3298914] Train: [3/100][84/2402] Data 0.004 (0.004) Batch 0.469 (0.478) Remain 31:14:45 loss: 1.1594 Lr: 0.00084
[2025-04-08 14:32:29,942 INFO misc.py line 113 3298914] Train: [3/100][85/2402] Data 0.003 (0.004) Batch 0.360 (0.477) Remain 31:09:07 loss: 1.3242 Lr: 0.00084
[2025-04-08 14:32:30,475 INFO misc.py line 113 3298914] Train: [3/100][86/2402] Data 0.003 (0.004) Batch 0.533 (0.477) Remain 31:11:47 loss: 1.6310 Lr: 0.00084
[2025-04-08 14:32:31,010 INFO misc.py line 113 3298914] Train: [3/100][87/2402] Data 0.004 (0.004) Batch 0.535 (0.478) Remain 31:14:29 loss: 0.9859 Lr: 0.00084
[2025-04-08 14:32:31,435 INFO misc.py line 113 3298914] Train: [3/100][88/2402] Data 0.004 (0.004) Batch 0.424 (0.477) Remain 31:12:00 loss: 1.1876 Lr: 0.00084
[2025-04-08 14:32:31,864 INFO misc.py line 113 3298914] Train: [3/100][89/2402] Data 0.003 (0.004) Batch 0.429 (0.477) Remain 31:09:47 loss: 1.5463 Lr: 0.00084
[2025-04-08 14:32:32,358 INFO misc.py line 113 3298914] Train: [3/100][90/2402] Data 0.004 (0.004) Batch 0.495 (0.477) Remain 31:10:35 loss: 1.1075 Lr: 0.00084
[2025-04-08 14:32:32,701 INFO misc.py line 113 3298914] Train: [3/100][91/2402] Data 0.003 (0.004) Batch 0.342 (0.475) Remain 31:04:35 loss: 1.4626 Lr: 0.00084
[2025-04-08 14:32:33,123 INFO misc.py line 113 3298914] Train: [3/100][92/2402] Data 0.004 (0.004) Batch 0.422 (0.475) Remain 31:02:14 loss: 0.9211 Lr: 0.00084
[2025-04-08 14:32:33,719 INFO misc.py line 113 3298914] Train: [3/100][93/2402] Data 0.004 (0.004) Batch 0.595 (0.476) Remain 31:07:28 loss: 1.1990 Lr: 0.00084
[2025-04-08 14:32:34,213 INFO misc.py line 113 3298914] Train: [3/100][94/2402] Data 0.004 (0.004) Batch 0.494 (0.476) Remain 31:08:15 loss: 0.9462 Lr: 0.00084
[2025-04-08 14:32:34,700 INFO misc.py line 113 3298914] Train: [3/100][95/2402] Data 0.004 (0.004) Batch 0.488 (0.477) Remain 31:08:43 loss: 1.0717 Lr: 0.00084
[2025-04-08 14:32:35,230 INFO misc.py line 113 3298914] Train: [3/100][96/2402] Data 0.003 (0.004) Batch 0.530 (0.477) Remain 31:10:58 loss: 1.2645 Lr: 0.00084
[2025-04-08 14:32:35,625 INFO misc.py line 113 3298914] Train: [3/100][97/2402] Data 0.004 (0.004) Batch 0.395 (0.476) Remain 31:07:31 loss: 1.2356 Lr: 0.00084
[2025-04-08 14:32:36,035 INFO misc.py line 113 3298914] Train: [3/100][98/2402] Data 0.003 (0.004) Batch 0.410 (0.476) Remain 31:04:46 loss: 1.2719 Lr: 0.00084
[2025-04-08 14:32:36,453 INFO misc.py line 113 3298914] Train: [3/100][99/2402] Data 0.004 (0.004) Batch 0.418 (0.475) Remain 31:02:26 loss: 1.2479 Lr: 0.00084
[2025-04-08 14:32:36,952 INFO misc.py line 113 3298914] Train: [3/100][100/2402] Data 0.004 (0.004) Batch 0.499 (0.475) Remain 31:03:24 loss: 1.0214 Lr: 0.00084
[2025-04-08 14:32:37,405 INFO misc.py line 113 3298914] Train: [3/100][101/2402] Data 0.004 (0.004) Batch 0.453 (0.475) Remain 31:02:30 loss: 1.2080 Lr: 0.00084
[2025-04-08 14:32:37,938 INFO misc.py line 113 3298914] Train: [3/100][102/2402] Data 0.003 (0.004) Batch 0.533 (0.476) Remain 31:04:48 loss: 1.5418 Lr: 0.00084
[2025-04-08 14:32:38,471 INFO misc.py line 113 3298914] Train: [3/100][103/2402] Data 0.004 (0.004) Batch 0.533 (0.476) Remain 31:07:02 loss: 1.3250 Lr: 0.00084
[2025-04-08 14:32:38,978 INFO misc.py line 113 3298914] Train: [3/100][104/2402] Data 0.003 (0.004) Batch 0.507 (0.476) Remain 31:08:15 loss: 0.7791 Lr: 0.00084
[2025-04-08 14:32:39,420 INFO misc.py line 113 3298914] Train: [3/100][105/2402] Data 0.003 (0.004) Batch 0.441 (0.476) Remain 31:06:53 loss: 1.3471 Lr: 0.00084
[2025-04-08 14:32:39,979 INFO misc.py line 113 3298914] Train: [3/100][106/2402] Data 0.004 (0.004) Batch 0.559 (0.477) Remain 31:10:03 loss: 1.5897 Lr: 0.00084
[2025-04-08 14:32:40,427 INFO misc.py line 113 3298914] Train: [3/100][107/2402] Data 0.003 (0.004) Batch 0.448 (0.477) Remain 31:08:57 loss: 1.3819 Lr: 0.00085
[2025-04-08 14:32:40,879 INFO misc.py line 113 3298914] Train: [3/100][108/2402] Data 0.004 (0.004) Batch 0.452 (0.476) Remain 31:08:01 loss: 1.6429 Lr: 0.00085
[2025-04-08 14:32:41,614 INFO misc.py line 113 3298914] Train: [3/100][109/2402] Data 0.004 (0.004) Batch 0.735 (0.479) Remain 31:17:34 loss: 1.7145 Lr: 0.00085
[2025-04-08 14:32:42,113 INFO misc.py line 113 3298914] Train: [3/100][110/2402] Data 0.004 (0.004) Batch 0.500 (0.479) Remain 31:18:20 loss: 1.3267 Lr: 0.00085
[2025-04-08 14:32:42,568 INFO misc.py line 113 3298914] Train: [3/100][111/2402] Data 0.003 (0.004) Batch 0.454 (0.479) Remain 31:17:25 loss: 1.3331 Lr: 0.00085
[2025-04-08 14:32:42,982 INFO misc.py line 113 3298914] Train: [3/100][112/2402] Data 0.004 (0.004) Batch 0.415 (0.478) Remain 31:15:06 loss: 1.0781 Lr: 0.00085
[2025-04-08 14:32:43,452 INFO misc.py line 113 3298914] Train: [3/100][113/2402] Data 0.004 (0.004) Batch 0.470 (0.478) Remain 31:14:48 loss: 1.0415 Lr: 0.00085
[2025-04-08 14:32:43,984 INFO misc.py line 113 3298914] Train: [3/100][114/2402] Data 0.003 (0.004) Batch 0.531 (0.479) Remain 31:16:41 loss: 1.1255 Lr: 0.00085
[2025-04-08 14:32:44,411 INFO misc.py line 113 3298914] Train: [3/100][115/2402] Data 0.004 (0.004) Batch 0.427 (0.478) Remain 31:14:52 loss: 1.4867 Lr: 0.00085
[2025-04-08 14:32:44,908 INFO misc.py line 113 3298914] Train: [3/100][116/2402] Data 0.004 (0.004) Batch 0.497 (0.478) Remain 31:15:31 loss: 1.2708 Lr: 0.00085
[2025-04-08 14:32:45,445 INFO misc.py line 113 3298914] Train: [3/100][117/2402] Data 0.004 (0.004) Batch 0.537 (0.479) Remain 31:17:31 loss: 1.6063 Lr: 0.00085
[2025-04-08 14:32:45,871 INFO misc.py line 113 3298914] Train: [3/100][118/2402] Data 0.004 (0.004) Batch 0.427 (0.478) Remain 31:15:44 loss: 1.2359 Lr: 0.00085
[2025-04-08 14:32:46,361 INFO misc.py line 113 3298914] Train: [3/100][119/2402] Data 0.004 (0.004) Batch 0.490 (0.478) Remain 31:16:06 loss: 1.2265 Lr: 0.00085
[2025-04-08 14:32:46,736 INFO misc.py line 113 3298914] Train: [3/100][120/2402] Data 0.003 (0.004) Batch 0.375 (0.478) Remain 31:12:37 loss: 1.2361 Lr: 0.00085
[2025-04-08 14:32:47,172 INFO misc.py line 113 3298914] Train: [3/100][121/2402] Data 0.004 (0.004) Batch 0.436 (0.477) Remain 31:11:14 loss: 0.9896 Lr: 0.00085
[2025-04-08 14:32:47,702 INFO misc.py line 113 3298914] Train: [3/100][122/2402] Data 0.004 (0.004) Batch 0.530 (0.478) Remain 31:12:58 loss: 1.0276 Lr: 0.00085
[2025-04-08 14:32:48,216 INFO misc.py line 113 3298914] Train: [3/100][123/2402] Data 0.004 (0.004) Batch 0.514 (0.478) Remain 31:14:10 loss: 1.3334 Lr: 0.00085
[2025-04-08 14:32:48,694 INFO misc.py line 113 3298914] Train: [3/100][124/2402] Data 0.004 (0.004) Batch 0.478 (0.478) Remain 31:14:09 loss: 1.2063 Lr: 0.00085
[2025-04-08 14:32:49,138 INFO misc.py line 113 3298914] Train: [3/100][125/2402] Data 0.004 (0.004) Batch 0.444 (0.478) Remain 31:13:02 loss: 1.2582 Lr: 0.00085
[2025-04-08 14:32:49,558 INFO misc.py line 113 3298914] Train: [3/100][126/2402] Data 0.004 (0.004) Batch 0.420 (0.477) Remain 31:11:12 loss: 1.4591 Lr: 0.00085
[2025-04-08 14:32:50,008 INFO misc.py line 113 3298914] Train: [3/100][127/2402] Data 0.004 (0.004) Batch 0.450 (0.477) Remain 31:10:20 loss: 1.1026 Lr: 0.00085
[2025-04-08 14:32:50,600 INFO misc.py line 113 3298914] Train: [3/100][128/2402] Data 0.004 (0.004) Batch 0.592 (0.478) Remain 31:13:55 loss: 1.3954 Lr: 0.00085
[2025-04-08 14:32:51,148 INFO misc.py line 113 3298914] Train: [3/100][129/2402] Data 0.004 (0.004) Batch 0.548 (0.478) Remain 31:16:06 loss: 1.5409 Lr: 0.00085
[2025-04-08 14:32:51,500 INFO misc.py line 113 3298914] Train: [3/100][130/2402] Data 0.004 (0.004) Batch 0.352 (0.477) Remain 31:12:11 loss: 1.1349 Lr: 0.00085
[2025-04-08 14:32:51,866 INFO misc.py line 113 3298914] Train: [3/100][131/2402] Data 0.003 (0.004) Batch 0.366 (0.477) Remain 31:08:46 loss: 1.0986 Lr: 0.00085
[2025-04-08 14:32:52,284 INFO misc.py line 113 3298914] Train: [3/100][132/2402] Data 0.004 (0.004) Batch 0.418 (0.476) Remain 31:06:58 loss: 1.8410 Lr: 0.00085
[2025-04-08 14:32:52,744 INFO misc.py line 113 3298914] Train: [3/100][133/2402] Data 0.003 (0.004) Batch 0.461 (0.476) Remain 31:06:30 loss: 0.9545 Lr: 0.00085
[2025-04-08 14:32:53,234 INFO misc.py line 113 3298914] Train: [3/100][134/2402] Data 0.003 (0.004) Batch 0.489 (0.476) Remain 31:06:53 loss: 0.9807 Lr: 0.00085
[2025-04-08 14:32:53,750 INFO misc.py line 113 3298914] Train: [3/100][135/2402] Data 0.004 (0.004) Batch 0.517 (0.476) Remain 31:08:05 loss: 1.1996 Lr: 0.00085
[2025-04-08 14:32:54,342 INFO misc.py line 113 3298914] Train: [3/100][136/2402] Data 0.004 (0.004) Batch 0.592 (0.477) Remain 31:11:29 loss: 1.6157 Lr: 0.00085
[2025-04-08 14:32:54,859 INFO misc.py line 113 3298914] Train: [3/100][137/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:12:37 loss: 1.1977 Lr: 0.00085
[2025-04-08 14:32:55,256 INFO misc.py line 113 3298914] Train: [3/100][138/2402] Data 0.004 (0.004) Batch 0.398 (0.477) Remain 31:10:17 loss: 1.3247 Lr: 0.00085
[2025-04-08 14:32:55,799 INFO misc.py line 113 3298914] Train: [3/100][139/2402] Data 0.003 (0.004) Batch 0.543 (0.477) Remain 31:12:11 loss: 1.8563 Lr: 0.00085
[2025-04-08 14:32:56,290 INFO misc.py line 113 3298914] Train: [3/100][140/2402] Data 0.004 (0.004) Batch 0.490 (0.478) Remain 31:12:33 loss: 1.4589 Lr: 0.00085
[2025-04-08 14:32:56,754 INFO misc.py line 113 3298914] Train: [3/100][141/2402] Data 0.004 (0.004) Batch 0.464 (0.477) Remain 31:12:10 loss: 1.4786 Lr: 0.00085
[2025-04-08 14:32:57,172 INFO misc.py line 113 3298914] Train: [3/100][142/2402] Data 0.004 (0.004) Batch 0.418 (0.477) Remain 31:10:29 loss: 1.4729 Lr: 0.00085
[2025-04-08 14:32:57,729 INFO misc.py line 113 3298914] Train: [3/100][143/2402] Data 0.003 (0.004) Batch 0.557 (0.478) Remain 31:12:43 loss: 1.3114 Lr: 0.00085
[2025-04-08 14:32:58,147 INFO misc.py line 113 3298914] Train: [3/100][144/2402] Data 0.004 (0.004) Batch 0.418 (0.477) Remain 31:11:02 loss: 1.1067 Lr: 0.00085
[2025-04-08 14:32:58,714 INFO misc.py line 113 3298914] Train: [3/100][145/2402] Data 0.004 (0.004) Batch 0.567 (0.478) Remain 31:13:31 loss: 1.5213 Lr: 0.00085
[2025-04-08 14:32:59,192 INFO misc.py line 113 3298914] Train: [3/100][146/2402] Data 0.003 (0.004) Batch 0.478 (0.478) Remain 31:13:30 loss: 1.0171 Lr: 0.00085
[2025-04-08 14:32:59,588 INFO misc.py line 113 3298914] Train: [3/100][147/2402] Data 0.004 (0.004) Batch 0.397 (0.477) Remain 31:11:17 loss: 1.2377 Lr: 0.00085
[2025-04-08 14:32:59,977 INFO misc.py line 113 3298914] Train: [3/100][148/2402] Data 0.004 (0.004) Batch 0.389 (0.477) Remain 31:08:53 loss: 1.3358 Lr: 0.00085
[2025-04-08 14:33:00,439 INFO misc.py line 113 3298914] Train: [3/100][149/2402] Data 0.004 (0.004) Batch 0.462 (0.477) Remain 31:08:29 loss: 1.2863 Lr: 0.00085
[2025-04-08 14:33:00,932 INFO misc.py line 113 3298914] Train: [3/100][150/2402] Data 0.003 (0.004) Batch 0.493 (0.477) Remain 31:08:55 loss: 1.2932 Lr: 0.00085
[2025-04-08 14:33:01,386 INFO misc.py line 113 3298914] Train: [3/100][151/2402] Data 0.003 (0.004) Batch 0.454 (0.477) Remain 31:08:18 loss: 1.4365 Lr: 0.00086
[2025-04-08 14:33:01,857 INFO misc.py line 113 3298914] Train: [3/100][152/2402] Data 0.004 (0.004) Batch 0.471 (0.476) Remain 31:08:09 loss: 1.4022 Lr: 0.00086
[2025-04-08 14:33:02,420 INFO misc.py line 113 3298914] Train: [3/100][153/2402] Data 0.003 (0.004) Batch 0.563 (0.477) Remain 31:10:24 loss: 1.0004 Lr: 0.00086
[2025-04-08 14:33:02,972 INFO misc.py line 113 3298914] Train: [3/100][154/2402] Data 0.004 (0.004) Batch 0.551 (0.478) Remain 31:12:20 loss: 1.2213 Lr: 0.00086
[2025-04-08 14:33:03,372 INFO misc.py line 113 3298914] Train: [3/100][155/2402] Data 0.003 (0.004) Batch 0.400 (0.477) Remain 31:10:19 loss: 1.3704 Lr: 0.00086
[2025-04-08 14:33:03,913 INFO misc.py line 113 3298914] Train: [3/100][156/2402] Data 0.004 (0.004) Batch 0.541 (0.477) Remain 31:11:57 loss: 1.1799 Lr: 0.00086
[2025-04-08 14:33:04,351 INFO misc.py line 113 3298914] Train: [3/100][157/2402] Data 0.003 (0.004) Batch 0.438 (0.477) Remain 31:10:57 loss: 0.9950 Lr: 0.00086
[2025-04-08 14:33:04,844 INFO misc.py line 113 3298914] Train: [3/100][158/2402] Data 0.004 (0.004) Batch 0.493 (0.477) Remain 31:11:20 loss: 0.8448 Lr: 0.00086
[2025-04-08 14:33:05,257 INFO misc.py line 113 3298914] Train: [3/100][159/2402] Data 0.004 (0.004) Batch 0.413 (0.477) Remain 31:09:43 loss: 1.1024 Lr: 0.00086
[2025-04-08 14:33:05,804 INFO misc.py line 113 3298914] Train: [3/100][160/2402] Data 0.004 (0.004) Batch 0.547 (0.477) Remain 31:11:28 loss: 1.3530 Lr: 0.00086
[2025-04-08 14:33:06,332 INFO misc.py line 113 3298914] Train: [3/100][161/2402] Data 0.004 (0.004) Batch 0.527 (0.478) Remain 31:12:42 loss: 1.1297 Lr: 0.00086
[2025-04-08 14:33:06,879 INFO misc.py line 113 3298914] Train: [3/100][162/2402] Data 0.004 (0.004) Batch 0.547 (0.478) Remain 31:14:24 loss: 1.4224 Lr: 0.00086
[2025-04-08 14:33:07,397 INFO misc.py line 113 3298914] Train: [3/100][163/2402] Data 0.004 (0.004) Batch 0.519 (0.478) Remain 31:15:23 loss: 1.5392 Lr: 0.00086
[2025-04-08 14:33:07,781 INFO misc.py line 113 3298914] Train: [3/100][164/2402] Data 0.004 (0.004) Batch 0.384 (0.478) Remain 31:13:04 loss: 1.4620 Lr: 0.00086
[2025-04-08 14:33:08,246 INFO misc.py line 113 3298914] Train: [3/100][165/2402] Data 0.004 (0.004) Batch 0.465 (0.478) Remain 31:12:45 loss: 1.0261 Lr: 0.00086
[2025-04-08 14:33:08,649 INFO misc.py line 113 3298914] Train: [3/100][166/2402] Data 0.004 (0.004) Batch 0.402 (0.477) Remain 31:10:56 loss: 1.1796 Lr: 0.00086
[2025-04-08 14:33:09,134 INFO misc.py line 113 3298914] Train: [3/100][167/2402] Data 0.004 (0.004) Batch 0.485 (0.477) Remain 31:11:07 loss: 1.4337 Lr: 0.00086
[2025-04-08 14:33:09,553 INFO misc.py line 113 3298914] Train: [3/100][168/2402] Data 0.003 (0.004) Batch 0.419 (0.477) Remain 31:09:44 loss: 1.1899 Lr: 0.00086
[2025-04-08 14:33:10,067 INFO misc.py line 113 3298914] Train: [3/100][169/2402] Data 0.004 (0.004) Batch 0.514 (0.477) Remain 31:10:36 loss: 1.0203 Lr: 0.00086
[2025-04-08 14:33:10,557 INFO misc.py line 113 3298914] Train: [3/100][170/2402] Data 0.004 (0.004) Batch 0.489 (0.477) Remain 31:10:53 loss: 1.8233 Lr: 0.00086
[2025-04-08 14:33:11,040 INFO misc.py line 113 3298914] Train: [3/100][171/2402] Data 0.004 (0.004) Batch 0.484 (0.477) Remain 31:11:02 loss: 1.4294 Lr: 0.00086
[2025-04-08 14:33:11,479 INFO misc.py line 113 3298914] Train: [3/100][172/2402] Data 0.003 (0.004) Batch 0.438 (0.477) Remain 31:10:07 loss: 1.2703 Lr: 0.00086
[2025-04-08 14:33:12,062 INFO misc.py line 113 3298914] Train: [3/100][173/2402] Data 0.004 (0.004) Batch 0.583 (0.478) Remain 31:12:33 loss: 1.6653 Lr: 0.00086
[2025-04-08 14:33:12,517 INFO misc.py line 113 3298914] Train: [3/100][174/2402] Data 0.004 (0.004) Batch 0.456 (0.478) Remain 31:12:03 loss: 1.2642 Lr: 0.00086
[2025-04-08 14:33:12,980 INFO misc.py line 113 3298914] Train: [3/100][175/2402] Data 0.004 (0.004) Batch 0.462 (0.477) Remain 31:11:41 loss: 1.5346 Lr: 0.00086
[2025-04-08 14:33:13,427 INFO misc.py line 113 3298914] Train: [3/100][176/2402] Data 0.004 (0.004) Batch 0.447 (0.477) Remain 31:10:59 loss: 1.2364 Lr: 0.00086
[2025-04-08 14:33:13,932 INFO misc.py line 113 3298914] Train: [3/100][177/2402] Data 0.003 (0.004) Batch 0.506 (0.477) Remain 31:11:37 loss: 1.2891 Lr: 0.00086
[2025-04-08 14:33:14,391 INFO misc.py line 113 3298914] Train: [3/100][178/2402] Data 0.003 (0.004) Batch 0.459 (0.477) Remain 31:11:12 loss: 1.1101 Lr: 0.00086
[2025-04-08 14:33:14,924 INFO misc.py line 113 3298914] Train: [3/100][179/2402] Data 0.004 (0.004) Batch 0.533 (0.478) Remain 31:12:26 loss: 1.5207 Lr: 0.00086
[2025-04-08 14:33:15,316 INFO misc.py line 113 3298914] Train: [3/100][180/2402] Data 0.003 (0.004) Batch 0.392 (0.477) Remain 31:10:32 loss: 1.3848 Lr: 0.00086
[2025-04-08 14:33:15,810 INFO misc.py line 113 3298914] Train: [3/100][181/2402] Data 0.004 (0.004) Batch 0.494 (0.477) Remain 31:10:53 loss: 1.0929 Lr: 0.00086
[2025-04-08 14:33:16,251 INFO misc.py line 113 3298914] Train: [3/100][182/2402] Data 0.004 (0.004) Batch 0.441 (0.477) Remain 31:10:04 loss: 1.1180 Lr: 0.00086
[2025-04-08 14:33:16,714 INFO misc.py line 113 3298914] Train: [3/100][183/2402] Data 0.004 (0.004) Batch 0.463 (0.477) Remain 31:09:45 loss: 1.2273 Lr: 0.00086
[2025-04-08 14:33:17,209 INFO misc.py line 113 3298914] Train: [3/100][184/2402] Data 0.004 (0.004) Batch 0.495 (0.477) Remain 31:10:09 loss: 1.2294 Lr: 0.00086
[2025-04-08 14:33:17,671 INFO misc.py line 113 3298914] Train: [3/100][185/2402] Data 0.004 (0.004) Batch 0.461 (0.477) Remain 31:09:48 loss: 1.0534 Lr: 0.00086
[2025-04-08 14:33:18,231 INFO misc.py line 113 3298914] Train: [3/100][186/2402] Data 0.004 (0.004) Batch 0.561 (0.477) Remain 31:11:36 loss: 1.3306 Lr: 0.00086
[2025-04-08 14:33:18,771 INFO misc.py line 113 3298914] Train: [3/100][187/2402] Data 0.004 (0.004) Batch 0.540 (0.478) Remain 31:12:55 loss: 1.1631 Lr: 0.00086
[2025-04-08 14:33:19,247 INFO misc.py line 113 3298914] Train: [3/100][188/2402] Data 0.003 (0.004) Batch 0.475 (0.478) Remain 31:12:52 loss: 1.5728 Lr: 0.00086
[2025-04-08 14:33:19,671 INFO misc.py line 113 3298914] Train: [3/100][189/2402] Data 0.003 (0.004) Batch 0.424 (0.477) Remain 31:11:44 loss: 1.1160 Lr: 0.00086
[2025-04-08 14:33:20,102 INFO misc.py line 113 3298914] Train: [3/100][190/2402] Data 0.003 (0.004) Batch 0.430 (0.477) Remain 31:10:44 loss: 1.4848 Lr: 0.00086
[2025-04-08 14:33:20,545 INFO misc.py line 113 3298914] Train: [3/100][191/2402] Data 0.004 (0.004) Batch 0.443 (0.477) Remain 31:10:01 loss: 1.2351 Lr: 0.00086
[2025-04-08 14:33:21,106 INFO misc.py line 113 3298914] Train: [3/100][192/2402] Data 0.003 (0.004) Batch 0.561 (0.477) Remain 31:11:45 loss: 0.8584 Lr: 0.00086
[2025-04-08 14:33:21,559 INFO misc.py line 113 3298914] Train: [3/100][193/2402] Data 0.003 (0.004) Batch 0.453 (0.477) Remain 31:11:15 loss: 1.1969 Lr: 0.00086
[2025-04-08 14:33:22,048 INFO misc.py line 113 3298914] Train: [3/100][194/2402] Data 0.004 (0.004) Batch 0.489 (0.477) Remain 31:11:28 loss: 1.0299 Lr: 0.00086
[2025-04-08 14:33:22,541 INFO misc.py line 113 3298914] Train: [3/100][195/2402] Data 0.004 (0.004) Batch 0.493 (0.477) Remain 31:11:47 loss: 1.2784 Lr: 0.00087
[2025-04-08 14:33:23,022 INFO misc.py line 113 3298914] Train: [3/100][196/2402] Data 0.004 (0.004) Batch 0.481 (0.478) Remain 31:11:52 loss: 1.5737 Lr: 0.00087
[2025-04-08 14:33:23,505 INFO misc.py line 113 3298914] Train: [3/100][197/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:11:58 loss: 1.1822 Lr: 0.00087
[2025-04-08 14:33:24,062 INFO misc.py line 113 3298914] Train: [3/100][198/2402] Data 0.004 (0.004) Batch 0.557 (0.478) Remain 31:13:33 loss: 1.4631 Lr: 0.00087
[2025-04-08 14:33:24,536 INFO misc.py line 113 3298914] Train: [3/100][199/2402] Data 0.004 (0.004) Batch 0.474 (0.478) Remain 31:13:28 loss: 1.4399 Lr: 0.00087
[2025-04-08 14:33:25,030 INFO misc.py line 113 3298914] Train: [3/100][200/2402] Data 0.003 (0.004) Batch 0.494 (0.478) Remain 31:13:47 loss: 1.8922 Lr: 0.00087
[2025-04-08 14:33:25,438 INFO misc.py line 113 3298914] Train: [3/100][201/2402] Data 0.003 (0.004) Batch 0.407 (0.478) Remain 31:12:22 loss: 1.0217 Lr: 0.00087
[2025-04-08 14:33:25,943 INFO misc.py line 113 3298914] Train: [3/100][202/2402] Data 0.004 (0.004) Batch 0.505 (0.478) Remain 31:12:54 loss: 1.4255 Lr: 0.00087
[2025-04-08 14:33:26,427 INFO misc.py line 113 3298914] Train: [3/100][203/2402] Data 0.004 (0.004) Batch 0.484 (0.478) Remain 31:13:01 loss: 1.0759 Lr: 0.00087
[2025-04-08 14:33:26,936 INFO misc.py line 113 3298914] Train: [3/100][204/2402] Data 0.004 (0.004) Batch 0.509 (0.478) Remain 31:13:37 loss: 1.3844 Lr: 0.00087
[2025-04-08 14:33:27,408 INFO misc.py line 113 3298914] Train: [3/100][205/2402] Data 0.004 (0.004) Batch 0.472 (0.478) Remain 31:13:29 loss: 1.0400 Lr: 0.00087
[2025-04-08 14:33:27,853 INFO misc.py line 113 3298914] Train: [3/100][206/2402] Data 0.004 (0.004) Batch 0.445 (0.478) Remain 31:12:51 loss: 1.5904 Lr: 0.00087
[2025-04-08 14:33:28,378 INFO misc.py line 113 3298914] Train: [3/100][207/2402] Data 0.003 (0.004) Batch 0.525 (0.478) Remain 31:13:45 loss: 1.2471 Lr: 0.00087
[2025-04-08 14:33:28,898 INFO misc.py line 113 3298914] Train: [3/100][208/2402] Data 0.004 (0.004) Batch 0.519 (0.478) Remain 31:14:32 loss: 1.0547 Lr: 0.00087
[2025-04-08 14:33:29,290 INFO misc.py line 113 3298914] Train: [3/100][209/2402] Data 0.003 (0.004) Batch 0.392 (0.478) Remain 31:12:53 loss: 0.9818 Lr: 0.00087
[2025-04-08 14:33:29,676 INFO misc.py line 113 3298914] Train: [3/100][210/2402] Data 0.006 (0.004) Batch 0.386 (0.477) Remain 31:11:08 loss: 1.1508 Lr: 0.00087
[2025-04-08 14:33:30,229 INFO misc.py line 113 3298914] Train: [3/100][211/2402] Data 0.003 (0.004) Batch 0.553 (0.478) Remain 31:12:34 loss: 1.2076 Lr: 0.00087
[2025-04-08 14:33:30,746 INFO misc.py line 113 3298914] Train: [3/100][212/2402] Data 0.004 (0.004) Batch 0.517 (0.478) Remain 31:13:18 loss: 1.0186 Lr: 0.00087
[2025-04-08 14:33:31,186 INFO misc.py line 113 3298914] Train: [3/100][213/2402] Data 0.004 (0.004) Batch 0.440 (0.478) Remain 31:12:35 loss: 1.4625 Lr: 0.00087
[2025-04-08 14:33:31,661 INFO misc.py line 113 3298914] Train: [3/100][214/2402] Data 0.004 (0.004) Batch 0.475 (0.478) Remain 31:12:31 loss: 1.1844 Lr: 0.00087
[2025-04-08 14:33:32,227 INFO misc.py line 113 3298914] Train: [3/100][215/2402] Data 0.004 (0.004) Batch 0.566 (0.478) Remain 31:14:09 loss: 1.4154 Lr: 0.00087
[2025-04-08 14:33:32,605 INFO misc.py line 113 3298914] Train: [3/100][216/2402] Data 0.004 (0.004) Batch 0.378 (0.478) Remain 31:12:17 loss: 1.9818 Lr: 0.00087
[2025-04-08 14:33:33,029 INFO misc.py line 113 3298914] Train: [3/100][217/2402] Data 0.004 (0.004) Batch 0.424 (0.477) Remain 31:11:18 loss: 1.0072 Lr: 0.00087
[2025-04-08 14:33:33,362 INFO misc.py line 113 3298914] Train: [3/100][218/2402] Data 0.004 (0.004) Batch 0.333 (0.477) Remain 31:08:39 loss: 1.2882 Lr: 0.00087
[2025-04-08 14:33:33,833 INFO misc.py line 113 3298914] Train: [3/100][219/2402] Data 0.004 (0.004) Batch 0.471 (0.477) Remain 31:08:33 loss: 1.4690 Lr: 0.00087
[2025-04-08 14:33:34,296 INFO misc.py line 113 3298914] Train: [3/100][220/2402] Data 0.004 (0.004) Batch 0.462 (0.477) Remain 31:08:17 loss: 1.1791 Lr: 0.00087
[2025-04-08 14:33:34,772 INFO misc.py line 113 3298914] Train: [3/100][221/2402] Data 0.004 (0.004) Batch 0.476 (0.477) Remain 31:08:16 loss: 1.2823 Lr: 0.00087
[2025-04-08 14:33:35,197 INFO misc.py line 113 3298914] Train: [3/100][222/2402] Data 0.003 (0.004) Batch 0.426 (0.476) Remain 31:07:21 loss: 1.0171 Lr: 0.00087
[2025-04-08 14:33:35,631 INFO misc.py line 113 3298914] Train: [3/100][223/2402] Data 0.003 (0.004) Batch 0.434 (0.476) Remain 31:06:35 loss: 0.9048 Lr: 0.00087
[2025-04-08 14:33:36,176 INFO misc.py line 113 3298914] Train: [3/100][224/2402] Data 0.004 (0.004) Batch 0.545 (0.477) Remain 31:07:47 loss: 1.4129 Lr: 0.00087
[2025-04-08 14:33:36,731 INFO misc.py line 113 3298914] Train: [3/100][225/2402] Data 0.003 (0.004) Batch 0.556 (0.477) Remain 31:09:10 loss: 1.4257 Lr: 0.00087
[2025-04-08 14:33:37,170 INFO misc.py line 113 3298914] Train: [3/100][226/2402] Data 0.004 (0.004) Batch 0.439 (0.477) Remain 31:08:30 loss: 1.2571 Lr: 0.00087
[2025-04-08 14:33:37,544 INFO misc.py line 113 3298914] Train: [3/100][227/2402] Data 0.004 (0.004) Batch 0.374 (0.476) Remain 31:06:41 loss: 1.1788 Lr: 0.00087
[2025-04-08 14:33:37,994 INFO misc.py line 113 3298914] Train: [3/100][228/2402] Data 0.004 (0.004) Batch 0.450 (0.476) Remain 31:06:13 loss: 1.5291 Lr: 0.00087
[2025-04-08 14:33:38,451 INFO misc.py line 113 3298914] Train: [3/100][229/2402] Data 0.004 (0.004) Batch 0.457 (0.476) Remain 31:05:53 loss: 0.8802 Lr: 0.00087
[2025-04-08 14:33:38,900 INFO misc.py line 113 3298914] Train: [3/100][230/2402] Data 0.003 (0.004) Batch 0.449 (0.476) Remain 31:05:25 loss: 1.2377 Lr: 0.00087
[2025-04-08 14:33:39,365 INFO misc.py line 113 3298914] Train: [3/100][231/2402] Data 0.003 (0.004) Batch 0.465 (0.476) Remain 31:05:13 loss: 1.2499 Lr: 0.00087
[2025-04-08 14:33:39,835 INFO misc.py line 113 3298914] Train: [3/100][232/2402] Data 0.004 (0.004) Batch 0.470 (0.476) Remain 31:05:06 loss: 0.9682 Lr: 0.00087
[2025-04-08 14:33:40,288 INFO misc.py line 113 3298914] Train: [3/100][233/2402] Data 0.003 (0.004) Batch 0.453 (0.476) Remain 31:04:42 loss: 1.3729 Lr: 0.00087
[2025-04-08 14:33:40,782 INFO misc.py line 113 3298914] Train: [3/100][234/2402] Data 0.003 (0.004) Batch 0.494 (0.476) Remain 31:05:00 loss: 1.2916 Lr: 0.00087
[2025-04-08 14:33:41,208 INFO misc.py line 113 3298914] Train: [3/100][235/2402] Data 0.004 (0.004) Batch 0.426 (0.476) Remain 31:04:09 loss: 1.3251 Lr: 0.00087
[2025-04-08 14:33:41,690 INFO misc.py line 113 3298914] Train: [3/100][236/2402] Data 0.003 (0.004) Batch 0.482 (0.476) Remain 31:04:15 loss: 1.3892 Lr: 0.00087
[2025-04-08 14:33:42,118 INFO misc.py line 113 3298914] Train: [3/100][237/2402] Data 0.003 (0.004) Batch 0.428 (0.475) Remain 31:03:27 loss: 1.2484 Lr: 0.00087
[2025-04-08 14:33:42,641 INFO misc.py line 113 3298914] Train: [3/100][238/2402] Data 0.004 (0.004) Batch 0.523 (0.476) Remain 31:04:14 loss: 1.6445 Lr: 0.00087
[2025-04-08 14:33:43,073 INFO misc.py line 113 3298914] Train: [3/100][239/2402] Data 0.003 (0.004) Batch 0.432 (0.475) Remain 31:03:30 loss: 1.3838 Lr: 0.00088
[2025-04-08 14:33:43,581 INFO misc.py line 113 3298914] Train: [3/100][240/2402] Data 0.004 (0.004) Batch 0.508 (0.476) Remain 31:04:02 loss: 1.2645 Lr: 0.00088
[2025-04-08 14:33:44,004 INFO misc.py line 113 3298914] Train: [3/100][241/2402] Data 0.004 (0.004) Batch 0.423 (0.475) Remain 31:03:10 loss: 1.8271 Lr: 0.00088
[2025-04-08 14:33:44,506 INFO misc.py line 113 3298914] Train: [3/100][242/2402] Data 0.003 (0.004) Batch 0.502 (0.475) Remain 31:03:35 loss: 1.4058 Lr: 0.00088
[2025-04-08 14:33:44,913 INFO misc.py line 113 3298914] Train: [3/100][243/2402] Data 0.004 (0.004) Batch 0.407 (0.475) Remain 31:02:27 loss: 1.2301 Lr: 0.00088
[2025-04-08 14:33:45,381 INFO misc.py line 113 3298914] Train: [3/100][244/2402] Data 0.003 (0.004) Batch 0.468 (0.475) Remain 31:02:20 loss: 1.3865 Lr: 0.00088
[2025-04-08 14:33:45,722 INFO misc.py line 113 3298914] Train: [3/100][245/2402] Data 0.003 (0.004) Batch 0.341 (0.475) Remain 31:00:10 loss: 1.3169 Lr: 0.00088
[2025-04-08 14:33:46,215 INFO misc.py line 113 3298914] Train: [3/100][246/2402] Data 0.004 (0.004) Batch 0.493 (0.475) Remain 31:00:27 loss: 1.1058 Lr: 0.00088
[2025-04-08 14:33:46,631 INFO misc.py line 113 3298914] Train: [3/100][247/2402] Data 0.003 (0.004) Batch 0.415 (0.474) Remain 30:59:29 loss: 1.2674 Lr: 0.00088
[2025-04-08 14:33:47,016 INFO misc.py line 113 3298914] Train: [3/100][248/2402] Data 0.003 (0.004) Batch 0.385 (0.474) Remain 30:58:03 loss: 1.2579 Lr: 0.00088
[2025-04-08 14:33:47,516 INFO misc.py line 113 3298914] Train: [3/100][249/2402] Data 0.003 (0.004) Batch 0.500 (0.474) Remain 30:58:27 loss: 1.1906 Lr: 0.00088
[2025-04-08 14:33:47,989 INFO misc.py line 113 3298914] Train: [3/100][250/2402] Data 0.003 (0.004) Batch 0.473 (0.474) Remain 30:58:25 loss: 1.5938 Lr: 0.00088
[2025-04-08 14:33:48,473 INFO misc.py line 113 3298914] Train: [3/100][251/2402] Data 0.003 (0.004) Batch 0.484 (0.474) Remain 30:58:35 loss: 1.1446 Lr: 0.00088
[2025-04-08 14:33:48,979 INFO misc.py line 113 3298914] Train: [3/100][252/2402] Data 0.004 (0.004) Batch 0.506 (0.474) Remain 30:59:04 loss: 0.9354 Lr: 0.00088
[2025-04-08 14:33:49,493 INFO misc.py line 113 3298914] Train: [3/100][253/2402] Data 0.003 (0.004) Batch 0.514 (0.475) Remain 30:59:40 loss: 1.2924 Lr: 0.00088
[2025-04-08 14:33:49,945 INFO misc.py line 113 3298914] Train: [3/100][254/2402] Data 0.004 (0.004) Batch 0.452 (0.474) Remain 30:59:19 loss: 1.4134 Lr: 0.00088
[2025-04-08 14:33:50,350 INFO misc.py line 113 3298914] Train: [3/100][255/2402] Data 0.003 (0.004) Batch 0.405 (0.474) Remain 30:58:14 loss: 1.0494 Lr: 0.00088
[2025-04-08 14:33:50,934 INFO misc.py line 113 3298914] Train: [3/100][256/2402] Data 0.003 (0.004) Batch 0.584 (0.475) Remain 30:59:56 loss: 0.8915 Lr: 0.00088
[2025-04-08 14:33:51,413 INFO misc.py line 113 3298914] Train: [3/100][257/2402] Data 0.004 (0.004) Batch 0.479 (0.475) Remain 30:59:59 loss: 1.0527 Lr: 0.00088
[2025-04-08 14:33:51,768 INFO misc.py line 113 3298914] Train: [3/100][258/2402] Data 0.003 (0.004) Batch 0.356 (0.474) Remain 30:58:09 loss: 0.6376 Lr: 0.00088
[2025-04-08 14:33:52,159 INFO misc.py line 113 3298914] Train: [3/100][259/2402] Data 0.003 (0.004) Batch 0.391 (0.474) Remain 30:56:52 loss: 2.2037 Lr: 0.00088
[2025-04-08 14:33:52,617 INFO misc.py line 113 3298914] Train: [3/100][260/2402] Data 0.004 (0.004) Batch 0.458 (0.474) Remain 30:56:37 loss: 1.2782 Lr: 0.00088
[2025-04-08 14:33:53,031 INFO misc.py line 113 3298914] Train: [3/100][261/2402] Data 0.003 (0.004) Batch 0.414 (0.474) Remain 30:55:42 loss: 1.0787 Lr: 0.00088
[2025-04-08 14:33:53,542 INFO misc.py line 113 3298914] Train: [3/100][262/2402] Data 0.004 (0.004) Batch 0.511 (0.474) Remain 30:56:15 loss: 1.4729 Lr: 0.00088
[2025-04-08 14:33:54,103 INFO misc.py line 113 3298914] Train: [3/100][263/2402] Data 0.004 (0.004) Batch 0.561 (0.474) Remain 30:57:34 loss: 1.4954 Lr: 0.00088
[2025-04-08 14:33:54,555 INFO misc.py line 113 3298914] Train: [3/100][264/2402] Data 0.003 (0.004) Batch 0.451 (0.474) Remain 30:57:13 loss: 0.9497 Lr: 0.00088
[2025-04-08 14:33:54,993 INFO misc.py line 113 3298914] Train: [3/100][265/2402] Data 0.004 (0.004) Batch 0.439 (0.474) Remain 30:56:41 loss: 1.0537 Lr: 0.00088
[2025-04-08 14:33:55,498 INFO misc.py line 113 3298914] Train: [3/100][266/2402] Data 0.003 (0.004) Batch 0.505 (0.474) Remain 30:57:08 loss: 0.8197 Lr: 0.00088
[2025-04-08 14:33:56,016 INFO misc.py line 113 3298914] Train: [3/100][267/2402] Data 0.003 (0.004) Batch 0.518 (0.474) Remain 30:57:47 loss: 1.0331 Lr: 0.00088
[2025-04-08 14:33:56,570 INFO misc.py line 113 3298914] Train: [3/100][268/2402] Data 0.004 (0.004) Batch 0.555 (0.474) Remain 30:58:58 loss: 1.0067 Lr: 0.00088
[2025-04-08 14:33:57,001 INFO misc.py line 113 3298914] Train: [3/100][269/2402] Data 0.003 (0.004) Batch 0.431 (0.474) Remain 30:58:19 loss: 0.9419 Lr: 0.00088
[2025-04-08 14:33:57,492 INFO misc.py line 113 3298914] Train: [3/100][270/2402] Data 0.003 (0.004) Batch 0.491 (0.474) Remain 30:58:33 loss: 1.7899 Lr: 0.00088
[2025-04-08 14:33:57,933 INFO misc.py line 113 3298914] Train: [3/100][271/2402] Data 0.004 (0.004) Batch 0.440 (0.474) Remain 30:58:03 loss: 1.0962 Lr: 0.00088
[2025-04-08 14:33:58,369 INFO misc.py line 113 3298914] Train: [3/100][272/2402] Data 0.004 (0.004) Batch 0.437 (0.474) Remain 30:57:29 loss: 1.3943 Lr: 0.00088
[2025-04-08 14:33:58,886 INFO misc.py line 113 3298914] Train: [3/100][273/2402] Data 0.003 (0.004) Batch 0.517 (0.474) Remain 30:58:07 loss: 1.1666 Lr: 0.00088
[2025-04-08 14:33:59,313 INFO misc.py line 113 3298914] Train: [3/100][274/2402] Data 0.004 (0.004) Batch 0.426 (0.474) Remain 30:57:25 loss: 1.0191 Lr: 0.00088
[2025-04-08 14:33:59,762 INFO misc.py line 113 3298914] Train: [3/100][275/2402] Data 0.003 (0.004) Batch 0.450 (0.474) Remain 30:57:03 loss: 0.8894 Lr: 0.00088
[2025-04-08 14:34:00,214 INFO misc.py line 113 3298914] Train: [3/100][276/2402] Data 0.003 (0.004) Batch 0.451 (0.474) Remain 30:56:43 loss: 1.2477 Lr: 0.00088
[2025-04-08 14:34:00,622 INFO misc.py line 113 3298914] Train: [3/100][277/2402] Data 0.004 (0.004) Batch 0.408 (0.474) Remain 30:55:47 loss: 1.6350 Lr: 0.00088
[2025-04-08 14:34:01,136 INFO misc.py line 113 3298914] Train: [3/100][278/2402] Data 0.003 (0.004) Batch 0.514 (0.474) Remain 30:56:21 loss: 1.3893 Lr: 0.00088
[2025-04-08 14:34:01,613 INFO misc.py line 113 3298914] Train: [3/100][279/2402] Data 0.004 (0.004) Batch 0.477 (0.474) Remain 30:56:23 loss: 1.2541 Lr: 0.00088
[2025-04-08 14:34:02,144 INFO misc.py line 113 3298914] Train: [3/100][280/2402] Data 0.003 (0.004) Batch 0.531 (0.474) Remain 30:57:11 loss: 1.1867 Lr: 0.00088
[2025-04-08 14:34:02,692 INFO misc.py line 113 3298914] Train: [3/100][281/2402] Data 0.004 (0.004) Batch 0.548 (0.474) Remain 30:58:13 loss: 1.1602 Lr: 0.00088
[2025-04-08 14:34:03,227 INFO misc.py line 113 3298914] Train: [3/100][282/2402] Data 0.003 (0.004) Batch 0.536 (0.474) Remain 30:59:04 loss: 1.2883 Lr: 0.00088
[2025-04-08 14:34:03,725 INFO misc.py line 113 3298914] Train: [3/100][283/2402] Data 0.004 (0.004) Batch 0.498 (0.475) Remain 30:59:23 loss: 1.3712 Lr: 0.00089
[2025-04-08 14:34:04,136 INFO misc.py line 113 3298914] Train: [3/100][284/2402] Data 0.003 (0.004) Batch 0.411 (0.474) Remain 30:58:29 loss: 1.5540 Lr: 0.00089
[2025-04-08 14:34:04,666 INFO misc.py line 113 3298914] Train: [3/100][285/2402] Data 0.003 (0.004) Batch 0.530 (0.474) Remain 30:59:16 loss: 1.3973 Lr: 0.00089
[2025-04-08 14:34:05,137 INFO misc.py line 113 3298914] Train: [3/100][286/2402] Data 0.004 (0.004) Batch 0.471 (0.474) Remain 30:59:12 loss: 1.1027 Lr: 0.00089
[2025-04-08 14:34:05,621 INFO misc.py line 113 3298914] Train: [3/100][287/2402] Data 0.004 (0.004) Batch 0.485 (0.475) Remain 30:59:20 loss: 1.0615 Lr: 0.00089
[2025-04-08 14:34:06,066 INFO misc.py line 113 3298914] Train: [3/100][288/2402] Data 0.003 (0.004) Batch 0.445 (0.474) Remain 30:58:55 loss: 0.8063 Lr: 0.00089
[2025-04-08 14:34:06,639 INFO misc.py line 113 3298914] Train: [3/100][289/2402] Data 0.003 (0.004) Batch 0.572 (0.475) Remain 31:00:15 loss: 1.3402 Lr: 0.00089
[2025-04-08 14:34:07,084 INFO misc.py line 113 3298914] Train: [3/100][290/2402] Data 0.004 (0.004) Batch 0.445 (0.475) Remain 30:59:50 loss: 1.2166 Lr: 0.00089
[2025-04-08 14:34:07,624 INFO misc.py line 113 3298914] Train: [3/100][291/2402] Data 0.004 (0.004) Batch 0.541 (0.475) Remain 31:00:44 loss: 1.2391 Lr: 0.00089
[2025-04-08 14:34:08,160 INFO misc.py line 113 3298914] Train: [3/100][292/2402] Data 0.004 (0.004) Batch 0.536 (0.475) Remain 31:01:33 loss: 1.3569 Lr: 0.00089
[2025-04-08 14:34:08,604 INFO misc.py line 113 3298914] Train: [3/100][293/2402] Data 0.004 (0.004) Batch 0.444 (0.475) Remain 31:01:07 loss: 0.9587 Lr: 0.00089
[2025-04-08 14:34:09,049 INFO misc.py line 113 3298914] Train: [3/100][294/2402] Data 0.003 (0.004) Batch 0.445 (0.475) Remain 31:00:43 loss: 0.7265 Lr: 0.00089
[2025-04-08 14:34:09,543 INFO misc.py line 113 3298914] Train: [3/100][295/2402] Data 0.003 (0.004) Batch 0.494 (0.475) Remain 31:00:58 loss: 1.4105 Lr: 0.00089
[2025-04-08 14:34:10,097 INFO misc.py line 113 3298914] Train: [3/100][296/2402] Data 0.003 (0.004) Batch 0.553 (0.475) Remain 31:02:00 loss: 1.5335 Lr: 0.00089
[2025-04-08 14:34:10,496 INFO misc.py line 113 3298914] Train: [3/100][297/2402] Data 0.003 (0.004) Batch 0.399 (0.475) Remain 31:00:59 loss: 1.0186 Lr: 0.00089
[2025-04-08 14:34:10,996 INFO misc.py line 113 3298914] Train: [3/100][298/2402] Data 0.003 (0.004) Batch 0.500 (0.475) Remain 31:01:18 loss: 1.2090 Lr: 0.00089
[2025-04-08 14:34:11,419 INFO misc.py line 113 3298914] Train: [3/100][299/2402] Data 0.003 (0.004) Batch 0.424 (0.475) Remain 31:00:37 loss: 1.3298 Lr: 0.00089
[2025-04-08 14:34:11,864 INFO misc.py line 113 3298914] Train: [3/100][300/2402] Data 0.004 (0.004) Batch 0.444 (0.475) Remain 31:00:12 loss: 1.4138 Lr: 0.00089
[2025-04-08 14:34:12,347 INFO misc.py line 113 3298914] Train: [3/100][301/2402] Data 0.003 (0.004) Batch 0.484 (0.475) Remain 31:00:19 loss: 1.0374 Lr: 0.00089
[2025-04-08 14:34:12,876 INFO misc.py line 113 3298914] Train: [3/100][302/2402] Data 0.003 (0.004) Batch 0.529 (0.475) Remain 31:01:01 loss: 1.8144 Lr: 0.00089
[2025-04-08 14:34:13,267 INFO misc.py line 113 3298914] Train: [3/100][303/2402] Data 0.004 (0.004) Batch 0.391 (0.475) Remain 30:59:55 loss: 1.2377 Lr: 0.00089
[2025-04-08 14:34:13,688 INFO misc.py line 113 3298914] Train: [3/100][304/2402] Data 0.003 (0.004) Batch 0.421 (0.475) Remain 30:59:12 loss: 1.0742 Lr: 0.00089
[2025-04-08 14:34:14,245 INFO misc.py line 113 3298914] Train: [3/100][305/2402] Data 0.004 (0.004) Batch 0.557 (0.475) Remain 31:00:16 loss: 1.2450 Lr: 0.00089
[2025-04-08 14:34:14,619 INFO misc.py line 113 3298914] Train: [3/100][306/2402] Data 0.004 (0.004) Batch 0.375 (0.474) Remain 30:58:58 loss: 1.0495 Lr: 0.00089
[2025-04-08 14:34:15,122 INFO misc.py line 113 3298914] Train: [3/100][307/2402] Data 0.003 (0.004) Batch 0.502 (0.475) Remain 30:59:18 loss: 1.1804 Lr: 0.00089
[2025-04-08 14:34:15,682 INFO misc.py line 113 3298914] Train: [3/100][308/2402] Data 0.004 (0.004) Batch 0.561 (0.475) Remain 31:00:24 loss: 1.7786 Lr: 0.00089
[2025-04-08 14:34:16,114 INFO misc.py line 113 3298914] Train: [3/100][309/2402] Data 0.003 (0.004) Batch 0.432 (0.475) Remain 30:59:51 loss: 0.9864 Lr: 0.00089
[2025-04-08 14:34:16,499 INFO misc.py line 113 3298914] Train: [3/100][310/2402] Data 0.003 (0.004) Batch 0.385 (0.474) Remain 30:58:42 loss: 1.1189 Lr: 0.00089
[2025-04-08 14:34:17,032 INFO misc.py line 113 3298914] Train: [3/100][311/2402] Data 0.004 (0.004) Batch 0.533 (0.475) Remain 30:59:26 loss: 1.6948 Lr: 0.00089
[2025-04-08 14:34:17,467 INFO misc.py line 113 3298914] Train: [3/100][312/2402] Data 0.003 (0.004) Batch 0.435 (0.474) Remain 30:58:55 loss: 1.2978 Lr: 0.00089
[2025-04-08 14:34:17,969 INFO misc.py line 113 3298914] Train: [3/100][313/2402] Data 0.003 (0.004) Batch 0.503 (0.475) Remain 30:59:16 loss: 1.3287 Lr: 0.00089
[2025-04-08 14:34:18,322 INFO misc.py line 113 3298914] Train: [3/100][314/2402] Data 0.004 (0.004) Batch 0.353 (0.474) Remain 30:57:44 loss: 1.5187 Lr: 0.00089
[2025-04-08 14:34:18,836 INFO misc.py line 113 3298914] Train: [3/100][315/2402] Data 0.003 (0.004) Batch 0.513 (0.474) Remain 30:58:12 loss: 1.1293 Lr: 0.00089
[2025-04-08 14:34:19,223 INFO misc.py line 113 3298914] Train: [3/100][316/2402] Data 0.004 (0.004) Batch 0.388 (0.474) Remain 30:57:07 loss: 1.5008 Lr: 0.00089
[2025-04-08 14:34:19,609 INFO misc.py line 113 3298914] Train: [3/100][317/2402] Data 0.004 (0.004) Batch 0.386 (0.474) Remain 30:56:00 loss: 0.7387 Lr: 0.00089
[2025-04-08 14:34:20,118 INFO misc.py line 113 3298914] Train: [3/100][318/2402] Data 0.003 (0.004) Batch 0.509 (0.474) Remain 30:56:27 loss: 1.3078 Lr: 0.00089
[2025-04-08 14:34:20,636 INFO misc.py line 113 3298914] Train: [3/100][319/2402] Data 0.004 (0.004) Batch 0.517 (0.474) Remain 30:56:58 loss: 1.4073 Lr: 0.00089
[2025-04-08 14:34:21,174 INFO misc.py line 113 3298914] Train: [3/100][320/2402] Data 0.004 (0.004) Batch 0.539 (0.474) Remain 30:57:46 loss: 1.3973 Lr: 0.00089
[2025-04-08 14:34:21,732 INFO misc.py line 113 3298914] Train: [3/100][321/2402] Data 0.005 (0.004) Batch 0.558 (0.474) Remain 30:58:47 loss: 1.5052 Lr: 0.00089
[2025-04-08 14:34:22,175 INFO misc.py line 113 3298914] Train: [3/100][322/2402] Data 0.003 (0.004) Batch 0.443 (0.474) Remain 30:58:23 loss: 1.3469 Lr: 0.00089
[2025-04-08 14:34:22,593 INFO misc.py line 113 3298914] Train: [3/100][323/2402] Data 0.004 (0.004) Batch 0.418 (0.474) Remain 30:57:42 loss: 1.0672 Lr: 0.00089
[2025-04-08 14:34:23,004 INFO misc.py line 113 3298914] Train: [3/100][324/2402] Data 0.003 (0.004) Batch 0.412 (0.474) Remain 30:56:55 loss: 1.2949 Lr: 0.00089
[2025-04-08 14:34:23,452 INFO misc.py line 113 3298914] Train: [3/100][325/2402] Data 0.004 (0.004) Batch 0.448 (0.474) Remain 30:56:36 loss: 1.5427 Lr: 0.00089
[2025-04-08 14:34:23,887 INFO misc.py line 113 3298914] Train: [3/100][326/2402] Data 0.004 (0.004) Batch 0.434 (0.474) Remain 30:56:06 loss: 1.3166 Lr: 0.00089
[2025-04-08 14:34:24,449 INFO misc.py line 113 3298914] Train: [3/100][327/2402] Data 0.003 (0.004) Batch 0.563 (0.474) Remain 30:57:11 loss: 1.0858 Lr: 0.00090
[2025-04-08 14:34:24,979 INFO misc.py line 113 3298914] Train: [3/100][328/2402] Data 0.003 (0.004) Batch 0.530 (0.474) Remain 30:57:50 loss: 1.2653 Lr: 0.00090
[2025-04-08 14:34:25,418 INFO misc.py line 113 3298914] Train: [3/100][329/2402] Data 0.004 (0.004) Batch 0.438 (0.474) Remain 30:57:24 loss: 1.0571 Lr: 0.00090
[2025-04-08 14:34:25,925 INFO misc.py line 113 3298914] Train: [3/100][330/2402] Data 0.003 (0.004) Batch 0.507 (0.474) Remain 30:57:47 loss: 1.0867 Lr: 0.00090
[2025-04-08 14:34:26,320 INFO misc.py line 113 3298914] Train: [3/100][331/2402] Data 0.003 (0.004) Batch 0.395 (0.474) Remain 30:56:50 loss: 1.1403 Lr: 0.00090
[2025-04-08 14:34:26,798 INFO misc.py line 113 3298914] Train: [3/100][332/2402] Data 0.003 (0.004) Batch 0.478 (0.474) Remain 30:56:53 loss: 1.2649 Lr: 0.00090
[2025-04-08 14:34:27,295 INFO misc.py line 113 3298914] Train: [3/100][333/2402] Data 0.004 (0.004) Batch 0.497 (0.474) Remain 30:57:08 loss: 0.9651 Lr: 0.00090
[2025-04-08 14:34:27,786 INFO misc.py line 113 3298914] Train: [3/100][334/2402] Data 0.003 (0.004) Batch 0.492 (0.474) Remain 30:57:21 loss: 1.4854 Lr: 0.00090
[2025-04-08 14:34:28,270 INFO misc.py line 113 3298914] Train: [3/100][335/2402] Data 0.003 (0.004) Batch 0.484 (0.474) Remain 30:57:27 loss: 0.8858 Lr: 0.00090
[2025-04-08 14:34:28,779 INFO misc.py line 113 3298914] Train: [3/100][336/2402] Data 0.004 (0.004) Batch 0.508 (0.474) Remain 30:57:51 loss: 1.8435 Lr: 0.00090
[2025-04-08 14:34:29,259 INFO misc.py line 113 3298914] Train: [3/100][337/2402] Data 0.003 (0.004) Batch 0.481 (0.474) Remain 30:57:55 loss: 1.1896 Lr: 0.00090
[2025-04-08 14:34:29,767 INFO misc.py line 113 3298914] Train: [3/100][338/2402] Data 0.003 (0.004) Batch 0.508 (0.474) Remain 30:58:18 loss: 1.4869 Lr: 0.00090
[2025-04-08 14:34:30,273 INFO misc.py line 113 3298914] Train: [3/100][339/2402] Data 0.004 (0.004) Batch 0.506 (0.474) Remain 30:58:39 loss: 0.9576 Lr: 0.00090
[2025-04-08 14:34:30,730 INFO misc.py line 113 3298914] Train: [3/100][340/2402] Data 0.003 (0.004) Batch 0.457 (0.474) Remain 30:58:27 loss: 1.5074 Lr: 0.00090
[2025-04-08 14:34:31,253 INFO misc.py line 113 3298914] Train: [3/100][341/2402] Data 0.015 (0.004) Batch 0.523 (0.475) Remain 30:59:00 loss: 1.5618 Lr: 0.00090
[2025-04-08 14:34:31,725 INFO misc.py line 113 3298914] Train: [3/100][342/2402] Data 0.003 (0.004) Batch 0.472 (0.475) Remain 30:58:57 loss: 1.1160 Lr: 0.00090
[2025-04-08 14:34:32,170 INFO misc.py line 113 3298914] Train: [3/100][343/2402] Data 0.003 (0.004) Batch 0.445 (0.474) Remain 30:58:37 loss: 1.1571 Lr: 0.00090
[2025-04-08 14:34:32,651 INFO misc.py line 113 3298914] Train: [3/100][344/2402] Data 0.004 (0.004) Batch 0.482 (0.474) Remain 30:58:41 loss: 1.3768 Lr: 0.00090
[2025-04-08 14:34:33,255 INFO misc.py line 113 3298914] Train: [3/100][345/2402] Data 0.003 (0.004) Batch 0.604 (0.475) Remain 31:00:10 loss: 1.1951 Lr: 0.00090
[2025-04-08 14:34:33,634 INFO misc.py line 113 3298914] Train: [3/100][346/2402] Data 0.003 (0.004) Batch 0.379 (0.475) Remain 30:59:04 loss: 1.0020 Lr: 0.00090
[2025-04-08 14:34:34,099 INFO misc.py line 113 3298914] Train: [3/100][347/2402] Data 0.003 (0.004) Batch 0.464 (0.475) Remain 30:58:56 loss: 1.3721 Lr: 0.00090
[2025-04-08 14:34:34,585 INFO misc.py line 113 3298914] Train: [3/100][348/2402] Data 0.003 (0.004) Batch 0.487 (0.475) Remain 30:59:04 loss: 1.3313 Lr: 0.00090
[2025-04-08 14:34:35,071 INFO misc.py line 113 3298914] Train: [3/100][349/2402] Data 0.004 (0.004) Batch 0.485 (0.475) Remain 30:59:11 loss: 1.7421 Lr: 0.00090
[2025-04-08 14:34:35,582 INFO misc.py line 113 3298914] Train: [3/100][350/2402] Data 0.004 (0.004) Batch 0.512 (0.475) Remain 30:59:36 loss: 0.8640 Lr: 0.00090
[2025-04-08 14:34:36,100 INFO misc.py line 113 3298914] Train: [3/100][351/2402] Data 0.003 (0.004) Batch 0.518 (0.475) Remain 31:00:04 loss: 1.3091 Lr: 0.00090
[2025-04-08 14:34:36,541 INFO misc.py line 113 3298914] Train: [3/100][352/2402] Data 0.003 (0.004) Batch 0.440 (0.475) Remain 30:59:41 loss: 1.2281 Lr: 0.00090
[2025-04-08 14:34:37,024 INFO misc.py line 113 3298914] Train: [3/100][353/2402] Data 0.003 (0.004) Batch 0.484 (0.475) Remain 30:59:46 loss: 1.1916 Lr: 0.00090
[2025-04-08 14:34:37,548 INFO misc.py line 113 3298914] Train: [3/100][354/2402] Data 0.004 (0.004) Batch 0.523 (0.475) Remain 31:00:18 loss: 1.2875 Lr: 0.00090
[2025-04-08 14:34:38,005 INFO misc.py line 113 3298914] Train: [3/100][355/2402] Data 0.004 (0.004) Batch 0.457 (0.475) Remain 31:00:06 loss: 1.3093 Lr: 0.00090
[2025-04-08 14:34:38,512 INFO misc.py line 113 3298914] Train: [3/100][356/2402] Data 0.004 (0.004) Batch 0.507 (0.475) Remain 31:00:27 loss: 0.7873 Lr: 0.00090
[2025-04-08 14:34:39,011 INFO misc.py line 113 3298914] Train: [3/100][357/2402] Data 0.004 (0.004) Batch 0.500 (0.475) Remain 31:00:43 loss: 1.8389 Lr: 0.00090
[2025-04-08 14:34:39,526 INFO misc.py line 113 3298914] Train: [3/100][358/2402] Data 0.003 (0.004) Batch 0.515 (0.475) Remain 31:01:08 loss: 1.2605 Lr: 0.00090
[2025-04-08 14:34:39,929 INFO misc.py line 113 3298914] Train: [3/100][359/2402] Data 0.003 (0.004) Batch 0.403 (0.475) Remain 31:00:21 loss: 1.6782 Lr: 0.00090
[2025-04-08 14:34:40,439 INFO misc.py line 113 3298914] Train: [3/100][360/2402] Data 0.003 (0.004) Batch 0.510 (0.475) Remain 31:00:43 loss: 1.1061 Lr: 0.00090
[2025-04-08 14:34:40,862 INFO misc.py line 113 3298914] Train: [3/100][361/2402] Data 0.003 (0.004) Batch 0.423 (0.475) Remain 31:00:08 loss: 0.8717 Lr: 0.00090
[2025-04-08 14:34:41,277 INFO misc.py line 113 3298914] Train: [3/100][362/2402] Data 0.004 (0.004) Batch 0.415 (0.475) Remain 30:59:29 loss: 1.2163 Lr: 0.00090
[2025-04-08 14:34:41,765 INFO misc.py line 113 3298914] Train: [3/100][363/2402] Data 0.003 (0.004) Batch 0.488 (0.475) Remain 30:59:37 loss: 1.4557 Lr: 0.00090
[2025-04-08 14:34:42,359 INFO misc.py line 113 3298914] Train: [3/100][364/2402] Data 0.003 (0.004) Batch 0.594 (0.475) Remain 31:00:54 loss: 0.9440 Lr: 0.00090
[2025-04-08 14:34:42,834 INFO misc.py line 113 3298914] Train: [3/100][365/2402] Data 0.004 (0.004) Batch 0.475 (0.475) Remain 31:00:54 loss: 1.3958 Lr: 0.00090
[2025-04-08 14:34:43,372 INFO misc.py line 113 3298914] Train: [3/100][366/2402] Data 0.003 (0.004) Batch 0.538 (0.475) Remain 31:01:34 loss: 1.4037 Lr: 0.00090
[2025-04-08 14:34:43,814 INFO misc.py line 113 3298914] Train: [3/100][367/2402] Data 0.004 (0.004) Batch 0.442 (0.475) Remain 31:01:12 loss: 1.2455 Lr: 0.00090
[2025-04-08 14:34:44,248 INFO misc.py line 113 3298914] Train: [3/100][368/2402] Data 0.003 (0.004) Batch 0.434 (0.475) Remain 31:00:45 loss: 1.3160 Lr: 0.00090
[2025-04-08 14:34:44,712 INFO misc.py line 113 3298914] Train: [3/100][369/2402] Data 0.003 (0.004) Batch 0.464 (0.475) Remain 31:00:38 loss: 1.2049 Lr: 0.00090
[2025-04-08 14:34:45,208 INFO misc.py line 113 3298914] Train: [3/100][370/2402] Data 0.003 (0.004) Batch 0.496 (0.475) Remain 31:00:50 loss: 1.2420 Lr: 0.00091
[2025-04-08 14:34:45,771 INFO misc.py line 113 3298914] Train: [3/100][371/2402] Data 0.003 (0.004) Batch 0.563 (0.475) Remain 31:01:46 loss: 1.0627 Lr: 0.00091
[2025-04-08 14:34:46,437 INFO misc.py line 113 3298914] Train: [3/100][372/2402] Data 0.004 (0.004) Batch 0.666 (0.476) Remain 31:03:47 loss: 1.1186 Lr: 0.00091
[2025-04-08 14:34:46,874 INFO misc.py line 113 3298914] Train: [3/100][373/2402] Data 0.003 (0.004) Batch 0.437 (0.476) Remain 31:03:22 loss: 1.3761 Lr: 0.00091
[2025-04-08 14:34:47,374 INFO misc.py line 113 3298914] Train: [3/100][374/2402] Data 0.004 (0.004) Batch 0.500 (0.476) Remain 31:03:37 loss: 1.1763 Lr: 0.00091
[2025-04-08 14:34:47,864 INFO misc.py line 113 3298914] Train: [3/100][375/2402] Data 0.004 (0.004) Batch 0.490 (0.476) Remain 31:03:45 loss: 0.7916 Lr: 0.00091
[2025-04-08 14:34:48,261 INFO misc.py line 113 3298914] Train: [3/100][376/2402] Data 0.003 (0.004) Batch 0.398 (0.476) Remain 31:02:55 loss: 1.0550 Lr: 0.00091
[2025-04-08 14:34:48,743 INFO misc.py line 113 3298914] Train: [3/100][377/2402] Data 0.003 (0.004) Batch 0.481 (0.476) Remain 31:02:58 loss: 0.7531 Lr: 0.00091
[2025-04-08 14:34:49,250 INFO misc.py line 113 3298914] Train: [3/100][378/2402] Data 0.004 (0.004) Batch 0.508 (0.476) Remain 31:03:18 loss: 1.8157 Lr: 0.00091
[2025-04-08 14:34:49,792 INFO misc.py line 113 3298914] Train: [3/100][379/2402] Data 0.003 (0.004) Batch 0.542 (0.476) Remain 31:03:59 loss: 1.4109 Lr: 0.00091
[2025-04-08 14:34:50,226 INFO misc.py line 113 3298914] Train: [3/100][380/2402] Data 0.003 (0.004) Batch 0.434 (0.476) Remain 31:03:32 loss: 1.1737 Lr: 0.00091
[2025-04-08 14:34:50,635 INFO misc.py line 113 3298914] Train: [3/100][381/2402] Data 0.004 (0.004) Batch 0.409 (0.476) Remain 31:02:50 loss: 1.3252 Lr: 0.00091
[2025-04-08 14:34:51,097 INFO misc.py line 113 3298914] Train: [3/100][382/2402] Data 0.003 (0.004) Batch 0.461 (0.476) Remain 31:02:41 loss: 1.2550 Lr: 0.00091
[2025-04-08 14:34:51,668 INFO misc.py line 113 3298914] Train: [3/100][383/2402] Data 0.004 (0.004) Batch 0.572 (0.476) Remain 31:03:40 loss: 1.0123 Lr: 0.00091
[2025-04-08 14:34:52,087 INFO misc.py line 113 3298914] Train: [3/100][384/2402] Data 0.003 (0.004) Batch 0.419 (0.476) Remain 31:03:04 loss: 1.1207 Lr: 0.00091
[2025-04-08 14:34:52,521 INFO misc.py line 113 3298914] Train: [3/100][385/2402] Data 0.003 (0.004) Batch 0.434 (0.476) Remain 31:02:38 loss: 1.0384 Lr: 0.00091
[2025-04-08 14:34:52,954 INFO misc.py line 113 3298914] Train: [3/100][386/2402] Data 0.004 (0.004) Batch 0.433 (0.475) Remain 31:02:11 loss: 1.0095 Lr: 0.00091
[2025-04-08 14:34:53,471 INFO misc.py line 113 3298914] Train: [3/100][387/2402] Data 0.004 (0.004) Batch 0.517 (0.476) Remain 31:02:37 loss: 1.0394 Lr: 0.00091
[2025-04-08 14:34:53,904 INFO misc.py line 113 3298914] Train: [3/100][388/2402] Data 0.003 (0.004) Batch 0.433 (0.475) Remain 31:02:10 loss: 0.9477 Lr: 0.00091
[2025-04-08 14:34:54,446 INFO misc.py line 113 3298914] Train: [3/100][389/2402] Data 0.003 (0.004) Batch 0.542 (0.476) Remain 31:02:50 loss: 0.8711 Lr: 0.00091
[2025-04-08 14:34:54,901 INFO misc.py line 113 3298914] Train: [3/100][390/2402] Data 0.003 (0.004) Batch 0.456 (0.476) Remain 31:02:38 loss: 1.3628 Lr: 0.00091
[2025-04-08 14:34:55,336 INFO misc.py line 113 3298914] Train: [3/100][391/2402] Data 0.003 (0.004) Batch 0.434 (0.475) Remain 31:02:12 loss: 1.0758 Lr: 0.00091
[2025-04-08 14:34:55,822 INFO misc.py line 113 3298914] Train: [3/100][392/2402] Data 0.004 (0.004) Batch 0.487 (0.475) Remain 31:02:18 loss: 1.4847 Lr: 0.00091
[2025-04-08 14:34:56,370 INFO misc.py line 113 3298914] Train: [3/100][393/2402] Data 0.004 (0.004) Batch 0.548 (0.476) Remain 31:03:02 loss: 1.1689 Lr: 0.00091
[2025-04-08 14:34:56,900 INFO misc.py line 113 3298914] Train: [3/100][394/2402] Data 0.003 (0.004) Batch 0.530 (0.476) Remain 31:03:34 loss: 1.5809 Lr: 0.00091
[2025-04-08 14:34:57,330 INFO misc.py line 113 3298914] Train: [3/100][395/2402] Data 0.004 (0.004) Batch 0.430 (0.476) Remain 31:03:06 loss: 1.1893 Lr: 0.00091
[2025-04-08 14:34:57,860 INFO misc.py line 113 3298914] Train: [3/100][396/2402] Data 0.004 (0.004) Batch 0.530 (0.476) Remain 31:03:38 loss: 1.0675 Lr: 0.00091
[2025-04-08 14:34:58,317 INFO misc.py line 113 3298914] Train: [3/100][397/2402] Data 0.003 (0.004) Batch 0.456 (0.476) Remain 31:03:26 loss: 1.2127 Lr: 0.00091
[2025-04-08 14:34:58,709 INFO misc.py line 113 3298914] Train: [3/100][398/2402] Data 0.004 (0.004) Batch 0.393 (0.476) Remain 31:02:36 loss: 1.3068 Lr: 0.00091
[2025-04-08 14:34:59,267 INFO misc.py line 113 3298914] Train: [3/100][399/2402] Data 0.004 (0.004) Batch 0.558 (0.476) Remain 31:03:24 loss: 1.7023 Lr: 0.00091
[2025-04-08 14:34:59,836 INFO misc.py line 113 3298914] Train: [3/100][400/2402] Data 0.003 (0.004) Batch 0.570 (0.476) Remain 31:04:19 loss: 1.3414 Lr: 0.00091
[2025-04-08 14:35:00,178 INFO misc.py line 113 3298914] Train: [3/100][401/2402] Data 0.004 (0.004) Batch 0.342 (0.476) Remain 31:02:59 loss: 1.0732 Lr: 0.00091
[2025-04-08 14:35:00,647 INFO misc.py line 113 3298914] Train: [3/100][402/2402] Data 0.004 (0.004) Batch 0.468 (0.476) Remain 31:02:55 loss: 1.1766 Lr: 0.00091
[2025-04-08 14:35:01,102 INFO misc.py line 113 3298914] Train: [3/100][403/2402] Data 0.004 (0.004) Batch 0.455 (0.476) Remain 31:02:42 loss: 1.4857 Lr: 0.00091
[2025-04-08 14:35:01,503 INFO misc.py line 113 3298914] Train: [3/100][404/2402] Data 0.004 (0.004) Batch 0.401 (0.475) Remain 31:01:58 loss: 1.1140 Lr: 0.00091
[2025-04-08 14:35:02,066 INFO misc.py line 113 3298914] Train: [3/100][405/2402] Data 0.004 (0.004) Batch 0.563 (0.476) Remain 31:02:49 loss: 1.7108 Lr: 0.00091
[2025-04-08 14:35:02,560 INFO misc.py line 113 3298914] Train: [3/100][406/2402] Data 0.004 (0.004) Batch 0.494 (0.476) Remain 31:02:59 loss: 1.4453 Lr: 0.00091
[2025-04-08 14:35:03,062 INFO misc.py line 113 3298914] Train: [3/100][407/2402] Data 0.004 (0.004) Batch 0.502 (0.476) Remain 31:03:14 loss: 1.4040 Lr: 0.00091
[2025-04-08 14:35:03,506 INFO misc.py line 113 3298914] Train: [3/100][408/2402] Data 0.004 (0.004) Batch 0.444 (0.476) Remain 31:02:54 loss: 1.2284 Lr: 0.00091
[2025-04-08 14:35:03,904 INFO misc.py line 113 3298914] Train: [3/100][409/2402] Data 0.004 (0.004) Batch 0.398 (0.475) Remain 31:02:09 loss: 1.4084 Lr: 0.00091
[2025-04-08 14:35:04,362 INFO misc.py line 113 3298914] Train: [3/100][410/2402] Data 0.004 (0.004) Batch 0.459 (0.475) Remain 31:01:59 loss: 1.2210 Lr: 0.00091
[2025-04-08 14:35:04,841 INFO misc.py line 113 3298914] Train: [3/100][411/2402] Data 0.003 (0.004) Batch 0.479 (0.475) Remain 31:02:00 loss: 1.3426 Lr: 0.00091
[2025-04-08 14:35:05,435 INFO misc.py line 113 3298914] Train: [3/100][412/2402] Data 0.003 (0.004) Batch 0.594 (0.476) Remain 31:03:08 loss: 1.3087 Lr: 0.00091
[2025-04-08 14:35:05,899 INFO misc.py line 113 3298914] Train: [3/100][413/2402] Data 0.004 (0.004) Batch 0.464 (0.476) Remain 31:03:01 loss: 1.0490 Lr: 0.00091
[2025-04-08 14:35:06,383 INFO misc.py line 113 3298914] Train: [3/100][414/2402] Data 0.004 (0.004) Batch 0.485 (0.476) Remain 31:03:05 loss: 1.0320 Lr: 0.00092
[2025-04-08 14:35:06,895 INFO misc.py line 113 3298914] Train: [3/100][415/2402] Data 0.003 (0.004) Batch 0.512 (0.476) Remain 31:03:26 loss: 1.4221 Lr: 0.00092
[2025-04-08 14:35:07,343 INFO misc.py line 113 3298914] Train: [3/100][416/2402] Data 0.004 (0.004) Batch 0.448 (0.476) Remain 31:03:09 loss: 0.9759 Lr: 0.00092
[2025-04-08 14:35:07,741 INFO misc.py line 113 3298914] Train: [3/100][417/2402] Data 0.003 (0.004) Batch 0.398 (0.476) Remain 31:02:24 loss: 0.6448 Lr: 0.00092
[2025-04-08 14:35:08,305 INFO misc.py line 113 3298914] Train: [3/100][418/2402] Data 0.004 (0.004) Batch 0.565 (0.476) Remain 31:03:14 loss: 1.0971 Lr: 0.00092
[2025-04-08 14:35:08,773 INFO misc.py line 113 3298914] Train: [3/100][419/2402] Data 0.003 (0.004) Batch 0.468 (0.476) Remain 31:03:09 loss: 0.8279 Lr: 0.00092
[2025-04-08 14:35:09,278 INFO misc.py line 113 3298914] Train: [3/100][420/2402] Data 0.004 (0.004) Batch 0.505 (0.476) Remain 31:03:25 loss: 0.9868 Lr: 0.00092
[2025-04-08 14:35:09,716 INFO misc.py line 113 3298914] Train: [3/100][421/2402] Data 0.003 (0.004) Batch 0.438 (0.476) Remain 31:03:03 loss: 1.2381 Lr: 0.00092
[2025-04-08 14:35:10,195 INFO misc.py line 113 3298914] Train: [3/100][422/2402] Data 0.003 (0.004) Batch 0.479 (0.476) Remain 31:03:05 loss: 1.2515 Lr: 0.00092
[2025-04-08 14:35:10,595 INFO misc.py line 113 3298914] Train: [3/100][423/2402] Data 0.004 (0.004) Batch 0.401 (0.476) Remain 31:02:22 loss: 0.6555 Lr: 0.00092
[2025-04-08 14:35:11,095 INFO misc.py line 113 3298914] Train: [3/100][424/2402] Data 0.003 (0.004) Batch 0.500 (0.476) Remain 31:02:35 loss: 1.1964 Lr: 0.00092
[2025-04-08 14:35:11,610 INFO misc.py line 113 3298914] Train: [3/100][425/2402] Data 0.003 (0.004) Batch 0.515 (0.476) Remain 31:02:56 loss: 1.1772 Lr: 0.00092
[2025-04-08 14:35:12,088 INFO misc.py line 113 3298914] Train: [3/100][426/2402] Data 0.004 (0.004) Batch 0.478 (0.476) Remain 31:02:57 loss: 1.1338 Lr: 0.00092
[2025-04-08 14:35:12,582 INFO misc.py line 113 3298914] Train: [3/100][427/2402] Data 0.003 (0.004) Batch 0.495 (0.476) Remain 31:03:07 loss: 1.3283 Lr: 0.00092
[2025-04-08 14:35:12,917 INFO misc.py line 113 3298914] Train: [3/100][428/2402] Data 0.003 (0.004) Batch 0.334 (0.475) Remain 31:01:48 loss: 1.5751 Lr: 0.00092
[2025-04-08 14:35:13,337 INFO misc.py line 113 3298914] Train: [3/100][429/2402] Data 0.004 (0.004) Batch 0.421 (0.475) Remain 31:01:18 loss: 1.2593 Lr: 0.00092
[2025-04-08 14:35:13,655 INFO misc.py line 113 3298914] Train: [3/100][430/2402] Data 0.003 (0.004) Batch 0.317 (0.475) Remain 30:59:51 loss: 0.9462 Lr: 0.00092
[2025-04-08 14:35:14,112 INFO misc.py line 113 3298914] Train: [3/100][431/2402] Data 0.004 (0.004) Batch 0.457 (0.475) Remain 30:59:40 loss: 1.4467 Lr: 0.00092
[2025-04-08 14:35:14,607 INFO misc.py line 113 3298914] Train: [3/100][432/2402] Data 0.004 (0.004) Batch 0.495 (0.475) Remain 30:59:51 loss: 1.0055 Lr: 0.00092
[2025-04-08 14:35:15,069 INFO misc.py line 113 3298914] Train: [3/100][433/2402] Data 0.004 (0.004) Batch 0.462 (0.475) Remain 30:59:43 loss: 0.8782 Lr: 0.00092
[2025-04-08 14:35:15,632 INFO misc.py line 113 3298914] Train: [3/100][434/2402] Data 0.003 (0.004) Batch 0.563 (0.475) Remain 31:00:31 loss: 1.0759 Lr: 0.00092
[2025-04-08 14:35:16,134 INFO misc.py line 113 3298914] Train: [3/100][435/2402] Data 0.004 (0.004) Batch 0.502 (0.475) Remain 31:00:45 loss: 1.2235 Lr: 0.00092
[2025-04-08 14:35:16,548 INFO misc.py line 113 3298914] Train: [3/100][436/2402] Data 0.003 (0.004) Batch 0.414 (0.475) Remain 31:00:11 loss: 1.6993 Lr: 0.00092
[2025-04-08 14:35:17,088 INFO misc.py line 113 3298914] Train: [3/100][437/2402] Data 0.003 (0.004) Batch 0.540 (0.475) Remain 31:00:46 loss: 1.5568 Lr: 0.00092
[2025-04-08 14:35:17,464 INFO misc.py line 113 3298914] Train: [3/100][438/2402] Data 0.003 (0.004) Batch 0.376 (0.475) Remain 30:59:52 loss: 1.5515 Lr: 0.00092
[2025-04-08 14:35:17,911 INFO misc.py line 113 3298914] Train: [3/100][439/2402] Data 0.003 (0.004) Batch 0.447 (0.475) Remain 30:59:36 loss: 1.0973 Lr: 0.00092
[2025-04-08 14:35:18,367 INFO misc.py line 113 3298914] Train: [3/100][440/2402] Data 0.003 (0.004) Batch 0.457 (0.475) Remain 30:59:26 loss: 1.6366 Lr: 0.00092
[2025-04-08 14:35:18,932 INFO misc.py line 113 3298914] Train: [3/100][441/2402] Data 0.003 (0.004) Batch 0.565 (0.475) Remain 31:00:14 loss: 1.2515 Lr: 0.00092
[2025-04-08 14:35:19,386 INFO misc.py line 113 3298914] Train: [3/100][442/2402] Data 0.003 (0.004) Batch 0.453 (0.475) Remain 31:00:02 loss: 1.3341 Lr: 0.00092
[2025-04-08 14:35:19,795 INFO misc.py line 113 3298914] Train: [3/100][443/2402] Data 0.003 (0.004) Batch 0.410 (0.475) Remain 30:59:26 loss: 1.1454 Lr: 0.00092
[2025-04-08 14:35:20,326 INFO misc.py line 113 3298914] Train: [3/100][444/2402] Data 0.004 (0.004) Batch 0.531 (0.475) Remain 30:59:56 loss: 0.8108 Lr: 0.00092
[2025-04-08 14:35:20,747 INFO misc.py line 113 3298914] Train: [3/100][445/2402] Data 0.004 (0.004) Batch 0.421 (0.475) Remain 30:59:27 loss: 1.0313 Lr: 0.00092
[2025-04-08 14:35:21,261 INFO misc.py line 113 3298914] Train: [3/100][446/2402] Data 0.003 (0.004) Batch 0.514 (0.475) Remain 30:59:47 loss: 1.1763 Lr: 0.00092
[2025-04-08 14:35:21,699 INFO misc.py line 113 3298914] Train: [3/100][447/2402] Data 0.004 (0.004) Batch 0.438 (0.475) Remain 30:59:27 loss: 1.3902 Lr: 0.00092
[2025-04-08 14:35:22,141 INFO misc.py line 113 3298914] Train: [3/100][448/2402] Data 0.004 (0.004) Batch 0.443 (0.475) Remain 30:59:09 loss: 1.2702 Lr: 0.00092
[2025-04-08 14:35:22,596 INFO misc.py line 113 3298914] Train: [3/100][449/2402] Data 0.004 (0.004) Batch 0.455 (0.475) Remain 30:58:58 loss: 0.8806 Lr: 0.00092
[2025-04-08 14:35:23,125 INFO misc.py line 113 3298914] Train: [3/100][450/2402] Data 0.004 (0.004) Batch 0.529 (0.475) Remain 30:59:26 loss: 1.0104 Lr: 0.00092
[2025-04-08 14:35:23,610 INFO misc.py line 113 3298914] Train: [3/100][451/2402] Data 0.004 (0.004) Batch 0.485 (0.475) Remain 30:59:31 loss: 1.2533 Lr: 0.00092
[2025-04-08 14:35:24,025 INFO misc.py line 113 3298914] Train: [3/100][452/2402] Data 0.003 (0.004) Batch 0.415 (0.475) Remain 30:58:59 loss: 1.4136 Lr: 0.00092
[2025-04-08 14:35:24,386 INFO misc.py line 113 3298914] Train: [3/100][453/2402] Data 0.004 (0.004) Batch 0.362 (0.474) Remain 30:58:00 loss: 1.8334 Lr: 0.00092
[2025-04-08 14:35:24,873 INFO misc.py line 113 3298914] Train: [3/100][454/2402] Data 0.004 (0.004) Batch 0.486 (0.475) Remain 30:58:05 loss: 1.4057 Lr: 0.00092
[2025-04-08 14:35:25,341 INFO misc.py line 113 3298914] Train: [3/100][455/2402] Data 0.003 (0.004) Batch 0.469 (0.475) Remain 30:58:02 loss: 1.2328 Lr: 0.00092
[2025-04-08 14:35:25,845 INFO misc.py line 113 3298914] Train: [3/100][456/2402] Data 0.003 (0.004) Batch 0.504 (0.475) Remain 30:58:17 loss: 1.6120 Lr: 0.00092
[2025-04-08 14:35:26,300 INFO misc.py line 113 3298914] Train: [3/100][457/2402] Data 0.004 (0.004) Batch 0.455 (0.475) Remain 30:58:06 loss: 1.0382 Lr: 0.00093
[2025-04-08 14:35:26,783 INFO misc.py line 113 3298914] Train: [3/100][458/2402] Data 0.003 (0.004) Batch 0.483 (0.475) Remain 30:58:10 loss: 0.9485 Lr: 0.00093
[2025-04-08 14:35:27,195 INFO misc.py line 113 3298914] Train: [3/100][459/2402] Data 0.003 (0.004) Batch 0.412 (0.474) Remain 30:57:37 loss: 1.2450 Lr: 0.00093
[2025-04-08 14:35:27,635 INFO misc.py line 113 3298914] Train: [3/100][460/2402] Data 0.004 (0.004) Batch 0.441 (0.474) Remain 30:57:19 loss: 1.4398 Lr: 0.00093
[2025-04-08 14:35:28,083 INFO misc.py line 113 3298914] Train: [3/100][461/2402] Data 0.003 (0.004) Batch 0.448 (0.474) Remain 30:57:05 loss: 1.2223 Lr: 0.00093
[2025-04-08 14:35:28,682 INFO misc.py line 113 3298914] Train: [3/100][462/2402] Data 0.003 (0.004) Batch 0.599 (0.475) Remain 30:58:08 loss: 1.1788 Lr: 0.00093
[2025-04-08 14:35:29,202 INFO misc.py line 113 3298914] Train: [3/100][463/2402] Data 0.003 (0.004) Batch 0.520 (0.475) Remain 30:58:31 loss: 1.4592 Lr: 0.00093
[2025-04-08 14:35:29,770 INFO misc.py line 113 3298914] Train: [3/100][464/2402] Data 0.003 (0.004) Batch 0.568 (0.475) Remain 30:59:18 loss: 1.3124 Lr: 0.00093
[2025-04-08 14:35:30,296 INFO misc.py line 113 3298914] Train: [3/100][465/2402] Data 0.004 (0.004) Batch 0.526 (0.475) Remain 30:59:44 loss: 1.1470 Lr: 0.00093
[2025-04-08 14:35:30,748 INFO misc.py line 113 3298914] Train: [3/100][466/2402] Data 0.004 (0.004) Batch 0.452 (0.475) Remain 30:59:32 loss: 1.1836 Lr: 0.00093
[2025-04-08 14:35:31,153 INFO misc.py line 113 3298914] Train: [3/100][467/2402] Data 0.003 (0.004) Batch 0.404 (0.475) Remain 30:58:55 loss: 1.3809 Lr: 0.00093
[2025-04-08 14:35:31,591 INFO misc.py line 113 3298914] Train: [3/100][468/2402] Data 0.003 (0.004) Batch 0.438 (0.475) Remain 30:58:37 loss: 0.9237 Lr: 0.00093
[2025-04-08 14:35:32,020 INFO misc.py line 113 3298914] Train: [3/100][469/2402] Data 0.003 (0.004) Batch 0.429 (0.475) Remain 30:58:13 loss: 1.0831 Lr: 0.00093
[2025-04-08 14:35:32,529 INFO misc.py line 113 3298914] Train: [3/100][470/2402] Data 0.004 (0.004) Batch 0.509 (0.475) Remain 30:58:30 loss: 1.0619 Lr: 0.00093
[2025-04-08 14:35:32,948 INFO misc.py line 113 3298914] Train: [3/100][471/2402] Data 0.003 (0.004) Batch 0.419 (0.475) Remain 30:58:01 loss: 1.0566 Lr: 0.00093
[2025-04-08 14:35:33,447 INFO misc.py line 113 3298914] Train: [3/100][472/2402] Data 0.004 (0.004) Batch 0.499 (0.475) Remain 30:58:13 loss: 1.0932 Lr: 0.00093
[2025-04-08 14:35:33,905 INFO misc.py line 113 3298914] Train: [3/100][473/2402] Data 0.004 (0.004) Batch 0.458 (0.475) Remain 30:58:04 loss: 0.9259 Lr: 0.00093
[2025-04-08 14:35:34,359 INFO misc.py line 113 3298914] Train: [3/100][474/2402] Data 0.003 (0.004) Batch 0.454 (0.475) Remain 30:57:53 loss: 1.3079 Lr: 0.00093
[2025-04-08 14:35:34,865 INFO misc.py line 113 3298914] Train: [3/100][475/2402] Data 0.003 (0.004) Batch 0.506 (0.475) Remain 30:58:09 loss: 1.4150 Lr: 0.00093
[2025-04-08 14:35:35,372 INFO misc.py line 113 3298914] Train: [3/100][476/2402] Data 0.004 (0.004) Batch 0.507 (0.475) Remain 30:58:24 loss: 1.3074 Lr: 0.00093
[2025-04-08 14:35:35,809 INFO misc.py line 113 3298914] Train: [3/100][477/2402] Data 0.003 (0.004) Batch 0.437 (0.475) Remain 30:58:05 loss: 1.8695 Lr: 0.00093
[2025-04-08 14:35:36,324 INFO misc.py line 113 3298914] Train: [3/100][478/2402] Data 0.003 (0.004) Batch 0.516 (0.475) Remain 30:58:25 loss: 1.2089 Lr: 0.00093
[2025-04-08 14:35:36,809 INFO misc.py line 113 3298914] Train: [3/100][479/2402] Data 0.004 (0.004) Batch 0.483 (0.475) Remain 30:58:29 loss: 1.1850 Lr: 0.00093
[2025-04-08 14:35:37,267 INFO misc.py line 113 3298914] Train: [3/100][480/2402] Data 0.005 (0.004) Batch 0.459 (0.475) Remain 30:58:21 loss: 1.1501 Lr: 0.00093
[2025-04-08 14:35:37,789 INFO misc.py line 113 3298914] Train: [3/100][481/2402] Data 0.003 (0.004) Batch 0.522 (0.475) Remain 30:58:43 loss: 1.3034 Lr: 0.00093
[2025-04-08 14:35:38,255 INFO misc.py line 113 3298914] Train: [3/100][482/2402] Data 0.003 (0.004) Batch 0.466 (0.475) Remain 30:58:39 loss: 1.2626 Lr: 0.00093
[2025-04-08 14:35:38,699 INFO misc.py line 113 3298914] Train: [3/100][483/2402] Data 0.003 (0.004) Batch 0.445 (0.475) Remain 30:58:23 loss: 1.2101 Lr: 0.00093
[2025-04-08 14:35:39,055 INFO misc.py line 113 3298914] Train: [3/100][484/2402] Data 0.004 (0.004) Batch 0.356 (0.474) Remain 30:57:25 loss: 1.0022 Lr: 0.00093
[2025-04-08 14:35:39,431 INFO misc.py line 113 3298914] Train: [3/100][485/2402] Data 0.004 (0.004) Batch 0.376 (0.474) Remain 30:56:37 loss: 1.2129 Lr: 0.00093
[2025-04-08 14:35:40,094 INFO misc.py line 113 3298914] Train: [3/100][486/2402] Data 0.004 (0.004) Batch 0.663 (0.475) Remain 30:58:08 loss: 1.4026 Lr: 0.00093
[2025-04-08 14:35:40,594 INFO misc.py line 113 3298914] Train: [3/100][487/2402] Data 0.004 (0.004) Batch 0.499 (0.475) Remain 30:58:19 loss: 0.9983 Lr: 0.00093
[2025-04-08 14:35:40,890 INFO misc.py line 113 3298914] Train: [3/100][488/2402] Data 0.003 (0.004) Batch 0.297 (0.474) Remain 30:56:53 loss: 1.7690 Lr: 0.00093
[2025-04-08 14:35:41,360 INFO misc.py line 113 3298914] Train: [3/100][489/2402] Data 0.003 (0.004) Batch 0.469 (0.474) Remain 30:56:50 loss: 1.4963 Lr: 0.00093
[2025-04-08 14:35:41,827 INFO misc.py line 113 3298914] Train: [3/100][490/2402] Data 0.004 (0.004) Batch 0.467 (0.474) Remain 30:56:46 loss: 1.2145 Lr: 0.00093
[2025-04-08 14:35:42,298 INFO misc.py line 113 3298914] Train: [3/100][491/2402] Data 0.004 (0.004) Batch 0.471 (0.474) Remain 30:56:44 loss: 1.3870 Lr: 0.00093
[2025-04-08 14:35:42,963 INFO misc.py line 113 3298914] Train: [3/100][492/2402] Data 0.004 (0.004) Batch 0.665 (0.475) Remain 30:58:15 loss: 1.3293 Lr: 0.00093
[2025-04-08 14:35:43,549 INFO misc.py line 113 3298914] Train: [3/100][493/2402] Data 0.004 (0.004) Batch 0.586 (0.475) Remain 30:59:08 loss: 0.9494 Lr: 0.00093
[2025-04-08 14:35:44,094 INFO misc.py line 113 3298914] Train: [3/100][494/2402] Data 0.004 (0.004) Batch 0.546 (0.475) Remain 30:59:41 loss: 1.4033 Lr: 0.00093
[2025-04-08 14:35:44,443 INFO misc.py line 113 3298914] Train: [3/100][495/2402] Data 0.003 (0.004) Batch 0.348 (0.475) Remain 30:58:40 loss: 1.2157 Lr: 0.00093
[2025-04-08 14:35:44,942 INFO misc.py line 113 3298914] Train: [3/100][496/2402] Data 0.004 (0.004) Batch 0.499 (0.475) Remain 30:58:52 loss: 1.4312 Lr: 0.00093
[2025-04-08 14:35:45,450 INFO misc.py line 113 3298914] Train: [3/100][497/2402] Data 0.004 (0.004) Batch 0.508 (0.475) Remain 30:59:07 loss: 1.1669 Lr: 0.00093
[2025-04-08 14:35:45,914 INFO misc.py line 113 3298914] Train: [3/100][498/2402] Data 0.003 (0.004) Batch 0.464 (0.475) Remain 30:59:01 loss: 1.0074 Lr: 0.00093
[2025-04-08 14:35:46,469 INFO misc.py line 113 3298914] Train: [3/100][499/2402] Data 0.004 (0.004) Batch 0.554 (0.475) Remain 30:59:39 loss: 1.4862 Lr: 0.00093
[2025-04-08 14:35:46,988 INFO misc.py line 113 3298914] Train: [3/100][500/2402] Data 0.003 (0.004) Batch 0.519 (0.475) Remain 30:59:59 loss: 1.3446 Lr: 0.00094
[2025-04-08 14:35:47,395 INFO misc.py line 113 3298914] Train: [3/100][501/2402] Data 0.003 (0.004) Batch 0.408 (0.475) Remain 30:59:27 loss: 1.1623 Lr: 0.00094
[2025-04-08 14:35:47,915 INFO misc.py line 113 3298914] Train: [3/100][502/2402] Data 0.003 (0.004) Batch 0.519 (0.475) Remain 30:59:47 loss: 1.4198 Lr: 0.00094
[2025-04-08 14:35:48,474 INFO misc.py line 113 3298914] Train: [3/100][503/2402] Data 0.003 (0.004) Batch 0.559 (0.475) Remain 31:00:26 loss: 1.4614 Lr: 0.00094
[2025-04-08 14:35:48,920 INFO misc.py line 113 3298914] Train: [3/100][504/2402] Data 0.003 (0.004) Batch 0.447 (0.475) Remain 31:00:12 loss: 1.3411 Lr: 0.00094
[2025-04-08 14:35:49,441 INFO misc.py line 113 3298914] Train: [3/100][505/2402] Data 0.003 (0.004) Batch 0.520 (0.475) Remain 31:00:33 loss: 1.4572 Lr: 0.00094
[2025-04-08 14:35:49,876 INFO misc.py line 113 3298914] Train: [3/100][506/2402] Data 0.003 (0.004) Batch 0.435 (0.475) Remain 31:00:14 loss: 1.2060 Lr: 0.00094
[2025-04-08 14:35:50,307 INFO misc.py line 113 3298914] Train: [3/100][507/2402] Data 0.004 (0.004) Batch 0.430 (0.475) Remain 30:59:52 loss: 1.3626 Lr: 0.00094
[2025-04-08 14:35:50,812 INFO misc.py line 113 3298914] Train: [3/100][508/2402] Data 0.004 (0.004) Batch 0.505 (0.475) Remain 31:00:06 loss: 1.0915 Lr: 0.00094
[2025-04-08 14:35:51,312 INFO misc.py line 113 3298914] Train: [3/100][509/2402] Data 0.003 (0.004) Batch 0.500 (0.475) Remain 31:00:17 loss: 1.0201 Lr: 0.00094
[2025-04-08 14:35:51,851 INFO misc.py line 113 3298914] Train: [3/100][510/2402] Data 0.004 (0.004) Batch 0.539 (0.475) Remain 31:00:46 loss: 0.8676 Lr: 0.00094
[2025-04-08 14:35:52,316 INFO misc.py line 113 3298914] Train: [3/100][511/2402] Data 0.004 (0.004) Batch 0.465 (0.475) Remain 31:00:41 loss: 0.9910 Lr: 0.00094
[2025-04-08 14:35:52,839 INFO misc.py line 113 3298914] Train: [3/100][512/2402] Data 0.003 (0.004) Batch 0.523 (0.475) Remain 31:01:02 loss: 0.8682 Lr: 0.00094
[2025-04-08 14:35:53,320 INFO misc.py line 113 3298914] Train: [3/100][513/2402] Data 0.003 (0.004) Batch 0.481 (0.475) Remain 31:01:04 loss: 1.3204 Lr: 0.00094
[2025-04-08 14:35:53,849 INFO misc.py line 113 3298914] Train: [3/100][514/2402] Data 0.003 (0.004) Batch 0.530 (0.476) Remain 31:01:29 loss: 0.8549 Lr: 0.00094
[2025-04-08 14:35:54,328 INFO misc.py line 113 3298914] Train: [3/100][515/2402] Data 0.003 (0.004) Batch 0.478 (0.476) Remain 31:01:30 loss: 0.9104 Lr: 0.00094
[2025-04-08 14:35:54,873 INFO misc.py line 113 3298914] Train: [3/100][516/2402] Data 0.003 (0.004) Batch 0.546 (0.476) Remain 31:02:01 loss: 1.2280 Lr: 0.00094
[2025-04-08 14:35:55,233 INFO misc.py line 113 3298914] Train: [3/100][517/2402] Data 0.004 (0.004) Batch 0.360 (0.475) Remain 31:01:08 loss: 1.3417 Lr: 0.00094
[2025-04-08 14:35:55,740 INFO misc.py line 113 3298914] Train: [3/100][518/2402] Data 0.004 (0.004) Batch 0.507 (0.475) Remain 31:01:22 loss: 1.1784 Lr: 0.00094
[2025-04-08 14:35:56,252 INFO misc.py line 113 3298914] Train: [3/100][519/2402] Data 0.004 (0.004) Batch 0.512 (0.476) Remain 31:01:38 loss: 1.4495 Lr: 0.00094
[2025-04-08 14:35:56,778 INFO misc.py line 113 3298914] Train: [3/100][520/2402] Data 0.003 (0.004) Batch 0.526 (0.476) Remain 31:02:00 loss: 1.0000 Lr: 0.00094
[2025-04-08 14:35:57,310 INFO misc.py line 113 3298914] Train: [3/100][521/2402] Data 0.004 (0.004) Batch 0.532 (0.476) Remain 31:02:26 loss: 1.1673 Lr: 0.00094
[2025-04-08 14:35:57,736 INFO misc.py line 113 3298914] Train: [3/100][522/2402] Data 0.004 (0.004) Batch 0.426 (0.476) Remain 31:02:02 loss: 0.8352 Lr: 0.00094
[2025-04-08 14:35:58,139 INFO misc.py line 113 3298914] Train: [3/100][523/2402] Data 0.004 (0.004) Batch 0.404 (0.476) Remain 31:01:29 loss: 1.0892 Lr: 0.00094
[2025-04-08 14:35:58,549 INFO misc.py line 113 3298914] Train: [3/100][524/2402] Data 0.003 (0.004) Batch 0.410 (0.475) Remain 31:00:59 loss: 1.3692 Lr: 0.00094
[2025-04-08 14:35:58,960 INFO misc.py line 113 3298914] Train: [3/100][525/2402] Data 0.003 (0.004) Batch 0.410 (0.475) Remain 31:00:30 loss: 1.4640 Lr: 0.00094
[2025-04-08 14:35:59,442 INFO misc.py line 113 3298914] Train: [3/100][526/2402] Data 0.004 (0.004) Batch 0.482 (0.475) Remain 31:00:32 loss: 1.1162 Lr: 0.00094
[2025-04-08 14:35:59,975 INFO misc.py line 113 3298914] Train: [3/100][527/2402] Data 0.003 (0.004) Batch 0.533 (0.475) Remain 31:00:58 loss: 0.7168 Lr: 0.00094
[2025-04-08 14:36:00,478 INFO misc.py line 113 3298914] Train: [3/100][528/2402] Data 0.004 (0.004) Batch 0.503 (0.475) Remain 31:01:09 loss: 1.1816 Lr: 0.00094
[2025-04-08 14:36:00,951 INFO misc.py line 113 3298914] Train: [3/100][529/2402] Data 0.003 (0.004) Batch 0.473 (0.475) Remain 31:01:08 loss: 1.5957 Lr: 0.00094
[2025-04-08 14:36:01,426 INFO misc.py line 113 3298914] Train: [3/100][530/2402] Data 0.003 (0.004) Batch 0.475 (0.475) Remain 31:01:07 loss: 0.9264 Lr: 0.00094
[2025-04-08 14:36:01,906 INFO misc.py line 113 3298914] Train: [3/100][531/2402] Data 0.003 (0.004) Batch 0.480 (0.475) Remain 31:01:09 loss: 0.9395 Lr: 0.00094
[2025-04-08 14:36:02,241 INFO misc.py line 113 3298914] Train: [3/100][532/2402] Data 0.004 (0.004) Batch 0.336 (0.475) Remain 31:00:06 loss: 1.3936 Lr: 0.00094
[2025-04-08 14:36:02,778 INFO misc.py line 113 3298914] Train: [3/100][533/2402] Data 0.003 (0.004) Batch 0.536 (0.475) Remain 31:00:33 loss: 1.1836 Lr: 0.00094
[2025-04-08 14:36:03,266 INFO misc.py line 113 3298914] Train: [3/100][534/2402] Data 0.004 (0.004) Batch 0.488 (0.475) Remain 31:00:38 loss: 1.1671 Lr: 0.00094
[2025-04-08 14:36:03,798 INFO misc.py line 113 3298914] Train: [3/100][535/2402] Data 0.003 (0.004) Batch 0.532 (0.475) Remain 31:01:02 loss: 1.0878 Lr: 0.00094
[2025-04-08 14:36:04,170 INFO misc.py line 113 3298914] Train: [3/100][536/2402] Data 0.003 (0.004) Batch 0.372 (0.475) Remain 31:00:16 loss: 1.3638 Lr: 0.00094
[2025-04-08 14:36:04,713 INFO misc.py line 113 3298914] Train: [3/100][537/2402] Data 0.004 (0.004) Batch 0.543 (0.475) Remain 31:00:46 loss: 1.7070 Lr: 0.00094
[2025-04-08 14:36:05,206 INFO misc.py line 113 3298914] Train: [3/100][538/2402] Data 0.003 (0.004) Batch 0.493 (0.475) Remain 31:00:53 loss: 1.4619 Lr: 0.00094
[2025-04-08 14:36:05,691 INFO misc.py line 113 3298914] Train: [3/100][539/2402] Data 0.004 (0.004) Batch 0.485 (0.475) Remain 31:00:57 loss: 1.6029 Lr: 0.00094
[2025-04-08 14:36:06,260 INFO misc.py line 113 3298914] Train: [3/100][540/2402] Data 0.004 (0.004) Batch 0.569 (0.476) Remain 31:01:37 loss: 1.5468 Lr: 0.00094
[2025-04-08 14:36:06,822 INFO misc.py line 113 3298914] Train: [3/100][541/2402] Data 0.004 (0.004) Batch 0.562 (0.476) Remain 31:02:14 loss: 1.4661 Lr: 0.00094
[2025-04-08 14:36:07,276 INFO misc.py line 113 3298914] Train: [3/100][542/2402] Data 0.003 (0.004) Batch 0.454 (0.476) Remain 31:02:04 loss: 0.9946 Lr: 0.00094
[2025-04-08 14:36:07,761 INFO misc.py line 113 3298914] Train: [3/100][543/2402] Data 0.004 (0.004) Batch 0.485 (0.476) Remain 31:02:08 loss: 1.3028 Lr: 0.00095
[2025-04-08 14:36:08,193 INFO misc.py line 113 3298914] Train: [3/100][544/2402] Data 0.004 (0.004) Batch 0.432 (0.476) Remain 31:01:48 loss: 0.7899 Lr: 0.00095
[2025-04-08 14:36:08,781 INFO misc.py line 113 3298914] Train: [3/100][545/2402] Data 0.003 (0.004) Batch 0.588 (0.476) Remain 31:02:37 loss: 1.5703 Lr: 0.00095
[2025-04-08 14:36:09,310 INFO misc.py line 113 3298914] Train: [3/100][546/2402] Data 0.003 (0.004) Batch 0.529 (0.476) Remain 31:02:59 loss: 1.1330 Lr: 0.00095
[2025-04-08 14:36:09,788 INFO misc.py line 113 3298914] Train: [3/100][547/2402] Data 0.004 (0.004) Batch 0.478 (0.476) Remain 31:03:00 loss: 0.7121 Lr: 0.00095
[2025-04-08 14:36:10,183 INFO misc.py line 113 3298914] Train: [3/100][548/2402] Data 0.003 (0.004) Batch 0.396 (0.476) Remain 31:02:25 loss: 1.7583 Lr: 0.00095
[2025-04-08 14:36:10,742 INFO misc.py line 113 3298914] Train: [3/100][549/2402] Data 0.003 (0.004) Batch 0.559 (0.476) Remain 31:03:00 loss: 1.4072 Lr: 0.00095
[2025-04-08 14:36:11,207 INFO misc.py line 113 3298914] Train: [3/100][550/2402] Data 0.004 (0.004) Batch 0.464 (0.476) Remain 31:02:54 loss: 1.2706 Lr: 0.00095
[2025-04-08 14:36:11,757 INFO misc.py line 113 3298914] Train: [3/100][551/2402] Data 0.004 (0.004) Batch 0.551 (0.476) Remain 31:03:26 loss: 1.2054 Lr: 0.00095
[2025-04-08 14:36:12,291 INFO misc.py line 113 3298914] Train: [3/100][552/2402] Data 0.004 (0.004) Batch 0.534 (0.476) Remain 31:03:50 loss: 1.0070 Lr: 0.00095
[2025-04-08 14:36:12,903 INFO misc.py line 113 3298914] Train: [3/100][553/2402] Data 0.003 (0.004) Batch 0.612 (0.476) Remain 31:04:48 loss: 0.8368 Lr: 0.00095
[2025-04-08 14:36:13,417 INFO misc.py line 113 3298914] Train: [3/100][554/2402] Data 0.004 (0.004) Batch 0.514 (0.477) Remain 31:05:03 loss: 1.4735 Lr: 0.00095
[2025-04-08 14:36:13,909 INFO misc.py line 113 3298914] Train: [3/100][555/2402] Data 0.003 (0.004) Batch 0.492 (0.477) Remain 31:05:09 loss: 1.4036 Lr: 0.00095
[2025-04-08 14:36:14,461 INFO misc.py line 113 3298914] Train: [3/100][556/2402] Data 0.004 (0.004) Batch 0.552 (0.477) Remain 31:05:40 loss: 1.6553 Lr: 0.00095
[2025-04-08 14:36:14,996 INFO misc.py line 113 3298914] Train: [3/100][557/2402] Data 0.004 (0.004) Batch 0.535 (0.477) Remain 31:06:05 loss: 1.2196 Lr: 0.00095
[2025-04-08 14:36:15,495 INFO misc.py line 113 3298914] Train: [3/100][558/2402] Data 0.004 (0.004) Batch 0.499 (0.477) Remain 31:06:14 loss: 1.3680 Lr: 0.00095
[2025-04-08 14:36:15,967 INFO misc.py line 113 3298914] Train: [3/100][559/2402] Data 0.003 (0.004) Batch 0.472 (0.477) Remain 31:06:12 loss: 1.3712 Lr: 0.00095
[2025-04-08 14:36:16,519 INFO misc.py line 113 3298914] Train: [3/100][560/2402] Data 0.003 (0.004) Batch 0.552 (0.477) Remain 31:06:43 loss: 1.3098 Lr: 0.00095
[2025-04-08 14:36:17,029 INFO misc.py line 113 3298914] Train: [3/100][561/2402] Data 0.004 (0.004) Batch 0.510 (0.477) Remain 31:06:56 loss: 0.9569 Lr: 0.00095
[2025-04-08 14:36:17,403 INFO misc.py line 113 3298914] Train: [3/100][562/2402] Data 0.003 (0.004) Batch 0.374 (0.477) Remain 31:06:12 loss: 1.3114 Lr: 0.00095
[2025-04-08 14:36:17,930 INFO misc.py line 113 3298914] Train: [3/100][563/2402] Data 0.004 (0.004) Batch 0.527 (0.477) Remain 31:06:33 loss: 1.1111 Lr: 0.00095
[2025-04-08 14:36:18,396 INFO misc.py line 113 3298914] Train: [3/100][564/2402] Data 0.004 (0.004) Batch 0.465 (0.477) Remain 31:06:28 loss: 1.2212 Lr: 0.00095
[2025-04-08 14:36:18,932 INFO misc.py line 113 3298914] Train: [3/100][565/2402] Data 0.004 (0.004) Batch 0.536 (0.477) Remain 31:06:52 loss: 1.4813 Lr: 0.00095
[2025-04-08 14:36:19,324 INFO misc.py line 113 3298914] Train: [3/100][566/2402] Data 0.003 (0.004) Batch 0.392 (0.477) Remain 31:06:16 loss: 1.3848 Lr: 0.00095
[2025-04-08 14:36:19,633 INFO misc.py line 113 3298914] Train: [3/100][567/2402] Data 0.004 (0.004) Batch 0.309 (0.477) Remain 31:05:06 loss: 1.5749 Lr: 0.00095
[2025-04-08 14:36:20,120 INFO misc.py line 113 3298914] Train: [3/100][568/2402] Data 0.003 (0.004) Batch 0.487 (0.477) Remain 31:05:10 loss: 1.5413 Lr: 0.00095
[2025-04-08 14:36:20,492 INFO misc.py line 113 3298914] Train: [3/100][569/2402] Data 0.004 (0.004) Batch 0.372 (0.476) Remain 31:04:26 loss: 0.9634 Lr: 0.00095
[2025-04-08 14:36:20,984 INFO misc.py line 113 3298914] Train: [3/100][570/2402] Data 0.004 (0.004) Batch 0.492 (0.476) Remain 31:04:32 loss: 1.0492 Lr: 0.00095
[2025-04-08 14:36:21,374 INFO misc.py line 113 3298914] Train: [3/100][571/2402] Data 0.004 (0.004) Batch 0.390 (0.476) Remain 31:03:55 loss: 0.6949 Lr: 0.00095
[2025-04-08 14:36:21,842 INFO misc.py line 113 3298914] Train: [3/100][572/2402] Data 0.003 (0.004) Batch 0.468 (0.476) Remain 31:03:52 loss: 1.2882 Lr: 0.00095
[2025-04-08 14:36:22,354 INFO misc.py line 113 3298914] Train: [3/100][573/2402] Data 0.004 (0.004) Batch 0.511 (0.476) Remain 31:04:06 loss: 1.2423 Lr: 0.00095
[2025-04-08 14:36:22,755 INFO misc.py line 113 3298914] Train: [3/100][574/2402] Data 0.004 (0.004) Batch 0.401 (0.476) Remain 31:03:34 loss: 0.8445 Lr: 0.00095
[2025-04-08 14:36:23,186 INFO misc.py line 113 3298914] Train: [3/100][575/2402] Data 0.003 (0.004) Batch 0.431 (0.476) Remain 31:03:15 loss: 1.4172 Lr: 0.00095
[2025-04-08 14:36:23,614 INFO misc.py line 113 3298914] Train: [3/100][576/2402] Data 0.004 (0.004) Batch 0.429 (0.476) Remain 31:02:55 loss: 1.4604 Lr: 0.00095
[2025-04-08 14:36:24,003 INFO misc.py line 113 3298914] Train: [3/100][577/2402] Data 0.004 (0.004) Batch 0.389 (0.476) Remain 31:02:19 loss: 1.3732 Lr: 0.00095
[2025-04-08 14:36:24,569 INFO misc.py line 113 3298914] Train: [3/100][578/2402] Data 0.003 (0.004) Batch 0.566 (0.476) Remain 31:02:56 loss: 0.9871 Lr: 0.00095
[2025-04-08 14:36:25,058 INFO misc.py line 113 3298914] Train: [3/100][579/2402] Data 0.004 (0.004) Batch 0.488 (0.476) Remain 31:03:00 loss: 1.1963 Lr: 0.00095
[2025-04-08 14:36:25,626 INFO misc.py line 113 3298914] Train: [3/100][580/2402] Data 0.003 (0.004) Batch 0.569 (0.476) Remain 31:03:37 loss: 1.3004 Lr: 0.00095
[2025-04-08 14:36:26,125 INFO misc.py line 113 3298914] Train: [3/100][581/2402] Data 0.004 (0.004) Batch 0.499 (0.476) Remain 31:03:46 loss: 0.9029 Lr: 0.00095
[2025-04-08 14:36:26,634 INFO misc.py line 113 3298914] Train: [3/100][582/2402] Data 0.003 (0.004) Batch 0.509 (0.476) Remain 31:03:59 loss: 1.1328 Lr: 0.00095
[2025-04-08 14:36:27,034 INFO misc.py line 113 3298914] Train: [3/100][583/2402] Data 0.004 (0.004) Batch 0.399 (0.476) Remain 31:03:27 loss: 1.1542 Lr: 0.00095
[2025-04-08 14:36:27,507 INFO misc.py line 113 3298914] Train: [3/100][584/2402] Data 0.004 (0.004) Batch 0.473 (0.476) Remain 31:03:26 loss: 1.1125 Lr: 0.00095
[2025-04-08 14:36:27,947 INFO misc.py line 113 3298914] Train: [3/100][585/2402] Data 0.004 (0.004) Batch 0.441 (0.476) Remain 31:03:11 loss: 1.0414 Lr: 0.00095
[2025-04-08 14:36:28,352 INFO misc.py line 113 3298914] Train: [3/100][586/2402] Data 0.004 (0.004) Batch 0.405 (0.476) Remain 31:02:42 loss: 1.3113 Lr: 0.00096
[2025-04-08 14:36:28,878 INFO misc.py line 113 3298914] Train: [3/100][587/2402] Data 0.003 (0.004) Batch 0.526 (0.476) Remain 31:03:01 loss: 1.2715 Lr: 0.00096
[2025-04-08 14:36:29,259 INFO misc.py line 113 3298914] Train: [3/100][588/2402] Data 0.003 (0.004) Batch 0.381 (0.476) Remain 31:02:23 loss: 1.3149 Lr: 0.00096
[2025-04-08 14:36:29,860 INFO misc.py line 113 3298914] Train: [3/100][589/2402] Data 0.003 (0.004) Batch 0.601 (0.476) Remain 31:03:12 loss: 1.6526 Lr: 0.00096
[2025-04-08 14:36:30,273 INFO misc.py line 113 3298914] Train: [3/100][590/2402] Data 0.004 (0.004) Batch 0.413 (0.476) Remain 31:02:46 loss: 1.5523 Lr: 0.00096
[2025-04-08 14:36:30,718 INFO misc.py line 113 3298914] Train: [3/100][591/2402] Data 0.003 (0.004) Batch 0.445 (0.476) Remain 31:02:34 loss: 1.2962 Lr: 0.00096
[2025-04-08 14:36:31,135 INFO misc.py line 113 3298914] Train: [3/100][592/2402] Data 0.003 (0.004) Batch 0.417 (0.476) Remain 31:02:10 loss: 1.4296 Lr: 0.00096
[2025-04-08 14:36:31,652 INFO misc.py line 113 3298914] Train: [3/100][593/2402] Data 0.003 (0.004) Batch 0.516 (0.476) Remain 31:02:26 loss: 1.0201 Lr: 0.00096
[2025-04-08 14:36:32,174 INFO misc.py line 113 3298914] Train: [3/100][594/2402] Data 0.003 (0.004) Batch 0.522 (0.476) Remain 31:02:44 loss: 1.3283 Lr: 0.00096
[2025-04-08 14:36:32,668 INFO misc.py line 113 3298914] Train: [3/100][595/2402] Data 0.004 (0.004) Batch 0.493 (0.476) Remain 31:02:50 loss: 0.9547 Lr: 0.00096
[2025-04-08 14:36:33,143 INFO misc.py line 113 3298914] Train: [3/100][596/2402] Data 0.003 (0.004) Batch 0.475 (0.476) Remain 31:02:49 loss: 1.2334 Lr: 0.00096
[2025-04-08 14:36:33,688 INFO misc.py line 113 3298914] Train: [3/100][597/2402] Data 0.003 (0.004) Batch 0.545 (0.476) Remain 31:03:16 loss: 1.2259 Lr: 0.00096
[2025-04-08 14:36:34,153 INFO misc.py line 113 3298914] Train: [3/100][598/2402] Data 0.003 (0.004) Batch 0.465 (0.476) Remain 31:03:11 loss: 1.1068 Lr: 0.00096
[2025-04-08 14:36:34,670 INFO misc.py line 113 3298914] Train: [3/100][599/2402] Data 0.004 (0.004) Batch 0.517 (0.476) Remain 31:03:27 loss: 1.2231 Lr: 0.00096
[2025-04-08 14:36:35,124 INFO misc.py line 113 3298914] Train: [3/100][600/2402] Data 0.004 (0.004) Batch 0.454 (0.476) Remain 31:03:17 loss: 1.6278 Lr: 0.00096
[2025-04-08 14:36:35,548 INFO misc.py line 113 3298914] Train: [3/100][601/2402] Data 0.004 (0.004) Batch 0.424 (0.476) Remain 31:02:57 loss: 1.7021 Lr: 0.00096
[2025-04-08 14:36:36,020 INFO misc.py line 113 3298914] Train: [3/100][602/2402] Data 0.003 (0.004) Batch 0.472 (0.476) Remain 31:02:55 loss: 1.0570 Lr: 0.00096
[2025-04-08 14:36:36,458 INFO misc.py line 113 3298914] Train: [3/100][603/2402] Data 0.004 (0.004) Batch 0.437 (0.476) Remain 31:02:39 loss: 1.2391 Lr: 0.00096
[2025-04-08 14:36:36,928 INFO misc.py line 113 3298914] Train: [3/100][604/2402] Data 0.003 (0.004) Batch 0.470 (0.476) Remain 31:02:36 loss: 1.3151 Lr: 0.00096
[2025-04-08 14:36:37,430 INFO misc.py line 113 3298914] Train: [3/100][605/2402] Data 0.004 (0.004) Batch 0.502 (0.476) Remain 31:02:46 loss: 1.2875 Lr: 0.00096
[2025-04-08 14:36:37,857 INFO misc.py line 113 3298914] Train: [3/100][606/2402] Data 0.004 (0.004) Batch 0.427 (0.476) Remain 31:02:26 loss: 1.4107 Lr: 0.00096
[2025-04-08 14:36:38,294 INFO misc.py line 113 3298914] Train: [3/100][607/2402] Data 0.004 (0.004) Batch 0.437 (0.476) Remain 31:02:11 loss: 1.2329 Lr: 0.00096
[2025-04-08 14:36:38,698 INFO misc.py line 113 3298914] Train: [3/100][608/2402] Data 0.004 (0.004) Batch 0.403 (0.476) Remain 31:01:42 loss: 1.3953 Lr: 0.00096
[2025-04-08 14:36:39,192 INFO misc.py line 113 3298914] Train: [3/100][609/2402] Data 0.004 (0.004) Batch 0.494 (0.476) Remain 31:01:49 loss: 1.0958 Lr: 0.00096
[2025-04-08 14:36:39,650 INFO misc.py line 113 3298914] Train: [3/100][610/2402] Data 0.003 (0.004) Batch 0.458 (0.476) Remain 31:01:42 loss: 1.2725 Lr: 0.00096
[2025-04-08 14:36:40,186 INFO misc.py line 113 3298914] Train: [3/100][611/2402] Data 0.003 (0.004) Batch 0.536 (0.476) Remain 31:02:04 loss: 1.6823 Lr: 0.00096
[2025-04-08 14:36:40,662 INFO misc.py line 113 3298914] Train: [3/100][612/2402] Data 0.004 (0.004) Batch 0.476 (0.476) Remain 31:02:04 loss: 1.1803 Lr: 0.00096
[2025-04-08 14:36:41,127 INFO misc.py line 113 3298914] Train: [3/100][613/2402] Data 0.004 (0.004) Batch 0.465 (0.476) Remain 31:01:59 loss: 1.0385 Lr: 0.00096
[2025-04-08 14:36:41,499 INFO misc.py line 113 3298914] Train: [3/100][614/2402] Data 0.004 (0.004) Batch 0.372 (0.476) Remain 31:01:19 loss: 1.2978 Lr: 0.00096
[2025-04-08 14:36:41,961 INFO misc.py line 113 3298914] Train: [3/100][615/2402] Data 0.003 (0.004) Batch 0.462 (0.476) Remain 31:01:13 loss: 1.0906 Lr: 0.00096
[2025-04-08 14:36:42,480 INFO misc.py line 113 3298914] Train: [3/100][616/2402] Data 0.004 (0.004) Batch 0.520 (0.476) Remain 31:01:30 loss: 1.2999 Lr: 0.00096
[2025-04-08 14:36:42,976 INFO misc.py line 113 3298914] Train: [3/100][617/2402] Data 0.004 (0.004) Batch 0.496 (0.476) Remain 31:01:37 loss: 1.2601 Lr: 0.00096
[2025-04-08 14:36:43,452 INFO misc.py line 113 3298914] Train: [3/100][618/2402] Data 0.004 (0.004) Batch 0.475 (0.476) Remain 31:01:36 loss: 1.3032 Lr: 0.00096
[2025-04-08 14:36:43,960 INFO misc.py line 113 3298914] Train: [3/100][619/2402] Data 0.003 (0.004) Batch 0.509 (0.476) Remain 31:01:48 loss: 1.2847 Lr: 0.00096
[2025-04-08 14:36:44,528 INFO misc.py line 113 3298914] Train: [3/100][620/2402] Data 0.003 (0.004) Batch 0.567 (0.476) Remain 31:02:23 loss: 1.3074 Lr: 0.00096
[2025-04-08 14:36:45,062 INFO misc.py line 113 3298914] Train: [3/100][621/2402] Data 0.003 (0.004) Batch 0.534 (0.476) Remain 31:02:44 loss: 1.2322 Lr: 0.00096
[2025-04-08 14:36:45,597 INFO misc.py line 113 3298914] Train: [3/100][622/2402] Data 0.004 (0.004) Batch 0.535 (0.476) Remain 31:03:06 loss: 1.2827 Lr: 0.00096
[2025-04-08 14:36:46,084 INFO misc.py line 113 3298914] Train: [3/100][623/2402] Data 0.003 (0.004) Batch 0.487 (0.476) Remain 31:03:10 loss: 1.0189 Lr: 0.00096
[2025-04-08 14:36:46,449 INFO misc.py line 113 3298914] Train: [3/100][624/2402] Data 0.003 (0.004) Batch 0.366 (0.476) Remain 31:02:28 loss: 2.0598 Lr: 0.00096
[2025-04-08 14:36:46,992 INFO misc.py line 113 3298914] Train: [3/100][625/2402] Data 0.003 (0.004) Batch 0.542 (0.476) Remain 31:02:52 loss: 1.3426 Lr: 0.00096
[2025-04-08 14:36:47,509 INFO misc.py line 113 3298914] Train: [3/100][626/2402] Data 0.004 (0.004) Batch 0.518 (0.476) Remain 31:03:07 loss: 1.0045 Lr: 0.00096
[2025-04-08 14:36:47,920 INFO misc.py line 113 3298914] Train: [3/100][627/2402] Data 0.004 (0.004) Batch 0.411 (0.476) Remain 31:02:42 loss: 1.2093 Lr: 0.00096
[2025-04-08 14:36:48,352 INFO misc.py line 113 3298914] Train: [3/100][628/2402] Data 0.003 (0.004) Batch 0.431 (0.476) Remain 31:02:25 loss: 1.0788 Lr: 0.00096
[2025-04-08 14:36:48,811 INFO misc.py line 113 3298914] Train: [3/100][629/2402] Data 0.003 (0.004) Batch 0.459 (0.476) Remain 31:02:18 loss: 1.3131 Lr: 0.00097
[2025-04-08 14:36:49,215 INFO misc.py line 113 3298914] Train: [3/100][630/2402] Data 0.004 (0.004) Batch 0.404 (0.476) Remain 31:01:51 loss: 1.5501 Lr: 0.00097
[2025-04-08 14:36:49,648 INFO misc.py line 113 3298914] Train: [3/100][631/2402] Data 0.003 (0.004) Batch 0.433 (0.476) Remain 31:01:34 loss: 1.1007 Lr: 0.00097
[2025-04-08 14:36:50,148 INFO misc.py line 113 3298914] Train: [3/100][632/2402] Data 0.004 (0.004) Batch 0.500 (0.476) Remain 31:01:43 loss: 1.2879 Lr: 0.00097
[2025-04-08 14:36:50,646 INFO misc.py line 113 3298914] Train: [3/100][633/2402] Data 0.004 (0.004) Batch 0.499 (0.476) Remain 31:01:51 loss: 1.1915 Lr: 0.00097
[2025-04-08 14:36:51,151 INFO misc.py line 113 3298914] Train: [3/100][634/2402] Data 0.003 (0.004) Batch 0.505 (0.476) Remain 31:02:01 loss: 0.9099 Lr: 0.00097
[2025-04-08 14:36:51,556 INFO misc.py line 113 3298914] Train: [3/100][635/2402] Data 0.004 (0.004) Batch 0.405 (0.476) Remain 31:01:34 loss: 1.4065 Lr: 0.00097
[2025-04-08 14:36:52,023 INFO misc.py line 113 3298914] Train: [3/100][636/2402] Data 0.003 (0.004) Batch 0.467 (0.476) Remain 31:01:31 loss: 1.6360 Lr: 0.00097
[2025-04-08 14:36:52,512 INFO misc.py line 113 3298914] Train: [3/100][637/2402] Data 0.003 (0.004) Batch 0.489 (0.476) Remain 31:01:35 loss: 1.4747 Lr: 0.00097
[2025-04-08 14:36:53,046 INFO misc.py line 113 3298914] Train: [3/100][638/2402] Data 0.004 (0.004) Batch 0.533 (0.476) Remain 31:01:56 loss: 1.0734 Lr: 0.00097
[2025-04-08 14:36:53,516 INFO misc.py line 113 3298914] Train: [3/100][639/2402] Data 0.004 (0.004) Batch 0.471 (0.476) Remain 31:01:53 loss: 1.0899 Lr: 0.00097
[2025-04-08 14:36:53,899 INFO misc.py line 113 3298914] Train: [3/100][640/2402] Data 0.003 (0.004) Batch 0.383 (0.476) Remain 31:01:19 loss: 0.9903 Lr: 0.00097
[2025-04-08 14:36:54,425 INFO misc.py line 113 3298914] Train: [3/100][641/2402] Data 0.003 (0.004) Batch 0.525 (0.476) Remain 31:01:37 loss: 1.3833 Lr: 0.00097
[2025-04-08 14:36:54,889 INFO misc.py line 113 3298914] Train: [3/100][642/2402] Data 0.003 (0.004) Batch 0.464 (0.476) Remain 31:01:32 loss: 1.2585 Lr: 0.00097
[2025-04-08 14:36:55,402 INFO misc.py line 113 3298914] Train: [3/100][643/2402] Data 0.003 (0.004) Batch 0.513 (0.476) Remain 31:01:45 loss: 1.2956 Lr: 0.00097
[2025-04-08 14:36:55,816 INFO misc.py line 113 3298914] Train: [3/100][644/2402] Data 0.004 (0.004) Batch 0.413 (0.476) Remain 31:01:21 loss: 1.3780 Lr: 0.00097
[2025-04-08 14:36:56,382 INFO misc.py line 113 3298914] Train: [3/100][645/2402] Data 0.004 (0.004) Batch 0.567 (0.476) Remain 31:01:54 loss: 1.3362 Lr: 0.00097
[2025-04-08 14:36:56,904 INFO misc.py line 113 3298914] Train: [3/100][646/2402] Data 0.003 (0.004) Batch 0.522 (0.476) Remain 31:02:11 loss: 1.0526 Lr: 0.00097
[2025-04-08 14:36:57,440 INFO misc.py line 113 3298914] Train: [3/100][647/2402] Data 0.004 (0.004) Batch 0.536 (0.476) Remain 31:02:32 loss: 1.3078 Lr: 0.00097
[2025-04-08 14:36:57,940 INFO misc.py line 113 3298914] Train: [3/100][648/2402] Data 0.003 (0.004) Batch 0.500 (0.476) Remain 31:02:40 loss: 1.7049 Lr: 0.00097
[2025-04-08 14:36:58,301 INFO misc.py line 113 3298914] Train: [3/100][649/2402] Data 0.003 (0.004) Batch 0.361 (0.476) Remain 31:01:58 loss: 1.0555 Lr: 0.00097
[2025-04-08 14:36:58,680 INFO misc.py line 113 3298914] Train: [3/100][650/2402] Data 0.004 (0.004) Batch 0.379 (0.476) Remain 31:01:23 loss: 1.0968 Lr: 0.00097
[2025-04-08 14:36:59,209 INFO misc.py line 113 3298914] Train: [3/100][651/2402] Data 0.004 (0.004) Batch 0.529 (0.476) Remain 31:01:41 loss: 1.2634 Lr: 0.00097
[2025-04-08 14:36:59,728 INFO misc.py line 113 3298914] Train: [3/100][652/2402] Data 0.015 (0.004) Batch 0.519 (0.476) Remain 31:01:56 loss: 1.2129 Lr: 0.00097
[2025-04-08 14:37:00,274 INFO misc.py line 113 3298914] Train: [3/100][653/2402] Data 0.003 (0.004) Batch 0.546 (0.476) Remain 31:02:21 loss: 0.8830 Lr: 0.00097
[2025-04-08 14:37:00,741 INFO misc.py line 113 3298914] Train: [3/100][654/2402] Data 0.004 (0.004) Batch 0.467 (0.476) Remain 31:02:17 loss: 1.5160 Lr: 0.00097
[2025-04-08 14:37:01,152 INFO misc.py line 113 3298914] Train: [3/100][655/2402] Data 0.003 (0.004) Batch 0.411 (0.476) Remain 31:01:54 loss: 1.3013 Lr: 0.00097
[2025-04-08 14:37:01,673 INFO misc.py line 113 3298914] Train: [3/100][656/2402] Data 0.003 (0.004) Batch 0.521 (0.476) Remain 31:02:09 loss: 1.0391 Lr: 0.00097
[2025-04-08 14:37:02,181 INFO misc.py line 113 3298914] Train: [3/100][657/2402] Data 0.004 (0.004) Batch 0.507 (0.476) Remain 31:02:20 loss: 1.0507 Lr: 0.00097
[2025-04-08 14:37:02,665 INFO misc.py line 113 3298914] Train: [3/100][658/2402] Data 0.003 (0.004) Batch 0.484 (0.476) Remain 31:02:23 loss: 1.4900 Lr: 0.00097
[2025-04-08 14:37:03,213 INFO misc.py line 113 3298914] Train: [3/100][659/2402] Data 0.004 (0.004) Batch 0.548 (0.476) Remain 31:02:48 loss: 0.8372 Lr: 0.00097
[2025-04-08 14:37:03,809 INFO misc.py line 113 3298914] Train: [3/100][660/2402] Data 0.004 (0.004) Batch 0.596 (0.476) Remain 31:03:30 loss: 1.1985 Lr: 0.00097
[2025-04-08 14:37:04,385 INFO misc.py line 113 3298914] Train: [3/100][661/2402] Data 0.003 (0.004) Batch 0.576 (0.476) Remain 31:04:05 loss: 1.3286 Lr: 0.00097
[2025-04-08 14:37:04,984 INFO misc.py line 113 3298914] Train: [3/100][662/2402] Data 0.003 (0.004) Batch 0.600 (0.477) Remain 31:04:49 loss: 1.0577 Lr: 0.00097
[2025-04-08 14:37:05,445 INFO misc.py line 113 3298914] Train: [3/100][663/2402] Data 0.003 (0.004) Batch 0.461 (0.477) Remain 31:04:43 loss: 0.9835 Lr: 0.00097
[2025-04-08 14:37:06,003 INFO misc.py line 113 3298914] Train: [3/100][664/2402] Data 0.004 (0.004) Batch 0.558 (0.477) Remain 31:05:11 loss: 1.3165 Lr: 0.00097
[2025-04-08 14:37:06,459 INFO misc.py line 113 3298914] Train: [3/100][665/2402] Data 0.004 (0.004) Batch 0.457 (0.477) Remain 31:05:03 loss: 1.3585 Lr: 0.00097
[2025-04-08 14:37:06,997 INFO misc.py line 113 3298914] Train: [3/100][666/2402] Data 0.004 (0.004) Batch 0.537 (0.477) Remain 31:05:24 loss: 1.4307 Lr: 0.00097
[2025-04-08 14:37:07,453 INFO misc.py line 113 3298914] Train: [3/100][667/2402] Data 0.004 (0.004) Batch 0.457 (0.477) Remain 31:05:17 loss: 1.0733 Lr: 0.00097
[2025-04-08 14:37:07,905 INFO misc.py line 113 3298914] Train: [3/100][668/2402] Data 0.003 (0.004) Batch 0.451 (0.477) Remain 31:05:07 loss: 1.0501 Lr: 0.00097
[2025-04-08 14:37:08,344 INFO misc.py line 113 3298914] Train: [3/100][669/2402] Data 0.004 (0.004) Batch 0.440 (0.477) Remain 31:04:54 loss: 1.6798 Lr: 0.00097
[2025-04-08 14:37:08,798 INFO misc.py line 113 3298914] Train: [3/100][670/2402] Data 0.003 (0.004) Batch 0.454 (0.477) Remain 31:04:45 loss: 1.0574 Lr: 0.00097
[2025-04-08 14:37:09,243 INFO misc.py line 113 3298914] Train: [3/100][671/2402] Data 0.003 (0.004) Batch 0.445 (0.477) Remain 31:04:33 loss: 1.0265 Lr: 0.00097
[2025-04-08 14:37:09,767 INFO misc.py line 113 3298914] Train: [3/100][672/2402] Data 0.004 (0.004) Batch 0.523 (0.477) Remain 31:04:49 loss: 1.3383 Lr: 0.00098
[2025-04-08 14:37:10,203 INFO misc.py line 113 3298914] Train: [3/100][673/2402] Data 0.003 (0.004) Batch 0.437 (0.477) Remain 31:04:35 loss: 1.1339 Lr: 0.00098
[2025-04-08 14:37:10,662 INFO misc.py line 113 3298914] Train: [3/100][674/2402] Data 0.003 (0.004) Batch 0.459 (0.477) Remain 31:04:28 loss: 0.8770 Lr: 0.00098
[2025-04-08 14:37:11,090 INFO misc.py line 113 3298914] Train: [3/100][675/2402] Data 0.003 (0.004) Batch 0.427 (0.477) Remain 31:04:11 loss: 1.4096 Lr: 0.00098
[2025-04-08 14:37:11,677 INFO misc.py line 113 3298914] Train: [3/100][676/2402] Data 0.003 (0.004) Batch 0.587 (0.477) Remain 31:04:49 loss: 1.2865 Lr: 0.00098
[2025-04-08 14:37:12,122 INFO misc.py line 113 3298914] Train: [3/100][677/2402] Data 0.004 (0.004) Batch 0.445 (0.477) Remain 31:04:37 loss: 1.1115 Lr: 0.00098
[2025-04-08 14:37:12,655 INFO misc.py line 113 3298914] Train: [3/100][678/2402] Data 0.004 (0.004) Batch 0.533 (0.477) Remain 31:04:56 loss: 1.4860 Lr: 0.00098
[2025-04-08 14:37:13,092 INFO misc.py line 113 3298914] Train: [3/100][679/2402] Data 0.003 (0.004) Batch 0.436 (0.477) Remain 31:04:42 loss: 1.2161 Lr: 0.00098
[2025-04-08 14:37:13,684 INFO misc.py line 113 3298914] Train: [3/100][680/2402] Data 0.004 (0.004) Batch 0.593 (0.477) Remain 31:05:22 loss: 1.3479 Lr: 0.00098
[2025-04-08 14:37:14,161 INFO misc.py line 113 3298914] Train: [3/100][681/2402] Data 0.004 (0.004) Batch 0.477 (0.477) Remain 31:05:21 loss: 1.5072 Lr: 0.00098
[2025-04-08 14:37:14,723 INFO misc.py line 113 3298914] Train: [3/100][682/2402] Data 0.004 (0.004) Batch 0.562 (0.477) Remain 31:05:50 loss: 1.5316 Lr: 0.00098
[2025-04-08 14:37:15,273 INFO misc.py line 113 3298914] Train: [3/100][683/2402] Data 0.003 (0.004) Batch 0.550 (0.477) Remain 31:06:15 loss: 1.1297 Lr: 0.00098
[2025-04-08 14:37:15,651 INFO misc.py line 113 3298914] Train: [3/100][684/2402] Data 0.004 (0.004) Batch 0.378 (0.477) Remain 31:05:40 loss: 1.0652 Lr: 0.00098
[2025-04-08 14:37:16,159 INFO misc.py line 113 3298914] Train: [3/100][685/2402] Data 0.003 (0.004) Batch 0.508 (0.477) Remain 31:05:51 loss: 0.9047 Lr: 0.00098
[2025-04-08 14:37:16,684 INFO misc.py line 113 3298914] Train: [3/100][686/2402] Data 0.003 (0.004) Batch 0.525 (0.477) Remain 31:06:06 loss: 1.2949 Lr: 0.00098
[2025-04-08 14:37:17,204 INFO misc.py line 113 3298914] Train: [3/100][687/2402] Data 0.004 (0.004) Batch 0.520 (0.477) Remain 31:06:21 loss: 1.8819 Lr: 0.00098
[2025-04-08 14:37:17,633 INFO misc.py line 113 3298914] Train: [3/100][688/2402] Data 0.004 (0.004) Batch 0.429 (0.477) Remain 31:06:04 loss: 1.4503 Lr: 0.00098
[2025-04-08 14:37:18,111 INFO misc.py line 113 3298914] Train: [3/100][689/2402] Data 0.004 (0.004) Batch 0.478 (0.477) Remain 31:06:04 loss: 1.5284 Lr: 0.00098
[2025-04-08 14:37:18,534 INFO misc.py line 113 3298914] Train: [3/100][690/2402] Data 0.004 (0.004) Batch 0.422 (0.477) Remain 31:05:45 loss: 1.4756 Lr: 0.00098
[2025-04-08 14:37:19,103 INFO misc.py line 113 3298914] Train: [3/100][691/2402] Data 0.003 (0.004) Batch 0.569 (0.477) Remain 31:06:16 loss: 1.2910 Lr: 0.00098
[2025-04-08 14:37:19,620 INFO misc.py line 113 3298914] Train: [3/100][692/2402] Data 0.003 (0.004) Batch 0.517 (0.477) Remain 31:06:29 loss: 1.1277 Lr: 0.00098
[2025-04-08 14:37:20,003 INFO misc.py line 113 3298914] Train: [3/100][693/2402] Data 0.004 (0.004) Batch 0.383 (0.477) Remain 31:05:56 loss: 1.0941 Lr: 0.00098
[2025-04-08 14:37:20,577 INFO misc.py line 113 3298914] Train: [3/100][694/2402] Data 0.003 (0.004) Batch 0.574 (0.477) Remain 31:06:29 loss: 1.4426 Lr: 0.00098
[2025-04-08 14:37:20,983 INFO misc.py line 113 3298914] Train: [3/100][695/2402] Data 0.003 (0.004) Batch 0.405 (0.477) Remain 31:06:04 loss: 1.0773 Lr: 0.00098
[2025-04-08 14:37:21,548 INFO misc.py line 113 3298914] Train: [3/100][696/2402] Data 0.004 (0.004) Batch 0.565 (0.477) Remain 31:06:33 loss: 1.6878 Lr: 0.00098
[2025-04-08 14:37:22,187 INFO misc.py line 113 3298914] Train: [3/100][697/2402] Data 0.004 (0.004) Batch 0.639 (0.477) Remain 31:07:28 loss: 1.4437 Lr: 0.00098
[2025-04-08 14:37:22,641 INFO misc.py line 113 3298914] Train: [3/100][698/2402] Data 0.003 (0.004) Batch 0.455 (0.477) Remain 31:07:19 loss: 1.0704 Lr: 0.00098
[2025-04-08 14:37:22,999 INFO misc.py line 113 3298914] Train: [3/100][699/2402] Data 0.003 (0.004) Batch 0.357 (0.477) Remain 31:06:38 loss: 0.8953 Lr: 0.00098
[2025-04-08 14:37:23,470 INFO misc.py line 113 3298914] Train: [3/100][700/2402] Data 0.004 (0.004) Batch 0.471 (0.477) Remain 31:06:36 loss: 0.7699 Lr: 0.00098
[2025-04-08 14:37:23,911 INFO misc.py line 113 3298914] Train: [3/100][701/2402] Data 0.004 (0.004) Batch 0.441 (0.477) Remain 31:06:23 loss: 1.2750 Lr: 0.00098
[2025-04-08 14:37:24,336 INFO misc.py line 113 3298914] Train: [3/100][702/2402] Data 0.003 (0.004) Batch 0.425 (0.477) Remain 31:06:05 loss: 1.1349 Lr: 0.00098
[2025-04-08 14:37:24,850 INFO misc.py line 113 3298914] Train: [3/100][703/2402] Data 0.004 (0.004) Batch 0.514 (0.477) Remain 31:06:17 loss: 1.5562 Lr: 0.00098
[2025-04-08 14:37:25,332 INFO misc.py line 113 3298914] Train: [3/100][704/2402] Data 0.003 (0.004) Batch 0.482 (0.477) Remain 31:06:18 loss: 1.5758 Lr: 0.00098
[2025-04-08 14:37:25,793 INFO misc.py line 113 3298914] Train: [3/100][705/2402] Data 0.003 (0.004) Batch 0.461 (0.477) Remain 31:06:13 loss: 1.1847 Lr: 0.00098
[2025-04-08 14:37:26,274 INFO misc.py line 113 3298914] Train: [3/100][706/2402] Data 0.003 (0.004) Batch 0.481 (0.477) Remain 31:06:13 loss: 1.6530 Lr: 0.00098
[2025-04-08 14:37:26,681 INFO misc.py line 113 3298914] Train: [3/100][707/2402] Data 0.004 (0.004) Batch 0.407 (0.477) Remain 31:05:49 loss: 0.8387 Lr: 0.00098
[2025-04-08 14:37:27,166 INFO misc.py line 113 3298914] Train: [3/100][708/2402] Data 0.004 (0.004) Batch 0.485 (0.477) Remain 31:05:51 loss: 1.4391 Lr: 0.00098
[2025-04-08 14:37:27,601 INFO misc.py line 113 3298914] Train: [3/100][709/2402] Data 0.004 (0.004) Batch 0.436 (0.477) Remain 31:05:37 loss: 1.2520 Lr: 0.00098
[2025-04-08 14:37:27,979 INFO misc.py line 113 3298914] Train: [3/100][710/2402] Data 0.003 (0.004) Batch 0.378 (0.477) Remain 31:05:04 loss: 1.5518 Lr: 0.00098
[2025-04-08 14:37:28,557 INFO misc.py line 113 3298914] Train: [3/100][711/2402] Data 0.004 (0.004) Batch 0.578 (0.477) Remain 31:05:37 loss: 1.4827 Lr: 0.00098
[2025-04-08 14:37:28,950 INFO misc.py line 113 3298914] Train: [3/100][712/2402] Data 0.003 (0.004) Batch 0.393 (0.477) Remain 31:05:09 loss: 1.0692 Lr: 0.00098
[2025-04-08 14:37:29,427 INFO misc.py line 113 3298914] Train: [3/100][713/2402] Data 0.004 (0.004) Batch 0.477 (0.477) Remain 31:05:08 loss: 1.5443 Lr: 0.00098
[2025-04-08 14:37:29,951 INFO misc.py line 113 3298914] Train: [3/100][714/2402] Data 0.004 (0.004) Batch 0.524 (0.477) Remain 31:05:23 loss: 1.2812 Lr: 0.00098
[2025-04-08 14:37:30,479 INFO misc.py line 113 3298914] Train: [3/100][715/2402] Data 0.004 (0.004) Batch 0.528 (0.477) Remain 31:05:40 loss: 1.2786 Lr: 0.00099
[2025-04-08 14:37:30,942 INFO misc.py line 113 3298914] Train: [3/100][716/2402] Data 0.003 (0.004) Batch 0.462 (0.477) Remain 31:05:35 loss: 1.0466 Lr: 0.00099
[2025-04-08 14:37:31,355 INFO misc.py line 113 3298914] Train: [3/100][717/2402] Data 0.004 (0.004) Batch 0.413 (0.477) Remain 31:05:13 loss: 1.3403 Lr: 0.00099
[2025-04-08 14:37:31,837 INFO misc.py line 113 3298914] Train: [3/100][718/2402] Data 0.003 (0.004) Batch 0.482 (0.477) Remain 31:05:14 loss: 2.0475 Lr: 0.00099
[2025-04-08 14:37:32,347 INFO misc.py line 113 3298914] Train: [3/100][719/2402] Data 0.003 (0.004) Batch 0.511 (0.477) Remain 31:05:25 loss: 1.1044 Lr: 0.00099
[2025-04-08 14:37:32,804 INFO misc.py line 113 3298914] Train: [3/100][720/2402] Data 0.004 (0.004) Batch 0.457 (0.477) Remain 31:05:18 loss: 1.2135 Lr: 0.00099
[2025-04-08 14:37:33,280 INFO misc.py line 113 3298914] Train: [3/100][721/2402] Data 0.003 (0.004) Batch 0.476 (0.477) Remain 31:05:17 loss: 1.5980 Lr: 0.00099
[2025-04-08 14:37:33,781 INFO misc.py line 113 3298914] Train: [3/100][722/2402] Data 0.003 (0.004) Batch 0.501 (0.477) Remain 31:05:24 loss: 1.1875 Lr: 0.00099
[2025-04-08 14:37:34,265 INFO misc.py line 113 3298914] Train: [3/100][723/2402] Data 0.004 (0.004) Batch 0.484 (0.477) Remain 31:05:26 loss: 1.0972 Lr: 0.00099
[2025-04-08 14:37:34,802 INFO misc.py line 113 3298914] Train: [3/100][724/2402] Data 0.003 (0.004) Batch 0.537 (0.477) Remain 31:05:45 loss: 1.1682 Lr: 0.00099
[2025-04-08 14:37:35,318 INFO misc.py line 113 3298914] Train: [3/100][725/2402] Data 0.004 (0.004) Batch 0.515 (0.477) Remain 31:05:57 loss: 1.4937 Lr: 0.00099
[2025-04-08 14:37:35,718 INFO misc.py line 113 3298914] Train: [3/100][726/2402] Data 0.004 (0.004) Batch 0.401 (0.477) Remain 31:05:32 loss: 1.0562 Lr: 0.00099
[2025-04-08 14:37:36,185 INFO misc.py line 113 3298914] Train: [3/100][727/2402] Data 0.003 (0.004) Batch 0.467 (0.477) Remain 31:05:28 loss: 0.9883 Lr: 0.00099
[2025-04-08 14:37:36,668 INFO misc.py line 113 3298914] Train: [3/100][728/2402] Data 0.004 (0.004) Batch 0.483 (0.477) Remain 31:05:30 loss: 0.8145 Lr: 0.00099
[2025-04-08 14:37:37,125 INFO misc.py line 113 3298914] Train: [3/100][729/2402] Data 0.003 (0.004) Batch 0.457 (0.477) Remain 31:05:23 loss: 0.8153 Lr: 0.00099
[2025-04-08 14:37:37,682 INFO misc.py line 113 3298914] Train: [3/100][730/2402] Data 0.004 (0.004) Batch 0.557 (0.477) Remain 31:05:48 loss: 1.1179 Lr: 0.00099
[2025-04-08 14:37:38,231 INFO misc.py line 113 3298914] Train: [3/100][731/2402] Data 0.003 (0.004) Batch 0.550 (0.477) Remain 31:06:11 loss: 1.2058 Lr: 0.00099
[2025-04-08 14:37:38,738 INFO misc.py line 113 3298914] Train: [3/100][732/2402] Data 0.003 (0.004) Batch 0.507 (0.477) Remain 31:06:20 loss: 2.0080 Lr: 0.00099
[2025-04-08 14:37:39,215 INFO misc.py line 113 3298914] Train: [3/100][733/2402] Data 0.004 (0.004) Batch 0.477 (0.477) Remain 31:06:20 loss: 1.1064 Lr: 0.00099
[2025-04-08 14:37:39,665 INFO misc.py line 113 3298914] Train: [3/100][734/2402] Data 0.004 (0.004) Batch 0.450 (0.477) Remain 31:06:10 loss: 1.2269 Lr: 0.00099
[2025-04-08 14:37:40,165 INFO misc.py line 113 3298914] Train: [3/100][735/2402] Data 0.004 (0.004) Batch 0.499 (0.477) Remain 31:06:17 loss: 1.0419 Lr: 0.00099
[2025-04-08 14:37:40,631 INFO misc.py line 113 3298914] Train: [3/100][736/2402] Data 0.004 (0.004) Batch 0.467 (0.477) Remain 31:06:13 loss: 1.6080 Lr: 0.00099
[2025-04-08 14:37:41,047 INFO misc.py line 113 3298914] Train: [3/100][737/2402] Data 0.003 (0.004) Batch 0.416 (0.477) Remain 31:05:53 loss: 1.3468 Lr: 0.00099
[2025-04-08 14:37:42,277 INFO misc.py line 113 3298914] Train: [3/100][738/2402] Data 0.683 (0.005) Batch 1.230 (0.478) Remain 31:09:53 loss: 1.2010 Lr: 0.00099
[2025-04-08 14:37:42,808 INFO misc.py line 113 3298914] Train: [3/100][739/2402] Data 0.004 (0.005) Batch 0.532 (0.478) Remain 31:10:09 loss: 1.5377 Lr: 0.00099
[2025-04-08 14:37:43,276 INFO misc.py line 113 3298914] Train: [3/100][740/2402] Data 0.003 (0.005) Batch 0.468 (0.478) Remain 31:10:06 loss: 1.2947 Lr: 0.00099
[2025-04-08 14:37:43,720 INFO misc.py line 113 3298914] Train: [3/100][741/2402] Data 0.003 (0.005) Batch 0.443 (0.478) Remain 31:09:54 loss: 1.7644 Lr: 0.00099
[2025-04-08 14:37:44,264 INFO misc.py line 113 3298914] Train: [3/100][742/2402] Data 0.004 (0.005) Batch 0.545 (0.478) Remain 31:10:15 loss: 0.9546 Lr: 0.00099
[2025-04-08 14:37:44,670 INFO misc.py line 113 3298914] Train: [3/100][743/2402] Data 0.003 (0.005) Batch 0.406 (0.478) Remain 31:09:51 loss: 1.2712 Lr: 0.00099
[2025-04-08 14:37:45,182 INFO misc.py line 113 3298914] Train: [3/100][744/2402] Data 0.004 (0.005) Batch 0.512 (0.478) Remain 31:10:01 loss: 1.3330 Lr: 0.00099
[2025-04-08 14:37:45,771 INFO misc.py line 113 3298914] Train: [3/100][745/2402] Data 0.003 (0.005) Batch 0.589 (0.478) Remain 31:10:36 loss: 1.3644 Lr: 0.00099
[2025-04-08 14:37:46,341 INFO misc.py line 113 3298914] Train: [3/100][746/2402] Data 0.004 (0.005) Batch 0.570 (0.478) Remain 31:11:05 loss: 1.1283 Lr: 0.00099
[2025-04-08 14:37:46,761 INFO misc.py line 113 3298914] Train: [3/100][747/2402] Data 0.004 (0.005) Batch 0.420 (0.478) Remain 31:10:46 loss: 0.9465 Lr: 0.00099
[2025-04-08 14:37:47,115 INFO misc.py line 113 3298914] Train: [3/100][748/2402] Data 0.003 (0.005) Batch 0.354 (0.478) Remain 31:10:06 loss: 1.2596 Lr: 0.00099
[2025-04-08 14:37:47,446 INFO misc.py line 113 3298914] Train: [3/100][749/2402] Data 0.003 (0.005) Batch 0.331 (0.478) Remain 31:09:19 loss: 1.3985 Lr: 0.00099
[2025-04-08 14:37:47,966 INFO misc.py line 113 3298914] Train: [3/100][750/2402] Data 0.004 (0.005) Batch 0.520 (0.478) Remain 31:09:32 loss: 1.2927 Lr: 0.00099
[2025-04-08 14:37:48,436 INFO misc.py line 113 3298914] Train: [3/100][751/2402] Data 0.004 (0.005) Batch 0.471 (0.478) Remain 31:09:29 loss: 1.4468 Lr: 0.00099
[2025-04-08 14:37:49,064 INFO misc.py line 113 3298914] Train: [3/100][752/2402] Data 0.004 (0.005) Batch 0.628 (0.478) Remain 31:10:16 loss: 1.3052 Lr: 0.00099
[2025-04-08 14:37:49,597 INFO misc.py line 113 3298914] Train: [3/100][753/2402] Data 0.003 (0.005) Batch 0.532 (0.478) Remain 31:10:32 loss: 1.0581 Lr: 0.00099
[2025-04-08 14:37:50,043 INFO misc.py line 113 3298914] Train: [3/100][754/2402] Data 0.004 (0.005) Batch 0.447 (0.478) Remain 31:10:22 loss: 0.9260 Lr: 0.00099
[2025-04-08 14:37:50,552 INFO misc.py line 113 3298914] Train: [3/100][755/2402] Data 0.003 (0.005) Batch 0.509 (0.478) Remain 31:10:31 loss: 1.4896 Lr: 0.00099
[2025-04-08 14:37:51,057 INFO misc.py line 113 3298914] Train: [3/100][756/2402] Data 0.003 (0.005) Batch 0.505 (0.478) Remain 31:10:39 loss: 0.8285 Lr: 0.00099
[2025-04-08 14:37:51,497 INFO misc.py line 113 3298914] Train: [3/100][757/2402] Data 0.003 (0.004) Batch 0.439 (0.478) Remain 31:10:26 loss: 0.9291 Lr: 0.00099
[2025-04-08 14:37:51,919 INFO misc.py line 113 3298914] Train: [3/100][758/2402] Data 0.004 (0.004) Batch 0.422 (0.478) Remain 31:10:08 loss: 0.8261 Lr: 0.00100
[2025-04-08 14:37:52,417 INFO misc.py line 113 3298914] Train: [3/100][759/2402] Data 0.004 (0.004) Batch 0.498 (0.478) Remain 31:10:14 loss: 1.2456 Lr: 0.00100
[2025-04-08 14:37:52,916 INFO misc.py line 113 3298914] Train: [3/100][760/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:10:20 loss: 1.3123 Lr: 0.00100
[2025-04-08 14:37:53,368 INFO misc.py line 113 3298914] Train: [3/100][761/2402] Data 0.004 (0.004) Batch 0.451 (0.478) Remain 31:10:11 loss: 1.1428 Lr: 0.00100
[2025-04-08 14:37:53,850 INFO misc.py line 113 3298914] Train: [3/100][762/2402] Data 0.004 (0.004) Batch 0.482 (0.478) Remain 31:10:12 loss: 1.3364 Lr: 0.00100
[2025-04-08 14:37:54,390 INFO misc.py line 113 3298914] Train: [3/100][763/2402] Data 0.003 (0.004) Batch 0.540 (0.478) Remain 31:10:30 loss: 1.1532 Lr: 0.00100
[2025-04-08 14:37:54,950 INFO misc.py line 113 3298914] Train: [3/100][764/2402] Data 0.004 (0.004) Batch 0.560 (0.478) Remain 31:10:55 loss: 1.3878 Lr: 0.00100
[2025-04-08 14:37:55,501 INFO misc.py line 113 3298914] Train: [3/100][765/2402] Data 0.003 (0.004) Batch 0.551 (0.479) Remain 31:11:17 loss: 1.4221 Lr: 0.00100
[2025-04-08 14:37:55,980 INFO misc.py line 113 3298914] Train: [3/100][766/2402] Data 0.004 (0.004) Batch 0.479 (0.479) Remain 31:11:16 loss: 1.8169 Lr: 0.00100
[2025-04-08 14:37:56,430 INFO misc.py line 113 3298914] Train: [3/100][767/2402] Data 0.004 (0.004) Batch 0.450 (0.478) Remain 31:11:07 loss: 1.4954 Lr: 0.00100
[2025-04-08 14:37:56,955 INFO misc.py line 113 3298914] Train: [3/100][768/2402] Data 0.003 (0.004) Batch 0.525 (0.479) Remain 31:11:21 loss: 1.2232 Lr: 0.00100
[2025-04-08 14:37:57,454 INFO misc.py line 113 3298914] Train: [3/100][769/2402] Data 0.003 (0.004) Batch 0.499 (0.479) Remain 31:11:27 loss: 1.4075 Lr: 0.00100
[2025-04-08 14:37:57,954 INFO misc.py line 113 3298914] Train: [3/100][770/2402] Data 0.004 (0.004) Batch 0.501 (0.479) Remain 31:11:33 loss: 1.3529 Lr: 0.00100
[2025-04-08 14:37:58,374 INFO misc.py line 113 3298914] Train: [3/100][771/2402] Data 0.003 (0.004) Batch 0.420 (0.479) Remain 31:11:15 loss: 1.4003 Lr: 0.00100
[2025-04-08 14:37:58,869 INFO misc.py line 113 3298914] Train: [3/100][772/2402] Data 0.004 (0.004) Batch 0.496 (0.479) Remain 31:11:19 loss: 1.3666 Lr: 0.00100
[2025-04-08 14:37:59,385 INFO misc.py line 113 3298914] Train: [3/100][773/2402] Data 0.003 (0.004) Batch 0.515 (0.479) Remain 31:11:30 loss: 1.3959 Lr: 0.00100
[2025-04-08 14:37:59,824 INFO misc.py line 113 3298914] Train: [3/100][774/2402] Data 0.004 (0.004) Batch 0.440 (0.479) Remain 31:11:18 loss: 1.0700 Lr: 0.00100
[2025-04-08 14:38:00,283 INFO misc.py line 113 3298914] Train: [3/100][775/2402] Data 0.003 (0.004) Batch 0.458 (0.479) Remain 31:11:11 loss: 1.2313 Lr: 0.00100
[2025-04-08 14:38:00,733 INFO misc.py line 113 3298914] Train: [3/100][776/2402] Data 0.003 (0.004) Batch 0.450 (0.478) Remain 31:11:02 loss: 1.4132 Lr: 0.00100
[2025-04-08 14:38:01,245 INFO misc.py line 113 3298914] Train: [3/100][777/2402] Data 0.004 (0.004) Batch 0.512 (0.479) Remain 31:11:12 loss: 1.3577 Lr: 0.00100
[2025-04-08 14:38:01,641 INFO misc.py line 113 3298914] Train: [3/100][778/2402] Data 0.004 (0.004) Batch 0.396 (0.478) Remain 31:10:46 loss: 1.2042 Lr: 0.00100
[2025-04-08 14:38:02,097 INFO misc.py line 113 3298914] Train: [3/100][779/2402] Data 0.003 (0.004) Batch 0.456 (0.478) Remain 31:10:39 loss: 0.9803 Lr: 0.00100
[2025-04-08 14:38:02,576 INFO misc.py line 113 3298914] Train: [3/100][780/2402] Data 0.003 (0.004) Batch 0.480 (0.478) Remain 31:10:39 loss: 1.3014 Lr: 0.00100
[2025-04-08 14:38:03,016 INFO misc.py line 113 3298914] Train: [3/100][781/2402] Data 0.003 (0.004) Batch 0.440 (0.478) Remain 31:10:26 loss: 1.1933 Lr: 0.00100
[2025-04-08 14:38:03,441 INFO misc.py line 113 3298914] Train: [3/100][782/2402] Data 0.003 (0.004) Batch 0.426 (0.478) Remain 31:10:10 loss: 1.2164 Lr: 0.00100
[2025-04-08 14:38:03,995 INFO misc.py line 113 3298914] Train: [3/100][783/2402] Data 0.003 (0.004) Batch 0.554 (0.478) Remain 31:10:32 loss: 1.3422 Lr: 0.00100
[2025-04-08 14:38:04,443 INFO misc.py line 113 3298914] Train: [3/100][784/2402] Data 0.003 (0.004) Batch 0.448 (0.478) Remain 31:10:23 loss: 0.9962 Lr: 0.00100
[2025-04-08 14:38:04,936 INFO misc.py line 113 3298914] Train: [3/100][785/2402] Data 0.003 (0.004) Batch 0.493 (0.478) Remain 31:10:27 loss: 1.7053 Lr: 0.00100
[2025-04-08 14:38:05,375 INFO misc.py line 113 3298914] Train: [3/100][786/2402] Data 0.004 (0.004) Batch 0.439 (0.478) Remain 31:10:14 loss: 1.2955 Lr: 0.00100
[2025-04-08 14:38:05,754 INFO misc.py line 113 3298914] Train: [3/100][787/2402] Data 0.003 (0.004) Batch 0.379 (0.478) Remain 31:09:44 loss: 1.0301 Lr: 0.00100
[2025-04-08 14:38:06,148 INFO misc.py line 113 3298914] Train: [3/100][788/2402] Data 0.004 (0.004) Batch 0.393 (0.478) Remain 31:09:18 loss: 0.7658 Lr: 0.00100
[2025-04-08 14:38:06,650 INFO misc.py line 113 3298914] Train: [3/100][789/2402] Data 0.004 (0.004) Batch 0.502 (0.478) Remain 31:09:25 loss: 1.0780 Lr: 0.00100
[2025-04-08 14:38:07,136 INFO misc.py line 113 3298914] Train: [3/100][790/2402] Data 0.003 (0.004) Batch 0.487 (0.478) Remain 31:09:27 loss: 1.2470 Lr: 0.00100
[2025-04-08 14:38:07,528 INFO misc.py line 113 3298914] Train: [3/100][791/2402] Data 0.003 (0.004) Batch 0.392 (0.478) Remain 31:09:01 loss: 1.1000 Lr: 0.00100
[2025-04-08 14:38:07,922 INFO misc.py line 113 3298914] Train: [3/100][792/2402] Data 0.004 (0.004) Batch 0.393 (0.478) Remain 31:08:35 loss: 1.8653 Lr: 0.00100
[2025-04-08 14:38:08,427 INFO misc.py line 113 3298914] Train: [3/100][793/2402] Data 0.004 (0.004) Batch 0.505 (0.478) Remain 31:08:43 loss: 0.9280 Lr: 0.00100
[2025-04-08 14:38:08,870 INFO misc.py line 113 3298914] Train: [3/100][794/2402] Data 0.004 (0.004) Batch 0.443 (0.478) Remain 31:08:32 loss: 1.3470 Lr: 0.00100
[2025-04-08 14:38:09,326 INFO misc.py line 113 3298914] Train: [3/100][795/2402] Data 0.004 (0.004) Batch 0.456 (0.478) Remain 31:08:25 loss: 1.1632 Lr: 0.00100
[2025-04-08 14:38:09,842 INFO misc.py line 113 3298914] Train: [3/100][796/2402] Data 0.004 (0.004) Batch 0.516 (0.478) Remain 31:08:36 loss: 1.7347 Lr: 0.00100
[2025-04-08 14:38:10,325 INFO misc.py line 113 3298914] Train: [3/100][797/2402] Data 0.003 (0.004) Batch 0.483 (0.478) Remain 31:08:37 loss: 1.1141 Lr: 0.00100
[2025-04-08 14:38:10,867 INFO misc.py line 113 3298914] Train: [3/100][798/2402] Data 0.004 (0.004) Batch 0.542 (0.478) Remain 31:08:55 loss: 1.3019 Lr: 0.00100
[2025-04-08 14:38:11,357 INFO misc.py line 113 3298914] Train: [3/100][799/2402] Data 0.004 (0.004) Batch 0.491 (0.478) Remain 31:08:59 loss: 0.8941 Lr: 0.00100
[2025-04-08 14:38:11,778 INFO misc.py line 113 3298914] Train: [3/100][800/2402] Data 0.004 (0.004) Batch 0.421 (0.478) Remain 31:08:41 loss: 1.2761 Lr: 0.00100
[2025-04-08 14:38:12,213 INFO misc.py line 113 3298914] Train: [3/100][801/2402] Data 0.003 (0.004) Batch 0.435 (0.478) Remain 31:08:28 loss: 1.5248 Lr: 0.00101
[2025-04-08 14:38:12,615 INFO misc.py line 113 3298914] Train: [3/100][802/2402] Data 0.004 (0.004) Batch 0.401 (0.478) Remain 31:08:05 loss: 0.8944 Lr: 0.00101
[2025-04-08 14:38:13,129 INFO misc.py line 113 3298914] Train: [3/100][803/2402] Data 0.003 (0.004) Batch 0.514 (0.478) Remain 31:08:16 loss: 0.8731 Lr: 0.00101
[2025-04-08 14:38:13,560 INFO misc.py line 113 3298914] Train: [3/100][804/2402] Data 0.005 (0.004) Batch 0.432 (0.478) Remain 31:08:02 loss: 1.1067 Lr: 0.00101
[2025-04-08 14:38:14,050 INFO misc.py line 113 3298914] Train: [3/100][805/2402] Data 0.003 (0.004) Batch 0.489 (0.478) Remain 31:08:04 loss: 1.0404 Lr: 0.00101
[2025-04-08 14:38:14,579 INFO misc.py line 113 3298914] Train: [3/100][806/2402] Data 0.004 (0.004) Batch 0.529 (0.478) Remain 31:08:19 loss: 1.1012 Lr: 0.00101
[2025-04-08 14:38:15,069 INFO misc.py line 113 3298914] Train: [3/100][807/2402] Data 0.004 (0.004) Batch 0.489 (0.478) Remain 31:08:22 loss: 1.2944 Lr: 0.00101
[2025-04-08 14:38:15,607 INFO misc.py line 113 3298914] Train: [3/100][808/2402] Data 0.004 (0.004) Batch 0.539 (0.478) Remain 31:08:39 loss: 0.9185 Lr: 0.00101
[2025-04-08 14:38:16,178 INFO misc.py line 113 3298914] Train: [3/100][809/2402] Data 0.004 (0.004) Batch 0.571 (0.478) Remain 31:09:06 loss: 1.3213 Lr: 0.00101
[2025-04-08 14:38:16,657 INFO misc.py line 113 3298914] Train: [3/100][810/2402] Data 0.003 (0.004) Batch 0.479 (0.478) Remain 31:09:06 loss: 0.7599 Lr: 0.00101
[2025-04-08 14:38:17,080 INFO misc.py line 113 3298914] Train: [3/100][811/2402] Data 0.004 (0.004) Batch 0.422 (0.478) Remain 31:08:49 loss: 1.0322 Lr: 0.00101
[2025-04-08 14:38:17,451 INFO misc.py line 113 3298914] Train: [3/100][812/2402] Data 0.004 (0.004) Batch 0.371 (0.478) Remain 31:08:17 loss: 1.1908 Lr: 0.00101
[2025-04-08 14:38:17,819 INFO misc.py line 113 3298914] Train: [3/100][813/2402] Data 0.003 (0.004) Batch 0.368 (0.478) Remain 31:07:45 loss: 1.9280 Lr: 0.00101
[2025-04-08 14:38:18,318 INFO misc.py line 113 3298914] Train: [3/100][814/2402] Data 0.003 (0.004) Batch 0.499 (0.478) Remain 31:07:51 loss: 1.0912 Lr: 0.00101
[2025-04-08 14:38:18,728 INFO misc.py line 113 3298914] Train: [3/100][815/2402] Data 0.004 (0.004) Batch 0.409 (0.478) Remain 31:07:31 loss: 0.8945 Lr: 0.00101
[2025-04-08 14:38:19,191 INFO misc.py line 113 3298914] Train: [3/100][816/2402] Data 0.004 (0.004) Batch 0.464 (0.478) Remain 31:07:26 loss: 0.8500 Lr: 0.00101
[2025-04-08 14:38:19,655 INFO misc.py line 113 3298914] Train: [3/100][817/2402] Data 0.004 (0.004) Batch 0.464 (0.478) Remain 31:07:22 loss: 1.3316 Lr: 0.00101
[2025-04-08 14:38:20,157 INFO misc.py line 113 3298914] Train: [3/100][818/2402] Data 0.003 (0.004) Batch 0.502 (0.478) Remain 31:07:28 loss: 1.4823 Lr: 0.00101
[2025-04-08 14:38:20,516 INFO misc.py line 113 3298914] Train: [3/100][819/2402] Data 0.003 (0.004) Batch 0.359 (0.478) Remain 31:06:54 loss: 1.0687 Lr: 0.00101
[2025-04-08 14:38:21,065 INFO misc.py line 113 3298914] Train: [3/100][820/2402] Data 0.003 (0.004) Batch 0.549 (0.478) Remain 31:07:14 loss: 1.3924 Lr: 0.00101
[2025-04-08 14:38:21,515 INFO misc.py line 113 3298914] Train: [3/100][821/2402] Data 0.004 (0.004) Batch 0.451 (0.478) Remain 31:07:05 loss: 1.6722 Lr: 0.00101
[2025-04-08 14:38:21,941 INFO misc.py line 113 3298914] Train: [3/100][822/2402] Data 0.004 (0.004) Batch 0.426 (0.478) Remain 31:06:50 loss: 1.3263 Lr: 0.00101
[2025-04-08 14:38:22,329 INFO misc.py line 113 3298914] Train: [3/100][823/2402] Data 0.004 (0.004) Batch 0.388 (0.477) Remain 31:06:24 loss: 1.0371 Lr: 0.00101
[2025-04-08 14:38:22,793 INFO misc.py line 113 3298914] Train: [3/100][824/2402] Data 0.004 (0.004) Batch 0.463 (0.477) Remain 31:06:20 loss: 1.2246 Lr: 0.00101
[2025-04-08 14:38:23,287 INFO misc.py line 113 3298914] Train: [3/100][825/2402] Data 0.004 (0.004) Batch 0.495 (0.477) Remain 31:06:24 loss: 1.4795 Lr: 0.00101
[2025-04-08 14:38:23,846 INFO misc.py line 113 3298914] Train: [3/100][826/2402] Data 0.003 (0.004) Batch 0.559 (0.478) Remain 31:06:47 loss: 1.2476 Lr: 0.00101
[2025-04-08 14:38:24,199 INFO misc.py line 113 3298914] Train: [3/100][827/2402] Data 0.003 (0.004) Batch 0.353 (0.477) Remain 31:06:11 loss: 1.1557 Lr: 0.00101
[2025-04-08 14:38:24,620 INFO misc.py line 113 3298914] Train: [3/100][828/2402] Data 0.003 (0.004) Batch 0.420 (0.477) Remain 31:05:54 loss: 1.0360 Lr: 0.00101
[2025-04-08 14:38:25,109 INFO misc.py line 113 3298914] Train: [3/100][829/2402] Data 0.004 (0.004) Batch 0.490 (0.477) Remain 31:05:57 loss: 1.4011 Lr: 0.00101
[2025-04-08 14:38:25,631 INFO misc.py line 113 3298914] Train: [3/100][830/2402] Data 0.003 (0.004) Batch 0.522 (0.477) Remain 31:06:09 loss: 2.0563 Lr: 0.00101
[2025-04-08 14:38:26,063 INFO misc.py line 113 3298914] Train: [3/100][831/2402] Data 0.004 (0.004) Batch 0.432 (0.477) Remain 31:05:56 loss: 1.1925 Lr: 0.00101
[2025-04-08 14:38:26,510 INFO misc.py line 113 3298914] Train: [3/100][832/2402] Data 0.003 (0.004) Batch 0.447 (0.477) Remain 31:05:47 loss: 1.1674 Lr: 0.00101
[2025-04-08 14:38:27,059 INFO misc.py line 113 3298914] Train: [3/100][833/2402] Data 0.004 (0.004) Batch 0.549 (0.477) Remain 31:06:07 loss: 1.4007 Lr: 0.00101
[2025-04-08 14:38:27,527 INFO misc.py line 113 3298914] Train: [3/100][834/2402] Data 0.004 (0.004) Batch 0.468 (0.477) Remain 31:06:04 loss: 1.4562 Lr: 0.00101
[2025-04-08 14:38:28,041 INFO misc.py line 113 3298914] Train: [3/100][835/2402] Data 0.003 (0.004) Batch 0.514 (0.477) Remain 31:06:14 loss: 1.1567 Lr: 0.00101
[2025-04-08 14:38:28,532 INFO misc.py line 113 3298914] Train: [3/100][836/2402] Data 0.003 (0.004) Batch 0.491 (0.477) Remain 31:06:17 loss: 1.3307 Lr: 0.00101
[2025-04-08 14:38:28,881 INFO misc.py line 113 3298914] Train: [3/100][837/2402] Data 0.004 (0.004) Batch 0.349 (0.477) Remain 31:05:40 loss: 0.9158 Lr: 0.00101
[2025-04-08 14:38:29,279 INFO misc.py line 113 3298914] Train: [3/100][838/2402] Data 0.003 (0.004) Batch 0.398 (0.477) Remain 31:05:18 loss: 1.2258 Lr: 0.00101
[2025-04-08 14:38:29,773 INFO misc.py line 113 3298914] Train: [3/100][839/2402] Data 0.004 (0.004) Batch 0.493 (0.477) Remain 31:05:22 loss: 1.2475 Lr: 0.00101
[2025-04-08 14:38:30,272 INFO misc.py line 113 3298914] Train: [3/100][840/2402] Data 0.004 (0.004) Batch 0.499 (0.477) Remain 31:05:27 loss: 1.5083 Lr: 0.00101
[2025-04-08 14:38:30,749 INFO misc.py line 113 3298914] Train: [3/100][841/2402] Data 0.004 (0.004) Batch 0.477 (0.477) Remain 31:05:27 loss: 0.8697 Lr: 0.00101
[2025-04-08 14:38:31,288 INFO misc.py line 113 3298914] Train: [3/100][842/2402] Data 0.003 (0.004) Batch 0.539 (0.477) Remain 31:05:44 loss: 1.2706 Lr: 0.00101
[2025-04-08 14:38:31,812 INFO misc.py line 113 3298914] Train: [3/100][843/2402] Data 0.004 (0.004) Batch 0.525 (0.477) Remain 31:05:56 loss: 1.1604 Lr: 0.00102
[2025-04-08 14:38:32,229 INFO misc.py line 113 3298914] Train: [3/100][844/2402] Data 0.003 (0.004) Batch 0.417 (0.477) Remain 31:05:39 loss: 1.1996 Lr: 0.00102
[2025-04-08 14:38:32,665 INFO misc.py line 113 3298914] Train: [3/100][845/2402] Data 0.003 (0.004) Batch 0.436 (0.477) Remain 31:05:27 loss: 0.9388 Lr: 0.00102
[2025-04-08 14:38:33,156 INFO misc.py line 113 3298914] Train: [3/100][846/2402] Data 0.003 (0.004) Batch 0.491 (0.477) Remain 31:05:30 loss: 1.3335 Lr: 0.00102
[2025-04-08 14:38:33,741 INFO misc.py line 113 3298914] Train: [3/100][847/2402] Data 0.004 (0.004) Batch 0.585 (0.477) Remain 31:06:00 loss: 1.4014 Lr: 0.00102
[2025-04-08 14:38:34,132 INFO misc.py line 113 3298914] Train: [3/100][848/2402] Data 0.004 (0.004) Batch 0.390 (0.477) Remain 31:05:35 loss: 0.9739 Lr: 0.00102
[2025-04-08 14:38:34,721 INFO misc.py line 113 3298914] Train: [3/100][849/2402] Data 0.003 (0.004) Batch 0.589 (0.477) Remain 31:06:06 loss: 1.4922 Lr: 0.00102
[2025-04-08 14:38:35,172 INFO misc.py line 113 3298914] Train: [3/100][850/2402] Data 0.004 (0.004) Batch 0.451 (0.477) Remain 31:05:58 loss: 1.3025 Lr: 0.00102
[2025-04-08 14:38:35,665 INFO misc.py line 113 3298914] Train: [3/100][851/2402] Data 0.004 (0.004) Batch 0.493 (0.477) Remain 31:06:02 loss: 1.5516 Lr: 0.00102
[2025-04-08 14:38:36,115 INFO misc.py line 113 3298914] Train: [3/100][852/2402] Data 0.004 (0.004) Batch 0.450 (0.477) Remain 31:05:54 loss: 1.1515 Lr: 0.00102
[2025-04-08 14:38:36,526 INFO misc.py line 113 3298914] Train: [3/100][853/2402] Data 0.003 (0.004) Batch 0.411 (0.477) Remain 31:05:35 loss: 1.2669 Lr: 0.00102
[2025-04-08 14:38:37,040 INFO misc.py line 113 3298914] Train: [3/100][854/2402] Data 0.004 (0.004) Batch 0.515 (0.477) Remain 31:05:45 loss: 1.2337 Lr: 0.00102
[2025-04-08 14:38:37,580 INFO misc.py line 113 3298914] Train: [3/100][855/2402] Data 0.003 (0.004) Batch 0.540 (0.477) Remain 31:06:02 loss: 1.3066 Lr: 0.00102
[2025-04-08 14:38:38,126 INFO misc.py line 113 3298914] Train: [3/100][856/2402] Data 0.004 (0.004) Batch 0.545 (0.477) Remain 31:06:20 loss: 1.0338 Lr: 0.00102
[2025-04-08 14:38:38,587 INFO misc.py line 113 3298914] Train: [3/100][857/2402] Data 0.003 (0.004) Batch 0.462 (0.477) Remain 31:06:15 loss: 1.1756 Lr: 0.00102
[2025-04-08 14:38:39,101 INFO misc.py line 113 3298914] Train: [3/100][858/2402] Data 0.004 (0.004) Batch 0.514 (0.477) Remain 31:06:25 loss: 1.0235 Lr: 0.00102
[2025-04-08 14:38:39,583 INFO misc.py line 113 3298914] Train: [3/100][859/2402] Data 0.003 (0.004) Batch 0.483 (0.477) Remain 31:06:25 loss: 1.5800 Lr: 0.00102
[2025-04-08 14:38:40,078 INFO misc.py line 113 3298914] Train: [3/100][860/2402] Data 0.003 (0.004) Batch 0.495 (0.477) Remain 31:06:30 loss: 0.7878 Lr: 0.00102
[2025-04-08 14:38:40,630 INFO misc.py line 113 3298914] Train: [3/100][861/2402] Data 0.004 (0.004) Batch 0.552 (0.478) Remain 31:06:50 loss: 1.6952 Lr: 0.00102
[2025-04-08 14:38:41,087 INFO misc.py line 113 3298914] Train: [3/100][862/2402] Data 0.003 (0.004) Batch 0.458 (0.478) Remain 31:06:44 loss: 1.1071 Lr: 0.00102
[2025-04-08 14:38:41,460 INFO misc.py line 113 3298914] Train: [3/100][863/2402] Data 0.004 (0.004) Batch 0.373 (0.477) Remain 31:06:15 loss: 1.4422 Lr: 0.00102
[2025-04-08 14:38:41,934 INFO misc.py line 113 3298914] Train: [3/100][864/2402] Data 0.003 (0.004) Batch 0.474 (0.477) Remain 31:06:13 loss: 1.0655 Lr: 0.00102
[2025-04-08 14:38:42,333 INFO misc.py line 113 3298914] Train: [3/100][865/2402] Data 0.003 (0.004) Batch 0.399 (0.477) Remain 31:05:51 loss: 0.8471 Lr: 0.00102
[2025-04-08 14:38:42,855 INFO misc.py line 113 3298914] Train: [3/100][866/2402] Data 0.004 (0.004) Batch 0.522 (0.477) Remain 31:06:03 loss: 0.9579 Lr: 0.00102
[2025-04-08 14:38:43,365 INFO misc.py line 113 3298914] Train: [3/100][867/2402] Data 0.003 (0.004) Batch 0.510 (0.477) Remain 31:06:11 loss: 1.2786 Lr: 0.00102
[2025-04-08 14:38:43,891 INFO misc.py line 113 3298914] Train: [3/100][868/2402] Data 0.003 (0.004) Batch 0.526 (0.477) Remain 31:06:24 loss: 1.5599 Lr: 0.00102
[2025-04-08 14:38:44,345 INFO misc.py line 113 3298914] Train: [3/100][869/2402] Data 0.003 (0.004) Batch 0.454 (0.477) Remain 31:06:17 loss: 1.3945 Lr: 0.00102
[2025-04-08 14:38:44,768 INFO misc.py line 113 3298914] Train: [3/100][870/2402] Data 0.004 (0.004) Batch 0.423 (0.477) Remain 31:06:02 loss: 1.0709 Lr: 0.00102
[2025-04-08 14:38:45,166 INFO misc.py line 113 3298914] Train: [3/100][871/2402] Data 0.003 (0.004) Batch 0.397 (0.477) Remain 31:05:40 loss: 1.1489 Lr: 0.00102
[2025-04-08 14:38:45,600 INFO misc.py line 113 3298914] Train: [3/100][872/2402] Data 0.004 (0.004) Batch 0.434 (0.477) Remain 31:05:28 loss: 1.1341 Lr: 0.00102
[2025-04-08 14:38:46,067 INFO misc.py line 113 3298914] Train: [3/100][873/2402] Data 0.004 (0.004) Batch 0.467 (0.477) Remain 31:05:24 loss: 1.0868 Lr: 0.00102
[2025-04-08 14:38:46,453 INFO misc.py line 113 3298914] Train: [3/100][874/2402] Data 0.003 (0.004) Batch 0.386 (0.477) Remain 31:04:59 loss: 0.9584 Lr: 0.00102
[2025-04-08 14:38:47,074 INFO misc.py line 113 3298914] Train: [3/100][875/2402] Data 0.004 (0.004) Batch 0.621 (0.477) Remain 31:05:38 loss: 1.3703 Lr: 0.00102
[2025-04-08 14:38:47,584 INFO misc.py line 113 3298914] Train: [3/100][876/2402] Data 0.004 (0.004) Batch 0.509 (0.477) Remain 31:05:46 loss: 1.0518 Lr: 0.00102
[2025-04-08 14:38:48,045 INFO misc.py line 113 3298914] Train: [3/100][877/2402] Data 0.004 (0.004) Batch 0.461 (0.477) Remain 31:05:41 loss: 0.6674 Lr: 0.00102
[2025-04-08 14:38:48,496 INFO misc.py line 113 3298914] Train: [3/100][878/2402] Data 0.003 (0.004) Batch 0.452 (0.477) Remain 31:05:34 loss: 1.2214 Lr: 0.00102
[2025-04-08 14:38:48,970 INFO misc.py line 113 3298914] Train: [3/100][879/2402] Data 0.003 (0.004) Batch 0.474 (0.477) Remain 31:05:32 loss: 1.1947 Lr: 0.00102
[2025-04-08 14:38:49,437 INFO misc.py line 113 3298914] Train: [3/100][880/2402] Data 0.004 (0.004) Batch 0.467 (0.477) Remain 31:05:29 loss: 0.8247 Lr: 0.00102
[2025-04-08 14:38:49,991 INFO misc.py line 113 3298914] Train: [3/100][881/2402] Data 0.003 (0.004) Batch 0.554 (0.477) Remain 31:05:49 loss: 1.4650 Lr: 0.00102
[2025-04-08 14:38:50,449 INFO misc.py line 113 3298914] Train: [3/100][882/2402] Data 0.004 (0.004) Batch 0.459 (0.477) Remain 31:05:44 loss: 1.3800 Lr: 0.00102
[2025-04-08 14:38:50,962 INFO misc.py line 113 3298914] Train: [3/100][883/2402] Data 0.003 (0.004) Batch 0.513 (0.477) Remain 31:05:52 loss: 1.0307 Lr: 0.00102
[2025-04-08 14:38:51,451 INFO misc.py line 113 3298914] Train: [3/100][884/2402] Data 0.004 (0.004) Batch 0.489 (0.477) Remain 31:05:55 loss: 1.0319 Lr: 0.00102
[2025-04-08 14:38:51,972 INFO misc.py line 113 3298914] Train: [3/100][885/2402] Data 0.003 (0.004) Batch 0.521 (0.477) Remain 31:06:06 loss: 1.3882 Lr: 0.00102
[2025-04-08 14:38:52,429 INFO misc.py line 113 3298914] Train: [3/100][886/2402] Data 0.003 (0.004) Batch 0.456 (0.477) Remain 31:06:00 loss: 1.4069 Lr: 0.00103
[2025-04-08 14:38:52,897 INFO misc.py line 113 3298914] Train: [3/100][887/2402] Data 0.004 (0.004) Batch 0.468 (0.477) Remain 31:05:57 loss: 1.0055 Lr: 0.00103
[2025-04-08 14:38:53,439 INFO misc.py line 113 3298914] Train: [3/100][888/2402] Data 0.004 (0.004) Batch 0.542 (0.477) Remain 31:06:14 loss: 1.3379 Lr: 0.00103
[2025-04-08 14:38:53,823 INFO misc.py line 113 3298914] Train: [3/100][889/2402] Data 0.003 (0.004) Batch 0.384 (0.477) Remain 31:05:49 loss: 1.0635 Lr: 0.00103
[2025-04-08 14:38:54,332 INFO misc.py line 113 3298914] Train: [3/100][890/2402] Data 0.003 (0.004) Batch 0.509 (0.477) Remain 31:05:57 loss: 1.0078 Lr: 0.00103
[2025-04-08 14:38:54,789 INFO misc.py line 113 3298914] Train: [3/100][891/2402] Data 0.004 (0.004) Batch 0.457 (0.477) Remain 31:05:51 loss: 1.4759 Lr: 0.00103
[2025-04-08 14:38:55,191 INFO misc.py line 113 3298914] Train: [3/100][892/2402] Data 0.003 (0.004) Batch 0.401 (0.477) Remain 31:05:30 loss: 0.9461 Lr: 0.00103
[2025-04-08 14:38:55,695 INFO misc.py line 113 3298914] Train: [3/100][893/2402] Data 0.004 (0.004) Batch 0.505 (0.477) Remain 31:05:37 loss: 1.0397 Lr: 0.00103
[2025-04-08 14:38:56,157 INFO misc.py line 113 3298914] Train: [3/100][894/2402] Data 0.004 (0.004) Batch 0.462 (0.477) Remain 31:05:32 loss: 1.7004 Lr: 0.00103
[2025-04-08 14:38:56,563 INFO misc.py line 113 3298914] Train: [3/100][895/2402] Data 0.003 (0.004) Batch 0.405 (0.477) Remain 31:05:13 loss: 1.2873 Lr: 0.00103
[2025-04-08 14:38:56,976 INFO misc.py line 113 3298914] Train: [3/100][896/2402] Data 0.003 (0.004) Batch 0.414 (0.477) Remain 31:04:56 loss: 1.9634 Lr: 0.00103
[2025-04-08 14:38:57,478 INFO misc.py line 113 3298914] Train: [3/100][897/2402] Data 0.004 (0.004) Batch 0.502 (0.477) Remain 31:05:02 loss: 1.0579 Lr: 0.00103
[2025-04-08 14:38:57,901 INFO misc.py line 113 3298914] Train: [3/100][898/2402] Data 0.003 (0.004) Batch 0.423 (0.477) Remain 31:04:47 loss: 1.8365 Lr: 0.00103
[2025-04-08 14:38:58,360 INFO misc.py line 113 3298914] Train: [3/100][899/2402] Data 0.004 (0.004) Batch 0.459 (0.477) Remain 31:04:42 loss: 1.3736 Lr: 0.00103
[2025-04-08 14:38:58,812 INFO misc.py line 113 3298914] Train: [3/100][900/2402] Data 0.003 (0.004) Batch 0.452 (0.477) Remain 31:04:35 loss: 1.1632 Lr: 0.00103
[2025-04-08 14:38:59,291 INFO misc.py line 113 3298914] Train: [3/100][901/2402] Data 0.004 (0.004) Batch 0.479 (0.477) Remain 31:04:35 loss: 1.0367 Lr: 0.00103
[2025-04-08 14:38:59,666 INFO misc.py line 113 3298914] Train: [3/100][902/2402] Data 0.004 (0.004) Batch 0.375 (0.477) Remain 31:04:08 loss: 0.8963 Lr: 0.00103
[2025-04-08 14:38:59,988 INFO misc.py line 113 3298914] Train: [3/100][903/2402] Data 0.003 (0.004) Batch 0.323 (0.477) Remain 31:03:27 loss: 1.0862 Lr: 0.00103
[2025-04-08 14:39:00,357 INFO misc.py line 113 3298914] Train: [3/100][904/2402] Data 0.003 (0.004) Batch 0.369 (0.477) Remain 31:02:58 loss: 0.8908 Lr: 0.00103
[2025-04-08 14:39:00,730 INFO misc.py line 113 3298914] Train: [3/100][905/2402] Data 0.004 (0.004) Batch 0.372 (0.477) Remain 31:02:31 loss: 1.3254 Lr: 0.00103
[2025-04-08 14:39:01,158 INFO misc.py line 113 3298914] Train: [3/100][906/2402] Data 0.004 (0.004) Batch 0.428 (0.477) Remain 31:02:18 loss: 1.1744 Lr: 0.00103
[2025-04-08 14:39:01,543 INFO misc.py line 113 3298914] Train: [3/100][907/2402] Data 0.003 (0.004) Batch 0.385 (0.476) Remain 31:01:54 loss: 1.0806 Lr: 0.00103
[2025-04-08 14:39:01,938 INFO misc.py line 113 3298914] Train: [3/100][908/2402] Data 0.004 (0.004) Batch 0.395 (0.476) Remain 31:01:32 loss: 1.1431 Lr: 0.00103
[2025-04-08 14:39:02,420 INFO misc.py line 113 3298914] Train: [3/100][909/2402] Data 0.003 (0.004) Batch 0.483 (0.476) Remain 31:01:33 loss: 1.0487 Lr: 0.00103
[2025-04-08 14:39:02,906 INFO misc.py line 113 3298914] Train: [3/100][910/2402] Data 0.003 (0.004) Batch 0.485 (0.476) Remain 31:01:35 loss: 1.5171 Lr: 0.00103
[2025-04-08 14:39:03,292 INFO misc.py line 113 3298914] Train: [3/100][911/2402] Data 0.004 (0.004) Batch 0.386 (0.476) Remain 31:01:11 loss: 0.7494 Lr: 0.00103
[2025-04-08 14:39:03,784 INFO misc.py line 113 3298914] Train: [3/100][912/2402] Data 0.004 (0.004) Batch 0.493 (0.476) Remain 31:01:15 loss: 1.2168 Lr: 0.00103
[2025-04-08 14:39:04,305 INFO misc.py line 113 3298914] Train: [3/100][913/2402] Data 0.003 (0.004) Batch 0.520 (0.476) Remain 31:01:26 loss: 0.9612 Lr: 0.00103
[2025-04-08 14:39:04,677 INFO misc.py line 113 3298914] Train: [3/100][914/2402] Data 0.004 (0.004) Batch 0.373 (0.476) Remain 31:00:59 loss: 0.8137 Lr: 0.00103
[2025-04-08 14:39:05,199 INFO misc.py line 113 3298914] Train: [3/100][915/2402] Data 0.003 (0.004) Batch 0.522 (0.476) Remain 31:01:10 loss: 1.4476 Lr: 0.00103
[2025-04-08 14:39:05,715 INFO misc.py line 113 3298914] Train: [3/100][916/2402] Data 0.003 (0.004) Batch 0.516 (0.476) Remain 31:01:20 loss: 1.0767 Lr: 0.00103
[2025-04-08 14:39:06,089 INFO misc.py line 113 3298914] Train: [3/100][917/2402] Data 0.004 (0.004) Batch 0.373 (0.476) Remain 31:00:53 loss: 1.5796 Lr: 0.00103
[2025-04-08 14:39:06,627 INFO misc.py line 113 3298914] Train: [3/100][918/2402] Data 0.004 (0.004) Batch 0.539 (0.476) Remain 31:01:08 loss: 1.4801 Lr: 0.00103
[2025-04-08 14:39:07,143 INFO misc.py line 113 3298914] Train: [3/100][919/2402] Data 0.004 (0.004) Batch 0.517 (0.476) Remain 31:01:18 loss: 0.6958 Lr: 0.00103
[2025-04-08 14:39:07,528 INFO misc.py line 113 3298914] Train: [3/100][920/2402] Data 0.003 (0.004) Batch 0.385 (0.476) Remain 31:00:54 loss: 1.0135 Lr: 0.00103
[2025-04-08 14:39:07,980 INFO misc.py line 113 3298914] Train: [3/100][921/2402] Data 0.003 (0.004) Batch 0.452 (0.476) Remain 31:00:48 loss: 1.2539 Lr: 0.00103
[2025-04-08 14:39:08,392 INFO misc.py line 113 3298914] Train: [3/100][922/2402] Data 0.003 (0.004) Batch 0.412 (0.476) Remain 31:00:31 loss: 1.2072 Lr: 0.00103
[2025-04-08 14:39:08,837 INFO misc.py line 113 3298914] Train: [3/100][923/2402] Data 0.004 (0.004) Batch 0.445 (0.476) Remain 31:00:22 loss: 1.2197 Lr: 0.00103
[2025-04-08 14:39:09,335 INFO misc.py line 113 3298914] Train: [3/100][924/2402] Data 0.004 (0.004) Batch 0.497 (0.476) Remain 31:00:27 loss: 0.8625 Lr: 0.00103
[2025-04-08 14:39:09,816 INFO misc.py line 113 3298914] Train: [3/100][925/2402] Data 0.004 (0.004) Batch 0.481 (0.476) Remain 31:00:28 loss: 1.1660 Lr: 0.00103
[2025-04-08 14:39:10,391 INFO misc.py line 113 3298914] Train: [3/100][926/2402] Data 0.003 (0.004) Batch 0.575 (0.476) Remain 31:00:53 loss: 0.9866 Lr: 0.00103
[2025-04-08 14:39:10,909 INFO misc.py line 113 3298914] Train: [3/100][927/2402] Data 0.004 (0.004) Batch 0.517 (0.476) Remain 31:01:03 loss: 1.5849 Lr: 0.00103
[2025-04-08 14:39:11,432 INFO misc.py line 113 3298914] Train: [3/100][928/2402] Data 0.004 (0.004) Batch 0.524 (0.476) Remain 31:01:14 loss: 0.8446 Lr: 0.00103
[2025-04-08 14:39:11,910 INFO misc.py line 113 3298914] Train: [3/100][929/2402] Data 0.004 (0.004) Batch 0.478 (0.476) Remain 31:01:14 loss: 1.1049 Lr: 0.00104
[2025-04-08 14:39:12,320 INFO misc.py line 113 3298914] Train: [3/100][930/2402] Data 0.004 (0.004) Batch 0.410 (0.476) Remain 31:00:57 loss: 1.5262 Lr: 0.00104
[2025-04-08 14:39:12,769 INFO misc.py line 113 3298914] Train: [3/100][931/2402] Data 0.003 (0.004) Batch 0.449 (0.476) Remain 31:00:50 loss: 0.9127 Lr: 0.00104
[2025-04-08 14:39:13,351 INFO misc.py line 113 3298914] Train: [3/100][932/2402] Data 0.004 (0.004) Batch 0.582 (0.476) Remain 31:01:16 loss: 1.1348 Lr: 0.00104
[2025-04-08 14:39:13,808 INFO misc.py line 113 3298914] Train: [3/100][933/2402] Data 0.003 (0.004) Batch 0.458 (0.476) Remain 31:01:11 loss: 1.0648 Lr: 0.00104
[2025-04-08 14:39:14,419 INFO misc.py line 113 3298914] Train: [3/100][934/2402] Data 0.105 (0.004) Batch 0.611 (0.476) Remain 31:01:44 loss: 1.4277 Lr: 0.00104
[2025-04-08 14:39:14,808 INFO misc.py line 113 3298914] Train: [3/100][935/2402] Data 0.004 (0.004) Batch 0.389 (0.476) Remain 31:01:22 loss: 1.0483 Lr: 0.00104
[2025-04-08 14:39:15,331 INFO misc.py line 113 3298914] Train: [3/100][936/2402] Data 0.004 (0.004) Batch 0.522 (0.476) Remain 31:01:33 loss: 0.9888 Lr: 0.00104
[2025-04-08 14:39:15,895 INFO misc.py line 113 3298914] Train: [3/100][937/2402] Data 0.004 (0.004) Batch 0.564 (0.476) Remain 31:01:54 loss: 0.8128 Lr: 0.00104
[2025-04-08 14:39:16,409 INFO misc.py line 113 3298914] Train: [3/100][938/2402] Data 0.004 (0.004) Batch 0.515 (0.477) Remain 31:02:03 loss: 1.0506 Lr: 0.00104
[2025-04-08 14:39:16,868 INFO misc.py line 113 3298914] Train: [3/100][939/2402] Data 0.003 (0.004) Batch 0.459 (0.477) Remain 31:01:58 loss: 1.1179 Lr: 0.00104
[2025-04-08 14:39:17,328 INFO misc.py line 113 3298914] Train: [3/100][940/2402] Data 0.003 (0.004) Batch 0.460 (0.476) Remain 31:01:54 loss: 1.2671 Lr: 0.00104
[2025-04-08 14:39:17,721 INFO misc.py line 113 3298914] Train: [3/100][941/2402] Data 0.003 (0.004) Batch 0.393 (0.476) Remain 31:01:32 loss: 1.3315 Lr: 0.00104
[2025-04-08 14:39:18,299 INFO misc.py line 113 3298914] Train: [3/100][942/2402] Data 0.003 (0.004) Batch 0.578 (0.477) Remain 31:01:57 loss: 1.5267 Lr: 0.00104
[2025-04-08 14:39:18,791 INFO misc.py line 113 3298914] Train: [3/100][943/2402] Data 0.003 (0.004) Batch 0.492 (0.477) Remain 31:02:01 loss: 1.0589 Lr: 0.00104
[2025-04-08 14:39:19,308 INFO misc.py line 113 3298914] Train: [3/100][944/2402] Data 0.003 (0.004) Batch 0.517 (0.477) Remain 31:02:10 loss: 1.0769 Lr: 0.00104
[2025-04-08 14:39:19,865 INFO misc.py line 113 3298914] Train: [3/100][945/2402] Data 0.004 (0.004) Batch 0.557 (0.477) Remain 31:02:30 loss: 1.4163 Lr: 0.00104
[2025-04-08 14:39:20,447 INFO misc.py line 113 3298914] Train: [3/100][946/2402] Data 0.004 (0.004) Batch 0.582 (0.477) Remain 31:02:56 loss: 1.3247 Lr: 0.00104
[2025-04-08 14:39:20,954 INFO misc.py line 113 3298914] Train: [3/100][947/2402] Data 0.003 (0.004) Batch 0.507 (0.477) Remain 31:03:03 loss: 1.2976 Lr: 0.00104
[2025-04-08 14:39:21,392 INFO misc.py line 113 3298914] Train: [3/100][948/2402] Data 0.004 (0.004) Batch 0.437 (0.477) Remain 31:02:52 loss: 1.1711 Lr: 0.00104
[2025-04-08 14:39:21,890 INFO misc.py line 113 3298914] Train: [3/100][949/2402] Data 0.003 (0.004) Batch 0.498 (0.477) Remain 31:02:57 loss: 1.3487 Lr: 0.00104
[2025-04-08 14:39:22,369 INFO misc.py line 113 3298914] Train: [3/100][950/2402] Data 0.003 (0.004) Batch 0.479 (0.477) Remain 31:02:57 loss: 0.6325 Lr: 0.00104
[2025-04-08 14:39:22,793 INFO misc.py line 113 3298914] Train: [3/100][951/2402] Data 0.004 (0.004) Batch 0.424 (0.477) Remain 31:02:44 loss: 1.3189 Lr: 0.00104
[2025-04-08 14:39:23,205 INFO misc.py line 113 3298914] Train: [3/100][952/2402] Data 0.003 (0.004) Batch 0.412 (0.477) Remain 31:02:27 loss: 1.1437 Lr: 0.00104
[2025-04-08 14:39:23,628 INFO misc.py line 113 3298914] Train: [3/100][953/2402] Data 0.003 (0.004) Batch 0.423 (0.477) Remain 31:02:14 loss: 1.1451 Lr: 0.00104
[2025-04-08 14:39:24,100 INFO misc.py line 113 3298914] Train: [3/100][954/2402] Data 0.004 (0.004) Batch 0.472 (0.477) Remain 31:02:12 loss: 0.8756 Lr: 0.00104
[2025-04-08 14:39:24,569 INFO misc.py line 113 3298914] Train: [3/100][955/2402] Data 0.003 (0.004) Batch 0.469 (0.477) Remain 31:02:10 loss: 1.1963 Lr: 0.00104
[2025-04-08 14:39:25,187 INFO misc.py line 113 3298914] Train: [3/100][956/2402] Data 0.004 (0.004) Batch 0.618 (0.477) Remain 31:02:44 loss: 1.0974 Lr: 0.00104
[2025-04-08 14:39:25,580 INFO misc.py line 113 3298914] Train: [3/100][957/2402] Data 0.004 (0.004) Batch 0.393 (0.477) Remain 31:02:23 loss: 1.2941 Lr: 0.00104
[2025-04-08 14:39:26,103 INFO misc.py line 113 3298914] Train: [3/100][958/2402] Data 0.003 (0.004) Batch 0.523 (0.477) Remain 31:02:34 loss: 1.5303 Lr: 0.00104
[2025-04-08 14:39:26,514 INFO misc.py line 113 3298914] Train: [3/100][959/2402] Data 0.003 (0.004) Batch 0.411 (0.477) Remain 31:02:17 loss: 1.4960 Lr: 0.00104
[2025-04-08 14:39:26,934 INFO misc.py line 113 3298914] Train: [3/100][960/2402] Data 0.004 (0.004) Batch 0.420 (0.477) Remain 31:02:03 loss: 1.4824 Lr: 0.00104
[2025-04-08 14:39:27,406 INFO misc.py line 113 3298914] Train: [3/100][961/2402] Data 0.003 (0.004) Batch 0.472 (0.477) Remain 31:02:01 loss: 1.0437 Lr: 0.00104
[2025-04-08 14:39:27,943 INFO misc.py line 113 3298914] Train: [3/100][962/2402] Data 0.003 (0.004) Batch 0.537 (0.477) Remain 31:02:16 loss: 1.1085 Lr: 0.00104
[2025-04-08 14:39:28,432 INFO misc.py line 113 3298914] Train: [3/100][963/2402] Data 0.004 (0.004) Batch 0.489 (0.477) Remain 31:02:18 loss: 1.0650 Lr: 0.00104
[2025-04-08 14:39:29,022 INFO misc.py line 113 3298914] Train: [3/100][964/2402] Data 0.004 (0.004) Batch 0.589 (0.477) Remain 31:02:45 loss: 1.3799 Lr: 0.00104
[2025-04-08 14:39:29,481 INFO misc.py line 113 3298914] Train: [3/100][965/2402] Data 0.003 (0.004) Batch 0.460 (0.477) Remain 31:02:41 loss: 1.5634 Lr: 0.00104
[2025-04-08 14:39:29,951 INFO misc.py line 113 3298914] Train: [3/100][966/2402] Data 0.003 (0.004) Batch 0.470 (0.477) Remain 31:02:38 loss: 1.2662 Lr: 0.00104
[2025-04-08 14:39:30,369 INFO misc.py line 113 3298914] Train: [3/100][967/2402] Data 0.004 (0.004) Batch 0.418 (0.477) Remain 31:02:24 loss: 1.3601 Lr: 0.00104
[2025-04-08 14:39:30,751 INFO misc.py line 113 3298914] Train: [3/100][968/2402] Data 0.004 (0.004) Batch 0.381 (0.477) Remain 31:02:00 loss: 1.3568 Lr: 0.00104
[2025-04-08 14:39:31,256 INFO misc.py line 113 3298914] Train: [3/100][969/2402] Data 0.004 (0.004) Batch 0.506 (0.477) Remain 31:02:07 loss: 1.0665 Lr: 0.00104
[2025-04-08 14:39:31,677 INFO misc.py line 113 3298914] Train: [3/100][970/2402] Data 0.004 (0.004) Batch 0.420 (0.477) Remain 31:01:53 loss: 1.2372 Lr: 0.00104
[2025-04-08 14:39:32,225 INFO misc.py line 113 3298914] Train: [3/100][971/2402] Data 0.003 (0.004) Batch 0.548 (0.477) Remain 31:02:09 loss: 1.5237 Lr: 0.00105
[2025-04-08 14:39:32,676 INFO misc.py line 113 3298914] Train: [3/100][972/2402] Data 0.003 (0.004) Batch 0.451 (0.477) Remain 31:02:03 loss: 0.8992 Lr: 0.00105
[2025-04-08 14:39:33,116 INFO misc.py line 113 3298914] Train: [3/100][973/2402] Data 0.004 (0.004) Batch 0.440 (0.477) Remain 31:01:54 loss: 1.0446 Lr: 0.00105
[2025-04-08 14:39:33,561 INFO misc.py line 113 3298914] Train: [3/100][974/2402] Data 0.004 (0.004) Batch 0.444 (0.477) Remain 31:01:45 loss: 1.4099 Lr: 0.00105
[2025-04-08 14:39:34,135 INFO misc.py line 113 3298914] Train: [3/100][975/2402] Data 0.004 (0.004) Batch 0.575 (0.477) Remain 31:02:09 loss: 1.3332 Lr: 0.00105
[2025-04-08 14:39:34,486 INFO misc.py line 113 3298914] Train: [3/100][976/2402] Data 0.003 (0.004) Batch 0.351 (0.476) Remain 31:01:38 loss: 1.4388 Lr: 0.00105
[2025-04-08 14:39:34,991 INFO misc.py line 113 3298914] Train: [3/100][977/2402] Data 0.003 (0.004) Batch 0.505 (0.477) Remain 31:01:44 loss: 1.2661 Lr: 0.00105
[2025-04-08 14:39:35,418 INFO misc.py line 113 3298914] Train: [3/100][978/2402] Data 0.004 (0.004) Batch 0.427 (0.476) Remain 31:01:32 loss: 1.2640 Lr: 0.00105
[2025-04-08 14:39:35,848 INFO misc.py line 113 3298914] Train: [3/100][979/2402] Data 0.003 (0.004) Batch 0.430 (0.476) Remain 31:01:20 loss: 1.1469 Lr: 0.00105
[2025-04-08 14:39:36,437 INFO misc.py line 113 3298914] Train: [3/100][980/2402] Data 0.003 (0.004) Batch 0.589 (0.477) Remain 31:01:47 loss: 1.3259 Lr: 0.00105
[2025-04-08 14:39:36,844 INFO misc.py line 113 3298914] Train: [3/100][981/2402] Data 0.004 (0.004) Batch 0.407 (0.476) Remain 31:01:29 loss: 1.1559 Lr: 0.00105
[2025-04-08 14:39:37,331 INFO misc.py line 113 3298914] Train: [3/100][982/2402] Data 0.003 (0.004) Batch 0.487 (0.476) Remain 31:01:31 loss: 1.4958 Lr: 0.00105
[2025-04-08 14:39:37,843 INFO misc.py line 113 3298914] Train: [3/100][983/2402] Data 0.003 (0.004) Batch 0.512 (0.477) Remain 31:01:40 loss: 1.3345 Lr: 0.00105
[2025-04-08 14:39:38,423 INFO misc.py line 113 3298914] Train: [3/100][984/2402] Data 0.004 (0.004) Batch 0.580 (0.477) Remain 31:02:04 loss: 1.2632 Lr: 0.00105
[2025-04-08 14:39:38,833 INFO misc.py line 113 3298914] Train: [3/100][985/2402] Data 0.003 (0.004) Batch 0.410 (0.477) Remain 31:01:47 loss: 1.0485 Lr: 0.00105
[2025-04-08 14:39:39,329 INFO misc.py line 113 3298914] Train: [3/100][986/2402] Data 0.003 (0.004) Batch 0.496 (0.477) Remain 31:01:52 loss: 0.8893 Lr: 0.00105
[2025-04-08 14:39:39,754 INFO misc.py line 113 3298914] Train: [3/100][987/2402] Data 0.004 (0.004) Batch 0.425 (0.477) Remain 31:01:39 loss: 1.2003 Lr: 0.00105
[2025-04-08 14:39:40,270 INFO misc.py line 113 3298914] Train: [3/100][988/2402] Data 0.003 (0.004) Batch 0.516 (0.477) Remain 31:01:48 loss: 1.4301 Lr: 0.00105
[2025-04-08 14:39:42,404 INFO misc.py line 113 3298914] Train: [3/100][989/2402] Data 1.566 (0.006) Batch 2.134 (0.478) Remain 31:08:21 loss: 1.1215 Lr: 0.00105
[2025-04-08 14:39:42,934 INFO misc.py line 113 3298914] Train: [3/100][990/2402] Data 0.004 (0.006) Batch 0.530 (0.478) Remain 31:08:33 loss: 1.3856 Lr: 0.00105
[2025-04-08 14:39:43,416 INFO misc.py line 113 3298914] Train: [3/100][991/2402] Data 0.003 (0.006) Batch 0.482 (0.478) Remain 31:08:34 loss: 0.9635 Lr: 0.00105
[2025-04-08 14:39:43,865 INFO misc.py line 113 3298914] Train: [3/100][992/2402] Data 0.004 (0.006) Batch 0.448 (0.478) Remain 31:08:26 loss: 1.1700 Lr: 0.00105
[2025-04-08 14:39:44,392 INFO misc.py line 113 3298914] Train: [3/100][993/2402] Data 0.003 (0.006) Batch 0.527 (0.478) Remain 31:08:37 loss: 0.9008 Lr: 0.00105
[2025-04-08 14:39:44,857 INFO misc.py line 113 3298914] Train: [3/100][994/2402] Data 0.004 (0.006) Batch 0.466 (0.478) Remain 31:08:34 loss: 1.4733 Lr: 0.00105
[2025-04-08 14:39:45,348 INFO misc.py line 113 3298914] Train: [3/100][995/2402] Data 0.004 (0.006) Batch 0.491 (0.478) Remain 31:08:36 loss: 1.4062 Lr: 0.00105
[2025-04-08 14:39:45,786 INFO misc.py line 113 3298914] Train: [3/100][996/2402] Data 0.004 (0.006) Batch 0.438 (0.478) Remain 31:08:26 loss: 1.2420 Lr: 0.00105
[2025-04-08 14:39:46,205 INFO misc.py line 113 3298914] Train: [3/100][997/2402] Data 0.003 (0.006) Batch 0.419 (0.478) Remain 31:08:12 loss: 0.9256 Lr: 0.00105
[2025-04-08 14:39:46,767 INFO misc.py line 113 3298914] Train: [3/100][998/2402] Data 0.003 (0.006) Batch 0.562 (0.478) Remain 31:08:31 loss: 1.3244 Lr: 0.00105
[2025-04-08 14:39:47,304 INFO misc.py line 113 3298914] Train: [3/100][999/2402] Data 0.004 (0.006) Batch 0.537 (0.478) Remain 31:08:44 loss: 1.1224 Lr: 0.00105
[2025-04-08 14:39:47,717 INFO misc.py line 113 3298914] Train: [3/100][1000/2402] Data 0.003 (0.006) Batch 0.414 (0.478) Remain 31:08:28 loss: 1.0136 Lr: 0.00105
[2025-04-08 14:39:48,227 INFO misc.py line 113 3298914] Train: [3/100][1001/2402] Data 0.003 (0.006) Batch 0.510 (0.478) Remain 31:08:35 loss: 1.2778 Lr: 0.00105
[2025-04-08 14:39:48,646 INFO misc.py line 113 3298914] Train: [3/100][1002/2402] Data 0.004 (0.006) Batch 0.418 (0.478) Remain 31:08:21 loss: 1.0034 Lr: 0.00105
[2025-04-08 14:39:49,133 INFO misc.py line 113 3298914] Train: [3/100][1003/2402] Data 0.003 (0.006) Batch 0.487 (0.478) Remain 31:08:22 loss: 0.7807 Lr: 0.00105
[2025-04-08 14:39:49,626 INFO misc.py line 113 3298914] Train: [3/100][1004/2402] Data 0.003 (0.006) Batch 0.494 (0.478) Remain 31:08:26 loss: 1.6749 Lr: 0.00105
[2025-04-08 14:39:49,976 INFO misc.py line 113 3298914] Train: [3/100][1005/2402] Data 0.003 (0.006) Batch 0.350 (0.478) Remain 31:07:55 loss: 1.3359 Lr: 0.00105
[2025-04-08 14:39:50,564 INFO misc.py line 113 3298914] Train: [3/100][1006/2402] Data 0.003 (0.006) Batch 0.588 (0.478) Remain 31:08:20 loss: 1.7352 Lr: 0.00105
[2025-04-08 14:39:50,988 INFO misc.py line 113 3298914] Train: [3/100][1007/2402] Data 0.004 (0.006) Batch 0.423 (0.478) Remain 31:08:07 loss: 0.8769 Lr: 0.00105
[2025-04-08 14:39:51,494 INFO misc.py line 113 3298914] Train: [3/100][1008/2402] Data 0.003 (0.006) Batch 0.507 (0.478) Remain 31:08:13 loss: 1.2580 Lr: 0.00105
[2025-04-08 14:39:52,073 INFO misc.py line 113 3298914] Train: [3/100][1009/2402] Data 0.003 (0.006) Batch 0.579 (0.478) Remain 31:08:36 loss: 1.2676 Lr: 0.00105
[2025-04-08 14:39:52,594 INFO misc.py line 113 3298914] Train: [3/100][1010/2402] Data 0.003 (0.006) Batch 0.521 (0.478) Remain 31:08:46 loss: 1.1055 Lr: 0.00105
[2025-04-08 14:39:53,094 INFO misc.py line 113 3298914] Train: [3/100][1011/2402] Data 0.004 (0.006) Batch 0.499 (0.478) Remain 31:08:50 loss: 1.0671 Lr: 0.00105
[2025-04-08 14:39:53,572 INFO misc.py line 113 3298914] Train: [3/100][1012/2402] Data 0.004 (0.006) Batch 0.478 (0.478) Remain 31:08:49 loss: 1.0779 Lr: 0.00105
[2025-04-08 14:39:54,072 INFO misc.py line 113 3298914] Train: [3/100][1013/2402] Data 0.003 (0.006) Batch 0.501 (0.478) Remain 31:08:54 loss: 1.3619 Lr: 0.00105
[2025-04-08 14:39:54,465 INFO misc.py line 113 3298914] Train: [3/100][1014/2402] Data 0.003 (0.006) Batch 0.393 (0.478) Remain 31:08:34 loss: 1.0035 Lr: 0.00106
[2025-04-08 14:39:54,989 INFO misc.py line 113 3298914] Train: [3/100][1015/2402] Data 0.003 (0.006) Batch 0.524 (0.478) Remain 31:08:44 loss: 1.4317 Lr: 0.00106
[2025-04-08 14:39:55,478 INFO misc.py line 113 3298914] Train: [3/100][1016/2402] Data 0.003 (0.006) Batch 0.489 (0.478) Remain 31:08:46 loss: 1.5393 Lr: 0.00106
[2025-04-08 14:39:55,903 INFO misc.py line 113 3298914] Train: [3/100][1017/2402] Data 0.004 (0.006) Batch 0.425 (0.478) Remain 31:08:33 loss: 1.1847 Lr: 0.00106
[2025-04-08 14:39:56,381 INFO misc.py line 113 3298914] Train: [3/100][1018/2402] Data 0.003 (0.006) Batch 0.478 (0.478) Remain 31:08:32 loss: 1.3332 Lr: 0.00106
[2025-04-08 14:39:56,809 INFO misc.py line 113 3298914] Train: [3/100][1019/2402] Data 0.003 (0.006) Batch 0.428 (0.478) Remain 31:08:20 loss: 0.7736 Lr: 0.00106
[2025-04-08 14:39:57,300 INFO misc.py line 113 3298914] Train: [3/100][1020/2402] Data 0.004 (0.006) Batch 0.491 (0.478) Remain 31:08:23 loss: 1.0697 Lr: 0.00106
[2025-04-08 14:39:57,812 INFO misc.py line 113 3298914] Train: [3/100][1021/2402] Data 0.004 (0.006) Batch 0.512 (0.478) Remain 31:08:30 loss: 1.1689 Lr: 0.00106
[2025-04-08 14:39:58,239 INFO misc.py line 113 3298914] Train: [3/100][1022/2402] Data 0.004 (0.006) Batch 0.427 (0.478) Remain 31:08:18 loss: 1.0075 Lr: 0.00106
[2025-04-08 14:39:58,636 INFO misc.py line 113 3298914] Train: [3/100][1023/2402] Data 0.003 (0.006) Batch 0.396 (0.478) Remain 31:07:58 loss: 0.7269 Lr: 0.00106
[2025-04-08 14:39:58,956 INFO misc.py line 113 3298914] Train: [3/100][1024/2402] Data 0.004 (0.006) Batch 0.321 (0.478) Remain 31:07:22 loss: 1.2587 Lr: 0.00106
[2025-04-08 14:39:59,372 INFO misc.py line 113 3298914] Train: [3/100][1025/2402] Data 0.003 (0.006) Batch 0.415 (0.478) Remain 31:07:07 loss: 1.3218 Lr: 0.00106
[2025-04-08 14:39:59,829 INFO misc.py line 113 3298914] Train: [3/100][1026/2402] Data 0.004 (0.006) Batch 0.456 (0.478) Remain 31:07:02 loss: 1.0815 Lr: 0.00106
[2025-04-08 14:40:00,316 INFO misc.py line 113 3298914] Train: [3/100][1027/2402] Data 0.004 (0.006) Batch 0.488 (0.478) Remain 31:07:03 loss: 1.4539 Lr: 0.00106
[2025-04-08 14:40:00,748 INFO misc.py line 113 3298914] Train: [3/100][1028/2402] Data 0.003 (0.006) Batch 0.432 (0.478) Remain 31:06:52 loss: 1.5612 Lr: 0.00106
[2025-04-08 14:40:01,133 INFO misc.py line 113 3298914] Train: [3/100][1029/2402] Data 0.003 (0.006) Batch 0.384 (0.478) Remain 31:06:31 loss: 1.1086 Lr: 0.00106
[2025-04-08 14:40:01,701 INFO misc.py line 113 3298914] Train: [3/100][1030/2402] Data 0.004 (0.006) Batch 0.569 (0.478) Remain 31:06:51 loss: 1.1046 Lr: 0.00106
[2025-04-08 14:40:02,141 INFO misc.py line 113 3298914] Train: [3/100][1031/2402] Data 0.003 (0.006) Batch 0.439 (0.478) Remain 31:06:41 loss: 1.1004 Lr: 0.00106
[2025-04-08 14:40:02,590 INFO misc.py line 113 3298914] Train: [3/100][1032/2402] Data 0.004 (0.006) Batch 0.450 (0.478) Remain 31:06:35 loss: 0.9951 Lr: 0.00106
[2025-04-08 14:40:03,098 INFO misc.py line 113 3298914] Train: [3/100][1033/2402] Data 0.003 (0.006) Batch 0.508 (0.478) Remain 31:06:41 loss: 1.2531 Lr: 0.00106
[2025-04-08 14:40:03,446 INFO misc.py line 113 3298914] Train: [3/100][1034/2402] Data 0.003 (0.006) Batch 0.348 (0.478) Remain 31:06:11 loss: 0.8258 Lr: 0.00106
[2025-04-08 14:40:03,893 INFO misc.py line 113 3298914] Train: [3/100][1035/2402] Data 0.004 (0.006) Batch 0.447 (0.478) Remain 31:06:03 loss: 1.3832 Lr: 0.00106
[2025-04-08 14:40:04,376 INFO misc.py line 113 3298914] Train: [3/100][1036/2402] Data 0.004 (0.006) Batch 0.483 (0.478) Remain 31:06:04 loss: 1.3916 Lr: 0.00106
[2025-04-08 14:40:04,887 INFO misc.py line 113 3298914] Train: [3/100][1037/2402] Data 0.003 (0.006) Batch 0.511 (0.478) Remain 31:06:11 loss: 1.4286 Lr: 0.00106
[2025-04-08 14:40:05,366 INFO misc.py line 113 3298914] Train: [3/100][1038/2402] Data 0.003 (0.006) Batch 0.479 (0.478) Remain 31:06:11 loss: 0.8461 Lr: 0.00106
[2025-04-08 14:40:05,810 INFO misc.py line 113 3298914] Train: [3/100][1039/2402] Data 0.004 (0.006) Batch 0.444 (0.478) Remain 31:06:03 loss: 1.0849 Lr: 0.00106
[2025-04-08 14:40:06,262 INFO misc.py line 113 3298914] Train: [3/100][1040/2402] Data 0.004 (0.006) Batch 0.452 (0.478) Remain 31:05:57 loss: 1.3946 Lr: 0.00106
[2025-04-08 14:40:06,742 INFO misc.py line 113 3298914] Train: [3/100][1041/2402] Data 0.003 (0.006) Batch 0.480 (0.478) Remain 31:05:57 loss: 1.2851 Lr: 0.00106
[2025-04-08 14:40:07,232 INFO misc.py line 113 3298914] Train: [3/100][1042/2402] Data 0.003 (0.006) Batch 0.489 (0.478) Remain 31:05:59 loss: 1.3818 Lr: 0.00106
[2025-04-08 14:40:07,734 INFO misc.py line 113 3298914] Train: [3/100][1043/2402] Data 0.004 (0.006) Batch 0.503 (0.478) Remain 31:06:04 loss: 1.2218 Lr: 0.00106
[2025-04-08 14:40:08,199 INFO misc.py line 113 3298914] Train: [3/100][1044/2402] Data 0.003 (0.006) Batch 0.465 (0.478) Remain 31:06:01 loss: 0.7387 Lr: 0.00106
[2025-04-08 14:40:08,522 INFO misc.py line 113 3298914] Train: [3/100][1045/2402] Data 0.003 (0.006) Batch 0.323 (0.478) Remain 31:05:25 loss: 1.0171 Lr: 0.00106
[2025-04-08 14:40:09,053 INFO misc.py line 113 3298914] Train: [3/100][1046/2402] Data 0.004 (0.006) Batch 0.531 (0.478) Remain 31:05:37 loss: 1.4279 Lr: 0.00106
[2025-04-08 14:40:09,595 INFO misc.py line 113 3298914] Train: [3/100][1047/2402] Data 0.003 (0.006) Batch 0.542 (0.478) Remain 31:05:51 loss: 1.4928 Lr: 0.00106
[2025-04-08 14:40:10,073 INFO misc.py line 113 3298914] Train: [3/100][1048/2402] Data 0.004 (0.006) Batch 0.478 (0.478) Remain 31:05:50 loss: 1.2547 Lr: 0.00106
[2025-04-08 14:40:10,636 INFO misc.py line 113 3298914] Train: [3/100][1049/2402] Data 0.003 (0.006) Batch 0.563 (0.478) Remain 31:06:09 loss: 0.8898 Lr: 0.00106
[2025-04-08 14:40:11,069 INFO misc.py line 113 3298914] Train: [3/100][1050/2402] Data 0.004 (0.006) Batch 0.434 (0.478) Remain 31:05:59 loss: 1.1249 Lr: 0.00106
[2025-04-08 14:40:11,517 INFO misc.py line 113 3298914] Train: [3/100][1051/2402] Data 0.004 (0.006) Batch 0.448 (0.478) Remain 31:05:51 loss: 1.1302 Lr: 0.00106
[2025-04-08 14:40:12,056 INFO misc.py line 113 3298914] Train: [3/100][1052/2402] Data 0.003 (0.006) Batch 0.539 (0.478) Remain 31:06:05 loss: 1.2281 Lr: 0.00106
[2025-04-08 14:40:12,491 INFO misc.py line 113 3298914] Train: [3/100][1053/2402] Data 0.004 (0.006) Batch 0.434 (0.478) Remain 31:05:54 loss: 1.3242 Lr: 0.00106
[2025-04-08 14:40:12,917 INFO misc.py line 113 3298914] Train: [3/100][1054/2402] Data 0.004 (0.006) Batch 0.427 (0.478) Remain 31:05:43 loss: 1.1406 Lr: 0.00106
[2025-04-08 14:40:13,431 INFO misc.py line 113 3298914] Train: [3/100][1055/2402] Data 0.003 (0.006) Batch 0.513 (0.478) Remain 31:05:50 loss: 1.1824 Lr: 0.00106
[2025-04-08 14:40:13,985 INFO misc.py line 113 3298914] Train: [3/100][1056/2402] Data 0.003 (0.006) Batch 0.555 (0.478) Remain 31:06:07 loss: 0.9176 Lr: 0.00107
[2025-04-08 14:40:14,430 INFO misc.py line 113 3298914] Train: [3/100][1057/2402] Data 0.004 (0.006) Batch 0.445 (0.478) Remain 31:05:59 loss: 1.5792 Lr: 0.00107
[2025-04-08 14:40:14,955 INFO misc.py line 113 3298914] Train: [3/100][1058/2402] Data 0.003 (0.006) Batch 0.524 (0.478) Remain 31:06:09 loss: 0.9954 Lr: 0.00107
[2025-04-08 14:40:15,341 INFO misc.py line 113 3298914] Train: [3/100][1059/2402] Data 0.004 (0.006) Batch 0.387 (0.478) Remain 31:05:48 loss: 1.3335 Lr: 0.00107
[2025-04-08 14:40:15,856 INFO misc.py line 113 3298914] Train: [3/100][1060/2402] Data 0.003 (0.006) Batch 0.515 (0.478) Remain 31:05:56 loss: 1.5524 Lr: 0.00107
[2025-04-08 14:40:16,305 INFO misc.py line 113 3298914] Train: [3/100][1061/2402] Data 0.004 (0.006) Batch 0.449 (0.478) Remain 31:05:49 loss: 1.0867 Lr: 0.00107
[2025-04-08 14:40:16,821 INFO misc.py line 113 3298914] Train: [3/100][1062/2402] Data 0.003 (0.006) Batch 0.515 (0.478) Remain 31:05:57 loss: 1.4099 Lr: 0.00107
[2025-04-08 14:40:17,359 INFO misc.py line 113 3298914] Train: [3/100][1063/2402] Data 0.003 (0.006) Batch 0.539 (0.478) Remain 31:06:10 loss: 1.2726 Lr: 0.00107
[2025-04-08 14:40:17,827 INFO misc.py line 113 3298914] Train: [3/100][1064/2402] Data 0.004 (0.006) Batch 0.467 (0.478) Remain 31:06:07 loss: 1.1184 Lr: 0.00107
[2025-04-08 14:40:18,334 INFO misc.py line 113 3298914] Train: [3/100][1065/2402] Data 0.004 (0.006) Batch 0.507 (0.478) Remain 31:06:13 loss: 1.1349 Lr: 0.00107
[2025-04-08 14:40:18,716 INFO misc.py line 113 3298914] Train: [3/100][1066/2402] Data 0.004 (0.006) Batch 0.382 (0.478) Remain 31:05:51 loss: 1.2485 Lr: 0.00107
[2025-04-08 14:40:19,148 INFO misc.py line 113 3298914] Train: [3/100][1067/2402] Data 0.004 (0.006) Batch 0.432 (0.478) Remain 31:05:41 loss: 1.5121 Lr: 0.00107
[2025-04-08 14:40:19,744 INFO misc.py line 113 3298914] Train: [3/100][1068/2402] Data 0.003 (0.006) Batch 0.597 (0.478) Remain 31:06:07 loss: 1.2425 Lr: 0.00107
[2025-04-08 14:40:20,292 INFO misc.py line 113 3298914] Train: [3/100][1069/2402] Data 0.004 (0.006) Batch 0.548 (0.478) Remain 31:06:22 loss: 1.2299 Lr: 0.00107
[2025-04-08 14:40:20,734 INFO misc.py line 113 3298914] Train: [3/100][1070/2402] Data 0.003 (0.006) Batch 0.441 (0.478) Remain 31:06:13 loss: 1.5191 Lr: 0.00107
[2025-04-08 14:40:21,185 INFO misc.py line 113 3298914] Train: [3/100][1071/2402] Data 0.003 (0.006) Batch 0.451 (0.478) Remain 31:06:07 loss: 0.7936 Lr: 0.00107
[2025-04-08 14:40:21,691 INFO misc.py line 113 3298914] Train: [3/100][1072/2402] Data 0.003 (0.006) Batch 0.506 (0.478) Remain 31:06:12 loss: 1.0961 Lr: 0.00107
[2025-04-08 14:40:22,167 INFO misc.py line 113 3298914] Train: [3/100][1073/2402] Data 0.004 (0.006) Batch 0.476 (0.478) Remain 31:06:11 loss: 1.4401 Lr: 0.00107
[2025-04-08 14:40:22,610 INFO misc.py line 113 3298914] Train: [3/100][1074/2402] Data 0.004 (0.006) Batch 0.444 (0.478) Remain 31:06:03 loss: 1.1257 Lr: 0.00107
[2025-04-08 14:40:22,958 INFO misc.py line 113 3298914] Train: [3/100][1075/2402] Data 0.003 (0.006) Batch 0.347 (0.478) Remain 31:05:34 loss: 1.4798 Lr: 0.00107
[2025-04-08 14:40:23,496 INFO misc.py line 113 3298914] Train: [3/100][1076/2402] Data 0.004 (0.006) Batch 0.539 (0.478) Remain 31:05:47 loss: 1.4152 Lr: 0.00107
[2025-04-08 14:40:23,921 INFO misc.py line 113 3298914] Train: [3/100][1077/2402] Data 0.004 (0.006) Batch 0.424 (0.478) Remain 31:05:35 loss: 1.0865 Lr: 0.00107
[2025-04-08 14:40:24,475 INFO misc.py line 113 3298914] Train: [3/100][1078/2402] Data 0.004 (0.006) Batch 0.555 (0.478) Remain 31:05:52 loss: 1.2066 Lr: 0.00107
[2025-04-08 14:40:24,895 INFO misc.py line 113 3298914] Train: [3/100][1079/2402] Data 0.003 (0.006) Batch 0.419 (0.478) Remain 31:05:38 loss: 1.4418 Lr: 0.00107
[2025-04-08 14:40:25,421 INFO misc.py line 113 3298914] Train: [3/100][1080/2402] Data 0.003 (0.006) Batch 0.526 (0.478) Remain 31:05:48 loss: 1.2978 Lr: 0.00107
[2025-04-08 14:40:25,903 INFO misc.py line 113 3298914] Train: [3/100][1081/2402] Data 0.003 (0.006) Batch 0.482 (0.478) Remain 31:05:49 loss: 1.1463 Lr: 0.00107
[2025-04-08 14:40:26,405 INFO misc.py line 113 3298914] Train: [3/100][1082/2402] Data 0.004 (0.006) Batch 0.502 (0.478) Remain 31:05:54 loss: 1.3074 Lr: 0.00107
[2025-04-08 14:40:26,916 INFO misc.py line 113 3298914] Train: [3/100][1083/2402] Data 0.004 (0.006) Batch 0.511 (0.478) Remain 31:06:00 loss: 1.1562 Lr: 0.00107
[2025-04-08 14:40:27,375 INFO misc.py line 113 3298914] Train: [3/100][1084/2402] Data 0.003 (0.006) Batch 0.459 (0.478) Remain 31:05:56 loss: 1.5429 Lr: 0.00107
[2025-04-08 14:40:27,916 INFO misc.py line 113 3298914] Train: [3/100][1085/2402] Data 0.004 (0.006) Batch 0.541 (0.478) Remain 31:06:09 loss: 1.2778 Lr: 0.00107
[2025-04-08 14:40:28,480 INFO misc.py line 113 3298914] Train: [3/100][1086/2402] Data 0.004 (0.006) Batch 0.565 (0.478) Remain 31:06:27 loss: 1.4018 Lr: 0.00107
[2025-04-08 14:40:28,920 INFO misc.py line 113 3298914] Train: [3/100][1087/2402] Data 0.003 (0.006) Batch 0.440 (0.478) Remain 31:06:18 loss: 1.4243 Lr: 0.00107
[2025-04-08 14:40:29,442 INFO misc.py line 113 3298914] Train: [3/100][1088/2402] Data 0.004 (0.006) Batch 0.522 (0.478) Remain 31:06:28 loss: 1.5572 Lr: 0.00107
[2025-04-08 14:40:29,941 INFO misc.py line 113 3298914] Train: [3/100][1089/2402] Data 0.003 (0.006) Batch 0.499 (0.478) Remain 31:06:32 loss: 1.7686 Lr: 0.00107
[2025-04-08 14:40:30,442 INFO misc.py line 113 3298914] Train: [3/100][1090/2402] Data 0.003 (0.006) Batch 0.501 (0.478) Remain 31:06:36 loss: 1.2980 Lr: 0.00107
[2025-04-08 14:40:30,830 INFO misc.py line 113 3298914] Train: [3/100][1091/2402] Data 0.004 (0.006) Batch 0.387 (0.478) Remain 31:06:16 loss: 1.1526 Lr: 0.00107
[2025-04-08 14:40:31,320 INFO misc.py line 113 3298914] Train: [3/100][1092/2402] Data 0.004 (0.006) Batch 0.491 (0.478) Remain 31:06:18 loss: 1.3092 Lr: 0.00107
[2025-04-08 14:40:31,744 INFO misc.py line 113 3298914] Train: [3/100][1093/2402] Data 0.004 (0.006) Batch 0.424 (0.478) Remain 31:06:06 loss: 0.8952 Lr: 0.00107
[2025-04-08 14:40:32,313 INFO misc.py line 113 3298914] Train: [3/100][1094/2402] Data 0.003 (0.006) Batch 0.569 (0.478) Remain 31:06:25 loss: 1.3538 Lr: 0.00107
[2025-04-08 14:40:32,856 INFO misc.py line 113 3298914] Train: [3/100][1095/2402] Data 0.003 (0.006) Batch 0.543 (0.478) Remain 31:06:39 loss: 1.3136 Lr: 0.00107
[2025-04-08 14:40:33,277 INFO misc.py line 113 3298914] Train: [3/100][1096/2402] Data 0.004 (0.006) Batch 0.421 (0.478) Remain 31:06:26 loss: 1.5877 Lr: 0.00107
[2025-04-08 14:40:33,820 INFO misc.py line 113 3298914] Train: [3/100][1097/2402] Data 0.003 (0.006) Batch 0.543 (0.478) Remain 31:06:40 loss: 1.3377 Lr: 0.00107
[2025-04-08 14:40:34,211 INFO misc.py line 113 3298914] Train: [3/100][1098/2402] Data 0.003 (0.006) Batch 0.391 (0.478) Remain 31:06:20 loss: 0.8187 Lr: 0.00107
[2025-04-08 14:40:34,740 INFO misc.py line 113 3298914] Train: [3/100][1099/2402] Data 0.004 (0.006) Batch 0.529 (0.478) Remain 31:06:31 loss: 1.3485 Lr: 0.00108
[2025-04-08 14:40:35,198 INFO misc.py line 113 3298914] Train: [3/100][1100/2402] Data 0.003 (0.006) Batch 0.458 (0.478) Remain 31:06:26 loss: 1.0959 Lr: 0.00108
[2025-04-08 14:40:35,622 INFO misc.py line 113 3298914] Train: [3/100][1101/2402] Data 0.003 (0.006) Batch 0.424 (0.478) Remain 31:06:14 loss: 1.1774 Lr: 0.00108
[2025-04-08 14:40:36,122 INFO misc.py line 113 3298914] Train: [3/100][1102/2402] Data 0.003 (0.006) Batch 0.500 (0.478) Remain 31:06:18 loss: 1.1942 Lr: 0.00108
[2025-04-08 14:40:36,595 INFO misc.py line 113 3298914] Train: [3/100][1103/2402] Data 0.003 (0.006) Batch 0.473 (0.478) Remain 31:06:17 loss: 1.2888 Lr: 0.00108
[2025-04-08 14:40:37,195 INFO misc.py line 113 3298914] Train: [3/100][1104/2402] Data 0.004 (0.006) Batch 0.600 (0.478) Remain 31:06:42 loss: 1.1035 Lr: 0.00108
[2025-04-08 14:40:37,767 INFO misc.py line 113 3298914] Train: [3/100][1105/2402] Data 0.003 (0.006) Batch 0.571 (0.478) Remain 31:07:02 loss: 1.2821 Lr: 0.00108
[2025-04-08 14:40:38,304 INFO misc.py line 113 3298914] Train: [3/100][1106/2402] Data 0.004 (0.006) Batch 0.537 (0.478) Remain 31:07:14 loss: 1.5172 Lr: 0.00108
[2025-04-08 14:40:38,704 INFO misc.py line 113 3298914] Train: [3/100][1107/2402] Data 0.004 (0.006) Batch 0.400 (0.478) Remain 31:06:57 loss: 1.1511 Lr: 0.00108
[2025-04-08 14:40:39,220 INFO misc.py line 113 3298914] Train: [3/100][1108/2402] Data 0.004 (0.006) Batch 0.516 (0.478) Remain 31:07:04 loss: 1.2283 Lr: 0.00108
[2025-04-08 14:40:39,627 INFO misc.py line 113 3298914] Train: [3/100][1109/2402] Data 0.003 (0.006) Batch 0.407 (0.478) Remain 31:06:49 loss: 1.0165 Lr: 0.00108
[2025-04-08 14:40:40,009 INFO misc.py line 113 3298914] Train: [3/100][1110/2402] Data 0.003 (0.006) Batch 0.382 (0.478) Remain 31:06:28 loss: 1.4659 Lr: 0.00108
[2025-04-08 14:40:40,463 INFO misc.py line 113 3298914] Train: [3/100][1111/2402] Data 0.003 (0.006) Batch 0.454 (0.478) Remain 31:06:22 loss: 1.6345 Lr: 0.00108
[2025-04-08 14:40:40,962 INFO misc.py line 113 3298914] Train: [3/100][1112/2402] Data 0.004 (0.006) Batch 0.499 (0.478) Remain 31:06:26 loss: 1.3363 Lr: 0.00108
[2025-04-08 14:40:41,403 INFO misc.py line 113 3298914] Train: [3/100][1113/2402] Data 0.003 (0.006) Batch 0.440 (0.478) Remain 31:06:18 loss: 1.3928 Lr: 0.00108
[2025-04-08 14:40:41,892 INFO misc.py line 113 3298914] Train: [3/100][1114/2402] Data 0.004 (0.006) Batch 0.489 (0.478) Remain 31:06:20 loss: 1.0898 Lr: 0.00108
[2025-04-08 14:40:42,436 INFO misc.py line 113 3298914] Train: [3/100][1115/2402] Data 0.003 (0.006) Batch 0.545 (0.478) Remain 31:06:34 loss: 1.1722 Lr: 0.00108
[2025-04-08 14:40:42,918 INFO misc.py line 113 3298914] Train: [3/100][1116/2402] Data 0.003 (0.006) Batch 0.481 (0.478) Remain 31:06:34 loss: 1.5347 Lr: 0.00108
[2025-04-08 14:40:43,436 INFO misc.py line 113 3298914] Train: [3/100][1117/2402] Data 0.004 (0.006) Batch 0.518 (0.478) Remain 31:06:42 loss: 0.5000 Lr: 0.00108
[2025-04-08 14:40:43,980 INFO misc.py line 113 3298914] Train: [3/100][1118/2402] Data 0.003 (0.006) Batch 0.544 (0.478) Remain 31:06:55 loss: 1.6586 Lr: 0.00108
[2025-04-08 14:40:44,381 INFO misc.py line 113 3298914] Train: [3/100][1119/2402] Data 0.004 (0.006) Batch 0.401 (0.478) Remain 31:06:38 loss: 1.0563 Lr: 0.00108
[2025-04-08 14:40:44,925 INFO misc.py line 113 3298914] Train: [3/100][1120/2402] Data 0.004 (0.006) Batch 0.545 (0.478) Remain 31:06:52 loss: 1.2624 Lr: 0.00108
[2025-04-08 14:40:45,369 INFO misc.py line 113 3298914] Train: [3/100][1121/2402] Data 0.003 (0.006) Batch 0.444 (0.478) Remain 31:06:44 loss: 1.4713 Lr: 0.00108
[2025-04-08 14:40:45,793 INFO misc.py line 113 3298914] Train: [3/100][1122/2402] Data 0.004 (0.006) Batch 0.423 (0.478) Remain 31:06:32 loss: 1.9639 Lr: 0.00108
[2025-04-08 14:40:46,222 INFO misc.py line 113 3298914] Train: [3/100][1123/2402] Data 0.004 (0.006) Batch 0.429 (0.478) Remain 31:06:22 loss: 1.4204 Lr: 0.00108
[2025-04-08 14:40:46,743 INFO misc.py line 113 3298914] Train: [3/100][1124/2402] Data 0.003 (0.006) Batch 0.521 (0.478) Remain 31:06:30 loss: 1.4049 Lr: 0.00108
[2025-04-08 14:40:47,272 INFO misc.py line 113 3298914] Train: [3/100][1125/2402] Data 0.003 (0.006) Batch 0.529 (0.478) Remain 31:06:40 loss: 1.1681 Lr: 0.00108
[2025-04-08 14:40:47,844 INFO misc.py line 113 3298914] Train: [3/100][1126/2402] Data 0.003 (0.006) Batch 0.572 (0.478) Remain 31:06:59 loss: 1.4828 Lr: 0.00108
[2025-04-08 14:40:48,287 INFO misc.py line 113 3298914] Train: [3/100][1127/2402] Data 0.004 (0.006) Batch 0.443 (0.478) Remain 31:06:52 loss: 0.7569 Lr: 0.00108
[2025-04-08 14:40:48,732 INFO misc.py line 113 3298914] Train: [3/100][1128/2402] Data 0.004 (0.006) Batch 0.445 (0.478) Remain 31:06:44 loss: 1.3299 Lr: 0.00108
[2025-04-08 14:40:49,076 INFO misc.py line 113 3298914] Train: [3/100][1129/2402] Data 0.003 (0.006) Batch 0.344 (0.478) Remain 31:06:16 loss: 0.5808 Lr: 0.00108
[2025-04-08 14:40:49,577 INFO misc.py line 113 3298914] Train: [3/100][1130/2402] Data 0.004 (0.006) Batch 0.502 (0.478) Remain 31:06:20 loss: 0.8976 Lr: 0.00108
[2025-04-08 14:40:50,114 INFO misc.py line 113 3298914] Train: [3/100][1131/2402] Data 0.004 (0.006) Batch 0.537 (0.478) Remain 31:06:32 loss: 0.9716 Lr: 0.00108
[2025-04-08 14:40:50,539 INFO misc.py line 113 3298914] Train: [3/100][1132/2402] Data 0.004 (0.006) Batch 0.425 (0.478) Remain 31:06:20 loss: 0.7848 Lr: 0.00108
[2025-04-08 14:40:51,064 INFO misc.py line 113 3298914] Train: [3/100][1133/2402] Data 0.003 (0.006) Batch 0.525 (0.478) Remain 31:06:30 loss: 1.4742 Lr: 0.00108
[2025-04-08 14:40:51,524 INFO misc.py line 113 3298914] Train: [3/100][1134/2402] Data 0.004 (0.006) Batch 0.460 (0.478) Remain 31:06:25 loss: 1.2220 Lr: 0.00108
[2025-04-08 14:40:51,939 INFO misc.py line 113 3298914] Train: [3/100][1135/2402] Data 0.003 (0.006) Batch 0.415 (0.478) Remain 31:06:12 loss: 1.2443 Lr: 0.00108
[2025-04-08 14:40:52,374 INFO misc.py line 113 3298914] Train: [3/100][1136/2402] Data 0.004 (0.006) Batch 0.435 (0.478) Remain 31:06:02 loss: 0.8250 Lr: 0.00108
[2025-04-08 14:40:52,811 INFO misc.py line 113 3298914] Train: [3/100][1137/2402] Data 0.003 (0.006) Batch 0.437 (0.478) Remain 31:05:54 loss: 0.9924 Lr: 0.00108
[2025-04-08 14:40:53,324 INFO misc.py line 113 3298914] Train: [3/100][1138/2402] Data 0.004 (0.006) Batch 0.513 (0.478) Remain 31:06:00 loss: 1.3732 Lr: 0.00108
[2025-04-08 14:40:53,906 INFO misc.py line 113 3298914] Train: [3/100][1139/2402] Data 0.004 (0.006) Batch 0.582 (0.478) Remain 31:06:21 loss: 1.1384 Lr: 0.00108
[2025-04-08 14:40:54,385 INFO misc.py line 113 3298914] Train: [3/100][1140/2402] Data 0.004 (0.006) Batch 0.479 (0.478) Remain 31:06:21 loss: 1.3508 Lr: 0.00108
[2025-04-08 14:40:54,837 INFO misc.py line 113 3298914] Train: [3/100][1141/2402] Data 0.004 (0.006) Batch 0.452 (0.478) Remain 31:06:15 loss: 0.9698 Lr: 0.00109
[2025-04-08 14:40:55,367 INFO misc.py line 113 3298914] Train: [3/100][1142/2402] Data 0.003 (0.006) Batch 0.531 (0.478) Remain 31:06:25 loss: 1.2689 Lr: 0.00109
[2025-04-08 14:40:55,874 INFO misc.py line 113 3298914] Train: [3/100][1143/2402] Data 0.003 (0.006) Batch 0.506 (0.478) Remain 31:06:31 loss: 1.3024 Lr: 0.00109
[2025-04-08 14:40:56,374 INFO misc.py line 113 3298914] Train: [3/100][1144/2402] Data 0.003 (0.006) Batch 0.501 (0.478) Remain 31:06:35 loss: 1.6593 Lr: 0.00109
[2025-04-08 14:40:56,866 INFO misc.py line 113 3298914] Train: [3/100][1145/2402] Data 0.003 (0.006) Batch 0.492 (0.478) Remain 31:06:37 loss: 1.3854 Lr: 0.00109
[2025-04-08 14:40:57,235 INFO misc.py line 113 3298914] Train: [3/100][1146/2402] Data 0.004 (0.006) Batch 0.368 (0.478) Remain 31:06:14 loss: 1.2417 Lr: 0.00109
[2025-04-08 14:40:57,693 INFO misc.py line 113 3298914] Train: [3/100][1147/2402] Data 0.004 (0.006) Batch 0.459 (0.478) Remain 31:06:10 loss: 1.5021 Lr: 0.00109
[2025-04-08 14:40:58,225 INFO misc.py line 113 3298914] Train: [3/100][1148/2402] Data 0.003 (0.006) Batch 0.532 (0.478) Remain 31:06:20 loss: 1.3786 Lr: 0.00109
[2025-04-08 14:40:58,736 INFO misc.py line 113 3298914] Train: [3/100][1149/2402] Data 0.004 (0.006) Batch 0.511 (0.478) Remain 31:06:27 loss: 1.4426 Lr: 0.00109
[2025-04-08 14:40:59,209 INFO misc.py line 113 3298914] Train: [3/100][1150/2402] Data 0.004 (0.006) Batch 0.473 (0.478) Remain 31:06:25 loss: 1.4407 Lr: 0.00109
[2025-04-08 14:40:59,664 INFO misc.py line 113 3298914] Train: [3/100][1151/2402] Data 0.003 (0.006) Batch 0.455 (0.478) Remain 31:06:20 loss: 1.7727 Lr: 0.00109
[2025-04-08 14:41:00,086 INFO misc.py line 113 3298914] Train: [3/100][1152/2402] Data 0.004 (0.006) Batch 0.422 (0.478) Remain 31:06:08 loss: 1.4819 Lr: 0.00109
[2025-04-08 14:41:00,503 INFO misc.py line 113 3298914] Train: [3/100][1153/2402] Data 0.003 (0.006) Batch 0.417 (0.478) Remain 31:05:55 loss: 1.6159 Lr: 0.00109
[2025-04-08 14:41:01,018 INFO misc.py line 113 3298914] Train: [3/100][1154/2402] Data 0.003 (0.006) Batch 0.515 (0.478) Remain 31:06:02 loss: 1.1995 Lr: 0.00109
[2025-04-08 14:41:01,503 INFO misc.py line 113 3298914] Train: [3/100][1155/2402] Data 0.003 (0.006) Batch 0.485 (0.478) Remain 31:06:03 loss: 1.3382 Lr: 0.00109
[2025-04-08 14:41:01,967 INFO misc.py line 113 3298914] Train: [3/100][1156/2402] Data 0.003 (0.006) Batch 0.463 (0.478) Remain 31:06:00 loss: 0.9848 Lr: 0.00109
[2025-04-08 14:41:02,482 INFO misc.py line 113 3298914] Train: [3/100][1157/2402] Data 0.004 (0.006) Batch 0.516 (0.478) Remain 31:06:07 loss: 1.1779 Lr: 0.00109
[2025-04-08 14:41:02,859 INFO misc.py line 113 3298914] Train: [3/100][1158/2402] Data 0.003 (0.006) Batch 0.376 (0.478) Remain 31:05:46 loss: 1.2556 Lr: 0.00109
[2025-04-08 14:41:03,288 INFO misc.py line 113 3298914] Train: [3/100][1159/2402] Data 0.004 (0.006) Batch 0.430 (0.478) Remain 31:05:36 loss: 0.9997 Lr: 0.00109
[2025-04-08 14:41:03,689 INFO misc.py line 113 3298914] Train: [3/100][1160/2402] Data 0.003 (0.006) Batch 0.401 (0.478) Remain 31:05:20 loss: 1.4422 Lr: 0.00109
[2025-04-08 14:41:04,230 INFO misc.py line 113 3298914] Train: [3/100][1161/2402] Data 0.003 (0.006) Batch 0.541 (0.478) Remain 31:05:32 loss: 1.1235 Lr: 0.00109
[2025-04-08 14:41:04,611 INFO misc.py line 113 3298914] Train: [3/100][1162/2402] Data 0.003 (0.006) Batch 0.382 (0.478) Remain 31:05:12 loss: 1.0801 Lr: 0.00109
[2025-04-08 14:41:05,040 INFO misc.py line 113 3298914] Train: [3/100][1163/2402] Data 0.004 (0.006) Batch 0.428 (0.478) Remain 31:05:01 loss: 1.3718 Lr: 0.00109
[2025-04-08 14:41:05,503 INFO misc.py line 113 3298914] Train: [3/100][1164/2402] Data 0.003 (0.006) Batch 0.463 (0.478) Remain 31:04:58 loss: 1.4668 Lr: 0.00109
[2025-04-08 14:41:06,008 INFO misc.py line 113 3298914] Train: [3/100][1165/2402] Data 0.003 (0.006) Batch 0.504 (0.478) Remain 31:05:03 loss: 1.2431 Lr: 0.00109
[2025-04-08 14:41:06,456 INFO misc.py line 113 3298914] Train: [3/100][1166/2402] Data 0.003 (0.006) Batch 0.448 (0.478) Remain 31:04:57 loss: 1.1869 Lr: 0.00109
[2025-04-08 14:41:06,941 INFO misc.py line 113 3298914] Train: [3/100][1167/2402] Data 0.003 (0.006) Batch 0.485 (0.478) Remain 31:04:57 loss: 2.0948 Lr: 0.00109
[2025-04-08 14:41:07,470 INFO misc.py line 113 3298914] Train: [3/100][1168/2402] Data 0.004 (0.006) Batch 0.529 (0.478) Remain 31:05:07 loss: 1.3071 Lr: 0.00109
[2025-04-08 14:41:07,932 INFO misc.py line 113 3298914] Train: [3/100][1169/2402] Data 0.004 (0.006) Batch 0.461 (0.478) Remain 31:05:03 loss: 0.8813 Lr: 0.00109
[2025-04-08 14:41:08,496 INFO misc.py line 113 3298914] Train: [3/100][1170/2402] Data 0.005 (0.006) Batch 0.565 (0.478) Remain 31:05:21 loss: 0.9930 Lr: 0.00109
[2025-04-08 14:41:09,010 INFO misc.py line 113 3298914] Train: [3/100][1171/2402] Data 0.004 (0.006) Batch 0.514 (0.478) Remain 31:05:27 loss: 0.8478 Lr: 0.00109
[2025-04-08 14:41:09,522 INFO misc.py line 113 3298914] Train: [3/100][1172/2402] Data 0.003 (0.006) Batch 0.512 (0.478) Remain 31:05:34 loss: 1.3127 Lr: 0.00109
[2025-04-08 14:41:09,974 INFO misc.py line 113 3298914] Train: [3/100][1173/2402] Data 0.004 (0.006) Batch 0.452 (0.478) Remain 31:05:28 loss: 1.2153 Lr: 0.00109
[2025-04-08 14:41:10,352 INFO misc.py line 113 3298914] Train: [3/100][1174/2402] Data 0.003 (0.006) Batch 0.377 (0.478) Remain 31:05:08 loss: 1.4826 Lr: 0.00109
[2025-04-08 14:41:10,765 INFO misc.py line 113 3298914] Train: [3/100][1175/2402] Data 0.003 (0.006) Batch 0.412 (0.478) Remain 31:04:54 loss: 0.8721 Lr: 0.00109
[2025-04-08 14:41:11,170 INFO misc.py line 113 3298914] Train: [3/100][1176/2402] Data 0.004 (0.006) Batch 0.406 (0.478) Remain 31:04:39 loss: 1.5594 Lr: 0.00109
[2025-04-08 14:41:11,646 INFO misc.py line 113 3298914] Train: [3/100][1177/2402] Data 0.004 (0.006) Batch 0.477 (0.478) Remain 31:04:38 loss: 0.9669 Lr: 0.00109
[2025-04-08 14:41:12,145 INFO misc.py line 113 3298914] Train: [3/100][1178/2402] Data 0.003 (0.006) Batch 0.499 (0.478) Remain 31:04:42 loss: 1.6667 Lr: 0.00109
[2025-04-08 14:41:12,546 INFO misc.py line 113 3298914] Train: [3/100][1179/2402] Data 0.003 (0.006) Batch 0.401 (0.478) Remain 31:04:26 loss: 1.2874 Lr: 0.00109
[2025-04-08 14:41:12,987 INFO misc.py line 113 3298914] Train: [3/100][1180/2402] Data 0.003 (0.006) Batch 0.441 (0.478) Remain 31:04:19 loss: 1.2459 Lr: 0.00109
[2025-04-08 14:41:13,390 INFO misc.py line 113 3298914] Train: [3/100][1181/2402] Data 0.003 (0.006) Batch 0.402 (0.478) Remain 31:04:03 loss: 1.1818 Lr: 0.00109
[2025-04-08 14:41:13,991 INFO misc.py line 113 3298914] Train: [3/100][1182/2402] Data 0.016 (0.006) Batch 0.601 (0.478) Remain 31:04:27 loss: 1.0760 Lr: 0.00109
[2025-04-08 14:41:14,520 INFO misc.py line 113 3298914] Train: [3/100][1183/2402] Data 0.004 (0.006) Batch 0.529 (0.478) Remain 31:04:37 loss: 1.2714 Lr: 0.00109
[2025-04-08 14:41:15,026 INFO misc.py line 113 3298914] Train: [3/100][1184/2402] Data 0.004 (0.006) Batch 0.507 (0.478) Remain 31:04:42 loss: 0.7996 Lr: 0.00110
[2025-04-08 14:41:15,398 INFO misc.py line 113 3298914] Train: [3/100][1185/2402] Data 0.003 (0.006) Batch 0.371 (0.478) Remain 31:04:21 loss: 1.0032 Lr: 0.00110
[2025-04-08 14:41:15,857 INFO misc.py line 113 3298914] Train: [3/100][1186/2402] Data 0.003 (0.006) Batch 0.459 (0.478) Remain 31:04:17 loss: 1.3216 Lr: 0.00110
[2025-04-08 14:41:16,407 INFO misc.py line 113 3298914] Train: [3/100][1187/2402] Data 0.004 (0.006) Batch 0.550 (0.478) Remain 31:04:30 loss: 1.3273 Lr: 0.00110
[2025-04-08 14:41:16,844 INFO misc.py line 113 3298914] Train: [3/100][1188/2402] Data 0.003 (0.006) Batch 0.437 (0.478) Remain 31:04:22 loss: 1.0513 Lr: 0.00110
[2025-04-08 14:41:17,406 INFO misc.py line 113 3298914] Train: [3/100][1189/2402] Data 0.003 (0.006) Batch 0.562 (0.478) Remain 31:04:38 loss: 1.5672 Lr: 0.00110
[2025-04-08 14:41:17,972 INFO misc.py line 113 3298914] Train: [3/100][1190/2402] Data 0.004 (0.006) Batch 0.566 (0.478) Remain 31:04:55 loss: 0.9856 Lr: 0.00110
[2025-04-08 14:41:18,508 INFO misc.py line 113 3298914] Train: [3/100][1191/2402] Data 0.004 (0.006) Batch 0.536 (0.478) Remain 31:05:06 loss: 1.3863 Lr: 0.00110
[2025-04-08 14:41:18,941 INFO misc.py line 113 3298914] Train: [3/100][1192/2402] Data 0.004 (0.006) Batch 0.433 (0.478) Remain 31:04:57 loss: 0.8132 Lr: 0.00110
[2025-04-08 14:41:19,431 INFO misc.py line 113 3298914] Train: [3/100][1193/2402] Data 0.003 (0.006) Batch 0.490 (0.478) Remain 31:04:59 loss: 1.3013 Lr: 0.00110
[2025-04-08 14:41:19,982 INFO misc.py line 113 3298914] Train: [3/100][1194/2402] Data 0.003 (0.006) Batch 0.550 (0.478) Remain 31:05:13 loss: 1.1567 Lr: 0.00110
[2025-04-08 14:41:20,513 INFO misc.py line 113 3298914] Train: [3/100][1195/2402] Data 0.004 (0.006) Batch 0.531 (0.478) Remain 31:05:22 loss: 1.0877 Lr: 0.00110
[2025-04-08 14:41:20,990 INFO misc.py line 113 3298914] Train: [3/100][1196/2402] Data 0.004 (0.006) Batch 0.478 (0.478) Remain 31:05:22 loss: 1.2349 Lr: 0.00110
[2025-04-08 14:41:21,527 INFO misc.py line 113 3298914] Train: [3/100][1197/2402] Data 0.004 (0.006) Batch 0.536 (0.478) Remain 31:05:33 loss: 1.3609 Lr: 0.00110
[2025-04-08 14:41:21,950 INFO misc.py line 113 3298914] Train: [3/100][1198/2402] Data 0.003 (0.006) Batch 0.423 (0.478) Remain 31:05:22 loss: 0.9161 Lr: 0.00110
[2025-04-08 14:41:22,448 INFO misc.py line 113 3298914] Train: [3/100][1199/2402] Data 0.003 (0.006) Batch 0.498 (0.478) Remain 31:05:25 loss: 1.3668 Lr: 0.00110
[2025-04-08 14:41:23,001 INFO misc.py line 113 3298914] Train: [3/100][1200/2402] Data 0.004 (0.006) Batch 0.553 (0.478) Remain 31:05:39 loss: 1.0360 Lr: 0.00110
[2025-04-08 14:41:23,488 INFO misc.py line 113 3298914] Train: [3/100][1201/2402] Data 0.004 (0.006) Batch 0.487 (0.478) Remain 31:05:41 loss: 1.2976 Lr: 0.00110
[2025-04-08 14:41:24,013 INFO misc.py line 113 3298914] Train: [3/100][1202/2402] Data 0.004 (0.006) Batch 0.525 (0.478) Remain 31:05:50 loss: 1.1301 Lr: 0.00110
[2025-04-08 14:41:24,455 INFO misc.py line 113 3298914] Train: [3/100][1203/2402] Data 0.004 (0.006) Batch 0.441 (0.478) Remain 31:05:42 loss: 1.0784 Lr: 0.00110
[2025-04-08 14:41:24,983 INFO misc.py line 113 3298914] Train: [3/100][1204/2402] Data 0.004 (0.006) Batch 0.529 (0.478) Remain 31:05:51 loss: 1.4142 Lr: 0.00110
[2025-04-08 14:41:25,547 INFO misc.py line 113 3298914] Train: [3/100][1205/2402] Data 0.004 (0.006) Batch 0.564 (0.478) Remain 31:06:08 loss: 1.3430 Lr: 0.00110
[2025-04-08 14:41:25,960 INFO misc.py line 113 3298914] Train: [3/100][1206/2402] Data 0.003 (0.006) Batch 0.412 (0.478) Remain 31:05:54 loss: 0.7940 Lr: 0.00110
[2025-04-08 14:41:26,481 INFO misc.py line 113 3298914] Train: [3/100][1207/2402] Data 0.003 (0.006) Batch 0.521 (0.478) Remain 31:06:02 loss: 1.0708 Lr: 0.00110
[2025-04-08 14:41:26,978 INFO misc.py line 113 3298914] Train: [3/100][1208/2402] Data 0.024 (0.006) Batch 0.497 (0.478) Remain 31:06:05 loss: 1.1163 Lr: 0.00110
[2025-04-08 14:41:27,440 INFO misc.py line 113 3298914] Train: [3/100][1209/2402] Data 0.003 (0.006) Batch 0.462 (0.478) Remain 31:06:02 loss: 0.9179 Lr: 0.00110
[2025-04-08 14:41:27,953 INFO misc.py line 113 3298914] Train: [3/100][1210/2402] Data 0.003 (0.006) Batch 0.512 (0.478) Remain 31:06:08 loss: 1.1796 Lr: 0.00110
[2025-04-08 14:41:28,534 INFO misc.py line 113 3298914] Train: [3/100][1211/2402] Data 0.004 (0.006) Batch 0.581 (0.478) Remain 31:06:28 loss: 1.5775 Lr: 0.00110
[2025-04-08 14:41:28,925 INFO misc.py line 113 3298914] Train: [3/100][1212/2402] Data 0.003 (0.006) Batch 0.391 (0.478) Remain 31:06:10 loss: 1.1613 Lr: 0.00110
[2025-04-08 14:41:29,340 INFO misc.py line 113 3298914] Train: [3/100][1213/2402] Data 0.003 (0.006) Batch 0.415 (0.478) Remain 31:05:58 loss: 1.2384 Lr: 0.00110
[2025-04-08 14:41:29,863 INFO misc.py line 113 3298914] Train: [3/100][1214/2402] Data 0.004 (0.006) Batch 0.523 (0.478) Remain 31:06:06 loss: 1.1891 Lr: 0.00110
[2025-04-08 14:41:30,459 INFO misc.py line 113 3298914] Train: [3/100][1215/2402] Data 0.003 (0.006) Batch 0.595 (0.478) Remain 31:06:28 loss: 1.1011 Lr: 0.00110
[2025-04-08 14:41:30,912 INFO misc.py line 113 3298914] Train: [3/100][1216/2402] Data 0.004 (0.006) Batch 0.453 (0.478) Remain 31:06:23 loss: 0.9025 Lr: 0.00110
[2025-04-08 14:41:31,506 INFO misc.py line 113 3298914] Train: [3/100][1217/2402] Data 0.003 (0.006) Batch 0.594 (0.478) Remain 31:06:45 loss: 1.0721 Lr: 0.00110
[2025-04-08 14:41:31,984 INFO misc.py line 113 3298914] Train: [3/100][1218/2402] Data 0.004 (0.006) Batch 0.478 (0.478) Remain 31:06:44 loss: 1.5889 Lr: 0.00110
[2025-04-08 14:41:32,476 INFO misc.py line 113 3298914] Train: [3/100][1219/2402] Data 0.004 (0.006) Batch 0.492 (0.478) Remain 31:06:46 loss: 1.5003 Lr: 0.00110
[2025-04-08 14:41:33,043 INFO misc.py line 113 3298914] Train: [3/100][1220/2402] Data 0.003 (0.006) Batch 0.566 (0.478) Remain 31:07:03 loss: 0.9483 Lr: 0.00110
[2025-04-08 14:41:33,614 INFO misc.py line 113 3298914] Train: [3/100][1221/2402] Data 0.004 (0.006) Batch 0.572 (0.478) Remain 31:07:20 loss: 1.5969 Lr: 0.00110
[2025-04-08 14:41:34,053 INFO misc.py line 113 3298914] Train: [3/100][1222/2402] Data 0.004 (0.006) Batch 0.439 (0.478) Remain 31:07:12 loss: 1.1592 Lr: 0.00110
[2025-04-08 14:41:34,562 INFO misc.py line 113 3298914] Train: [3/100][1223/2402] Data 0.004 (0.006) Batch 0.509 (0.478) Remain 31:07:17 loss: 1.1433 Lr: 0.00110
[2025-04-08 14:41:35,014 INFO misc.py line 113 3298914] Train: [3/100][1224/2402] Data 0.003 (0.006) Batch 0.452 (0.478) Remain 31:07:12 loss: 1.0248 Lr: 0.00110
[2025-04-08 14:41:35,501 INFO misc.py line 113 3298914] Train: [3/100][1225/2402] Data 0.003 (0.006) Batch 0.487 (0.478) Remain 31:07:13 loss: 1.1437 Lr: 0.00110
[2025-04-08 14:41:36,031 INFO misc.py line 113 3298914] Train: [3/100][1226/2402] Data 0.004 (0.006) Batch 0.530 (0.478) Remain 31:07:22 loss: 1.4657 Lr: 0.00111
[2025-04-08 14:41:36,473 INFO misc.py line 113 3298914] Train: [3/100][1227/2402] Data 0.003 (0.006) Batch 0.441 (0.478) Remain 31:07:15 loss: 1.0994 Lr: 0.00111
[2025-04-08 14:41:36,930 INFO misc.py line 113 3298914] Train: [3/100][1228/2402] Data 0.004 (0.006) Batch 0.457 (0.478) Remain 31:07:10 loss: 1.0809 Lr: 0.00111
[2025-04-08 14:41:37,300 INFO misc.py line 113 3298914] Train: [3/100][1229/2402] Data 0.003 (0.006) Batch 0.371 (0.478) Remain 31:06:49 loss: 1.0636 Lr: 0.00111
[2025-04-08 14:41:37,847 INFO misc.py line 113 3298914] Train: [3/100][1230/2402] Data 0.003 (0.006) Batch 0.546 (0.478) Remain 31:07:02 loss: 1.3384 Lr: 0.00111
[2025-04-08 14:41:38,410 INFO misc.py line 113 3298914] Train: [3/100][1231/2402] Data 0.004 (0.006) Batch 0.563 (0.478) Remain 31:07:17 loss: 1.2834 Lr: 0.00111
[2025-04-08 14:41:38,929 INFO misc.py line 113 3298914] Train: [3/100][1232/2402] Data 0.003 (0.006) Batch 0.519 (0.478) Remain 31:07:25 loss: 1.2507 Lr: 0.00111
[2025-04-08 14:41:39,385 INFO misc.py line 113 3298914] Train: [3/100][1233/2402] Data 0.004 (0.005) Batch 0.456 (0.478) Remain 31:07:20 loss: 1.4284 Lr: 0.00111
[2025-04-08 14:41:39,868 INFO misc.py line 113 3298914] Train: [3/100][1234/2402] Data 0.003 (0.005) Batch 0.484 (0.478) Remain 31:07:20 loss: 1.2232 Lr: 0.00111
[2025-04-08 14:41:40,358 INFO misc.py line 113 3298914] Train: [3/100][1235/2402] Data 0.003 (0.005) Batch 0.489 (0.478) Remain 31:07:22 loss: 1.3103 Lr: 0.00111
[2025-04-08 14:41:40,813 INFO misc.py line 113 3298914] Train: [3/100][1236/2402] Data 0.004 (0.005) Batch 0.456 (0.478) Remain 31:07:17 loss: 1.5326 Lr: 0.00111
[2025-04-08 14:41:41,298 INFO misc.py line 113 3298914] Train: [3/100][1237/2402] Data 0.003 (0.005) Batch 0.485 (0.478) Remain 31:07:18 loss: 1.5465 Lr: 0.00111
[2025-04-08 14:41:41,620 INFO misc.py line 113 3298914] Train: [3/100][1238/2402] Data 0.003 (0.005) Batch 0.321 (0.478) Remain 31:06:48 loss: 1.1671 Lr: 0.00111
[2025-04-08 14:41:42,217 INFO misc.py line 113 3298914] Train: [3/100][1239/2402] Data 0.004 (0.005) Batch 0.597 (0.478) Remain 31:07:10 loss: 1.3301 Lr: 0.00111
[2025-04-08 14:41:42,707 INFO misc.py line 113 3298914] Train: [3/100][1240/2402] Data 0.004 (0.005) Batch 0.490 (0.478) Remain 31:07:11 loss: 1.2870 Lr: 0.00111
[2025-04-08 14:41:43,191 INFO misc.py line 113 3298914] Train: [3/100][1241/2402] Data 0.003 (0.005) Batch 0.485 (0.478) Remain 31:07:12 loss: 1.2208 Lr: 0.00111
[2025-04-08 14:41:43,698 INFO misc.py line 113 3298914] Train: [3/100][1242/2402] Data 0.004 (0.005) Batch 0.506 (0.478) Remain 31:07:17 loss: 1.2863 Lr: 0.00111
[2025-04-08 14:41:44,217 INFO misc.py line 113 3298914] Train: [3/100][1243/2402] Data 0.004 (0.005) Batch 0.519 (0.479) Remain 31:07:24 loss: 1.1926 Lr: 0.00111
[2025-04-08 14:41:44,682 INFO misc.py line 113 3298914] Train: [3/100][1244/2402] Data 0.004 (0.005) Batch 0.465 (0.478) Remain 31:07:21 loss: 1.1239 Lr: 0.00111
[2025-04-08 14:41:45,135 INFO misc.py line 113 3298914] Train: [3/100][1245/2402] Data 0.003 (0.005) Batch 0.454 (0.478) Remain 31:07:16 loss: 1.4594 Lr: 0.00111
[2025-04-08 14:41:45,784 INFO misc.py line 113 3298914] Train: [3/100][1246/2402] Data 0.003 (0.005) Batch 0.648 (0.479) Remain 31:07:47 loss: 1.2551 Lr: 0.00111
[2025-04-08 14:41:46,311 INFO misc.py line 113 3298914] Train: [3/100][1247/2402] Data 0.004 (0.005) Batch 0.527 (0.479) Remain 31:07:56 loss: 1.0497 Lr: 0.00111
[2025-04-08 14:41:46,743 INFO misc.py line 113 3298914] Train: [3/100][1248/2402] Data 0.004 (0.005) Batch 0.432 (0.479) Remain 31:07:47 loss: 0.9844 Lr: 0.00111
[2025-04-08 14:41:47,252 INFO misc.py line 113 3298914] Train: [3/100][1249/2402] Data 0.004 (0.005) Batch 0.509 (0.479) Remain 31:07:52 loss: 0.8765 Lr: 0.00111
[2025-04-08 14:41:47,772 INFO misc.py line 113 3298914] Train: [3/100][1250/2402] Data 0.003 (0.005) Batch 0.520 (0.479) Remain 31:07:59 loss: 1.2244 Lr: 0.00111
[2025-04-08 14:41:48,210 INFO misc.py line 113 3298914] Train: [3/100][1251/2402] Data 0.004 (0.005) Batch 0.438 (0.479) Remain 31:07:51 loss: 1.1161 Lr: 0.00111
[2025-04-08 14:41:48,668 INFO misc.py line 113 3298914] Train: [3/100][1252/2402] Data 0.004 (0.005) Batch 0.458 (0.479) Remain 31:07:47 loss: 0.8515 Lr: 0.00111
[2025-04-08 14:41:49,158 INFO misc.py line 113 3298914] Train: [3/100][1253/2402] Data 0.003 (0.005) Batch 0.490 (0.479) Remain 31:07:48 loss: 1.4159 Lr: 0.00111
[2025-04-08 14:41:49,581 INFO misc.py line 113 3298914] Train: [3/100][1254/2402] Data 0.003 (0.005) Batch 0.423 (0.479) Remain 31:07:37 loss: 1.1881 Lr: 0.00111
[2025-04-08 14:41:49,957 INFO misc.py line 113 3298914] Train: [3/100][1255/2402] Data 0.004 (0.005) Batch 0.376 (0.479) Remain 31:07:18 loss: 1.0640 Lr: 0.00111
[2025-04-08 14:41:50,411 INFO misc.py line 113 3298914] Train: [3/100][1256/2402] Data 0.004 (0.005) Batch 0.454 (0.478) Remain 31:07:13 loss: 1.0550 Lr: 0.00111
[2025-04-08 14:41:50,960 INFO misc.py line 113 3298914] Train: [3/100][1257/2402] Data 0.003 (0.005) Batch 0.550 (0.479) Remain 31:07:26 loss: 1.1596 Lr: 0.00111
[2025-04-08 14:41:51,420 INFO misc.py line 113 3298914] Train: [3/100][1258/2402] Data 0.004 (0.005) Batch 0.460 (0.479) Remain 31:07:22 loss: 1.0162 Lr: 0.00111
[2025-04-08 14:41:51,946 INFO misc.py line 113 3298914] Train: [3/100][1259/2402] Data 0.003 (0.005) Batch 0.525 (0.479) Remain 31:07:30 loss: 1.0142 Lr: 0.00111
[2025-04-08 14:41:52,455 INFO misc.py line 113 3298914] Train: [3/100][1260/2402] Data 0.003 (0.005) Batch 0.509 (0.479) Remain 31:07:35 loss: 1.3237 Lr: 0.00111
[2025-04-08 14:41:53,043 INFO misc.py line 113 3298914] Train: [3/100][1261/2402] Data 0.003 (0.005) Batch 0.588 (0.479) Remain 31:07:55 loss: 0.9400 Lr: 0.00111
[2025-04-08 14:41:53,597 INFO misc.py line 113 3298914] Train: [3/100][1262/2402] Data 0.003 (0.005) Batch 0.554 (0.479) Remain 31:08:08 loss: 1.1544 Lr: 0.00111
[2025-04-08 14:41:54,007 INFO misc.py line 113 3298914] Train: [3/100][1263/2402] Data 0.004 (0.005) Batch 0.410 (0.479) Remain 31:07:55 loss: 0.6817 Lr: 0.00111
[2025-04-08 14:41:54,573 INFO misc.py line 113 3298914] Train: [3/100][1264/2402] Data 0.003 (0.005) Batch 0.566 (0.479) Remain 31:08:11 loss: 1.2474 Lr: 0.00111
[2025-04-08 14:41:55,019 INFO misc.py line 113 3298914] Train: [3/100][1265/2402] Data 0.003 (0.005) Batch 0.446 (0.479) Remain 31:08:05 loss: 1.0494 Lr: 0.00111
[2025-04-08 14:41:55,494 INFO misc.py line 113 3298914] Train: [3/100][1266/2402] Data 0.003 (0.005) Batch 0.475 (0.479) Remain 31:08:03 loss: 1.4168 Lr: 0.00111
[2025-04-08 14:41:55,976 INFO misc.py line 113 3298914] Train: [3/100][1267/2402] Data 0.003 (0.005) Batch 0.482 (0.479) Remain 31:08:03 loss: 1.5843 Lr: 0.00111
[2025-04-08 14:41:56,445 INFO misc.py line 113 3298914] Train: [3/100][1268/2402] Data 0.003 (0.005) Batch 0.469 (0.479) Remain 31:08:01 loss: 1.3883 Lr: 0.00111
[2025-04-08 14:41:56,954 INFO misc.py line 113 3298914] Train: [3/100][1269/2402] Data 0.004 (0.005) Batch 0.509 (0.479) Remain 31:08:06 loss: 1.5732 Lr: 0.00112
[2025-04-08 14:41:57,411 INFO misc.py line 113 3298914] Train: [3/100][1270/2402] Data 0.003 (0.005) Batch 0.457 (0.479) Remain 31:08:02 loss: 1.0400 Lr: 0.00112
[2025-04-08 14:41:57,727 INFO misc.py line 113 3298914] Train: [3/100][1271/2402] Data 0.003 (0.005) Batch 0.316 (0.479) Remain 31:07:31 loss: 1.0490 Lr: 0.00112
[2025-04-08 14:41:58,282 INFO misc.py line 113 3298914] Train: [3/100][1272/2402] Data 0.003 (0.005) Batch 0.554 (0.479) Remain 31:07:45 loss: 1.2964 Lr: 0.00112
[2025-04-08 14:41:58,755 INFO misc.py line 113 3298914] Train: [3/100][1273/2402] Data 0.004 (0.005) Batch 0.473 (0.479) Remain 31:07:43 loss: 0.9335 Lr: 0.00112
[2025-04-08 14:41:59,265 INFO misc.py line 113 3298914] Train: [3/100][1274/2402] Data 0.004 (0.005) Batch 0.510 (0.479) Remain 31:07:49 loss: 1.1891 Lr: 0.00112
[2025-04-08 14:41:59,808 INFO misc.py line 113 3298914] Train: [3/100][1275/2402] Data 0.003 (0.005) Batch 0.543 (0.479) Remain 31:08:00 loss: 1.1161 Lr: 0.00112
[2025-04-08 14:42:00,214 INFO misc.py line 113 3298914] Train: [3/100][1276/2402] Data 0.004 (0.005) Batch 0.406 (0.479) Remain 31:07:46 loss: 0.8035 Lr: 0.00112
[2025-04-08 14:42:00,676 INFO misc.py line 113 3298914] Train: [3/100][1277/2402] Data 0.003 (0.005) Batch 0.462 (0.479) Remain 31:07:43 loss: 0.9239 Lr: 0.00112
[2025-04-08 14:42:01,094 INFO misc.py line 113 3298914] Train: [3/100][1278/2402] Data 0.003 (0.005) Batch 0.418 (0.479) Remain 31:07:31 loss: 1.0309 Lr: 0.00112
[2025-04-08 14:42:01,605 INFO misc.py line 113 3298914] Train: [3/100][1279/2402] Data 0.003 (0.005) Batch 0.510 (0.479) Remain 31:07:36 loss: 0.9509 Lr: 0.00112
[2025-04-08 14:42:02,104 INFO misc.py line 113 3298914] Train: [3/100][1280/2402] Data 0.003 (0.005) Batch 0.499 (0.479) Remain 31:07:40 loss: 1.3347 Lr: 0.00112
[2025-04-08 14:42:02,544 INFO misc.py line 113 3298914] Train: [3/100][1281/2402] Data 0.003 (0.005) Batch 0.441 (0.479) Remain 31:07:32 loss: 1.4629 Lr: 0.00112
[2025-04-08 14:42:03,039 INFO misc.py line 113 3298914] Train: [3/100][1282/2402] Data 0.003 (0.005) Batch 0.494 (0.479) Remain 31:07:35 loss: 1.2117 Lr: 0.00112
[2025-04-08 14:42:03,453 INFO misc.py line 113 3298914] Train: [3/100][1283/2402] Data 0.003 (0.005) Batch 0.414 (0.479) Remain 31:07:22 loss: 1.5715 Lr: 0.00112
[2025-04-08 14:42:03,938 INFO misc.py line 113 3298914] Train: [3/100][1284/2402] Data 0.004 (0.005) Batch 0.485 (0.479) Remain 31:07:23 loss: 1.1013 Lr: 0.00112
[2025-04-08 14:42:04,272 INFO misc.py line 113 3298914] Train: [3/100][1285/2402] Data 0.003 (0.005) Batch 0.334 (0.478) Remain 31:06:56 loss: 0.7589 Lr: 0.00112
[2025-04-08 14:42:04,800 INFO misc.py line 113 3298914] Train: [3/100][1286/2402] Data 0.003 (0.005) Batch 0.527 (0.479) Remain 31:07:05 loss: 1.2841 Lr: 0.00112
[2025-04-08 14:42:05,307 INFO misc.py line 113 3298914] Train: [3/100][1287/2402] Data 0.004 (0.005) Batch 0.507 (0.479) Remain 31:07:09 loss: 1.2844 Lr: 0.00112
[2025-04-08 14:42:05,829 INFO misc.py line 113 3298914] Train: [3/100][1288/2402] Data 0.004 (0.005) Batch 0.522 (0.479) Remain 31:07:17 loss: 1.5295 Lr: 0.00112
[2025-04-08 14:42:06,316 INFO misc.py line 113 3298914] Train: [3/100][1289/2402] Data 0.004 (0.005) Batch 0.487 (0.479) Remain 31:07:18 loss: 1.3346 Lr: 0.00112
[2025-04-08 14:42:06,813 INFO misc.py line 113 3298914] Train: [3/100][1290/2402] Data 0.004 (0.005) Batch 0.497 (0.479) Remain 31:07:21 loss: 1.3838 Lr: 0.00112
[2025-04-08 14:42:07,160 INFO misc.py line 113 3298914] Train: [3/100][1291/2402] Data 0.003 (0.005) Batch 0.347 (0.478) Remain 31:06:56 loss: 1.0394 Lr: 0.00112
[2025-04-08 14:42:07,640 INFO misc.py line 113 3298914] Train: [3/100][1292/2402] Data 0.003 (0.005) Batch 0.480 (0.478) Remain 31:06:56 loss: 1.1351 Lr: 0.00112
[2025-04-08 14:42:08,268 INFO misc.py line 113 3298914] Train: [3/100][1293/2402] Data 0.004 (0.005) Batch 0.629 (0.479) Remain 31:07:23 loss: 1.2383 Lr: 0.00112
[2025-04-08 14:42:08,674 INFO misc.py line 113 3298914] Train: [3/100][1294/2402] Data 0.004 (0.005) Batch 0.406 (0.479) Remain 31:07:09 loss: 1.2862 Lr: 0.00112
[2025-04-08 14:42:09,128 INFO misc.py line 113 3298914] Train: [3/100][1295/2402] Data 0.004 (0.005) Batch 0.454 (0.479) Remain 31:07:04 loss: 1.4524 Lr: 0.00112
[2025-04-08 14:42:09,524 INFO misc.py line 113 3298914] Train: [3/100][1296/2402] Data 0.003 (0.005) Batch 0.396 (0.478) Remain 31:06:49 loss: 1.1356 Lr: 0.00112
[2025-04-08 14:42:09,920 INFO misc.py line 113 3298914] Train: [3/100][1297/2402] Data 0.003 (0.005) Batch 0.396 (0.478) Remain 31:06:33 loss: 0.9433 Lr: 0.00112
[2025-04-08 14:42:10,425 INFO misc.py line 113 3298914] Train: [3/100][1298/2402] Data 0.003 (0.005) Batch 0.505 (0.478) Remain 31:06:38 loss: 1.3625 Lr: 0.00112
[2025-04-08 14:42:11,040 INFO misc.py line 113 3298914] Train: [3/100][1299/2402] Data 0.003 (0.005) Batch 0.615 (0.479) Remain 31:07:02 loss: 1.3565 Lr: 0.00112
[2025-04-08 14:42:11,553 INFO misc.py line 113 3298914] Train: [3/100][1300/2402] Data 0.004 (0.005) Batch 0.513 (0.479) Remain 31:07:08 loss: 1.2693 Lr: 0.00112
[2025-04-08 14:42:11,997 INFO misc.py line 113 3298914] Train: [3/100][1301/2402] Data 0.003 (0.005) Batch 0.444 (0.479) Remain 31:07:01 loss: 1.3063 Lr: 0.00112
[2025-04-08 14:42:12,470 INFO misc.py line 113 3298914] Train: [3/100][1302/2402] Data 0.004 (0.005) Batch 0.473 (0.479) Remain 31:07:00 loss: 1.4921 Lr: 0.00112
[2025-04-08 14:42:12,948 INFO misc.py line 113 3298914] Train: [3/100][1303/2402] Data 0.004 (0.005) Batch 0.478 (0.479) Remain 31:06:59 loss: 1.2861 Lr: 0.00112
[2025-04-08 14:42:13,500 INFO misc.py line 113 3298914] Train: [3/100][1304/2402] Data 0.003 (0.005) Batch 0.551 (0.479) Remain 31:07:12 loss: 1.3498 Lr: 0.00112
[2025-04-08 14:42:13,923 INFO misc.py line 113 3298914] Train: [3/100][1305/2402] Data 0.003 (0.005) Batch 0.423 (0.479) Remain 31:07:01 loss: 1.3650 Lr: 0.00112
[2025-04-08 14:42:14,363 INFO misc.py line 113 3298914] Train: [3/100][1306/2402] Data 0.004 (0.005) Batch 0.441 (0.479) Remain 31:06:54 loss: 0.6348 Lr: 0.00112
[2025-04-08 14:42:14,914 INFO misc.py line 113 3298914] Train: [3/100][1307/2402] Data 0.004 (0.005) Batch 0.551 (0.479) Remain 31:07:06 loss: 0.8278 Lr: 0.00112
[2025-04-08 14:42:15,384 INFO misc.py line 113 3298914] Train: [3/100][1308/2402] Data 0.003 (0.005) Batch 0.470 (0.479) Remain 31:07:04 loss: 1.1404 Lr: 0.00112
[2025-04-08 14:42:15,823 INFO misc.py line 113 3298914] Train: [3/100][1309/2402] Data 0.003 (0.005) Batch 0.439 (0.479) Remain 31:06:57 loss: 1.8025 Lr: 0.00112
[2025-04-08 14:42:16,319 INFO misc.py line 113 3298914] Train: [3/100][1310/2402] Data 0.003 (0.005) Batch 0.496 (0.479) Remain 31:07:00 loss: 1.2560 Lr: 0.00112
[2025-04-08 14:42:16,760 INFO misc.py line 113 3298914] Train: [3/100][1311/2402] Data 0.003 (0.005) Batch 0.441 (0.479) Remain 31:06:52 loss: 1.0464 Lr: 0.00113
[2025-04-08 14:42:17,262 INFO misc.py line 113 3298914] Train: [3/100][1312/2402] Data 0.004 (0.005) Batch 0.502 (0.479) Remain 31:06:56 loss: 1.1398 Lr: 0.00113
[2025-04-08 14:42:17,809 INFO misc.py line 113 3298914] Train: [3/100][1313/2402] Data 0.004 (0.005) Batch 0.547 (0.479) Remain 31:07:08 loss: 1.6041 Lr: 0.00113
[2025-04-08 14:42:18,172 INFO misc.py line 113 3298914] Train: [3/100][1314/2402] Data 0.003 (0.005) Batch 0.363 (0.478) Remain 31:06:47 loss: 1.0317 Lr: 0.00113
[2025-04-08 14:42:18,743 INFO misc.py line 113 3298914] Train: [3/100][1315/2402] Data 0.003 (0.005) Batch 0.571 (0.479) Remain 31:07:03 loss: 1.2289 Lr: 0.00113
[2025-04-08 14:42:19,213 INFO misc.py line 113 3298914] Train: [3/100][1316/2402] Data 0.004 (0.005) Batch 0.470 (0.479) Remain 31:07:01 loss: 1.5732 Lr: 0.00113
[2025-04-08 14:42:19,763 INFO misc.py line 113 3298914] Train: [3/100][1317/2402] Data 0.003 (0.005) Batch 0.551 (0.479) Remain 31:07:13 loss: 1.3370 Lr: 0.00113
[2025-04-08 14:42:20,290 INFO misc.py line 113 3298914] Train: [3/100][1318/2402] Data 0.004 (0.005) Batch 0.527 (0.479) Remain 31:07:21 loss: 1.1810 Lr: 0.00113
[2025-04-08 14:42:20,783 INFO misc.py line 113 3298914] Train: [3/100][1319/2402] Data 0.004 (0.005) Batch 0.493 (0.479) Remain 31:07:23 loss: 1.2049 Lr: 0.00113
[2025-04-08 14:42:21,286 INFO misc.py line 113 3298914] Train: [3/100][1320/2402] Data 0.004 (0.005) Batch 0.504 (0.479) Remain 31:07:27 loss: 1.3204 Lr: 0.00113
[2025-04-08 14:42:21,787 INFO misc.py line 113 3298914] Train: [3/100][1321/2402] Data 0.003 (0.005) Batch 0.500 (0.479) Remain 31:07:30 loss: 1.1524 Lr: 0.00113
[2025-04-08 14:42:22,259 INFO misc.py line 113 3298914] Train: [3/100][1322/2402] Data 0.003 (0.005) Batch 0.472 (0.479) Remain 31:07:29 loss: 1.1595 Lr: 0.00113
[2025-04-08 14:42:22,758 INFO misc.py line 113 3298914] Train: [3/100][1323/2402] Data 0.003 (0.005) Batch 0.499 (0.479) Remain 31:07:32 loss: 1.1748 Lr: 0.00113
[2025-04-08 14:42:23,319 INFO misc.py line 113 3298914] Train: [3/100][1324/2402] Data 0.003 (0.005) Batch 0.560 (0.479) Remain 31:07:46 loss: 1.1241 Lr: 0.00113
[2025-04-08 14:42:23,733 INFO misc.py line 113 3298914] Train: [3/100][1325/2402] Data 0.004 (0.005) Batch 0.414 (0.479) Remain 31:07:34 loss: 0.8971 Lr: 0.00113
[2025-04-08 14:42:24,236 INFO misc.py line 113 3298914] Train: [3/100][1326/2402] Data 0.003 (0.005) Batch 0.503 (0.479) Remain 31:07:38 loss: 1.1674 Lr: 0.00113
[2025-04-08 14:42:24,620 INFO misc.py line 113 3298914] Train: [3/100][1327/2402] Data 0.004 (0.005) Batch 0.384 (0.479) Remain 31:07:21 loss: 1.0031 Lr: 0.00113
[2025-04-08 14:42:25,133 INFO misc.py line 113 3298914] Train: [3/100][1328/2402] Data 0.003 (0.005) Batch 0.513 (0.479) Remain 31:07:26 loss: 1.1761 Lr: 0.00113
[2025-04-08 14:42:25,573 INFO misc.py line 113 3298914] Train: [3/100][1329/2402] Data 0.003 (0.005) Batch 0.440 (0.479) Remain 31:07:19 loss: 1.1295 Lr: 0.00113
[2025-04-08 14:42:26,081 INFO misc.py line 113 3298914] Train: [3/100][1330/2402] Data 0.004 (0.005) Batch 0.508 (0.479) Remain 31:07:23 loss: 1.0724 Lr: 0.00113
[2025-04-08 14:42:26,618 INFO misc.py line 113 3298914] Train: [3/100][1331/2402] Data 0.004 (0.005) Batch 0.538 (0.479) Remain 31:07:33 loss: 1.5156 Lr: 0.00113
[2025-04-08 14:42:27,006 INFO misc.py line 113 3298914] Train: [3/100][1332/2402] Data 0.004 (0.005) Batch 0.389 (0.479) Remain 31:07:17 loss: 0.9193 Lr: 0.00113
[2025-04-08 14:42:27,472 INFO misc.py line 113 3298914] Train: [3/100][1333/2402] Data 0.003 (0.005) Batch 0.466 (0.479) Remain 31:07:14 loss: 1.0812 Lr: 0.00113
[2025-04-08 14:42:27,979 INFO misc.py line 113 3298914] Train: [3/100][1334/2402] Data 0.003 (0.005) Batch 0.506 (0.479) Remain 31:07:19 loss: 1.1963 Lr: 0.00113
[2025-04-08 14:42:28,527 INFO misc.py line 113 3298914] Train: [3/100][1335/2402] Data 0.052 (0.005) Batch 0.548 (0.479) Remain 31:07:30 loss: 1.2388 Lr: 0.00113
[2025-04-08 14:42:29,047 INFO misc.py line 113 3298914] Train: [3/100][1336/2402] Data 0.003 (0.005) Batch 0.520 (0.479) Remain 31:07:37 loss: 1.2440 Lr: 0.00113
[2025-04-08 14:42:29,445 INFO misc.py line 113 3298914] Train: [3/100][1337/2402] Data 0.003 (0.005) Batch 0.398 (0.479) Remain 31:07:23 loss: 1.2581 Lr: 0.00113
[2025-04-08 14:42:30,008 INFO misc.py line 113 3298914] Train: [3/100][1338/2402] Data 0.004 (0.005) Batch 0.562 (0.479) Remain 31:07:37 loss: 0.7769 Lr: 0.00113
[2025-04-08 14:42:30,453 INFO misc.py line 113 3298914] Train: [3/100][1339/2402] Data 0.003 (0.005) Batch 0.446 (0.479) Remain 31:07:31 loss: 1.4489 Lr: 0.00113
[2025-04-08 14:42:30,932 INFO misc.py line 113 3298914] Train: [3/100][1340/2402] Data 0.003 (0.005) Batch 0.479 (0.479) Remain 31:07:30 loss: 1.1988 Lr: 0.00113
[2025-04-08 14:42:31,430 INFO misc.py line 113 3298914] Train: [3/100][1341/2402] Data 0.003 (0.005) Batch 0.498 (0.479) Remain 31:07:33 loss: 1.1774 Lr: 0.00113
[2025-04-08 14:42:31,974 INFO misc.py line 113 3298914] Train: [3/100][1342/2402] Data 0.003 (0.005) Batch 0.544 (0.479) Remain 31:07:44 loss: 1.6198 Lr: 0.00113
[2025-04-08 14:42:32,485 INFO misc.py line 113 3298914] Train: [3/100][1343/2402] Data 0.004 (0.005) Batch 0.511 (0.479) Remain 31:07:49 loss: 0.7602 Lr: 0.00113
[2025-04-08 14:42:32,955 INFO misc.py line 113 3298914] Train: [3/100][1344/2402] Data 0.004 (0.005) Batch 0.470 (0.479) Remain 31:07:47 loss: 0.8914 Lr: 0.00113
[2025-04-08 14:42:33,531 INFO misc.py line 113 3298914] Train: [3/100][1345/2402] Data 0.004 (0.005) Batch 0.576 (0.479) Remain 31:08:03 loss: 0.9749 Lr: 0.00113
[2025-04-08 14:42:34,054 INFO misc.py line 113 3298914] Train: [3/100][1346/2402] Data 0.003 (0.005) Batch 0.523 (0.479) Remain 31:08:11 loss: 1.3233 Lr: 0.00113
[2025-04-08 14:42:34,586 INFO misc.py line 113 3298914] Train: [3/100][1347/2402] Data 0.004 (0.005) Batch 0.533 (0.479) Remain 31:08:19 loss: 1.0197 Lr: 0.00113
[2025-04-08 14:42:34,947 INFO misc.py line 113 3298914] Train: [3/100][1348/2402] Data 0.003 (0.005) Batch 0.361 (0.479) Remain 31:07:59 loss: 0.9733 Lr: 0.00113
[2025-04-08 14:42:35,460 INFO misc.py line 113 3298914] Train: [3/100][1349/2402] Data 0.003 (0.005) Batch 0.513 (0.479) Remain 31:08:04 loss: 1.7922 Lr: 0.00113
[2025-04-08 14:42:35,991 INFO misc.py line 113 3298914] Train: [3/100][1350/2402] Data 0.004 (0.005) Batch 0.530 (0.479) Remain 31:08:12 loss: 0.7573 Lr: 0.00113
[2025-04-08 14:42:36,544 INFO misc.py line 113 3298914] Train: [3/100][1351/2402] Data 0.004 (0.005) Batch 0.554 (0.479) Remain 31:08:25 loss: 1.1209 Lr: 0.00113
[2025-04-08 14:42:37,098 INFO misc.py line 113 3298914] Train: [3/100][1352/2402] Data 0.003 (0.005) Batch 0.554 (0.479) Remain 31:08:37 loss: 0.9294 Lr: 0.00113
[2025-04-08 14:42:37,610 INFO misc.py line 113 3298914] Train: [3/100][1353/2402] Data 0.003 (0.005) Batch 0.512 (0.479) Remain 31:08:43 loss: 0.8691 Lr: 0.00113
[2025-04-08 14:42:38,040 INFO misc.py line 113 3298914] Train: [3/100][1354/2402] Data 0.003 (0.005) Batch 0.430 (0.479) Remain 31:08:34 loss: 1.3251 Lr: 0.00114
[2025-04-08 14:42:38,481 INFO misc.py line 113 3298914] Train: [3/100][1355/2402] Data 0.003 (0.005) Batch 0.441 (0.479) Remain 31:08:27 loss: 1.4692 Lr: 0.00114
[2025-04-08 14:42:39,046 INFO misc.py line 113 3298914] Train: [3/100][1356/2402] Data 0.003 (0.005) Batch 0.565 (0.479) Remain 31:08:41 loss: 0.9182 Lr: 0.00114
[2025-04-08 14:42:39,455 INFO misc.py line 113 3298914] Train: [3/100][1357/2402] Data 0.003 (0.005) Batch 0.408 (0.479) Remain 31:08:28 loss: 1.2215 Lr: 0.00114
[2025-04-08 14:42:39,949 INFO misc.py line 113 3298914] Train: [3/100][1358/2402] Data 0.004 (0.005) Batch 0.494 (0.479) Remain 31:08:30 loss: 1.2497 Lr: 0.00114
[2025-04-08 14:42:40,452 INFO misc.py line 113 3298914] Train: [3/100][1359/2402] Data 0.003 (0.005) Batch 0.503 (0.479) Remain 31:08:34 loss: 1.2826 Lr: 0.00114
[2025-04-08 14:42:41,024 INFO misc.py line 113 3298914] Train: [3/100][1360/2402] Data 0.003 (0.005) Batch 0.572 (0.479) Remain 31:08:50 loss: 1.1039 Lr: 0.00114
[2025-04-08 14:42:41,622 INFO misc.py line 113 3298914] Train: [3/100][1361/2402] Data 0.003 (0.005) Batch 0.598 (0.479) Remain 31:09:10 loss: 1.5683 Lr: 0.00114
[2025-04-08 14:42:42,095 INFO misc.py line 113 3298914] Train: [3/100][1362/2402] Data 0.003 (0.005) Batch 0.473 (0.479) Remain 31:09:08 loss: 1.0165 Lr: 0.00114
[2025-04-08 14:42:42,564 INFO misc.py line 113 3298914] Train: [3/100][1363/2402] Data 0.003 (0.005) Batch 0.469 (0.479) Remain 31:09:06 loss: 1.2545 Lr: 0.00114
[2025-04-08 14:42:43,065 INFO misc.py line 113 3298914] Train: [3/100][1364/2402] Data 0.004 (0.005) Batch 0.501 (0.479) Remain 31:09:09 loss: 1.2562 Lr: 0.00114
[2025-04-08 14:42:43,553 INFO misc.py line 113 3298914] Train: [3/100][1365/2402] Data 0.003 (0.005) Batch 0.488 (0.479) Remain 31:09:10 loss: 1.7094 Lr: 0.00114
[2025-04-08 14:42:43,986 INFO misc.py line 113 3298914] Train: [3/100][1366/2402] Data 0.003 (0.005) Batch 0.433 (0.479) Remain 31:09:02 loss: 1.3720 Lr: 0.00114
[2025-04-08 14:42:44,404 INFO misc.py line 113 3298914] Train: [3/100][1367/2402] Data 0.004 (0.005) Batch 0.419 (0.479) Remain 31:08:51 loss: 1.0176 Lr: 0.00114
[2025-04-08 14:42:44,894 INFO misc.py line 113 3298914] Train: [3/100][1368/2402] Data 0.004 (0.005) Batch 0.489 (0.479) Remain 31:08:52 loss: 1.0503 Lr: 0.00114
[2025-04-08 14:42:45,308 INFO misc.py line 113 3298914] Train: [3/100][1369/2402] Data 0.003 (0.005) Batch 0.414 (0.479) Remain 31:08:41 loss: 0.9980 Lr: 0.00114
[2025-04-08 14:42:45,739 INFO misc.py line 113 3298914] Train: [3/100][1370/2402] Data 0.003 (0.005) Batch 0.431 (0.479) Remain 31:08:32 loss: 1.0732 Lr: 0.00114
[2025-04-08 14:42:46,245 INFO misc.py line 113 3298914] Train: [3/100][1371/2402] Data 0.004 (0.005) Batch 0.506 (0.479) Remain 31:08:36 loss: 1.3117 Lr: 0.00114
[2025-04-08 14:42:46,782 INFO misc.py line 113 3298914] Train: [3/100][1372/2402] Data 0.004 (0.005) Batch 0.537 (0.479) Remain 31:08:45 loss: 1.0885 Lr: 0.00114
[2025-04-08 14:42:47,409 INFO misc.py line 113 3298914] Train: [3/100][1373/2402] Data 0.017 (0.005) Batch 0.627 (0.479) Remain 31:09:10 loss: 1.0961 Lr: 0.00114
[2025-04-08 14:42:47,839 INFO misc.py line 113 3298914] Train: [3/100][1374/2402] Data 0.003 (0.005) Batch 0.431 (0.479) Remain 31:09:01 loss: 1.4461 Lr: 0.00114
[2025-04-08 14:42:48,292 INFO misc.py line 113 3298914] Train: [3/100][1375/2402] Data 0.003 (0.005) Batch 0.453 (0.479) Remain 31:08:56 loss: 1.2697 Lr: 0.00114
[2025-04-08 14:42:48,790 INFO misc.py line 113 3298914] Train: [3/100][1376/2402] Data 0.003 (0.005) Batch 0.498 (0.479) Remain 31:08:59 loss: 1.2256 Lr: 0.00114
[2025-04-08 14:42:49,232 INFO misc.py line 113 3298914] Train: [3/100][1377/2402] Data 0.003 (0.005) Batch 0.442 (0.479) Remain 31:08:52 loss: 0.9603 Lr: 0.00114
[2025-04-08 14:42:49,632 INFO misc.py line 113 3298914] Train: [3/100][1378/2402] Data 0.003 (0.005) Batch 0.400 (0.479) Remain 31:08:38 loss: 1.2178 Lr: 0.00114
[2025-04-08 14:42:50,051 INFO misc.py line 113 3298914] Train: [3/100][1379/2402] Data 0.004 (0.005) Batch 0.419 (0.479) Remain 31:08:28 loss: 1.0453 Lr: 0.00114
[2025-04-08 14:42:50,586 INFO misc.py line 113 3298914] Train: [3/100][1380/2402] Data 0.004 (0.005) Batch 0.535 (0.479) Remain 31:08:37 loss: 1.1723 Lr: 0.00114
[2025-04-08 14:42:50,988 INFO misc.py line 113 3298914] Train: [3/100][1381/2402] Data 0.004 (0.005) Batch 0.402 (0.479) Remain 31:08:23 loss: 1.2451 Lr: 0.00114
[2025-04-08 14:42:51,463 INFO misc.py line 113 3298914] Train: [3/100][1382/2402] Data 0.003 (0.005) Batch 0.475 (0.479) Remain 31:08:22 loss: 1.2790 Lr: 0.00114
[2025-04-08 14:42:52,039 INFO misc.py line 113 3298914] Train: [3/100][1383/2402] Data 0.004 (0.005) Batch 0.575 (0.479) Remain 31:08:38 loss: 1.1776 Lr: 0.00114
[2025-04-08 14:42:52,446 INFO misc.py line 113 3298914] Train: [3/100][1384/2402] Data 0.004 (0.005) Batch 0.407 (0.479) Remain 31:08:25 loss: 1.2073 Lr: 0.00114
[2025-04-08 14:42:53,041 INFO misc.py line 113 3298914] Train: [3/100][1385/2402] Data 0.003 (0.005) Batch 0.596 (0.479) Remain 31:08:44 loss: 1.1083 Lr: 0.00114
[2025-04-08 14:42:53,600 INFO misc.py line 113 3298914] Train: [3/100][1386/2402] Data 0.004 (0.005) Batch 0.558 (0.479) Remain 31:08:57 loss: 0.8732 Lr: 0.00114
[2025-04-08 14:42:54,071 INFO misc.py line 113 3298914] Train: [3/100][1387/2402] Data 0.004 (0.005) Batch 0.471 (0.479) Remain 31:08:55 loss: 1.2185 Lr: 0.00114
[2025-04-08 14:42:54,535 INFO misc.py line 113 3298914] Train: [3/100][1388/2402] Data 0.003 (0.005) Batch 0.465 (0.479) Remain 31:08:52 loss: 1.2061 Lr: 0.00114
[2025-04-08 14:42:55,114 INFO misc.py line 113 3298914] Train: [3/100][1389/2402] Data 0.004 (0.005) Batch 0.579 (0.479) Remain 31:09:09 loss: 1.0166 Lr: 0.00114
[2025-04-08 14:42:55,528 INFO misc.py line 113 3298914] Train: [3/100][1390/2402] Data 0.003 (0.005) Batch 0.415 (0.479) Remain 31:08:57 loss: 1.6242 Lr: 0.00114
[2025-04-08 14:42:56,029 INFO misc.py line 113 3298914] Train: [3/100][1391/2402] Data 0.003 (0.005) Batch 0.500 (0.479) Remain 31:09:00 loss: 1.0725 Lr: 0.00114
[2025-04-08 14:42:56,480 INFO misc.py line 113 3298914] Train: [3/100][1392/2402] Data 0.003 (0.005) Batch 0.451 (0.479) Remain 31:08:55 loss: 1.3773 Lr: 0.00114
[2025-04-08 14:42:57,021 INFO misc.py line 113 3298914] Train: [3/100][1393/2402] Data 0.003 (0.005) Batch 0.541 (0.479) Remain 31:09:05 loss: 1.1997 Lr: 0.00114
[2025-04-08 14:42:57,482 INFO misc.py line 113 3298914] Train: [3/100][1394/2402] Data 0.003 (0.005) Batch 0.461 (0.479) Remain 31:09:02 loss: 1.1698 Lr: 0.00114
[2025-04-08 14:42:57,837 INFO misc.py line 113 3298914] Train: [3/100][1395/2402] Data 0.004 (0.005) Batch 0.355 (0.479) Remain 31:08:40 loss: 1.1338 Lr: 0.00114
[2025-04-08 14:42:58,287 INFO misc.py line 113 3298914] Train: [3/100][1396/2402] Data 0.003 (0.005) Batch 0.449 (0.479) Remain 31:08:35 loss: 1.2863 Lr: 0.00115
[2025-04-08 14:42:58,784 INFO misc.py line 113 3298914] Train: [3/100][1397/2402] Data 0.003 (0.005) Batch 0.498 (0.479) Remain 31:08:38 loss: 1.3202 Lr: 0.00115
[2025-04-08 14:42:59,257 INFO misc.py line 113 3298914] Train: [3/100][1398/2402] Data 0.003 (0.005) Batch 0.472 (0.479) Remain 31:08:36 loss: 0.9032 Lr: 0.00115
[2025-04-08 14:42:59,805 INFO misc.py line 113 3298914] Train: [3/100][1399/2402] Data 0.003 (0.005) Batch 0.548 (0.479) Remain 31:08:47 loss: 1.2324 Lr: 0.00115
[2025-04-08 14:43:00,295 INFO misc.py line 113 3298914] Train: [3/100][1400/2402] Data 0.004 (0.005) Batch 0.490 (0.479) Remain 31:08:48 loss: 1.4000 Lr: 0.00115
[2025-04-08 14:43:00,871 INFO misc.py line 113 3298914] Train: [3/100][1401/2402] Data 0.003 (0.005) Batch 0.576 (0.479) Remain 31:09:04 loss: 0.8220 Lr: 0.00115
[2025-04-08 14:43:01,396 INFO misc.py line 113 3298914] Train: [3/100][1402/2402] Data 0.004 (0.005) Batch 0.525 (0.479) Remain 31:09:11 loss: 1.4626 Lr: 0.00115
[2025-04-08 14:43:01,856 INFO misc.py line 113 3298914] Train: [3/100][1403/2402] Data 0.004 (0.005) Batch 0.460 (0.479) Remain 31:09:07 loss: 1.1965 Lr: 0.00115
[2025-04-08 14:43:02,380 INFO misc.py line 113 3298914] Train: [3/100][1404/2402] Data 0.004 (0.005) Batch 0.524 (0.479) Remain 31:09:14 loss: 1.0862 Lr: 0.00115
[2025-04-08 14:43:02,923 INFO misc.py line 113 3298914] Train: [3/100][1405/2402] Data 0.004 (0.005) Batch 0.543 (0.479) Remain 31:09:25 loss: 1.4298 Lr: 0.00115
[2025-04-08 14:43:03,365 INFO misc.py line 113 3298914] Train: [3/100][1406/2402] Data 0.003 (0.005) Batch 0.442 (0.479) Remain 31:09:18 loss: 1.2317 Lr: 0.00115
[2025-04-08 14:43:03,883 INFO misc.py line 113 3298914] Train: [3/100][1407/2402] Data 0.003 (0.005) Batch 0.519 (0.479) Remain 31:09:24 loss: 1.4462 Lr: 0.00115
[2025-04-08 14:43:04,462 INFO misc.py line 113 3298914] Train: [3/100][1408/2402] Data 0.003 (0.005) Batch 0.579 (0.479) Remain 31:09:40 loss: 0.9153 Lr: 0.00115
[2025-04-08 14:43:04,879 INFO misc.py line 113 3298914] Train: [3/100][1409/2402] Data 0.003 (0.005) Batch 0.417 (0.479) Remain 31:09:29 loss: 1.4710 Lr: 0.00115
[2025-04-08 14:43:05,410 INFO misc.py line 113 3298914] Train: [3/100][1410/2402] Data 0.003 (0.005) Batch 0.532 (0.479) Remain 31:09:37 loss: 1.6787 Lr: 0.00115
[2025-04-08 14:43:05,743 INFO misc.py line 113 3298914] Train: [3/100][1411/2402] Data 0.003 (0.005) Batch 0.332 (0.479) Remain 31:09:12 loss: 0.8425 Lr: 0.00115
[2025-04-08 14:43:06,152 INFO misc.py line 113 3298914] Train: [3/100][1412/2402] Data 0.004 (0.005) Batch 0.410 (0.479) Remain 31:09:00 loss: 0.7333 Lr: 0.00115
[2025-04-08 14:43:06,701 INFO misc.py line 113 3298914] Train: [3/100][1413/2402] Data 0.003 (0.005) Batch 0.549 (0.479) Remain 31:09:11 loss: 1.0646 Lr: 0.00115
[2025-04-08 14:43:07,191 INFO misc.py line 113 3298914] Train: [3/100][1414/2402] Data 0.003 (0.005) Batch 0.490 (0.479) Remain 31:09:13 loss: 1.0497 Lr: 0.00115
[2025-04-08 14:43:07,685 INFO misc.py line 113 3298914] Train: [3/100][1415/2402] Data 0.004 (0.005) Batch 0.494 (0.479) Remain 31:09:15 loss: 1.4735 Lr: 0.00115
[2025-04-08 14:43:08,116 INFO misc.py line 113 3298914] Train: [3/100][1416/2402] Data 0.004 (0.005) Batch 0.431 (0.479) Remain 31:09:06 loss: 1.4715 Lr: 0.00115
[2025-04-08 14:43:08,638 INFO misc.py line 113 3298914] Train: [3/100][1417/2402] Data 0.003 (0.005) Batch 0.523 (0.479) Remain 31:09:13 loss: 1.3113 Lr: 0.00115
[2025-04-08 14:43:09,103 INFO misc.py line 113 3298914] Train: [3/100][1418/2402] Data 0.004 (0.005) Batch 0.465 (0.479) Remain 31:09:10 loss: 1.7851 Lr: 0.00115
[2025-04-08 14:43:09,631 INFO misc.py line 113 3298914] Train: [3/100][1419/2402] Data 0.003 (0.005) Batch 0.528 (0.479) Remain 31:09:17 loss: 1.3997 Lr: 0.00115
[2025-04-08 14:43:10,070 INFO misc.py line 113 3298914] Train: [3/100][1420/2402] Data 0.003 (0.005) Batch 0.439 (0.479) Remain 31:09:10 loss: 0.9271 Lr: 0.00115
[2025-04-08 14:43:10,540 INFO misc.py line 113 3298914] Train: [3/100][1421/2402] Data 0.004 (0.005) Batch 0.470 (0.479) Remain 31:09:08 loss: 1.3361 Lr: 0.00115
[2025-04-08 14:43:11,064 INFO misc.py line 113 3298914] Train: [3/100][1422/2402] Data 0.004 (0.005) Batch 0.524 (0.479) Remain 31:09:15 loss: 1.3156 Lr: 0.00115
[2025-04-08 14:43:11,527 INFO misc.py line 113 3298914] Train: [3/100][1423/2402] Data 0.003 (0.005) Batch 0.463 (0.479) Remain 31:09:12 loss: 1.1618 Lr: 0.00115
[2025-04-08 14:43:12,041 INFO misc.py line 113 3298914] Train: [3/100][1424/2402] Data 0.004 (0.005) Batch 0.514 (0.479) Remain 31:09:17 loss: 1.0868 Lr: 0.00115
[2025-04-08 14:43:12,424 INFO misc.py line 113 3298914] Train: [3/100][1425/2402] Data 0.003 (0.005) Batch 0.383 (0.479) Remain 31:09:01 loss: 1.0395 Lr: 0.00115
[2025-04-08 14:43:12,841 INFO misc.py line 113 3298914] Train: [3/100][1426/2402] Data 0.003 (0.005) Batch 0.417 (0.479) Remain 31:08:50 loss: 1.1705 Lr: 0.00115
[2025-04-08 14:43:13,351 INFO misc.py line 113 3298914] Train: [3/100][1427/2402] Data 0.004 (0.005) Batch 0.509 (0.479) Remain 31:08:54 loss: 1.4082 Lr: 0.00115
[2025-04-08 14:43:13,838 INFO misc.py line 113 3298914] Train: [3/100][1428/2402] Data 0.005 (0.005) Batch 0.488 (0.479) Remain 31:08:55 loss: 0.9873 Lr: 0.00115
[2025-04-08 14:43:14,360 INFO misc.py line 113 3298914] Train: [3/100][1429/2402] Data 0.003 (0.005) Batch 0.522 (0.479) Remain 31:09:02 loss: 1.0613 Lr: 0.00115
[2025-04-08 14:43:14,769 INFO misc.py line 113 3298914] Train: [3/100][1430/2402] Data 0.004 (0.005) Batch 0.409 (0.479) Remain 31:08:50 loss: 0.9565 Lr: 0.00115
[2025-04-08 14:43:15,203 INFO misc.py line 113 3298914] Train: [3/100][1431/2402] Data 0.003 (0.005) Batch 0.435 (0.479) Remain 31:08:42 loss: 1.5417 Lr: 0.00115
[2025-04-08 14:43:15,689 INFO misc.py line 113 3298914] Train: [3/100][1432/2402] Data 0.004 (0.005) Batch 0.485 (0.479) Remain 31:08:43 loss: 1.3031 Lr: 0.00115
[2025-04-08 14:43:16,121 INFO misc.py line 113 3298914] Train: [3/100][1433/2402] Data 0.004 (0.005) Batch 0.432 (0.479) Remain 31:08:35 loss: 1.2864 Lr: 0.00115
[2025-04-08 14:43:16,650 INFO misc.py line 113 3298914] Train: [3/100][1434/2402] Data 0.004 (0.005) Batch 0.529 (0.479) Remain 31:08:42 loss: 1.1827 Lr: 0.00115
[2025-04-08 14:43:17,099 INFO misc.py line 113 3298914] Train: [3/100][1435/2402] Data 0.004 (0.005) Batch 0.450 (0.479) Remain 31:08:37 loss: 1.1856 Lr: 0.00115
[2025-04-08 14:43:17,503 INFO misc.py line 113 3298914] Train: [3/100][1436/2402] Data 0.003 (0.005) Batch 0.403 (0.479) Remain 31:08:24 loss: 1.2331 Lr: 0.00115
[2025-04-08 14:43:17,938 INFO misc.py line 113 3298914] Train: [3/100][1437/2402] Data 0.004 (0.005) Batch 0.436 (0.479) Remain 31:08:16 loss: 1.1552 Lr: 0.00115
[2025-04-08 14:43:18,477 INFO misc.py line 113 3298914] Train: [3/100][1438/2402] Data 0.004 (0.005) Batch 0.540 (0.479) Remain 31:08:26 loss: 1.3650 Lr: 0.00115
[2025-04-08 14:43:18,920 INFO misc.py line 113 3298914] Train: [3/100][1439/2402] Data 0.003 (0.005) Batch 0.442 (0.479) Remain 31:08:19 loss: 1.3357 Lr: 0.00116
[2025-04-08 14:43:19,372 INFO misc.py line 113 3298914] Train: [3/100][1440/2402] Data 0.003 (0.005) Batch 0.452 (0.479) Remain 31:08:14 loss: 1.4915 Lr: 0.00116
[2025-04-08 14:43:19,889 INFO misc.py line 113 3298914] Train: [3/100][1441/2402] Data 0.004 (0.005) Batch 0.517 (0.479) Remain 31:08:20 loss: 1.2427 Lr: 0.00116
[2025-04-08 14:43:20,353 INFO misc.py line 113 3298914] Train: [3/100][1442/2402] Data 0.004 (0.005) Batch 0.464 (0.479) Remain 31:08:17 loss: 0.9061 Lr: 0.00116
[2025-04-08 14:43:20,883 INFO misc.py line 113 3298914] Train: [3/100][1443/2402] Data 0.004 (0.005) Batch 0.531 (0.479) Remain 31:08:25 loss: 1.2157 Lr: 0.00116
[2025-04-08 14:43:21,249 INFO misc.py line 113 3298914] Train: [3/100][1444/2402] Data 0.003 (0.005) Batch 0.365 (0.479) Remain 31:08:06 loss: 1.0079 Lr: 0.00116
[2025-04-08 14:43:21,780 INFO misc.py line 113 3298914] Train: [3/100][1445/2402] Data 0.003 (0.005) Batch 0.531 (0.479) Remain 31:08:14 loss: 1.2078 Lr: 0.00116
[2025-04-08 14:43:22,196 INFO misc.py line 113 3298914] Train: [3/100][1446/2402] Data 0.004 (0.005) Batch 0.416 (0.479) Remain 31:08:03 loss: 1.4737 Lr: 0.00116
[2025-04-08 14:43:22,723 INFO misc.py line 113 3298914] Train: [3/100][1447/2402] Data 0.003 (0.005) Batch 0.527 (0.479) Remain 31:08:11 loss: 1.1297 Lr: 0.00116
[2025-04-08 14:43:23,164 INFO misc.py line 113 3298914] Train: [3/100][1448/2402] Data 0.003 (0.005) Batch 0.441 (0.479) Remain 31:08:04 loss: 0.9405 Lr: 0.00116
[2025-04-08 14:43:23,617 INFO misc.py line 113 3298914] Train: [3/100][1449/2402] Data 0.004 (0.005) Batch 0.453 (0.479) Remain 31:07:59 loss: 1.4707 Lr: 0.00116
[2025-04-08 14:43:24,151 INFO misc.py line 113 3298914] Train: [3/100][1450/2402] Data 0.004 (0.005) Batch 0.534 (0.479) Remain 31:08:08 loss: 0.9249 Lr: 0.00116
[2025-04-08 14:43:24,576 INFO misc.py line 113 3298914] Train: [3/100][1451/2402] Data 0.003 (0.005) Batch 0.425 (0.479) Remain 31:07:58 loss: 1.2501 Lr: 0.00116
[2025-04-08 14:43:24,963 INFO misc.py line 113 3298914] Train: [3/100][1452/2402] Data 0.003 (0.005) Batch 0.387 (0.479) Remain 31:07:43 loss: 1.1245 Lr: 0.00116
[2025-04-08 14:43:25,412 INFO misc.py line 113 3298914] Train: [3/100][1453/2402] Data 0.003 (0.005) Batch 0.449 (0.479) Remain 31:07:38 loss: 1.0689 Lr: 0.00116
[2025-04-08 14:43:25,828 INFO misc.py line 113 3298914] Train: [3/100][1454/2402] Data 0.003 (0.005) Batch 0.416 (0.479) Remain 31:07:27 loss: 1.0806 Lr: 0.00116
[2025-04-08 14:43:26,311 INFO misc.py line 113 3298914] Train: [3/100][1455/2402] Data 0.004 (0.005) Batch 0.483 (0.479) Remain 31:07:27 loss: 1.1118 Lr: 0.00116
[2025-04-08 14:43:26,703 INFO misc.py line 113 3298914] Train: [3/100][1456/2402] Data 0.004 (0.005) Batch 0.392 (0.479) Remain 31:07:13 loss: 1.0417 Lr: 0.00116
[2025-04-08 14:43:27,258 INFO misc.py line 113 3298914] Train: [3/100][1457/2402] Data 0.004 (0.005) Batch 0.555 (0.479) Remain 31:07:25 loss: 1.4893 Lr: 0.00116
[2025-04-08 14:43:27,631 INFO misc.py line 113 3298914] Train: [3/100][1458/2402] Data 0.003 (0.005) Batch 0.373 (0.479) Remain 31:07:07 loss: 1.3846 Lr: 0.00116
[2025-04-08 14:43:28,095 INFO misc.py line 113 3298914] Train: [3/100][1459/2402] Data 0.004 (0.005) Batch 0.464 (0.479) Remain 31:07:04 loss: 1.1272 Lr: 0.00116
[2025-04-08 14:43:28,552 INFO misc.py line 113 3298914] Train: [3/100][1460/2402] Data 0.004 (0.005) Batch 0.457 (0.479) Remain 31:07:00 loss: 1.1522 Lr: 0.00116
[2025-04-08 14:43:29,014 INFO misc.py line 113 3298914] Train: [3/100][1461/2402] Data 0.003 (0.005) Batch 0.462 (0.479) Remain 31:06:57 loss: 1.8239 Lr: 0.00116
[2025-04-08 14:43:29,481 INFO misc.py line 113 3298914] Train: [3/100][1462/2402] Data 0.004 (0.005) Batch 0.467 (0.479) Remain 31:06:55 loss: 1.1721 Lr: 0.00116
[2025-04-08 14:43:29,969 INFO misc.py line 113 3298914] Train: [3/100][1463/2402] Data 0.004 (0.005) Batch 0.489 (0.479) Remain 31:06:56 loss: 1.7052 Lr: 0.00116
[2025-04-08 14:43:30,488 INFO misc.py line 113 3298914] Train: [3/100][1464/2402] Data 0.003 (0.005) Batch 0.519 (0.479) Remain 31:07:02 loss: 1.3897 Lr: 0.00116
[2025-04-08 14:43:30,964 INFO misc.py line 113 3298914] Train: [3/100][1465/2402] Data 0.004 (0.005) Batch 0.475 (0.479) Remain 31:07:01 loss: 0.7780 Lr: 0.00116
[2025-04-08 14:43:31,386 INFO misc.py line 113 3298914] Train: [3/100][1466/2402] Data 0.003 (0.005) Batch 0.422 (0.479) Remain 31:06:51 loss: 1.5815 Lr: 0.00116
[2025-04-08 14:43:31,895 INFO misc.py line 113 3298914] Train: [3/100][1467/2402] Data 0.003 (0.005) Batch 0.509 (0.479) Remain 31:06:55 loss: 1.1499 Lr: 0.00116
[2025-04-08 14:43:32,268 INFO misc.py line 113 3298914] Train: [3/100][1468/2402] Data 0.004 (0.005) Batch 0.373 (0.479) Remain 31:06:38 loss: 1.2139 Lr: 0.00116
[2025-04-08 14:43:32,744 INFO misc.py line 113 3298914] Train: [3/100][1469/2402] Data 0.003 (0.005) Batch 0.476 (0.479) Remain 31:06:37 loss: 1.5540 Lr: 0.00116
[2025-04-08 14:43:33,274 INFO misc.py line 113 3298914] Train: [3/100][1470/2402] Data 0.004 (0.005) Batch 0.530 (0.479) Remain 31:06:45 loss: 1.3052 Lr: 0.00116
[2025-04-08 14:43:33,677 INFO misc.py line 113 3298914] Train: [3/100][1471/2402] Data 0.004 (0.005) Batch 0.404 (0.479) Remain 31:06:32 loss: 1.0509 Lr: 0.00116
[2025-04-08 14:43:34,222 INFO misc.py line 113 3298914] Train: [3/100][1472/2402] Data 0.003 (0.005) Batch 0.544 (0.479) Remain 31:06:42 loss: 1.6504 Lr: 0.00116
[2025-04-08 14:43:34,690 INFO misc.py line 113 3298914] Train: [3/100][1473/2402] Data 0.003 (0.005) Batch 0.468 (0.479) Remain 31:06:40 loss: 1.4106 Lr: 0.00116
[2025-04-08 14:43:35,241 INFO misc.py line 113 3298914] Train: [3/100][1474/2402] Data 0.003 (0.005) Batch 0.551 (0.479) Remain 31:06:51 loss: 1.1857 Lr: 0.00116
[2025-04-08 14:43:35,674 INFO misc.py line 113 3298914] Train: [3/100][1475/2402] Data 0.003 (0.005) Batch 0.433 (0.479) Remain 31:06:43 loss: 1.0391 Lr: 0.00116
[2025-04-08 14:43:36,070 INFO misc.py line 113 3298914] Train: [3/100][1476/2402] Data 0.004 (0.005) Batch 0.396 (0.479) Remain 31:06:30 loss: 1.2025 Lr: 0.00116
[2025-04-08 14:43:36,659 INFO misc.py line 113 3298914] Train: [3/100][1477/2402] Data 0.003 (0.005) Batch 0.589 (0.479) Remain 31:06:47 loss: 1.1305 Lr: 0.00116
[2025-04-08 14:43:37,061 INFO misc.py line 113 3298914] Train: [3/100][1478/2402] Data 0.003 (0.005) Batch 0.402 (0.479) Remain 31:06:34 loss: 1.4807 Lr: 0.00116
[2025-04-08 14:43:37,454 INFO misc.py line 113 3298914] Train: [3/100][1479/2402] Data 0.004 (0.005) Batch 0.392 (0.479) Remain 31:06:20 loss: 1.4333 Lr: 0.00116
[2025-04-08 14:43:38,002 INFO misc.py line 113 3298914] Train: [3/100][1480/2402] Data 0.003 (0.005) Batch 0.548 (0.479) Remain 31:06:30 loss: 1.0547 Lr: 0.00116
[2025-04-08 14:43:38,514 INFO misc.py line 113 3298914] Train: [3/100][1481/2402] Data 0.003 (0.005) Batch 0.512 (0.479) Remain 31:06:35 loss: 1.1779 Lr: 0.00117
[2025-04-08 14:43:38,874 INFO misc.py line 113 3298914] Train: [3/100][1482/2402] Data 0.003 (0.005) Batch 0.360 (0.479) Remain 31:06:16 loss: 1.5318 Lr: 0.00117
[2025-04-08 14:43:39,328 INFO misc.py line 113 3298914] Train: [3/100][1483/2402] Data 0.003 (0.005) Batch 0.454 (0.479) Remain 31:06:12 loss: 0.7398 Lr: 0.00117
[2025-04-08 14:43:39,868 INFO misc.py line 113 3298914] Train: [3/100][1484/2402] Data 0.003 (0.005) Batch 0.540 (0.479) Remain 31:06:21 loss: 1.0210 Lr: 0.00117
[2025-04-08 14:43:40,355 INFO misc.py line 113 3298914] Train: [3/100][1485/2402] Data 0.003 (0.005) Batch 0.486 (0.479) Remain 31:06:22 loss: 1.0245 Lr: 0.00117
[2025-04-08 14:43:40,803 INFO misc.py line 113 3298914] Train: [3/100][1486/2402] Data 0.003 (0.005) Batch 0.448 (0.479) Remain 31:06:16 loss: 0.9724 Lr: 0.00117
[2025-04-08 14:43:41,263 INFO misc.py line 113 3298914] Train: [3/100][1487/2402] Data 0.003 (0.005) Batch 0.460 (0.479) Remain 31:06:13 loss: 1.0968 Lr: 0.00117
[2025-04-08 14:43:41,802 INFO misc.py line 113 3298914] Train: [3/100][1488/2402] Data 0.004 (0.005) Batch 0.540 (0.479) Remain 31:06:22 loss: 1.3550 Lr: 0.00117
[2025-04-08 14:43:42,297 INFO misc.py line 113 3298914] Train: [3/100][1489/2402] Data 0.004 (0.005) Batch 0.495 (0.479) Remain 31:06:24 loss: 1.1612 Lr: 0.00117
[2025-04-08 14:43:42,794 INFO misc.py line 113 3298914] Train: [3/100][1490/2402] Data 0.003 (0.005) Batch 0.496 (0.479) Remain 31:06:26 loss: 0.8887 Lr: 0.00117
[2025-04-08 14:43:43,323 INFO misc.py line 113 3298914] Train: [3/100][1491/2402] Data 0.003 (0.005) Batch 0.529 (0.479) Remain 31:06:34 loss: 1.7095 Lr: 0.00117
[2025-04-08 14:43:43,786 INFO misc.py line 113 3298914] Train: [3/100][1492/2402] Data 0.004 (0.005) Batch 0.463 (0.479) Remain 31:06:31 loss: 1.6920 Lr: 0.00117
[2025-04-08 14:43:44,213 INFO misc.py line 113 3298914] Train: [3/100][1493/2402] Data 0.003 (0.005) Batch 0.427 (0.479) Remain 31:06:22 loss: 1.2942 Lr: 0.00117
[2025-04-08 14:43:44,574 INFO misc.py line 113 3298914] Train: [3/100][1494/2402] Data 0.004 (0.005) Batch 0.361 (0.479) Remain 31:06:03 loss: 0.7104 Lr: 0.00117
[2025-04-08 14:43:44,974 INFO misc.py line 113 3298914] Train: [3/100][1495/2402] Data 0.004 (0.005) Batch 0.400 (0.479) Remain 31:05:50 loss: 1.0344 Lr: 0.00117
[2025-04-08 14:43:45,501 INFO misc.py line 113 3298914] Train: [3/100][1496/2402] Data 0.004 (0.005) Batch 0.528 (0.479) Remain 31:05:58 loss: 1.3041 Lr: 0.00117
[2025-04-08 14:43:45,836 INFO misc.py line 113 3298914] Train: [3/100][1497/2402] Data 0.004 (0.005) Batch 0.334 (0.479) Remain 31:05:34 loss: 1.2064 Lr: 0.00117
[2025-04-08 14:43:46,362 INFO misc.py line 113 3298914] Train: [3/100][1498/2402] Data 0.004 (0.005) Batch 0.527 (0.479) Remain 31:05:42 loss: 0.8892 Lr: 0.00117
[2025-04-08 14:43:46,892 INFO misc.py line 113 3298914] Train: [3/100][1499/2402] Data 0.003 (0.005) Batch 0.529 (0.479) Remain 31:05:49 loss: 1.4197 Lr: 0.00117
[2025-04-08 14:43:47,393 INFO misc.py line 113 3298914] Train: [3/100][1500/2402] Data 0.003 (0.005) Batch 0.501 (0.479) Remain 31:05:52 loss: 1.3592 Lr: 0.00117
[2025-04-08 14:43:47,877 INFO misc.py line 113 3298914] Train: [3/100][1501/2402] Data 0.003 (0.005) Batch 0.484 (0.479) Remain 31:05:52 loss: 0.7799 Lr: 0.00117
[2025-04-08 14:43:48,280 INFO misc.py line 113 3298914] Train: [3/100][1502/2402] Data 0.003 (0.005) Batch 0.403 (0.479) Remain 31:05:40 loss: 1.0532 Lr: 0.00117
[2025-04-08 14:43:48,734 INFO misc.py line 113 3298914] Train: [3/100][1503/2402] Data 0.004 (0.005) Batch 0.454 (0.479) Remain 31:05:36 loss: 0.8298 Lr: 0.00117
[2025-04-08 14:43:49,173 INFO misc.py line 113 3298914] Train: [3/100][1504/2402] Data 0.003 (0.005) Batch 0.440 (0.479) Remain 31:05:29 loss: 1.2833 Lr: 0.00117
[2025-04-08 14:43:49,683 INFO misc.py line 113 3298914] Train: [3/100][1505/2402] Data 0.003 (0.005) Batch 0.510 (0.479) Remain 31:05:34 loss: 0.9044 Lr: 0.00117
[2025-04-08 14:43:50,162 INFO misc.py line 113 3298914] Train: [3/100][1506/2402] Data 0.004 (0.005) Batch 0.478 (0.479) Remain 31:05:33 loss: 1.2152 Lr: 0.00117
[2025-04-08 14:43:50,654 INFO misc.py line 113 3298914] Train: [3/100][1507/2402] Data 0.004 (0.005) Batch 0.492 (0.479) Remain 31:05:35 loss: 1.0744 Lr: 0.00117
[2025-04-08 14:43:51,134 INFO misc.py line 113 3298914] Train: [3/100][1508/2402] Data 0.003 (0.005) Batch 0.480 (0.479) Remain 31:05:35 loss: 1.0438 Lr: 0.00117
[2025-04-08 14:43:51,627 INFO misc.py line 113 3298914] Train: [3/100][1509/2402] Data 0.004 (0.005) Batch 0.493 (0.479) Remain 31:05:36 loss: 1.1197 Lr: 0.00117
[2025-04-08 14:43:51,997 INFO misc.py line 113 3298914] Train: [3/100][1510/2402] Data 0.003 (0.005) Batch 0.370 (0.479) Remain 31:05:19 loss: 1.3259 Lr: 0.00117
[2025-04-08 14:43:52,419 INFO misc.py line 113 3298914] Train: [3/100][1511/2402] Data 0.003 (0.005) Batch 0.422 (0.478) Remain 31:05:10 loss: 1.5752 Lr: 0.00117
[2025-04-08 14:43:52,948 INFO misc.py line 113 3298914] Train: [3/100][1512/2402] Data 0.004 (0.005) Batch 0.529 (0.479) Remain 31:05:17 loss: 0.8569 Lr: 0.00117
[2025-04-08 14:43:53,436 INFO misc.py line 113 3298914] Train: [3/100][1513/2402] Data 0.003 (0.005) Batch 0.487 (0.479) Remain 31:05:18 loss: 1.2812 Lr: 0.00117
[2025-04-08 14:43:53,971 INFO misc.py line 113 3298914] Train: [3/100][1514/2402] Data 0.004 (0.005) Batch 0.536 (0.479) Remain 31:05:26 loss: 1.0687 Lr: 0.00117
[2025-04-08 14:43:54,483 INFO misc.py line 113 3298914] Train: [3/100][1515/2402] Data 0.004 (0.005) Batch 0.512 (0.479) Remain 31:05:31 loss: 1.1934 Lr: 0.00117
[2025-04-08 14:43:54,938 INFO misc.py line 113 3298914] Train: [3/100][1516/2402] Data 0.004 (0.005) Batch 0.455 (0.479) Remain 31:05:27 loss: 1.3157 Lr: 0.00117
[2025-04-08 14:43:55,366 INFO misc.py line 113 3298914] Train: [3/100][1517/2402] Data 0.003 (0.005) Batch 0.428 (0.479) Remain 31:05:19 loss: 0.9128 Lr: 0.00117
[2025-04-08 14:43:55,889 INFO misc.py line 113 3298914] Train: [3/100][1518/2402] Data 0.003 (0.005) Batch 0.523 (0.479) Remain 31:05:25 loss: 1.1699 Lr: 0.00117
[2025-04-08 14:43:56,311 INFO misc.py line 113 3298914] Train: [3/100][1519/2402] Data 0.004 (0.005) Batch 0.422 (0.479) Remain 31:05:16 loss: 1.3913 Lr: 0.00117
[2025-04-08 14:43:56,857 INFO misc.py line 113 3298914] Train: [3/100][1520/2402] Data 0.003 (0.005) Batch 0.546 (0.479) Remain 31:05:26 loss: 1.2323 Lr: 0.00117
[2025-04-08 14:43:57,373 INFO misc.py line 113 3298914] Train: [3/100][1521/2402] Data 0.003 (0.005) Batch 0.516 (0.479) Remain 31:05:31 loss: 0.9747 Lr: 0.00117
[2025-04-08 14:43:57,874 INFO misc.py line 113 3298914] Train: [3/100][1522/2402] Data 0.004 (0.005) Batch 0.500 (0.479) Remain 31:05:34 loss: 1.2417 Lr: 0.00117
[2025-04-08 14:43:58,253 INFO misc.py line 113 3298914] Train: [3/100][1523/2402] Data 0.003 (0.005) Batch 0.379 (0.479) Remain 31:05:18 loss: 1.0689 Lr: 0.00117
[2025-04-08 14:43:58,599 INFO misc.py line 113 3298914] Train: [3/100][1524/2402] Data 0.003 (0.005) Batch 0.346 (0.478) Remain 31:04:57 loss: 1.3362 Lr: 0.00118
[2025-04-08 14:43:59,104 INFO misc.py line 113 3298914] Train: [3/100][1525/2402] Data 0.003 (0.005) Batch 0.505 (0.478) Remain 31:05:01 loss: 1.0303 Lr: 0.00118
[2025-04-08 14:43:59,567 INFO misc.py line 113 3298914] Train: [3/100][1526/2402] Data 0.004 (0.005) Batch 0.463 (0.478) Remain 31:04:58 loss: 1.4035 Lr: 0.00118
[2025-04-08 14:44:00,138 INFO misc.py line 113 3298914] Train: [3/100][1527/2402] Data 0.004 (0.005) Batch 0.571 (0.479) Remain 31:05:12 loss: 1.2107 Lr: 0.00118
[2025-04-08 14:44:00,649 INFO misc.py line 113 3298914] Train: [3/100][1528/2402] Data 0.004 (0.005) Batch 0.512 (0.479) Remain 31:05:16 loss: 1.4495 Lr: 0.00118
[2025-04-08 14:44:01,104 INFO misc.py line 113 3298914] Train: [3/100][1529/2402] Data 0.003 (0.005) Batch 0.454 (0.479) Remain 31:05:12 loss: 0.7998 Lr: 0.00118
[2025-04-08 14:44:01,645 INFO misc.py line 113 3298914] Train: [3/100][1530/2402] Data 0.004 (0.005) Batch 0.541 (0.479) Remain 31:05:21 loss: 1.1398 Lr: 0.00118
[2025-04-08 14:44:02,184 INFO misc.py line 113 3298914] Train: [3/100][1531/2402] Data 0.004 (0.005) Batch 0.539 (0.479) Remain 31:05:30 loss: 1.5139 Lr: 0.00118
[2025-04-08 14:44:02,751 INFO misc.py line 113 3298914] Train: [3/100][1532/2402] Data 0.004 (0.005) Batch 0.567 (0.479) Remain 31:05:43 loss: 1.3644 Lr: 0.00118
[2025-04-08 14:44:03,156 INFO misc.py line 113 3298914] Train: [3/100][1533/2402] Data 0.003 (0.005) Batch 0.405 (0.479) Remain 31:05:31 loss: 1.0472 Lr: 0.00118
[2025-04-08 14:44:03,582 INFO misc.py line 113 3298914] Train: [3/100][1534/2402] Data 0.003 (0.005) Batch 0.425 (0.479) Remain 31:05:23 loss: 1.0937 Lr: 0.00118
[2025-04-08 14:44:04,035 INFO misc.py line 113 3298914] Train: [3/100][1535/2402] Data 0.004 (0.005) Batch 0.454 (0.479) Remain 31:05:18 loss: 1.0862 Lr: 0.00118
[2025-04-08 14:44:04,413 INFO misc.py line 113 3298914] Train: [3/100][1536/2402] Data 0.003 (0.005) Batch 0.378 (0.479) Remain 31:05:03 loss: 1.4184 Lr: 0.00118
[2025-04-08 14:44:04,929 INFO misc.py line 113 3298914] Train: [3/100][1537/2402] Data 0.003 (0.005) Batch 0.516 (0.479) Remain 31:05:08 loss: 1.4420 Lr: 0.00118
[2025-04-08 14:44:05,381 INFO misc.py line 113 3298914] Train: [3/100][1538/2402] Data 0.003 (0.005) Batch 0.453 (0.479) Remain 31:05:03 loss: 1.1895 Lr: 0.00118
[2025-04-08 14:44:05,855 INFO misc.py line 113 3298914] Train: [3/100][1539/2402] Data 0.003 (0.005) Batch 0.474 (0.479) Remain 31:05:02 loss: 1.1409 Lr: 0.00118
[2025-04-08 14:44:06,390 INFO misc.py line 113 3298914] Train: [3/100][1540/2402] Data 0.003 (0.005) Batch 0.534 (0.479) Remain 31:05:10 loss: 1.1640 Lr: 0.00118
[2025-04-08 14:44:06,977 INFO misc.py line 113 3298914] Train: [3/100][1541/2402] Data 0.004 (0.005) Batch 0.587 (0.479) Remain 31:05:26 loss: 0.9610 Lr: 0.00118
[2025-04-08 14:44:07,461 INFO misc.py line 113 3298914] Train: [3/100][1542/2402] Data 0.003 (0.005) Batch 0.483 (0.479) Remain 31:05:27 loss: 1.0611 Lr: 0.00118
[2025-04-08 14:44:07,841 INFO misc.py line 113 3298914] Train: [3/100][1543/2402] Data 0.004 (0.005) Batch 0.381 (0.479) Remain 31:05:11 loss: 0.9172 Lr: 0.00118
[2025-04-08 14:44:08,239 INFO misc.py line 113 3298914] Train: [3/100][1544/2402] Data 0.003 (0.005) Batch 0.397 (0.479) Remain 31:04:58 loss: 1.1102 Lr: 0.00118
[2025-04-08 14:44:08,681 INFO misc.py line 113 3298914] Train: [3/100][1545/2402] Data 0.003 (0.005) Batch 0.443 (0.478) Remain 31:04:53 loss: 1.5281 Lr: 0.00118
[2025-04-08 14:44:09,096 INFO misc.py line 113 3298914] Train: [3/100][1546/2402] Data 0.003 (0.005) Batch 0.414 (0.478) Remain 31:04:42 loss: 1.3602 Lr: 0.00118
[2025-04-08 14:44:09,599 INFO misc.py line 113 3298914] Train: [3/100][1547/2402] Data 0.004 (0.005) Batch 0.504 (0.478) Remain 31:04:46 loss: 1.0708 Lr: 0.00118
[2025-04-08 14:44:10,168 INFO misc.py line 113 3298914] Train: [3/100][1548/2402] Data 0.003 (0.005) Batch 0.569 (0.479) Remain 31:04:59 loss: 1.0737 Lr: 0.00118
[2025-04-08 14:44:10,747 INFO misc.py line 113 3298914] Train: [3/100][1549/2402] Data 0.004 (0.005) Batch 0.579 (0.479) Remain 31:05:13 loss: 1.2782 Lr: 0.00118
[2025-04-08 14:44:11,192 INFO misc.py line 113 3298914] Train: [3/100][1550/2402] Data 0.004 (0.005) Batch 0.446 (0.479) Remain 31:05:08 loss: 1.3717 Lr: 0.00118
[2025-04-08 14:44:11,667 INFO misc.py line 113 3298914] Train: [3/100][1551/2402] Data 0.003 (0.005) Batch 0.475 (0.479) Remain 31:05:07 loss: 1.5721 Lr: 0.00118
[2025-04-08 14:44:12,208 INFO misc.py line 113 3298914] Train: [3/100][1552/2402] Data 0.004 (0.005) Batch 0.541 (0.479) Remain 31:05:16 loss: 1.2703 Lr: 0.00118
[2025-04-08 14:44:12,807 INFO misc.py line 113 3298914] Train: [3/100][1553/2402] Data 0.003 (0.005) Batch 0.599 (0.479) Remain 31:05:34 loss: 0.9085 Lr: 0.00118
[2025-04-08 14:44:13,201 INFO misc.py line 113 3298914] Train: [3/100][1554/2402] Data 0.004 (0.005) Batch 0.394 (0.479) Remain 31:05:20 loss: 0.9566 Lr: 0.00118
[2025-04-08 14:44:13,692 INFO misc.py line 113 3298914] Train: [3/100][1555/2402] Data 0.003 (0.005) Batch 0.492 (0.479) Remain 31:05:22 loss: 1.0010 Lr: 0.00118
[2025-04-08 14:44:13,982 INFO misc.py line 113 3298914] Train: [3/100][1556/2402] Data 0.003 (0.005) Batch 0.290 (0.479) Remain 31:04:53 loss: 1.1061 Lr: 0.00118
[2025-04-08 14:44:14,562 INFO misc.py line 113 3298914] Train: [3/100][1557/2402] Data 0.004 (0.005) Batch 0.581 (0.479) Remain 31:05:08 loss: 1.2663 Lr: 0.00118
[2025-04-08 14:44:15,057 INFO misc.py line 113 3298914] Train: [3/100][1558/2402] Data 0.003 (0.005) Batch 0.495 (0.479) Remain 31:05:10 loss: 1.2342 Lr: 0.00118
[2025-04-08 14:44:15,499 INFO misc.py line 113 3298914] Train: [3/100][1559/2402] Data 0.004 (0.005) Batch 0.442 (0.479) Remain 31:05:04 loss: 0.8617 Lr: 0.00118
[2025-04-08 14:44:16,006 INFO misc.py line 113 3298914] Train: [3/100][1560/2402] Data 0.003 (0.005) Batch 0.507 (0.479) Remain 31:05:07 loss: 1.2287 Lr: 0.00118
[2025-04-08 14:44:16,502 INFO misc.py line 113 3298914] Train: [3/100][1561/2402] Data 0.004 (0.005) Batch 0.497 (0.479) Remain 31:05:10 loss: 1.0251 Lr: 0.00118
[2025-04-08 14:44:16,966 INFO misc.py line 113 3298914] Train: [3/100][1562/2402] Data 0.003 (0.005) Batch 0.463 (0.479) Remain 31:05:07 loss: 1.4469 Lr: 0.00118
[2025-04-08 14:44:17,509 INFO misc.py line 113 3298914] Train: [3/100][1563/2402] Data 0.004 (0.005) Batch 0.543 (0.479) Remain 31:05:16 loss: 1.4939 Lr: 0.00118
[2025-04-08 14:44:18,037 INFO misc.py line 113 3298914] Train: [3/100][1564/2402] Data 0.004 (0.005) Batch 0.528 (0.479) Remain 31:05:23 loss: 0.8415 Lr: 0.00118
[2025-04-08 14:44:18,510 INFO misc.py line 113 3298914] Train: [3/100][1565/2402] Data 0.004 (0.005) Batch 0.473 (0.479) Remain 31:05:22 loss: 0.9968 Lr: 0.00118
[2025-04-08 14:44:19,060 INFO misc.py line 113 3298914] Train: [3/100][1566/2402] Data 0.004 (0.005) Batch 0.550 (0.479) Remain 31:05:32 loss: 0.8970 Lr: 0.00118
[2025-04-08 14:44:19,542 INFO misc.py line 113 3298914] Train: [3/100][1567/2402] Data 0.003 (0.005) Batch 0.482 (0.479) Remain 31:05:32 loss: 0.8655 Lr: 0.00119
[2025-04-08 14:44:19,985 INFO misc.py line 113 3298914] Train: [3/100][1568/2402] Data 0.004 (0.005) Batch 0.443 (0.479) Remain 31:05:26 loss: 0.9635 Lr: 0.00119
[2025-04-08 14:44:20,502 INFO misc.py line 113 3298914] Train: [3/100][1569/2402] Data 0.003 (0.005) Batch 0.516 (0.479) Remain 31:05:31 loss: 1.5358 Lr: 0.00119
[2025-04-08 14:44:21,016 INFO misc.py line 113 3298914] Train: [3/100][1570/2402] Data 0.003 (0.005) Batch 0.514 (0.479) Remain 31:05:36 loss: 1.4916 Lr: 0.00119
[2025-04-08 14:44:21,463 INFO misc.py line 113 3298914] Train: [3/100][1571/2402] Data 0.004 (0.005) Batch 0.447 (0.479) Remain 31:05:31 loss: 1.2476 Lr: 0.00119
[2025-04-08 14:44:21,936 INFO misc.py line 113 3298914] Train: [3/100][1572/2402] Data 0.003 (0.005) Batch 0.473 (0.479) Remain 31:05:30 loss: 1.1707 Lr: 0.00119
[2025-04-08 14:44:22,506 INFO misc.py line 113 3298914] Train: [3/100][1573/2402] Data 0.004 (0.005) Batch 0.570 (0.479) Remain 31:05:43 loss: 1.6046 Lr: 0.00119
[2025-04-08 14:44:23,000 INFO misc.py line 113 3298914] Train: [3/100][1574/2402] Data 0.003 (0.005) Batch 0.495 (0.479) Remain 31:05:45 loss: 1.3026 Lr: 0.00119
[2025-04-08 14:44:23,481 INFO misc.py line 113 3298914] Train: [3/100][1575/2402] Data 0.003 (0.005) Batch 0.480 (0.479) Remain 31:05:44 loss: 0.9556 Lr: 0.00119
[2025-04-08 14:44:24,032 INFO misc.py line 113 3298914] Train: [3/100][1576/2402] Data 0.004 (0.005) Batch 0.551 (0.479) Remain 31:05:55 loss: 1.1670 Lr: 0.00119
[2025-04-08 14:44:24,508 INFO misc.py line 113 3298914] Train: [3/100][1577/2402] Data 0.003 (0.005) Batch 0.477 (0.479) Remain 31:05:54 loss: 1.0843 Lr: 0.00119
[2025-04-08 14:44:25,007 INFO misc.py line 113 3298914] Train: [3/100][1578/2402] Data 0.003 (0.005) Batch 0.498 (0.479) Remain 31:05:56 loss: 1.4575 Lr: 0.00119
[2025-04-08 14:44:25,520 INFO misc.py line 113 3298914] Train: [3/100][1579/2402] Data 0.003 (0.005) Batch 0.514 (0.479) Remain 31:06:01 loss: 1.1123 Lr: 0.00119
[2025-04-08 14:44:25,876 INFO misc.py line 113 3298914] Train: [3/100][1580/2402] Data 0.004 (0.005) Batch 0.355 (0.479) Remain 31:05:42 loss: 1.2426 Lr: 0.00119
[2025-04-08 14:44:26,246 INFO misc.py line 113 3298914] Train: [3/100][1581/2402] Data 0.004 (0.005) Batch 0.371 (0.479) Remain 31:05:26 loss: 1.1264 Lr: 0.00119
[2025-04-08 14:44:26,766 INFO misc.py line 113 3298914] Train: [3/100][1582/2402] Data 0.004 (0.005) Batch 0.520 (0.479) Remain 31:05:31 loss: 1.0066 Lr: 0.00119
[2025-04-08 14:44:27,138 INFO misc.py line 113 3298914] Train: [3/100][1583/2402] Data 0.004 (0.005) Batch 0.372 (0.479) Remain 31:05:15 loss: 1.2988 Lr: 0.00119
[2025-04-08 14:44:27,711 INFO misc.py line 113 3298914] Train: [3/100][1584/2402] Data 0.003 (0.005) Batch 0.573 (0.479) Remain 31:05:28 loss: 1.5459 Lr: 0.00119
[2025-04-08 14:44:28,187 INFO misc.py line 113 3298914] Train: [3/100][1585/2402] Data 0.003 (0.005) Batch 0.476 (0.479) Remain 31:05:27 loss: 1.1928 Lr: 0.00119
[2025-04-08 14:44:28,773 INFO misc.py line 113 3298914] Train: [3/100][1586/2402] Data 0.004 (0.005) Batch 0.586 (0.479) Remain 31:05:43 loss: 1.4218 Lr: 0.00119
[2025-04-08 14:44:29,223 INFO misc.py line 113 3298914] Train: [3/100][1587/2402] Data 0.003 (0.005) Batch 0.450 (0.479) Remain 31:05:38 loss: 1.1608 Lr: 0.00119
[2025-04-08 14:44:29,743 INFO misc.py line 113 3298914] Train: [3/100][1588/2402] Data 0.003 (0.005) Batch 0.520 (0.479) Remain 31:05:44 loss: 1.5985 Lr: 0.00119
[2025-04-08 14:44:30,236 INFO misc.py line 113 3298914] Train: [3/100][1589/2402] Data 0.003 (0.005) Batch 0.493 (0.479) Remain 31:05:45 loss: 0.8270 Lr: 0.00119
[2025-04-08 14:44:30,768 INFO misc.py line 113 3298914] Train: [3/100][1590/2402] Data 0.003 (0.005) Batch 0.532 (0.479) Remain 31:05:53 loss: 0.9271 Lr: 0.00119
[2025-04-08 14:44:31,214 INFO misc.py line 113 3298914] Train: [3/100][1591/2402] Data 0.003 (0.005) Batch 0.446 (0.479) Remain 31:05:47 loss: 0.9484 Lr: 0.00119
[2025-04-08 14:44:31,620 INFO misc.py line 113 3298914] Train: [3/100][1592/2402] Data 0.003 (0.005) Batch 0.406 (0.479) Remain 31:05:36 loss: 1.0489 Lr: 0.00119
[2025-04-08 14:44:32,181 INFO misc.py line 113 3298914] Train: [3/100][1593/2402] Data 0.003 (0.005) Batch 0.560 (0.479) Remain 31:05:48 loss: 1.1088 Lr: 0.00119
[2025-04-08 14:44:32,633 INFO misc.py line 113 3298914] Train: [3/100][1594/2402] Data 0.004 (0.005) Batch 0.452 (0.479) Remain 31:05:43 loss: 1.5762 Lr: 0.00119
[2025-04-08 14:44:33,145 INFO misc.py line 113 3298914] Train: [3/100][1595/2402] Data 0.003 (0.005) Batch 0.512 (0.479) Remain 31:05:48 loss: 1.2990 Lr: 0.00119
[2025-04-08 14:44:33,612 INFO misc.py line 113 3298914] Train: [3/100][1596/2402] Data 0.003 (0.005) Batch 0.468 (0.479) Remain 31:05:46 loss: 1.0412 Lr: 0.00119
[2025-04-08 14:44:33,997 INFO misc.py line 113 3298914] Train: [3/100][1597/2402] Data 0.004 (0.005) Batch 0.384 (0.479) Remain 31:05:31 loss: 0.8779 Lr: 0.00119
[2025-04-08 14:44:34,315 INFO misc.py line 113 3298914] Train: [3/100][1598/2402] Data 0.003 (0.005) Batch 0.318 (0.479) Remain 31:05:07 loss: 1.0982 Lr: 0.00119
[2025-04-08 14:44:34,682 INFO misc.py line 113 3298914] Train: [3/100][1599/2402] Data 0.004 (0.005) Batch 0.367 (0.479) Remain 31:04:51 loss: 1.4541 Lr: 0.00119
[2025-04-08 14:44:35,261 INFO misc.py line 113 3298914] Train: [3/100][1600/2402] Data 0.004 (0.005) Batch 0.578 (0.479) Remain 31:05:05 loss: 1.3515 Lr: 0.00119
[2025-04-08 14:44:35,782 INFO misc.py line 113 3298914] Train: [3/100][1601/2402] Data 0.003 (0.005) Batch 0.521 (0.479) Remain 31:05:10 loss: 1.5343 Lr: 0.00119
[2025-04-08 14:44:36,307 INFO misc.py line 113 3298914] Train: [3/100][1602/2402] Data 0.003 (0.005) Batch 0.526 (0.479) Remain 31:05:17 loss: 1.0989 Lr: 0.00119
[2025-04-08 14:44:36,727 INFO misc.py line 113 3298914] Train: [3/100][1603/2402] Data 0.003 (0.005) Batch 0.420 (0.479) Remain 31:05:08 loss: 1.6200 Lr: 0.00119
[2025-04-08 14:44:37,261 INFO misc.py line 113 3298914] Train: [3/100][1604/2402] Data 0.004 (0.005) Batch 0.534 (0.479) Remain 31:05:15 loss: 0.8614 Lr: 0.00119
[2025-04-08 14:44:37,624 INFO misc.py line 113 3298914] Train: [3/100][1605/2402] Data 0.004 (0.005) Batch 0.363 (0.479) Remain 31:04:58 loss: 0.9009 Lr: 0.00119
[2025-04-08 14:44:38,095 INFO misc.py line 113 3298914] Train: [3/100][1606/2402] Data 0.004 (0.005) Batch 0.471 (0.479) Remain 31:04:56 loss: 1.3247 Lr: 0.00119
[2025-04-08 14:44:38,630 INFO misc.py line 113 3298914] Train: [3/100][1607/2402] Data 0.003 (0.005) Batch 0.535 (0.479) Remain 31:05:04 loss: 1.2123 Lr: 0.00119
[2025-04-08 14:44:39,140 INFO misc.py line 113 3298914] Train: [3/100][1608/2402] Data 0.004 (0.005) Batch 0.510 (0.479) Remain 31:05:08 loss: 0.8427 Lr: 0.00119
[2025-04-08 14:44:39,532 INFO misc.py line 113 3298914] Train: [3/100][1609/2402] Data 0.004 (0.005) Batch 0.392 (0.479) Remain 31:04:55 loss: 1.1433 Lr: 0.00120
[2025-04-08 14:44:39,997 INFO misc.py line 113 3298914] Train: [3/100][1610/2402] Data 0.003 (0.005) Batch 0.465 (0.479) Remain 31:04:53 loss: 1.3341 Lr: 0.00120
[2025-04-08 14:44:40,465 INFO misc.py line 113 3298914] Train: [3/100][1611/2402] Data 0.003 (0.005) Batch 0.468 (0.479) Remain 31:04:51 loss: 1.1210 Lr: 0.00120
[2025-04-08 14:44:40,991 INFO misc.py line 113 3298914] Train: [3/100][1612/2402] Data 0.004 (0.005) Batch 0.526 (0.479) Remain 31:04:57 loss: 1.0945 Lr: 0.00120
[2025-04-08 14:44:41,446 INFO misc.py line 113 3298914] Train: [3/100][1613/2402] Data 0.003 (0.005) Batch 0.454 (0.479) Remain 31:04:53 loss: 0.9651 Lr: 0.00120
[2025-04-08 14:44:41,902 INFO misc.py line 113 3298914] Train: [3/100][1614/2402] Data 0.003 (0.005) Batch 0.456 (0.479) Remain 31:04:49 loss: 0.8350 Lr: 0.00120
[2025-04-08 14:44:42,361 INFO misc.py line 113 3298914] Train: [3/100][1615/2402] Data 0.003 (0.005) Batch 0.458 (0.479) Remain 31:04:46 loss: 0.7768 Lr: 0.00120
[2025-04-08 14:44:42,812 INFO misc.py line 113 3298914] Train: [3/100][1616/2402] Data 0.004 (0.005) Batch 0.451 (0.479) Remain 31:04:41 loss: 1.2706 Lr: 0.00120
[2025-04-08 14:44:43,318 INFO misc.py line 113 3298914] Train: [3/100][1617/2402] Data 0.003 (0.005) Batch 0.506 (0.479) Remain 31:04:45 loss: 1.1091 Lr: 0.00120
[2025-04-08 14:44:43,874 INFO misc.py line 113 3298914] Train: [3/100][1618/2402] Data 0.003 (0.005) Batch 0.556 (0.479) Remain 31:04:56 loss: 1.0268 Lr: 0.00120
[2025-04-08 14:44:44,415 INFO misc.py line 113 3298914] Train: [3/100][1619/2402] Data 0.004 (0.005) Batch 0.541 (0.479) Remain 31:05:04 loss: 1.5490 Lr: 0.00120
[2025-04-08 14:44:44,930 INFO misc.py line 113 3298914] Train: [3/100][1620/2402] Data 0.003 (0.005) Batch 0.515 (0.479) Remain 31:05:09 loss: 0.9202 Lr: 0.00120
[2025-04-08 14:44:45,414 INFO misc.py line 113 3298914] Train: [3/100][1621/2402] Data 0.004 (0.005) Batch 0.483 (0.479) Remain 31:05:09 loss: 1.3885 Lr: 0.00120
[2025-04-08 14:44:45,956 INFO misc.py line 113 3298914] Train: [3/100][1622/2402] Data 0.003 (0.005) Batch 0.542 (0.479) Remain 31:05:18 loss: 1.4063 Lr: 0.00120
[2025-04-08 14:44:46,452 INFO misc.py line 113 3298914] Train: [3/100][1623/2402] Data 0.004 (0.005) Batch 0.496 (0.479) Remain 31:05:20 loss: 1.2557 Lr: 0.00120
[2025-04-08 14:44:46,923 INFO misc.py line 113 3298914] Train: [3/100][1624/2402] Data 0.003 (0.005) Batch 0.471 (0.479) Remain 31:05:18 loss: 0.7997 Lr: 0.00120
[2025-04-08 14:44:47,505 INFO misc.py line 113 3298914] Train: [3/100][1625/2402] Data 0.004 (0.005) Batch 0.582 (0.479) Remain 31:05:33 loss: 1.1700 Lr: 0.00120
[2025-04-08 14:44:47,969 INFO misc.py line 113 3298914] Train: [3/100][1626/2402] Data 0.004 (0.005) Batch 0.464 (0.479) Remain 31:05:30 loss: 1.1956 Lr: 0.00120
[2025-04-08 14:44:48,403 INFO misc.py line 113 3298914] Train: [3/100][1627/2402] Data 0.003 (0.005) Batch 0.433 (0.479) Remain 31:05:23 loss: 0.9295 Lr: 0.00120
[2025-04-08 14:44:48,857 INFO misc.py line 113 3298914] Train: [3/100][1628/2402] Data 0.003 (0.005) Batch 0.454 (0.479) Remain 31:05:19 loss: 0.9804 Lr: 0.00120
[2025-04-08 14:44:49,252 INFO misc.py line 113 3298914] Train: [3/100][1629/2402] Data 0.004 (0.005) Batch 0.395 (0.479) Remain 31:05:07 loss: 1.3961 Lr: 0.00120
[2025-04-08 14:44:49,805 INFO misc.py line 113 3298914] Train: [3/100][1630/2402] Data 0.003 (0.005) Batch 0.552 (0.479) Remain 31:05:17 loss: 1.4475 Lr: 0.00120
[2025-04-08 14:44:50,311 INFO misc.py line 113 3298914] Train: [3/100][1631/2402] Data 0.004 (0.005) Batch 0.507 (0.479) Remain 31:05:20 loss: 1.4198 Lr: 0.00120
[2025-04-08 14:44:50,818 INFO misc.py line 113 3298914] Train: [3/100][1632/2402] Data 0.004 (0.005) Batch 0.507 (0.479) Remain 31:05:24 loss: 1.6037 Lr: 0.00120
[2025-04-08 14:44:51,213 INFO misc.py line 113 3298914] Train: [3/100][1633/2402] Data 0.004 (0.005) Batch 0.395 (0.479) Remain 31:05:11 loss: 0.9324 Lr: 0.00120
[2025-04-08 14:44:51,665 INFO misc.py line 113 3298914] Train: [3/100][1634/2402] Data 0.003 (0.005) Batch 0.452 (0.479) Remain 31:05:07 loss: 1.6083 Lr: 0.00120
[2025-04-08 14:44:52,054 INFO misc.py line 113 3298914] Train: [3/100][1635/2402] Data 0.004 (0.005) Batch 0.390 (0.479) Remain 31:04:54 loss: 1.3000 Lr: 0.00120
[2025-04-08 14:44:52,570 INFO misc.py line 113 3298914] Train: [3/100][1636/2402] Data 0.004 (0.005) Batch 0.516 (0.479) Remain 31:04:59 loss: 1.4444 Lr: 0.00120
[2025-04-08 14:44:53,159 INFO misc.py line 113 3298914] Train: [3/100][1637/2402] Data 0.004 (0.005) Batch 0.589 (0.479) Remain 31:05:14 loss: 1.1668 Lr: 0.00120
[2025-04-08 14:44:53,698 INFO misc.py line 113 3298914] Train: [3/100][1638/2402] Data 0.003 (0.005) Batch 0.539 (0.479) Remain 31:05:22 loss: 1.1379 Lr: 0.00120
[2025-04-08 14:44:54,192 INFO misc.py line 113 3298914] Train: [3/100][1639/2402] Data 0.004 (0.005) Batch 0.493 (0.479) Remain 31:05:24 loss: 0.9955 Lr: 0.00120
[2025-04-08 14:44:54,636 INFO misc.py line 113 3298914] Train: [3/100][1640/2402] Data 0.004 (0.005) Batch 0.445 (0.479) Remain 31:05:18 loss: 1.6750 Lr: 0.00120
[2025-04-08 14:44:55,147 INFO misc.py line 113 3298914] Train: [3/100][1641/2402] Data 0.004 (0.005) Batch 0.510 (0.479) Remain 31:05:22 loss: 1.2651 Lr: 0.00120
[2025-04-08 14:44:55,516 INFO misc.py line 113 3298914] Train: [3/100][1642/2402] Data 0.004 (0.005) Batch 0.369 (0.479) Remain 31:05:06 loss: 1.1248 Lr: 0.00120
[2025-04-08 14:44:56,067 INFO misc.py line 113 3298914] Train: [3/100][1643/2402] Data 0.004 (0.005) Batch 0.551 (0.479) Remain 31:05:16 loss: 1.4513 Lr: 0.00120
[2025-04-08 14:44:56,613 INFO misc.py line 113 3298914] Train: [3/100][1644/2402] Data 0.004 (0.005) Batch 0.546 (0.479) Remain 31:05:25 loss: 1.2883 Lr: 0.00120
[2025-04-08 14:44:57,084 INFO misc.py line 113 3298914] Train: [3/100][1645/2402] Data 0.003 (0.005) Batch 0.471 (0.479) Remain 31:05:24 loss: 1.2105 Lr: 0.00120
[2025-04-08 14:44:57,601 INFO misc.py line 113 3298914] Train: [3/100][1646/2402] Data 0.003 (0.005) Batch 0.517 (0.479) Remain 31:05:28 loss: 1.1167 Lr: 0.00120
[2025-04-08 14:44:58,078 INFO misc.py line 113 3298914] Train: [3/100][1647/2402] Data 0.003 (0.005) Batch 0.478 (0.479) Remain 31:05:28 loss: 0.9749 Lr: 0.00120
[2025-04-08 14:44:58,601 INFO misc.py line 113 3298914] Train: [3/100][1648/2402] Data 0.003 (0.005) Batch 0.523 (0.479) Remain 31:05:34 loss: 1.2201 Lr: 0.00120
[2025-04-08 14:44:59,126 INFO misc.py line 113 3298914] Train: [3/100][1649/2402] Data 0.004 (0.005) Batch 0.525 (0.479) Remain 31:05:40 loss: 1.1776 Lr: 0.00120
[2025-04-08 14:44:59,676 INFO misc.py line 113 3298914] Train: [3/100][1650/2402] Data 0.003 (0.005) Batch 0.549 (0.479) Remain 31:05:49 loss: 1.5095 Lr: 0.00120
[2025-04-08 14:45:00,315 INFO misc.py line 113 3298914] Train: [3/100][1651/2402] Data 0.004 (0.005) Batch 0.639 (0.479) Remain 31:06:11 loss: 1.2737 Lr: 0.00120
[2025-04-08 14:45:00,824 INFO misc.py line 113 3298914] Train: [3/100][1652/2402] Data 0.004 (0.005) Batch 0.509 (0.479) Remain 31:06:15 loss: 1.5263 Lr: 0.00121
[2025-04-08 14:45:01,388 INFO misc.py line 113 3298914] Train: [3/100][1653/2402] Data 0.004 (0.005) Batch 0.564 (0.479) Remain 31:06:27 loss: 1.7736 Lr: 0.00121
[2025-04-08 14:45:01,949 INFO misc.py line 113 3298914] Train: [3/100][1654/2402] Data 0.003 (0.005) Batch 0.561 (0.479) Remain 31:06:38 loss: 1.1441 Lr: 0.00121
[2025-04-08 14:45:02,403 INFO misc.py line 113 3298914] Train: [3/100][1655/2402] Data 0.003 (0.005) Batch 0.454 (0.479) Remain 31:06:34 loss: 1.2825 Lr: 0.00121
[2025-04-08 14:45:02,872 INFO misc.py line 113 3298914] Train: [3/100][1656/2402] Data 0.003 (0.005) Batch 0.469 (0.479) Remain 31:06:32 loss: 1.4544 Lr: 0.00121
[2025-04-08 14:45:03,402 INFO misc.py line 113 3298914] Train: [3/100][1657/2402] Data 0.004 (0.005) Batch 0.530 (0.479) Remain 31:06:39 loss: 0.9284 Lr: 0.00121
[2025-04-08 14:45:03,898 INFO misc.py line 113 3298914] Train: [3/100][1658/2402] Data 0.003 (0.005) Batch 0.496 (0.479) Remain 31:06:41 loss: 0.9586 Lr: 0.00121
[2025-04-08 14:45:04,354 INFO misc.py line 113 3298914] Train: [3/100][1659/2402] Data 0.015 (0.005) Batch 0.456 (0.479) Remain 31:06:37 loss: 0.9898 Lr: 0.00121
[2025-04-08 14:45:04,823 INFO misc.py line 113 3298914] Train: [3/100][1660/2402] Data 0.003 (0.005) Batch 0.469 (0.479) Remain 31:06:35 loss: 1.0349 Lr: 0.00121
[2025-04-08 14:45:05,365 INFO misc.py line 113 3298914] Train: [3/100][1661/2402] Data 0.003 (0.005) Batch 0.542 (0.479) Remain 31:06:43 loss: 1.0939 Lr: 0.00121
[2025-04-08 14:45:05,999 INFO misc.py line 113 3298914] Train: [3/100][1662/2402] Data 0.003 (0.005) Batch 0.634 (0.479) Remain 31:07:05 loss: 1.0927 Lr: 0.00121
[2025-04-08 14:45:06,479 INFO misc.py line 113 3298914] Train: [3/100][1663/2402] Data 0.003 (0.005) Batch 0.480 (0.479) Remain 31:07:04 loss: 1.3436 Lr: 0.00121
[2025-04-08 14:45:07,060 INFO misc.py line 113 3298914] Train: [3/100][1664/2402] Data 0.004 (0.005) Batch 0.581 (0.479) Remain 31:07:18 loss: 1.4830 Lr: 0.00121
[2025-04-08 14:45:07,530 INFO misc.py line 113 3298914] Train: [3/100][1665/2402] Data 0.003 (0.005) Batch 0.470 (0.479) Remain 31:07:16 loss: 1.2027 Lr: 0.00121
[2025-04-08 14:45:07,937 INFO misc.py line 113 3298914] Train: [3/100][1666/2402] Data 0.004 (0.005) Batch 0.406 (0.479) Remain 31:07:06 loss: 0.7652 Lr: 0.00121
[2025-04-08 14:45:08,407 INFO misc.py line 113 3298914] Train: [3/100][1667/2402] Data 0.004 (0.005) Batch 0.470 (0.479) Remain 31:07:04 loss: 1.1158 Lr: 0.00121
[2025-04-08 14:45:08,892 INFO misc.py line 113 3298914] Train: [3/100][1668/2402] Data 0.003 (0.005) Batch 0.486 (0.479) Remain 31:07:04 loss: 1.1889 Lr: 0.00121
[2025-04-08 14:45:09,393 INFO misc.py line 113 3298914] Train: [3/100][1669/2402] Data 0.003 (0.005) Batch 0.501 (0.479) Remain 31:07:07 loss: 0.8102 Lr: 0.00121
[2025-04-08 14:45:09,888 INFO misc.py line 113 3298914] Train: [3/100][1670/2402] Data 0.003 (0.005) Batch 0.495 (0.479) Remain 31:07:08 loss: 1.1552 Lr: 0.00121
[2025-04-08 14:45:10,429 INFO misc.py line 113 3298914] Train: [3/100][1671/2402] Data 0.003 (0.005) Batch 0.541 (0.479) Remain 31:07:17 loss: 1.2318 Lr: 0.00121
[2025-04-08 14:45:11,001 INFO misc.py line 113 3298914] Train: [3/100][1672/2402] Data 0.003 (0.005) Batch 0.572 (0.479) Remain 31:07:29 loss: 1.0280 Lr: 0.00121
[2025-04-08 14:45:11,519 INFO misc.py line 113 3298914] Train: [3/100][1673/2402] Data 0.003 (0.005) Batch 0.518 (0.479) Remain 31:07:34 loss: 1.2009 Lr: 0.00121
[2025-04-08 14:45:12,044 INFO misc.py line 113 3298914] Train: [3/100][1674/2402] Data 0.004 (0.005) Batch 0.525 (0.479) Remain 31:07:40 loss: 1.0333 Lr: 0.00121
[2025-04-08 14:45:12,548 INFO misc.py line 113 3298914] Train: [3/100][1675/2402] Data 0.004 (0.005) Batch 0.504 (0.479) Remain 31:07:43 loss: 1.0500 Lr: 0.00121
[2025-04-08 14:45:12,964 INFO misc.py line 113 3298914] Train: [3/100][1676/2402] Data 0.004 (0.005) Batch 0.416 (0.479) Remain 31:07:34 loss: 0.6900 Lr: 0.00121
[2025-04-08 14:45:13,452 INFO misc.py line 113 3298914] Train: [3/100][1677/2402] Data 0.004 (0.005) Batch 0.488 (0.479) Remain 31:07:34 loss: 0.8433 Lr: 0.00121
[2025-04-08 14:45:13,943 INFO misc.py line 113 3298914] Train: [3/100][1678/2402] Data 0.003 (0.005) Batch 0.491 (0.479) Remain 31:07:35 loss: 0.9346 Lr: 0.00121
[2025-04-08 14:45:14,327 INFO misc.py line 113 3298914] Train: [3/100][1679/2402] Data 0.003 (0.005) Batch 0.384 (0.479) Remain 31:07:22 loss: 1.1107 Lr: 0.00121
[2025-04-08 14:45:14,850 INFO misc.py line 113 3298914] Train: [3/100][1680/2402] Data 0.004 (0.005) Batch 0.523 (0.479) Remain 31:07:27 loss: 0.9455 Lr: 0.00121
[2025-04-08 14:45:15,198 INFO misc.py line 113 3298914] Train: [3/100][1681/2402] Data 0.003 (0.005) Batch 0.348 (0.479) Remain 31:07:08 loss: 1.3387 Lr: 0.00121
[2025-04-08 14:45:15,723 INFO misc.py line 113 3298914] Train: [3/100][1682/2402] Data 0.003 (0.005) Batch 0.525 (0.479) Remain 31:07:14 loss: 1.7003 Lr: 0.00121
[2025-04-08 14:45:16,190 INFO misc.py line 113 3298914] Train: [3/100][1683/2402] Data 0.004 (0.005) Batch 0.468 (0.479) Remain 31:07:12 loss: 0.9312 Lr: 0.00121
[2025-04-08 14:45:16,653 INFO misc.py line 113 3298914] Train: [3/100][1684/2402] Data 0.003 (0.005) Batch 0.462 (0.479) Remain 31:07:09 loss: 1.2773 Lr: 0.00121
[2025-04-08 14:45:17,150 INFO misc.py line 113 3298914] Train: [3/100][1685/2402] Data 0.003 (0.005) Batch 0.497 (0.479) Remain 31:07:11 loss: 1.1263 Lr: 0.00121
[2025-04-08 14:45:17,544 INFO misc.py line 113 3298914] Train: [3/100][1686/2402] Data 0.004 (0.005) Batch 0.393 (0.479) Remain 31:06:59 loss: 1.4507 Lr: 0.00121
[2025-04-08 14:45:18,078 INFO misc.py line 113 3298914] Train: [3/100][1687/2402] Data 0.004 (0.005) Batch 0.534 (0.479) Remain 31:07:06 loss: 1.4789 Lr: 0.00121
[2025-04-08 14:45:18,485 INFO misc.py line 113 3298914] Train: [3/100][1688/2402] Data 0.004 (0.005) Batch 0.407 (0.479) Remain 31:06:56 loss: 1.3852 Lr: 0.00121
[2025-04-08 14:45:18,909 INFO misc.py line 113 3298914] Train: [3/100][1689/2402] Data 0.004 (0.005) Batch 0.424 (0.479) Remain 31:06:47 loss: 1.3011 Lr: 0.00121
[2025-04-08 14:45:19,468 INFO misc.py line 113 3298914] Train: [3/100][1690/2402] Data 0.003 (0.005) Batch 0.559 (0.479) Remain 31:06:58 loss: 1.0229 Lr: 0.00121
[2025-04-08 14:45:19,895 INFO misc.py line 113 3298914] Train: [3/100][1691/2402] Data 0.003 (0.005) Batch 0.427 (0.479) Remain 31:06:50 loss: 1.3974 Lr: 0.00121
[2025-04-08 14:45:20,414 INFO misc.py line 113 3298914] Train: [3/100][1692/2402] Data 0.004 (0.005) Batch 0.519 (0.479) Remain 31:06:55 loss: 1.7209 Lr: 0.00121
[2025-04-08 14:45:20,798 INFO misc.py line 113 3298914] Train: [3/100][1693/2402] Data 0.004 (0.005) Batch 0.384 (0.479) Remain 31:06:42 loss: 1.1949 Lr: 0.00121
[2025-04-08 14:45:21,339 INFO misc.py line 113 3298914] Train: [3/100][1694/2402] Data 0.004 (0.005) Batch 0.542 (0.479) Remain 31:06:50 loss: 0.8814 Lr: 0.00121
[2025-04-08 14:45:21,724 INFO misc.py line 113 3298914] Train: [3/100][1695/2402] Data 0.004 (0.005) Batch 0.385 (0.479) Remain 31:06:36 loss: 1.0678 Lr: 0.00122
[2025-04-08 14:45:22,207 INFO misc.py line 113 3298914] Train: [3/100][1696/2402] Data 0.004 (0.005) Batch 0.483 (0.479) Remain 31:06:36 loss: 0.7136 Lr: 0.00122
[2025-04-08 14:45:22,677 INFO misc.py line 113 3298914] Train: [3/100][1697/2402] Data 0.003 (0.005) Batch 0.470 (0.479) Remain 31:06:34 loss: 1.1304 Lr: 0.00122
[2025-04-08 14:45:23,206 INFO misc.py line 113 3298914] Train: [3/100][1698/2402] Data 0.004 (0.005) Batch 0.529 (0.479) Remain 31:06:41 loss: 1.0235 Lr: 0.00122
[2025-04-08 14:45:23,656 INFO misc.py line 113 3298914] Train: [3/100][1699/2402] Data 0.004 (0.005) Batch 0.449 (0.479) Remain 31:06:36 loss: 0.9687 Lr: 0.00122
[2025-04-08 14:45:24,179 INFO misc.py line 113 3298914] Train: [3/100][1700/2402] Data 0.003 (0.005) Batch 0.523 (0.479) Remain 31:06:42 loss: 0.9874 Lr: 0.00122
[2025-04-08 14:45:24,721 INFO misc.py line 113 3298914] Train: [3/100][1701/2402] Data 0.004 (0.005) Batch 0.542 (0.479) Remain 31:06:50 loss: 1.4517 Lr: 0.00122
[2025-04-08 14:45:25,242 INFO misc.py line 113 3298914] Train: [3/100][1702/2402] Data 0.004 (0.005) Batch 0.521 (0.479) Remain 31:06:55 loss: 1.2650 Lr: 0.00122
[2025-04-08 14:45:25,750 INFO misc.py line 113 3298914] Train: [3/100][1703/2402] Data 0.004 (0.005) Batch 0.508 (0.479) Remain 31:06:59 loss: 1.2854 Lr: 0.00122
[2025-04-08 14:45:26,172 INFO misc.py line 113 3298914] Train: [3/100][1704/2402] Data 0.003 (0.005) Batch 0.423 (0.479) Remain 31:06:50 loss: 1.0445 Lr: 0.00122
[2025-04-08 14:45:26,691 INFO misc.py line 113 3298914] Train: [3/100][1705/2402] Data 0.003 (0.005) Batch 0.519 (0.479) Remain 31:06:55 loss: 0.7697 Lr: 0.00122
[2025-04-08 14:45:27,222 INFO misc.py line 113 3298914] Train: [3/100][1706/2402] Data 0.004 (0.005) Batch 0.531 (0.479) Remain 31:07:02 loss: 1.2253 Lr: 0.00122
[2025-04-08 14:45:27,695 INFO misc.py line 113 3298914] Train: [3/100][1707/2402] Data 0.003 (0.005) Batch 0.473 (0.479) Remain 31:07:01 loss: 1.6534 Lr: 0.00122
[2025-04-08 14:45:28,181 INFO misc.py line 113 3298914] Train: [3/100][1708/2402] Data 0.004 (0.005) Batch 0.486 (0.479) Remain 31:07:01 loss: 1.2764 Lr: 0.00122
[2025-04-08 14:45:28,594 INFO misc.py line 113 3298914] Train: [3/100][1709/2402] Data 0.004 (0.005) Batch 0.413 (0.479) Remain 31:06:52 loss: 1.4378 Lr: 0.00122
[2025-04-08 14:45:28,989 INFO misc.py line 113 3298914] Train: [3/100][1710/2402] Data 0.003 (0.005) Batch 0.395 (0.479) Remain 31:06:40 loss: 1.2502 Lr: 0.00122
[2025-04-08 14:45:29,550 INFO misc.py line 113 3298914] Train: [3/100][1711/2402] Data 0.003 (0.005) Batch 0.560 (0.479) Remain 31:06:50 loss: 2.1123 Lr: 0.00122
[2025-04-08 14:45:29,996 INFO misc.py line 113 3298914] Train: [3/100][1712/2402] Data 0.003 (0.005) Batch 0.446 (0.479) Remain 31:06:45 loss: 1.3785 Lr: 0.00122
[2025-04-08 14:45:30,447 INFO misc.py line 113 3298914] Train: [3/100][1713/2402] Data 0.004 (0.005) Batch 0.451 (0.479) Remain 31:06:41 loss: 1.1565 Lr: 0.00122
[2025-04-08 14:45:30,988 INFO misc.py line 113 3298914] Train: [3/100][1714/2402] Data 0.004 (0.005) Batch 0.542 (0.479) Remain 31:06:49 loss: 1.4147 Lr: 0.00122
[2025-04-08 14:45:31,590 INFO misc.py line 113 3298914] Train: [3/100][1715/2402] Data 0.004 (0.005) Batch 0.602 (0.479) Remain 31:07:05 loss: 1.4213 Lr: 0.00122
[2025-04-08 14:45:32,115 INFO misc.py line 113 3298914] Train: [3/100][1716/2402] Data 0.004 (0.005) Batch 0.525 (0.479) Remain 31:07:11 loss: 1.1400 Lr: 0.00122
[2025-04-08 14:45:32,521 INFO misc.py line 113 3298914] Train: [3/100][1717/2402] Data 0.003 (0.005) Batch 0.405 (0.479) Remain 31:07:00 loss: 1.5056 Lr: 0.00122
[2025-04-08 14:45:32,999 INFO misc.py line 113 3298914] Train: [3/100][1718/2402] Data 0.003 (0.005) Batch 0.478 (0.479) Remain 31:07:00 loss: 1.3058 Lr: 0.00122
[2025-04-08 14:45:33,417 INFO misc.py line 113 3298914] Train: [3/100][1719/2402] Data 0.004 (0.005) Batch 0.418 (0.479) Remain 31:06:51 loss: 1.1704 Lr: 0.00122
[2025-04-08 14:45:33,998 INFO misc.py line 113 3298914] Train: [3/100][1720/2402] Data 0.004 (0.005) Batch 0.582 (0.479) Remain 31:07:04 loss: 1.2386 Lr: 0.00122
[2025-04-08 14:45:34,391 INFO misc.py line 113 3298914] Train: [3/100][1721/2402] Data 0.003 (0.005) Batch 0.392 (0.479) Remain 31:06:52 loss: 0.9581 Lr: 0.00122
[2025-04-08 14:45:34,887 INFO misc.py line 113 3298914] Train: [3/100][1722/2402] Data 0.003 (0.005) Batch 0.496 (0.479) Remain 31:06:54 loss: 1.4378 Lr: 0.00122
[2025-04-08 14:45:35,309 INFO misc.py line 113 3298914] Train: [3/100][1723/2402] Data 0.004 (0.005) Batch 0.422 (0.479) Remain 31:06:45 loss: 1.5100 Lr: 0.00122
[2025-04-08 14:45:35,961 INFO misc.py line 113 3298914] Train: [3/100][1724/2402] Data 0.004 (0.005) Batch 0.653 (0.479) Remain 31:07:08 loss: 1.3354 Lr: 0.00122
[2025-04-08 14:45:36,448 INFO misc.py line 113 3298914] Train: [3/100][1725/2402] Data 0.004 (0.005) Batch 0.487 (0.479) Remain 31:07:09 loss: 0.7489 Lr: 0.00122
[2025-04-08 14:45:36,981 INFO misc.py line 113 3298914] Train: [3/100][1726/2402] Data 0.004 (0.005) Batch 0.533 (0.479) Remain 31:07:16 loss: 1.2900 Lr: 0.00122
[2025-04-08 14:45:37,427 INFO misc.py line 113 3298914] Train: [3/100][1727/2402] Data 0.004 (0.005) Batch 0.446 (0.479) Remain 31:07:11 loss: 1.6639 Lr: 0.00122
[2025-04-08 14:45:37,920 INFO misc.py line 113 3298914] Train: [3/100][1728/2402] Data 0.003 (0.005) Batch 0.494 (0.479) Remain 31:07:12 loss: 1.1179 Lr: 0.00122
[2025-04-08 14:45:38,436 INFO misc.py line 113 3298914] Train: [3/100][1729/2402] Data 0.004 (0.005) Batch 0.516 (0.479) Remain 31:07:17 loss: 1.0985 Lr: 0.00122
[2025-04-08 14:45:39,205 INFO misc.py line 113 3298914] Train: [3/100][1730/2402] Data 0.004 (0.005) Batch 0.769 (0.480) Remain 31:07:55 loss: 0.9061 Lr: 0.00122
[2025-04-08 14:45:39,673 INFO misc.py line 113 3298914] Train: [3/100][1731/2402] Data 0.003 (0.005) Batch 0.467 (0.480) Remain 31:07:53 loss: 1.3789 Lr: 0.00122
[2025-04-08 14:45:40,197 INFO misc.py line 113 3298914] Train: [3/100][1732/2402] Data 0.004 (0.005) Batch 0.524 (0.480) Remain 31:07:59 loss: 0.9070 Lr: 0.00122
[2025-04-08 14:45:40,701 INFO misc.py line 113 3298914] Train: [3/100][1733/2402] Data 0.004 (0.005) Batch 0.504 (0.480) Remain 31:08:01 loss: 1.3334 Lr: 0.00122
[2025-04-08 14:45:41,150 INFO misc.py line 113 3298914] Train: [3/100][1734/2402] Data 0.003 (0.005) Batch 0.449 (0.480) Remain 31:07:57 loss: 1.2350 Lr: 0.00122
[2025-04-08 14:45:41,627 INFO misc.py line 113 3298914] Train: [3/100][1735/2402] Data 0.003 (0.005) Batch 0.477 (0.480) Remain 31:07:56 loss: 1.0146 Lr: 0.00122
[2025-04-08 14:45:42,060 INFO misc.py line 113 3298914] Train: [3/100][1736/2402] Data 0.004 (0.005) Batch 0.433 (0.480) Remain 31:07:49 loss: 1.6051 Lr: 0.00122
[2025-04-08 14:45:42,559 INFO misc.py line 113 3298914] Train: [3/100][1737/2402] Data 0.003 (0.005) Batch 0.499 (0.480) Remain 31:07:51 loss: 0.9442 Lr: 0.00122
[2025-04-08 14:45:43,118 INFO misc.py line 113 3298914] Train: [3/100][1738/2402] Data 0.004 (0.005) Batch 0.559 (0.480) Remain 31:08:02 loss: 1.3348 Lr: 0.00123
[2025-04-08 14:45:43,514 INFO misc.py line 113 3298914] Train: [3/100][1739/2402] Data 0.003 (0.005) Batch 0.396 (0.480) Remain 31:07:50 loss: 1.0502 Lr: 0.00123
[2025-04-08 14:45:44,095 INFO misc.py line 113 3298914] Train: [3/100][1740/2402] Data 0.004 (0.005) Batch 0.581 (0.480) Remain 31:08:03 loss: 1.5774 Lr: 0.00123
[2025-04-08 14:45:44,607 INFO misc.py line 113 3298914] Train: [3/100][1741/2402] Data 0.004 (0.005) Batch 0.512 (0.480) Remain 31:08:07 loss: 1.0440 Lr: 0.00123
[2025-04-08 14:45:45,153 INFO misc.py line 113 3298914] Train: [3/100][1742/2402] Data 0.004 (0.005) Batch 0.547 (0.480) Remain 31:08:15 loss: 1.5096 Lr: 0.00123
[2025-04-08 14:45:45,651 INFO misc.py line 113 3298914] Train: [3/100][1743/2402] Data 0.003 (0.005) Batch 0.498 (0.480) Remain 31:08:17 loss: 1.2616 Lr: 0.00123
[2025-04-08 14:45:46,195 INFO misc.py line 113 3298914] Train: [3/100][1744/2402] Data 0.004 (0.005) Batch 0.544 (0.480) Remain 31:08:25 loss: 1.3001 Lr: 0.00123
[2025-04-08 14:45:46,657 INFO misc.py line 113 3298914] Train: [3/100][1745/2402] Data 0.003 (0.005) Batch 0.462 (0.480) Remain 31:08:22 loss: 0.8277 Lr: 0.00123
[2025-04-08 14:45:47,137 INFO misc.py line 113 3298914] Train: [3/100][1746/2402] Data 0.004 (0.005) Batch 0.481 (0.480) Remain 31:08:22 loss: 1.5157 Lr: 0.00123
[2025-04-08 14:45:47,616 INFO misc.py line 113 3298914] Train: [3/100][1747/2402] Data 0.003 (0.005) Batch 0.478 (0.480) Remain 31:08:21 loss: 1.7573 Lr: 0.00123
[2025-04-08 14:45:48,107 INFO misc.py line 113 3298914] Train: [3/100][1748/2402] Data 0.003 (0.005) Batch 0.491 (0.480) Remain 31:08:23 loss: 1.1846 Lr: 0.00123
[2025-04-08 14:45:48,585 INFO misc.py line 113 3298914] Train: [3/100][1749/2402] Data 0.003 (0.005) Batch 0.478 (0.480) Remain 31:08:22 loss: 1.5178 Lr: 0.00123
[2025-04-08 14:45:49,020 INFO misc.py line 113 3298914] Train: [3/100][1750/2402] Data 0.003 (0.005) Batch 0.435 (0.480) Remain 31:08:15 loss: 0.8814 Lr: 0.00123
[2025-04-08 14:45:49,557 INFO misc.py line 113 3298914] Train: [3/100][1751/2402] Data 0.004 (0.005) Batch 0.537 (0.480) Remain 31:08:22 loss: 1.0536 Lr: 0.00123
[2025-04-08 14:45:50,071 INFO misc.py line 113 3298914] Train: [3/100][1752/2402] Data 0.004 (0.005) Batch 0.514 (0.480) Remain 31:08:27 loss: 1.1179 Lr: 0.00123
[2025-04-08 14:45:50,651 INFO misc.py line 113 3298914] Train: [3/100][1753/2402] Data 0.003 (0.005) Batch 0.579 (0.480) Remain 31:08:39 loss: 1.5446 Lr: 0.00123
[2025-04-08 14:45:51,202 INFO misc.py line 113 3298914] Train: [3/100][1754/2402] Data 0.004 (0.005) Batch 0.551 (0.480) Remain 31:08:48 loss: 1.1016 Lr: 0.00123
[2025-04-08 14:45:51,587 INFO misc.py line 113 3298914] Train: [3/100][1755/2402] Data 0.004 (0.005) Batch 0.385 (0.480) Remain 31:08:35 loss: 1.4991 Lr: 0.00123
[2025-04-08 14:45:52,127 INFO misc.py line 113 3298914] Train: [3/100][1756/2402] Data 0.004 (0.005) Batch 0.540 (0.480) Remain 31:08:43 loss: 0.8233 Lr: 0.00123
[2025-04-08 14:45:52,669 INFO misc.py line 113 3298914] Train: [3/100][1757/2402] Data 0.003 (0.005) Batch 0.542 (0.480) Remain 31:08:51 loss: 1.2220 Lr: 0.00123
[2025-04-08 14:45:53,101 INFO misc.py line 113 3298914] Train: [3/100][1758/2402] Data 0.003 (0.005) Batch 0.432 (0.480) Remain 31:08:44 loss: 1.3266 Lr: 0.00123
[2025-04-08 14:45:53,623 INFO misc.py line 113 3298914] Train: [3/100][1759/2402] Data 0.004 (0.005) Batch 0.523 (0.480) Remain 31:08:49 loss: 1.2767 Lr: 0.00123
[2025-04-08 14:45:54,106 INFO misc.py line 113 3298914] Train: [3/100][1760/2402] Data 0.003 (0.005) Batch 0.482 (0.480) Remain 31:08:49 loss: 0.9164 Lr: 0.00123
[2025-04-08 14:45:54,657 INFO misc.py line 113 3298914] Train: [3/100][1761/2402] Data 0.004 (0.005) Batch 0.551 (0.480) Remain 31:08:58 loss: 1.2338 Lr: 0.00123
[2025-04-08 14:45:55,158 INFO misc.py line 113 3298914] Train: [3/100][1762/2402] Data 0.004 (0.005) Batch 0.502 (0.480) Remain 31:09:00 loss: 1.1828 Lr: 0.00123
[2025-04-08 14:45:55,642 INFO misc.py line 113 3298914] Train: [3/100][1763/2402] Data 0.004 (0.005) Batch 0.484 (0.480) Remain 31:09:00 loss: 0.9965 Lr: 0.00123
[2025-04-08 14:45:56,142 INFO misc.py line 113 3298914] Train: [3/100][1764/2402] Data 0.004 (0.005) Batch 0.500 (0.480) Remain 31:09:02 loss: 1.1849 Lr: 0.00123
[2025-04-08 14:45:56,543 INFO misc.py line 113 3298914] Train: [3/100][1765/2402] Data 0.003 (0.005) Batch 0.401 (0.480) Remain 31:08:51 loss: 1.1226 Lr: 0.00123
[2025-04-08 14:45:57,055 INFO misc.py line 113 3298914] Train: [3/100][1766/2402] Data 0.003 (0.005) Batch 0.511 (0.480) Remain 31:08:55 loss: 0.9176 Lr: 0.00123
[2025-04-08 14:45:57,581 INFO misc.py line 113 3298914] Train: [3/100][1767/2402] Data 0.004 (0.005) Batch 0.527 (0.480) Remain 31:09:01 loss: 1.1911 Lr: 0.00123
[2025-04-08 14:45:58,105 INFO misc.py line 113 3298914] Train: [3/100][1768/2402] Data 0.004 (0.005) Batch 0.523 (0.480) Remain 31:09:06 loss: 1.1579 Lr: 0.00123
[2025-04-08 14:45:58,614 INFO misc.py line 113 3298914] Train: [3/100][1769/2402] Data 0.004 (0.005) Batch 0.509 (0.480) Remain 31:09:09 loss: 1.3054 Lr: 0.00123
[2025-04-08 14:45:59,070 INFO misc.py line 113 3298914] Train: [3/100][1770/2402] Data 0.003 (0.005) Batch 0.456 (0.480) Remain 31:09:06 loss: 1.1595 Lr: 0.00123
[2025-04-08 14:45:59,595 INFO misc.py line 113 3298914] Train: [3/100][1771/2402] Data 0.003 (0.005) Batch 0.526 (0.480) Remain 31:09:11 loss: 1.4259 Lr: 0.00123
[2025-04-08 14:46:00,018 INFO misc.py line 113 3298914] Train: [3/100][1772/2402] Data 0.004 (0.005) Batch 0.422 (0.480) Remain 31:09:03 loss: 1.3312 Lr: 0.00123
[2025-04-08 14:46:00,506 INFO misc.py line 113 3298914] Train: [3/100][1773/2402] Data 0.004 (0.005) Batch 0.489 (0.480) Remain 31:09:04 loss: 0.8358 Lr: 0.00123
[2025-04-08 14:46:01,036 INFO misc.py line 113 3298914] Train: [3/100][1774/2402] Data 0.004 (0.005) Batch 0.530 (0.480) Remain 31:09:10 loss: 1.1091 Lr: 0.00123
[2025-04-08 14:46:01,608 INFO misc.py line 113 3298914] Train: [3/100][1775/2402] Data 0.003 (0.005) Batch 0.572 (0.480) Remain 31:09:22 loss: 1.5437 Lr: 0.00123
[2025-04-08 14:46:01,986 INFO misc.py line 113 3298914] Train: [3/100][1776/2402] Data 0.004 (0.005) Batch 0.378 (0.480) Remain 31:09:08 loss: 0.7991 Lr: 0.00123
[2025-04-08 14:46:02,404 INFO misc.py line 113 3298914] Train: [3/100][1777/2402] Data 0.004 (0.005) Batch 0.417 (0.480) Remain 31:08:59 loss: 0.9724 Lr: 0.00123
[2025-04-08 14:46:02,754 INFO misc.py line 113 3298914] Train: [3/100][1778/2402] Data 0.003 (0.005) Batch 0.350 (0.480) Remain 31:08:41 loss: 1.1749 Lr: 0.00123
[2025-04-08 14:46:03,101 INFO misc.py line 113 3298914] Train: [3/100][1779/2402] Data 0.004 (0.005) Batch 0.347 (0.480) Remain 31:08:23 loss: 0.8987 Lr: 0.00123
[2025-04-08 14:46:03,547 INFO misc.py line 113 3298914] Train: [3/100][1780/2402] Data 0.003 (0.005) Batch 0.446 (0.480) Remain 31:08:19 loss: 1.0672 Lr: 0.00123
[2025-04-08 14:46:04,092 INFO misc.py line 113 3298914] Train: [3/100][1781/2402] Data 0.003 (0.005) Batch 0.545 (0.480) Remain 31:08:27 loss: 1.0396 Lr: 0.00124
[2025-04-08 14:46:04,644 INFO misc.py line 113 3298914] Train: [3/100][1782/2402] Data 0.004 (0.005) Batch 0.553 (0.480) Remain 31:08:36 loss: 0.9828 Lr: 0.00124
[2025-04-08 14:46:05,034 INFO misc.py line 113 3298914] Train: [3/100][1783/2402] Data 0.003 (0.005) Batch 0.389 (0.480) Remain 31:08:23 loss: 0.7212 Lr: 0.00124
[2025-04-08 14:46:05,658 INFO misc.py line 113 3298914] Train: [3/100][1784/2402] Data 0.003 (0.005) Batch 0.624 (0.480) Remain 31:08:42 loss: 1.4163 Lr: 0.00124
[2025-04-08 14:46:06,090 INFO misc.py line 113 3298914] Train: [3/100][1785/2402] Data 0.004 (0.005) Batch 0.432 (0.480) Remain 31:08:35 loss: 0.8721 Lr: 0.00124
[2025-04-08 14:46:06,480 INFO misc.py line 113 3298914] Train: [3/100][1786/2402] Data 0.003 (0.005) Batch 0.390 (0.480) Remain 31:08:23 loss: 0.8889 Lr: 0.00124
[2025-04-08 14:46:07,010 INFO misc.py line 113 3298914] Train: [3/100][1787/2402] Data 0.004 (0.005) Batch 0.530 (0.480) Remain 31:08:29 loss: 1.2747 Lr: 0.00124
[2025-04-08 14:46:07,587 INFO misc.py line 113 3298914] Train: [3/100][1788/2402] Data 0.004 (0.005) Batch 0.577 (0.480) Remain 31:08:41 loss: 1.3576 Lr: 0.00124
[2025-04-08 14:46:07,961 INFO misc.py line 113 3298914] Train: [3/100][1789/2402] Data 0.004 (0.005) Batch 0.374 (0.480) Remain 31:08:27 loss: 0.7276 Lr: 0.00124
[2025-04-08 14:46:08,439 INFO misc.py line 113 3298914] Train: [3/100][1790/2402] Data 0.004 (0.005) Batch 0.479 (0.480) Remain 31:08:26 loss: 1.5097 Lr: 0.00124
[2025-04-08 14:46:08,884 INFO misc.py line 113 3298914] Train: [3/100][1791/2402] Data 0.004 (0.005) Batch 0.445 (0.480) Remain 31:08:21 loss: 0.8023 Lr: 0.00124
[2025-04-08 14:46:09,421 INFO misc.py line 113 3298914] Train: [3/100][1792/2402] Data 0.003 (0.005) Batch 0.536 (0.480) Remain 31:08:28 loss: 1.0826 Lr: 0.00124
[2025-04-08 14:46:09,892 INFO misc.py line 113 3298914] Train: [3/100][1793/2402] Data 0.003 (0.005) Batch 0.472 (0.480) Remain 31:08:26 loss: 1.3911 Lr: 0.00124
[2025-04-08 14:46:10,287 INFO misc.py line 113 3298914] Train: [3/100][1794/2402] Data 0.003 (0.005) Batch 0.395 (0.480) Remain 31:08:15 loss: 0.8786 Lr: 0.00124
[2025-04-08 14:46:10,729 INFO misc.py line 113 3298914] Train: [3/100][1795/2402] Data 0.003 (0.005) Batch 0.442 (0.480) Remain 31:08:09 loss: 1.0594 Lr: 0.00124
[2025-04-08 14:46:11,207 INFO misc.py line 113 3298914] Train: [3/100][1796/2402] Data 0.003 (0.005) Batch 0.478 (0.480) Remain 31:08:09 loss: 1.3175 Lr: 0.00124
[2025-04-08 14:46:11,708 INFO misc.py line 113 3298914] Train: [3/100][1797/2402] Data 0.003 (0.005) Batch 0.501 (0.480) Remain 31:08:11 loss: 1.2580 Lr: 0.00124
[2025-04-08 14:46:12,282 INFO misc.py line 113 3298914] Train: [3/100][1798/2402] Data 0.003 (0.005) Batch 0.574 (0.480) Remain 31:08:23 loss: 1.1062 Lr: 0.00124
[2025-04-08 14:46:12,775 INFO misc.py line 113 3298914] Train: [3/100][1799/2402] Data 0.003 (0.005) Batch 0.492 (0.480) Remain 31:08:24 loss: 1.0067 Lr: 0.00124
[2025-04-08 14:46:13,354 INFO misc.py line 113 3298914] Train: [3/100][1800/2402] Data 0.004 (0.005) Batch 0.579 (0.480) Remain 31:08:36 loss: 1.3917 Lr: 0.00124
[2025-04-08 14:46:13,952 INFO misc.py line 113 3298914] Train: [3/100][1801/2402] Data 0.004 (0.005) Batch 0.598 (0.480) Remain 31:08:51 loss: 1.3750 Lr: 0.00124
[2025-04-08 14:46:14,443 INFO misc.py line 113 3298914] Train: [3/100][1802/2402] Data 0.003 (0.005) Batch 0.492 (0.480) Remain 31:08:52 loss: 1.2010 Lr: 0.00124
[2025-04-08 14:46:14,957 INFO misc.py line 113 3298914] Train: [3/100][1803/2402] Data 0.004 (0.005) Batch 0.514 (0.480) Remain 31:08:56 loss: 1.0718 Lr: 0.00124
[2025-04-08 14:46:15,451 INFO misc.py line 113 3298914] Train: [3/100][1804/2402] Data 0.004 (0.005) Batch 0.494 (0.480) Remain 31:08:57 loss: 1.2423 Lr: 0.00124
[2025-04-08 14:46:15,940 INFO misc.py line 113 3298914] Train: [3/100][1805/2402] Data 0.003 (0.005) Batch 0.490 (0.480) Remain 31:08:58 loss: 0.9510 Lr: 0.00124
[2025-04-08 14:46:16,455 INFO misc.py line 113 3298914] Train: [3/100][1806/2402] Data 0.004 (0.005) Batch 0.515 (0.480) Remain 31:09:02 loss: 0.7330 Lr: 0.00124
[2025-04-08 14:46:16,856 INFO misc.py line 113 3298914] Train: [3/100][1807/2402] Data 0.003 (0.005) Batch 0.400 (0.480) Remain 31:08:51 loss: 1.2018 Lr: 0.00124
[2025-04-08 14:46:17,322 INFO misc.py line 113 3298914] Train: [3/100][1808/2402] Data 0.004 (0.005) Batch 0.467 (0.480) Remain 31:08:49 loss: 1.2830 Lr: 0.00124
[2025-04-08 14:46:17,832 INFO misc.py line 113 3298914] Train: [3/100][1809/2402] Data 0.004 (0.005) Batch 0.510 (0.480) Remain 31:08:52 loss: 1.4701 Lr: 0.00124
[2025-04-08 14:46:18,309 INFO misc.py line 113 3298914] Train: [3/100][1810/2402] Data 0.004 (0.005) Batch 0.477 (0.480) Remain 31:08:51 loss: 1.1144 Lr: 0.00124
[2025-04-08 14:46:18,844 INFO misc.py line 113 3298914] Train: [3/100][1811/2402] Data 0.003 (0.005) Batch 0.535 (0.480) Remain 31:08:58 loss: 1.1624 Lr: 0.00124
[2025-04-08 14:46:19,294 INFO misc.py line 113 3298914] Train: [3/100][1812/2402] Data 0.004 (0.005) Batch 0.451 (0.480) Remain 31:08:54 loss: 1.5971 Lr: 0.00124
[2025-04-08 14:46:19,716 INFO misc.py line 113 3298914] Train: [3/100][1813/2402] Data 0.004 (0.005) Batch 0.422 (0.480) Remain 31:08:46 loss: 1.0695 Lr: 0.00124
[2025-04-08 14:46:20,118 INFO misc.py line 113 3298914] Train: [3/100][1814/2402] Data 0.003 (0.005) Batch 0.402 (0.480) Remain 31:08:35 loss: 1.1201 Lr: 0.00124
[2025-04-08 14:46:20,612 INFO misc.py line 113 3298914] Train: [3/100][1815/2402] Data 0.003 (0.005) Batch 0.494 (0.480) Remain 31:08:37 loss: 1.0558 Lr: 0.00124
[2025-04-08 14:46:21,068 INFO misc.py line 113 3298914] Train: [3/100][1816/2402] Data 0.003 (0.005) Batch 0.456 (0.480) Remain 31:08:33 loss: 1.6185 Lr: 0.00124
[2025-04-08 14:46:21,632 INFO misc.py line 113 3298914] Train: [3/100][1817/2402] Data 0.004 (0.005) Batch 0.564 (0.480) Remain 31:08:43 loss: 0.9488 Lr: 0.00124
[2025-04-08 14:46:22,052 INFO misc.py line 113 3298914] Train: [3/100][1818/2402] Data 0.003 (0.005) Batch 0.420 (0.480) Remain 31:08:35 loss: 1.2709 Lr: 0.00124
[2025-04-08 14:46:22,486 INFO misc.py line 113 3298914] Train: [3/100][1819/2402] Data 0.003 (0.005) Batch 0.434 (0.480) Remain 31:08:29 loss: 1.0253 Lr: 0.00124
[2025-04-08 14:46:22,928 INFO misc.py line 113 3298914] Train: [3/100][1820/2402] Data 0.004 (0.005) Batch 0.442 (0.480) Remain 31:08:23 loss: 1.2723 Lr: 0.00124
[2025-04-08 14:46:23,429 INFO misc.py line 113 3298914] Train: [3/100][1821/2402] Data 0.004 (0.005) Batch 0.502 (0.480) Remain 31:08:26 loss: 1.4693 Lr: 0.00124
[2025-04-08 14:46:23,780 INFO misc.py line 113 3298914] Train: [3/100][1822/2402] Data 0.003 (0.005) Batch 0.351 (0.480) Remain 31:08:09 loss: 0.7232 Lr: 0.00124
[2025-04-08 14:46:24,270 INFO misc.py line 113 3298914] Train: [3/100][1823/2402] Data 0.004 (0.005) Batch 0.490 (0.480) Remain 31:08:09 loss: 1.0616 Lr: 0.00124
[2025-04-08 14:46:24,824 INFO misc.py line 113 3298914] Train: [3/100][1824/2402] Data 0.003 (0.005) Batch 0.554 (0.480) Remain 31:08:18 loss: 0.9646 Lr: 0.00125
[2025-04-08 14:46:25,210 INFO misc.py line 113 3298914] Train: [3/100][1825/2402] Data 0.004 (0.005) Batch 0.386 (0.480) Remain 31:08:06 loss: 1.1199 Lr: 0.00125
[2025-04-08 14:46:25,663 INFO misc.py line 113 3298914] Train: [3/100][1826/2402] Data 0.003 (0.005) Batch 0.453 (0.480) Remain 31:08:02 loss: 1.1675 Lr: 0.00125
[2025-04-08 14:46:26,124 INFO misc.py line 113 3298914] Train: [3/100][1827/2402] Data 0.003 (0.005) Batch 0.461 (0.480) Remain 31:07:59 loss: 0.8010 Lr: 0.00125
[2025-04-08 14:46:26,491 INFO misc.py line 113 3298914] Train: [3/100][1828/2402] Data 0.004 (0.005) Batch 0.367 (0.480) Remain 31:07:44 loss: 1.0593 Lr: 0.00125
[2025-04-08 14:46:26,935 INFO misc.py line 113 3298914] Train: [3/100][1829/2402] Data 0.004 (0.005) Batch 0.444 (0.480) Remain 31:07:39 loss: 1.1156 Lr: 0.00125
[2025-04-08 14:46:27,437 INFO misc.py line 113 3298914] Train: [3/100][1830/2402] Data 0.004 (0.005) Batch 0.502 (0.480) Remain 31:07:41 loss: 0.7810 Lr: 0.00125
[2025-04-08 14:46:27,961 INFO misc.py line 113 3298914] Train: [3/100][1831/2402] Data 0.003 (0.005) Batch 0.524 (0.480) Remain 31:07:47 loss: 1.1277 Lr: 0.00125
[2025-04-08 14:46:28,448 INFO misc.py line 113 3298914] Train: [3/100][1832/2402] Data 0.003 (0.005) Batch 0.487 (0.480) Remain 31:07:47 loss: 0.8335 Lr: 0.00125
[2025-04-08 14:46:28,912 INFO misc.py line 113 3298914] Train: [3/100][1833/2402] Data 0.004 (0.005) Batch 0.463 (0.480) Remain 31:07:44 loss: 1.0632 Lr: 0.00125
[2025-04-08 14:46:29,387 INFO misc.py line 113 3298914] Train: [3/100][1834/2402] Data 0.004 (0.005) Batch 0.476 (0.480) Remain 31:07:43 loss: 1.3045 Lr: 0.00125
[2025-04-08 14:46:29,795 INFO misc.py line 113 3298914] Train: [3/100][1835/2402] Data 0.004 (0.005) Batch 0.408 (0.480) Remain 31:07:34 loss: 1.2603 Lr: 0.00125
[2025-04-08 14:46:30,220 INFO misc.py line 113 3298914] Train: [3/100][1836/2402] Data 0.003 (0.005) Batch 0.425 (0.480) Remain 31:07:26 loss: 1.5160 Lr: 0.00125
[2025-04-08 14:46:30,666 INFO misc.py line 113 3298914] Train: [3/100][1837/2402] Data 0.003 (0.005) Batch 0.445 (0.480) Remain 31:07:22 loss: 1.0400 Lr: 0.00125
[2025-04-08 14:46:31,172 INFO misc.py line 113 3298914] Train: [3/100][1838/2402] Data 0.004 (0.005) Batch 0.506 (0.480) Remain 31:07:24 loss: 1.2129 Lr: 0.00125
[2025-04-08 14:46:31,695 INFO misc.py line 113 3298914] Train: [3/100][1839/2402] Data 0.004 (0.005) Batch 0.523 (0.480) Remain 31:07:29 loss: 1.3253 Lr: 0.00125
[2025-04-08 14:46:32,093 INFO misc.py line 113 3298914] Train: [3/100][1840/2402] Data 0.004 (0.005) Batch 0.398 (0.480) Remain 31:07:19 loss: 1.3166 Lr: 0.00125
[2025-04-08 14:46:32,559 INFO misc.py line 113 3298914] Train: [3/100][1841/2402] Data 0.003 (0.005) Batch 0.466 (0.480) Remain 31:07:16 loss: 1.1626 Lr: 0.00125
[2025-04-08 14:46:33,094 INFO misc.py line 113 3298914] Train: [3/100][1842/2402] Data 0.003 (0.005) Batch 0.535 (0.480) Remain 31:07:23 loss: 1.2330 Lr: 0.00125
[2025-04-08 14:46:33,606 INFO misc.py line 113 3298914] Train: [3/100][1843/2402] Data 0.004 (0.005) Batch 0.512 (0.480) Remain 31:07:26 loss: 1.4587 Lr: 0.00125
[2025-04-08 14:46:33,995 INFO misc.py line 113 3298914] Train: [3/100][1844/2402] Data 0.004 (0.005) Batch 0.390 (0.480) Remain 31:07:15 loss: 1.0002 Lr: 0.00125
[2025-04-08 14:46:34,433 INFO misc.py line 113 3298914] Train: [3/100][1845/2402] Data 0.003 (0.005) Batch 0.438 (0.480) Remain 31:07:09 loss: 1.0119 Lr: 0.00125
[2025-04-08 14:46:34,957 INFO misc.py line 113 3298914] Train: [3/100][1846/2402] Data 0.003 (0.005) Batch 0.524 (0.480) Remain 31:07:14 loss: 0.7949 Lr: 0.00125
[2025-04-08 14:46:35,429 INFO misc.py line 113 3298914] Train: [3/100][1847/2402] Data 0.004 (0.005) Batch 0.472 (0.480) Remain 31:07:12 loss: 1.3418 Lr: 0.00125
[2025-04-08 14:46:35,871 INFO misc.py line 113 3298914] Train: [3/100][1848/2402] Data 0.003 (0.005) Batch 0.441 (0.480) Remain 31:07:07 loss: 0.9147 Lr: 0.00125
[2025-04-08 14:46:36,362 INFO misc.py line 113 3298914] Train: [3/100][1849/2402] Data 0.003 (0.005) Batch 0.491 (0.480) Remain 31:07:08 loss: 1.2836 Lr: 0.00125
[2025-04-08 14:46:36,901 INFO misc.py line 113 3298914] Train: [3/100][1850/2402] Data 0.004 (0.005) Batch 0.539 (0.480) Remain 31:07:15 loss: 1.2905 Lr: 0.00125
[2025-04-08 14:46:37,394 INFO misc.py line 113 3298914] Train: [3/100][1851/2402] Data 0.004 (0.005) Batch 0.493 (0.480) Remain 31:07:16 loss: 1.0607 Lr: 0.00125
[2025-04-08 14:46:37,957 INFO misc.py line 113 3298914] Train: [3/100][1852/2402] Data 0.004 (0.005) Batch 0.563 (0.480) Remain 31:07:26 loss: 1.1731 Lr: 0.00125
[2025-04-08 14:46:38,523 INFO misc.py line 113 3298914] Train: [3/100][1853/2402] Data 0.003 (0.005) Batch 0.566 (0.480) Remain 31:07:37 loss: 0.7082 Lr: 0.00125
[2025-04-08 14:46:39,056 INFO misc.py line 113 3298914] Train: [3/100][1854/2402] Data 0.004 (0.005) Batch 0.533 (0.480) Remain 31:07:43 loss: 1.3414 Lr: 0.00125
[2025-04-08 14:46:39,517 INFO misc.py line 113 3298914] Train: [3/100][1855/2402] Data 0.004 (0.005) Batch 0.461 (0.480) Remain 31:07:40 loss: 1.6215 Lr: 0.00125
[2025-04-08 14:46:40,011 INFO misc.py line 113 3298914] Train: [3/100][1856/2402] Data 0.003 (0.005) Batch 0.495 (0.480) Remain 31:07:42 loss: 1.1743 Lr: 0.00125
[2025-04-08 14:46:40,421 INFO misc.py line 113 3298914] Train: [3/100][1857/2402] Data 0.004 (0.005) Batch 0.410 (0.480) Remain 31:07:32 loss: 1.1340 Lr: 0.00125
[2025-04-08 14:46:40,871 INFO misc.py line 113 3298914] Train: [3/100][1858/2402] Data 0.003 (0.005) Batch 0.450 (0.480) Remain 31:07:28 loss: 1.1018 Lr: 0.00125
[2025-04-08 14:46:41,410 INFO misc.py line 113 3298914] Train: [3/100][1859/2402] Data 0.004 (0.005) Batch 0.539 (0.480) Remain 31:07:35 loss: 1.2673 Lr: 0.00125
[2025-04-08 14:46:41,863 INFO misc.py line 113 3298914] Train: [3/100][1860/2402] Data 0.004 (0.005) Batch 0.452 (0.480) Remain 31:07:31 loss: 1.3495 Lr: 0.00125
[2025-04-08 14:46:42,333 INFO misc.py line 113 3298914] Train: [3/100][1861/2402] Data 0.004 (0.005) Batch 0.470 (0.480) Remain 31:07:29 loss: 2.1874 Lr: 0.00125
[2025-04-08 14:46:42,791 INFO misc.py line 113 3298914] Train: [3/100][1862/2402] Data 0.004 (0.005) Batch 0.459 (0.480) Remain 31:07:26 loss: 1.5383 Lr: 0.00125
[2025-04-08 14:46:43,197 INFO misc.py line 113 3298914] Train: [3/100][1863/2402] Data 0.004 (0.005) Batch 0.405 (0.480) Remain 31:07:16 loss: 1.2210 Lr: 0.00125
[2025-04-08 14:46:43,585 INFO misc.py line 113 3298914] Train: [3/100][1864/2402] Data 0.003 (0.005) Batch 0.388 (0.480) Remain 31:07:04 loss: 1.0666 Lr: 0.00125
[2025-04-08 14:46:44,090 INFO misc.py line 113 3298914] Train: [3/100][1865/2402] Data 0.003 (0.005) Batch 0.505 (0.480) Remain 31:07:07 loss: 1.1285 Lr: 0.00125
[2025-04-08 14:46:44,507 INFO misc.py line 113 3298914] Train: [3/100][1866/2402] Data 0.004 (0.005) Batch 0.418 (0.480) Remain 31:06:59 loss: 1.3318 Lr: 0.00125
[2025-04-08 14:46:44,952 INFO misc.py line 113 3298914] Train: [3/100][1867/2402] Data 0.003 (0.005) Batch 0.444 (0.480) Remain 31:06:54 loss: 1.4111 Lr: 0.00126
[2025-04-08 14:46:45,435 INFO misc.py line 113 3298914] Train: [3/100][1868/2402] Data 0.003 (0.005) Batch 0.483 (0.480) Remain 31:06:54 loss: 1.4347 Lr: 0.00126
[2025-04-08 14:46:45,963 INFO misc.py line 113 3298914] Train: [3/100][1869/2402] Data 0.004 (0.005) Batch 0.528 (0.480) Remain 31:06:59 loss: 1.0806 Lr: 0.00126
[2025-04-08 14:46:46,308 INFO misc.py line 113 3298914] Train: [3/100][1870/2402] Data 0.004 (0.005) Batch 0.345 (0.480) Remain 31:06:42 loss: 1.2115 Lr: 0.00126
[2025-04-08 14:46:46,775 INFO misc.py line 113 3298914] Train: [3/100][1871/2402] Data 0.003 (0.005) Batch 0.467 (0.480) Remain 31:06:40 loss: 1.2311 Lr: 0.00126
[2025-04-08 14:46:47,331 INFO misc.py line 113 3298914] Train: [3/100][1872/2402] Data 0.004 (0.005) Batch 0.556 (0.480) Remain 31:06:49 loss: 1.0785 Lr: 0.00126
[2025-04-08 14:46:47,791 INFO misc.py line 113 3298914] Train: [3/100][1873/2402] Data 0.003 (0.005) Batch 0.459 (0.480) Remain 31:06:46 loss: 1.0134 Lr: 0.00126
[2025-04-08 14:46:48,193 INFO misc.py line 113 3298914] Train: [3/100][1874/2402] Data 0.004 (0.005) Batch 0.402 (0.480) Remain 31:06:36 loss: 0.8808 Lr: 0.00126
[2025-04-08 14:46:48,735 INFO misc.py line 113 3298914] Train: [3/100][1875/2402] Data 0.003 (0.005) Batch 0.543 (0.480) Remain 31:06:43 loss: 1.1273 Lr: 0.00126
[2025-04-08 14:46:49,221 INFO misc.py line 113 3298914] Train: [3/100][1876/2402] Data 0.004 (0.005) Batch 0.486 (0.480) Remain 31:06:44 loss: 0.7669 Lr: 0.00126
[2025-04-08 14:46:49,690 INFO misc.py line 113 3298914] Train: [3/100][1877/2402] Data 0.004 (0.005) Batch 0.469 (0.480) Remain 31:06:42 loss: 0.8588 Lr: 0.00126
[2025-04-08 14:46:50,285 INFO misc.py line 113 3298914] Train: [3/100][1878/2402] Data 0.003 (0.005) Batch 0.594 (0.480) Remain 31:06:56 loss: 1.5385 Lr: 0.00126
[2025-04-08 14:46:50,691 INFO misc.py line 113 3298914] Train: [3/100][1879/2402] Data 0.004 (0.005) Batch 0.407 (0.480) Remain 31:06:46 loss: 1.3461 Lr: 0.00126
[2025-04-08 14:46:51,197 INFO misc.py line 113 3298914] Train: [3/100][1880/2402] Data 0.003 (0.005) Batch 0.506 (0.480) Remain 31:06:49 loss: 1.2070 Lr: 0.00126
[2025-04-08 14:46:51,629 INFO misc.py line 113 3298914] Train: [3/100][1881/2402] Data 0.004 (0.005) Batch 0.432 (0.480) Remain 31:06:43 loss: 1.3588 Lr: 0.00126
[2025-04-08 14:46:52,151 INFO misc.py line 113 3298914] Train: [3/100][1882/2402] Data 0.004 (0.005) Batch 0.522 (0.480) Remain 31:06:47 loss: 0.9220 Lr: 0.00126
[2025-04-08 14:46:52,628 INFO misc.py line 113 3298914] Train: [3/100][1883/2402] Data 0.004 (0.005) Batch 0.476 (0.480) Remain 31:06:46 loss: 1.1698 Lr: 0.00126
[2025-04-08 14:46:53,041 INFO misc.py line 113 3298914] Train: [3/100][1884/2402] Data 0.004 (0.005) Batch 0.413 (0.480) Remain 31:06:38 loss: 0.9298 Lr: 0.00126
[2025-04-08 14:46:53,555 INFO misc.py line 113 3298914] Train: [3/100][1885/2402] Data 0.004 (0.005) Batch 0.514 (0.480) Remain 31:06:41 loss: 1.2555 Lr: 0.00126
[2025-04-08 14:46:53,968 INFO misc.py line 113 3298914] Train: [3/100][1886/2402] Data 0.004 (0.005) Batch 0.413 (0.480) Remain 31:06:33 loss: 0.9240 Lr: 0.00126
[2025-04-08 14:46:54,511 INFO misc.py line 113 3298914] Train: [3/100][1887/2402] Data 0.003 (0.005) Batch 0.543 (0.480) Remain 31:06:40 loss: 1.1956 Lr: 0.00126
[2025-04-08 14:46:54,986 INFO misc.py line 113 3298914] Train: [3/100][1888/2402] Data 0.004 (0.005) Batch 0.475 (0.480) Remain 31:06:39 loss: 1.4446 Lr: 0.00126
[2025-04-08 14:46:55,512 INFO misc.py line 113 3298914] Train: [3/100][1889/2402] Data 0.004 (0.005) Batch 0.526 (0.480) Remain 31:06:44 loss: 0.9835 Lr: 0.00126
[2025-04-08 14:46:55,677 ERROR events.py line 611 3298914] Traceback (most recent call last):
  File "/zhome/c9/c/156514/Pointcept/pointcept/engines/train.py", line 173, in train
    self.run_step()
  File "/zhome/c9/c/156514/Pointcept/pointcept/engines/train.py", line 196, in run_step
    output_dict = self.model(input_dict)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/default.py", line 63, in forward
    point = self.backbone(point)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/point_transformer_v3/point_transformer_v3m2_sonata.py", line 728, in forward
    point = self.enc(point)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/modules.py", line 82, in forward
    input = module(input)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/modules.py", line 82, in forward
    input = module(input)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/point_transformer_v3/point_transformer_v3m2_sonata.py", line 460, in forward
    point.serialization(order=order, shuffle_orders=self.shuffle_orders)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/utils/structure.py", line 89, in serialization
    code = [
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/utils/structure.py", line 90, in <listcomp>
    encode(self.grid_coord, self.batch, depth, order=order_) for order_ in order
  File "/zhome/c9/c/156514/sonata/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/utils/serialization/default.py", line 18, in encode
    code = hilbert_encode(grid_coord[:, [1, 0, 2]], depth=depth)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/utils/serialization/default.py", line 55, in hilbert_encode
    return hilbert_encode_(grid_coord, num_dims=3, num_bits=depth)
  File "/zhome/c9/c/156514/Pointcept/pointcept/models/utils/serialization/hilbert.py", line 169, in encode
    torch.logical_not(mask[:, None]).repeat(1, gray.shape[2] - bit - 1),
KeyboardInterrupt

